{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8e8a714-9575-4f64-b2cf-3d02fe7195cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71ee2749-955d-4989-aacd-c7468717c307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>35000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>B</td>\n",
       "      <td>6000</td>\n",
       "      <td>11.49</td>\n",
       "      <td>0.17</td>\n",
       "      <td>N</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>56000</td>\n",
       "      <td>OWN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>C</td>\n",
       "      <td>4000</td>\n",
       "      <td>13.35</td>\n",
       "      <td>0.07</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>28800</td>\n",
       "      <td>OWN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>PERSONAL</td>\n",
       "      <td>A</td>\n",
       "      <td>6000</td>\n",
       "      <td>8.90</td>\n",
       "      <td>0.21</td>\n",
       "      <td>N</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>70000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>14.0</td>\n",
       "      <td>VENTURE</td>\n",
       "      <td>B</td>\n",
       "      <td>12000</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.17</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>60000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>A</td>\n",
       "      <td>6000</td>\n",
       "      <td>6.92</td>\n",
       "      <td>0.10</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  person_age  person_income person_home_ownership  person_emp_length  \\\n",
       "0   0          37          35000                  RENT                0.0   \n",
       "1   1          22          56000                   OWN                6.0   \n",
       "2   2          29          28800                   OWN                8.0   \n",
       "3   3          30          70000                  RENT               14.0   \n",
       "4   4          22          60000                  RENT                2.0   \n",
       "\n",
       "  loan_intent loan_grade  loan_amnt  loan_int_rate  loan_percent_income  \\\n",
       "0   EDUCATION          B       6000          11.49                 0.17   \n",
       "1     MEDICAL          C       4000          13.35                 0.07   \n",
       "2    PERSONAL          A       6000           8.90                 0.21   \n",
       "3     VENTURE          B      12000          11.11                 0.17   \n",
       "4     MEDICAL          A       6000           6.92                 0.10   \n",
       "\n",
       "  cb_person_default_on_file  cb_person_cred_hist_length  loan_status  \n",
       "0                         N                          14            0  \n",
       "1                         N                           2            0  \n",
       "2                         N                          10            0  \n",
       "3                         N                           5            0  \n",
       "4                         N                           3            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data: (58645, 13)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"Data/loan data/train.csv\")\n",
    "display(data.head(5))\n",
    "print(\"shape of data: {}\".format(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ce8f380-6444-4b4e-8bca-b65b672eb750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RENT' 'OWN' 'MORTGAGE' 'OTHER']\n",
      "['EDUCATION' 'MEDICAL' 'PERSONAL' 'VENTURE' 'DEBTCONSOLIDATION'\n",
      " 'HOMEIMPROVEMENT']\n",
      "['B' 'C' 'A' 'D' 'E' 'F' 'G']\n",
      "['N' 'Y']\n"
     ]
    }
   ],
   "source": [
    "# check data to see if we have to do imputations\n",
    "print(data['person_home_ownership'].unique())\n",
    "print(data['loan_intent'].unique())\n",
    "print(data['loan_grade'].unique())\n",
    "print(data['cb_person_default_on_file'].unique())\n",
    "\n",
    "categoricalCols = ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file']\n",
    "continuousCols = ['person_age', 'person_income', 'person_emp_length', 'loan_amnt', 'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f60551da-b80a-4e2a-bc37-386280cd8e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(data[continuousCols].corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2145e18-dec9-4ecf-8e6a-592277b9841d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['OTHER', 'RENT', 'MORTGAGE', 'OWN'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, LabelBinarizer, OneHotEncoder\n",
    "homeOwnership = OrdinalEncoder(categories=[['OTHER', 'RENT', 'MORTGAGE','OWN']])\n",
    "data['person_home_ownership'] = homeOwnership.fit_transform(data[['person_home_ownership']])\n",
    "print(homeOwnership.categories_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66fddc4d-4b73-44dc-9969-1ecfe827a5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loan_intent_DEBTCONSOLIDATION</th>\n",
       "      <th>loan_intent_EDUCATION</th>\n",
       "      <th>loan_intent_HOMEIMPROVEMENT</th>\n",
       "      <th>loan_intent_MEDICAL</th>\n",
       "      <th>loan_intent_PERSONAL</th>\n",
       "      <th>loan_intent_VENTURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>35000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B</td>\n",
       "      <td>6000</td>\n",
       "      <td>11.49</td>\n",
       "      <td>0.17</td>\n",
       "      <td>N</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>56000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>C</td>\n",
       "      <td>4000</td>\n",
       "      <td>13.35</td>\n",
       "      <td>0.07</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>28800</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>A</td>\n",
       "      <td>6000</td>\n",
       "      <td>8.90</td>\n",
       "      <td>0.21</td>\n",
       "      <td>N</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>70000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>B</td>\n",
       "      <td>12000</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.17</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>60000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A</td>\n",
       "      <td>6000</td>\n",
       "      <td>6.92</td>\n",
       "      <td>0.10</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58640</th>\n",
       "      <td>58640</td>\n",
       "      <td>34</td>\n",
       "      <td>120000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>D</td>\n",
       "      <td>25000</td>\n",
       "      <td>15.95</td>\n",
       "      <td>0.21</td>\n",
       "      <td>Y</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58641</th>\n",
       "      <td>58641</td>\n",
       "      <td>28</td>\n",
       "      <td>28800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C</td>\n",
       "      <td>10000</td>\n",
       "      <td>12.73</td>\n",
       "      <td>0.35</td>\n",
       "      <td>N</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58642</th>\n",
       "      <td>58642</td>\n",
       "      <td>23</td>\n",
       "      <td>44000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>D</td>\n",
       "      <td>6800</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58643</th>\n",
       "      <td>58643</td>\n",
       "      <td>22</td>\n",
       "      <td>30000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A</td>\n",
       "      <td>5000</td>\n",
       "      <td>8.90</td>\n",
       "      <td>0.17</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58644</th>\n",
       "      <td>58644</td>\n",
       "      <td>31</td>\n",
       "      <td>75000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B</td>\n",
       "      <td>15000</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.20</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58645 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  person_age  person_income  person_home_ownership  \\\n",
       "0          0          37          35000                    1.0   \n",
       "1          1          22          56000                    3.0   \n",
       "2          2          29          28800                    3.0   \n",
       "3          3          30          70000                    1.0   \n",
       "4          4          22          60000                    1.0   \n",
       "...      ...         ...            ...                    ...   \n",
       "58640  58640          34         120000                    2.0   \n",
       "58641  58641          28          28800                    1.0   \n",
       "58642  58642          23          44000                    1.0   \n",
       "58643  58643          22          30000                    1.0   \n",
       "58644  58644          31          75000                    2.0   \n",
       "\n",
       "       person_emp_length loan_grade  loan_amnt  loan_int_rate  \\\n",
       "0                    0.0          B       6000          11.49   \n",
       "1                    6.0          C       4000          13.35   \n",
       "2                    8.0          A       6000           8.90   \n",
       "3                   14.0          B      12000          11.11   \n",
       "4                    2.0          A       6000           6.92   \n",
       "...                  ...        ...        ...            ...   \n",
       "58640                5.0          D      25000          15.95   \n",
       "58641                0.0          C      10000          12.73   \n",
       "58642                7.0          D       6800          16.00   \n",
       "58643                2.0          A       5000           8.90   \n",
       "58644                2.0          B      15000          11.11   \n",
       "\n",
       "       loan_percent_income cb_person_default_on_file  \\\n",
       "0                     0.17                         N   \n",
       "1                     0.07                         N   \n",
       "2                     0.21                         N   \n",
       "3                     0.17                         N   \n",
       "4                     0.10                         N   \n",
       "...                    ...                       ...   \n",
       "58640                 0.21                         Y   \n",
       "58641                 0.35                         N   \n",
       "58642                 0.15                         N   \n",
       "58643                 0.17                         N   \n",
       "58644                 0.20                         N   \n",
       "\n",
       "       cb_person_cred_hist_length  loan_status  loan_intent_DEBTCONSOLIDATION  \\\n",
       "0                              14            0                            0.0   \n",
       "1                               2            0                            0.0   \n",
       "2                              10            0                            0.0   \n",
       "3                               5            0                            0.0   \n",
       "4                               3            0                            0.0   \n",
       "...                           ...          ...                            ...   \n",
       "58640                          10            0                            0.0   \n",
       "58641                           8            1                            0.0   \n",
       "58642                           2            1                            0.0   \n",
       "58643                           3            0                            0.0   \n",
       "58644                           5            0                            0.0   \n",
       "\n",
       "       loan_intent_EDUCATION  loan_intent_HOMEIMPROVEMENT  \\\n",
       "0                        1.0                          0.0   \n",
       "1                        0.0                          0.0   \n",
       "2                        0.0                          0.0   \n",
       "3                        0.0                          0.0   \n",
       "4                        0.0                          0.0   \n",
       "...                      ...                          ...   \n",
       "58640                    1.0                          0.0   \n",
       "58641                    0.0                          0.0   \n",
       "58642                    1.0                          0.0   \n",
       "58643                    1.0                          0.0   \n",
       "58644                    0.0                          0.0   \n",
       "\n",
       "       loan_intent_MEDICAL  loan_intent_PERSONAL  loan_intent_VENTURE  \n",
       "0                      0.0                   0.0                  0.0  \n",
       "1                      1.0                   0.0                  0.0  \n",
       "2                      0.0                   1.0                  0.0  \n",
       "3                      0.0                   0.0                  1.0  \n",
       "4                      1.0                   0.0                  0.0  \n",
       "...                    ...                   ...                  ...  \n",
       "58640                  0.0                   0.0                  0.0  \n",
       "58641                  1.0                   0.0                  0.0  \n",
       "58642                  0.0                   0.0                  0.0  \n",
       "58643                  0.0                   0.0                  0.0  \n",
       "58644                  0.0                   0.0                  1.0  \n",
       "\n",
       "[58645 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# there is no order for loan amounts and since the dimentionality of the data is already fairly small, we will use One hot encoding\n",
    "loanIntent = OneHotEncoder()\n",
    "temp = loanIntent.fit_transform(data[['loan_intent']]).toarray()\n",
    "encodedDF = pd.DataFrame(temp, columns = loanIntent.get_feature_names_out())\n",
    "data = pd.concat([data, encodedDF], axis=1)\n",
    "data.drop(columns=['loan_intent'], inplace=True)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a40d54a-e444-444e-b731-2ac07ffcc36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['G', 'F', 'E', 'D', 'C', 'B', 'A'], dtype=object)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loan_intent_DEBTCONSOLIDATION</th>\n",
       "      <th>loan_intent_EDUCATION</th>\n",
       "      <th>loan_intent_HOMEIMPROVEMENT</th>\n",
       "      <th>loan_intent_MEDICAL</th>\n",
       "      <th>loan_intent_PERSONAL</th>\n",
       "      <th>loan_intent_VENTURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>35000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>11.49</td>\n",
       "      <td>0.17</td>\n",
       "      <td>N</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>56000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>13.35</td>\n",
       "      <td>0.07</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>28800</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>8.90</td>\n",
       "      <td>0.21</td>\n",
       "      <td>N</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>70000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12000</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.17</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>60000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>6.92</td>\n",
       "      <td>0.10</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58640</th>\n",
       "      <td>58640</td>\n",
       "      <td>34</td>\n",
       "      <td>120000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25000</td>\n",
       "      <td>15.95</td>\n",
       "      <td>0.21</td>\n",
       "      <td>Y</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58641</th>\n",
       "      <td>58641</td>\n",
       "      <td>28</td>\n",
       "      <td>28800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>12.73</td>\n",
       "      <td>0.35</td>\n",
       "      <td>N</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58642</th>\n",
       "      <td>58642</td>\n",
       "      <td>23</td>\n",
       "      <td>44000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6800</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58643</th>\n",
       "      <td>58643</td>\n",
       "      <td>22</td>\n",
       "      <td>30000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>8.90</td>\n",
       "      <td>0.17</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58644</th>\n",
       "      <td>58644</td>\n",
       "      <td>31</td>\n",
       "      <td>75000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15000</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.20</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58645 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  person_age  person_income  person_home_ownership  \\\n",
       "0          0          37          35000                    1.0   \n",
       "1          1          22          56000                    3.0   \n",
       "2          2          29          28800                    3.0   \n",
       "3          3          30          70000                    1.0   \n",
       "4          4          22          60000                    1.0   \n",
       "...      ...         ...            ...                    ...   \n",
       "58640  58640          34         120000                    2.0   \n",
       "58641  58641          28          28800                    1.0   \n",
       "58642  58642          23          44000                    1.0   \n",
       "58643  58643          22          30000                    1.0   \n",
       "58644  58644          31          75000                    2.0   \n",
       "\n",
       "       person_emp_length  loan_grade  loan_amnt  loan_int_rate  \\\n",
       "0                    0.0         5.0       6000          11.49   \n",
       "1                    6.0         4.0       4000          13.35   \n",
       "2                    8.0         6.0       6000           8.90   \n",
       "3                   14.0         5.0      12000          11.11   \n",
       "4                    2.0         6.0       6000           6.92   \n",
       "...                  ...         ...        ...            ...   \n",
       "58640                5.0         3.0      25000          15.95   \n",
       "58641                0.0         4.0      10000          12.73   \n",
       "58642                7.0         3.0       6800          16.00   \n",
       "58643                2.0         6.0       5000           8.90   \n",
       "58644                2.0         5.0      15000          11.11   \n",
       "\n",
       "       loan_percent_income cb_person_default_on_file  \\\n",
       "0                     0.17                         N   \n",
       "1                     0.07                         N   \n",
       "2                     0.21                         N   \n",
       "3                     0.17                         N   \n",
       "4                     0.10                         N   \n",
       "...                    ...                       ...   \n",
       "58640                 0.21                         Y   \n",
       "58641                 0.35                         N   \n",
       "58642                 0.15                         N   \n",
       "58643                 0.17                         N   \n",
       "58644                 0.20                         N   \n",
       "\n",
       "       cb_person_cred_hist_length  loan_status  loan_intent_DEBTCONSOLIDATION  \\\n",
       "0                              14            0                            0.0   \n",
       "1                               2            0                            0.0   \n",
       "2                              10            0                            0.0   \n",
       "3                               5            0                            0.0   \n",
       "4                               3            0                            0.0   \n",
       "...                           ...          ...                            ...   \n",
       "58640                          10            0                            0.0   \n",
       "58641                           8            1                            0.0   \n",
       "58642                           2            1                            0.0   \n",
       "58643                           3            0                            0.0   \n",
       "58644                           5            0                            0.0   \n",
       "\n",
       "       loan_intent_EDUCATION  loan_intent_HOMEIMPROVEMENT  \\\n",
       "0                        1.0                          0.0   \n",
       "1                        0.0                          0.0   \n",
       "2                        0.0                          0.0   \n",
       "3                        0.0                          0.0   \n",
       "4                        0.0                          0.0   \n",
       "...                      ...                          ...   \n",
       "58640                    1.0                          0.0   \n",
       "58641                    0.0                          0.0   \n",
       "58642                    1.0                          0.0   \n",
       "58643                    1.0                          0.0   \n",
       "58644                    0.0                          0.0   \n",
       "\n",
       "       loan_intent_MEDICAL  loan_intent_PERSONAL  loan_intent_VENTURE  \n",
       "0                      0.0                   0.0                  0.0  \n",
       "1                      1.0                   0.0                  0.0  \n",
       "2                      0.0                   1.0                  0.0  \n",
       "3                      0.0                   0.0                  1.0  \n",
       "4                      1.0                   0.0                  0.0  \n",
       "...                    ...                   ...                  ...  \n",
       "58640                  0.0                   0.0                  0.0  \n",
       "58641                  1.0                   0.0                  0.0  \n",
       "58642                  0.0                   0.0                  0.0  \n",
       "58643                  0.0                   0.0                  0.0  \n",
       "58644                  0.0                   0.0                  1.0  \n",
       "\n",
       "[58645 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loan_grade is risk associated with loan/person, Grade A is lowest risk and risk increases as you go down\n",
    "# this is why we will use an ordinal encoder with A giving the highest score\n",
    "loanGrade = OrdinalEncoder(categories=[['G', 'F', 'E','D', 'C', 'B', 'A']])\n",
    "data['loan_grade'] = loanGrade.fit_transform(data[['loan_grade']])\n",
    "print(loanGrade.categories_)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4ed88a7-f243-4378-ae5a-e75328d8fc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['Y', 'N'], dtype=object)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loan_intent_DEBTCONSOLIDATION</th>\n",
       "      <th>loan_intent_EDUCATION</th>\n",
       "      <th>loan_intent_HOMEIMPROVEMENT</th>\n",
       "      <th>loan_intent_MEDICAL</th>\n",
       "      <th>loan_intent_PERSONAL</th>\n",
       "      <th>loan_intent_VENTURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>35000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>11.49</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>56000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>13.35</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>28800</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>8.90</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>70000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12000</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>60000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>6.92</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58640</th>\n",
       "      <td>58640</td>\n",
       "      <td>34</td>\n",
       "      <td>120000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25000</td>\n",
       "      <td>15.95</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58641</th>\n",
       "      <td>58641</td>\n",
       "      <td>28</td>\n",
       "      <td>28800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>12.73</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58642</th>\n",
       "      <td>58642</td>\n",
       "      <td>23</td>\n",
       "      <td>44000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6800</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58643</th>\n",
       "      <td>58643</td>\n",
       "      <td>22</td>\n",
       "      <td>30000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>8.90</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58644</th>\n",
       "      <td>58644</td>\n",
       "      <td>31</td>\n",
       "      <td>75000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15000</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58645 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  person_age  person_income  person_home_ownership  \\\n",
       "0          0          37          35000                    1.0   \n",
       "1          1          22          56000                    3.0   \n",
       "2          2          29          28800                    3.0   \n",
       "3          3          30          70000                    1.0   \n",
       "4          4          22          60000                    1.0   \n",
       "...      ...         ...            ...                    ...   \n",
       "58640  58640          34         120000                    2.0   \n",
       "58641  58641          28          28800                    1.0   \n",
       "58642  58642          23          44000                    1.0   \n",
       "58643  58643          22          30000                    1.0   \n",
       "58644  58644          31          75000                    2.0   \n",
       "\n",
       "       person_emp_length  loan_grade  loan_amnt  loan_int_rate  \\\n",
       "0                    0.0         5.0       6000          11.49   \n",
       "1                    6.0         4.0       4000          13.35   \n",
       "2                    8.0         6.0       6000           8.90   \n",
       "3                   14.0         5.0      12000          11.11   \n",
       "4                    2.0         6.0       6000           6.92   \n",
       "...                  ...         ...        ...            ...   \n",
       "58640                5.0         3.0      25000          15.95   \n",
       "58641                0.0         4.0      10000          12.73   \n",
       "58642                7.0         3.0       6800          16.00   \n",
       "58643                2.0         6.0       5000           8.90   \n",
       "58644                2.0         5.0      15000          11.11   \n",
       "\n",
       "       loan_percent_income  cb_person_default_on_file  \\\n",
       "0                     0.17                        1.0   \n",
       "1                     0.07                        1.0   \n",
       "2                     0.21                        1.0   \n",
       "3                     0.17                        1.0   \n",
       "4                     0.10                        1.0   \n",
       "...                    ...                        ...   \n",
       "58640                 0.21                        0.0   \n",
       "58641                 0.35                        1.0   \n",
       "58642                 0.15                        1.0   \n",
       "58643                 0.17                        1.0   \n",
       "58644                 0.20                        1.0   \n",
       "\n",
       "       cb_person_cred_hist_length  loan_status  loan_intent_DEBTCONSOLIDATION  \\\n",
       "0                              14            0                            0.0   \n",
       "1                               2            0                            0.0   \n",
       "2                              10            0                            0.0   \n",
       "3                               5            0                            0.0   \n",
       "4                               3            0                            0.0   \n",
       "...                           ...          ...                            ...   \n",
       "58640                          10            0                            0.0   \n",
       "58641                           8            1                            0.0   \n",
       "58642                           2            1                            0.0   \n",
       "58643                           3            0                            0.0   \n",
       "58644                           5            0                            0.0   \n",
       "\n",
       "       loan_intent_EDUCATION  loan_intent_HOMEIMPROVEMENT  \\\n",
       "0                        1.0                          0.0   \n",
       "1                        0.0                          0.0   \n",
       "2                        0.0                          0.0   \n",
       "3                        0.0                          0.0   \n",
       "4                        0.0                          0.0   \n",
       "...                      ...                          ...   \n",
       "58640                    1.0                          0.0   \n",
       "58641                    0.0                          0.0   \n",
       "58642                    1.0                          0.0   \n",
       "58643                    1.0                          0.0   \n",
       "58644                    0.0                          0.0   \n",
       "\n",
       "       loan_intent_MEDICAL  loan_intent_PERSONAL  loan_intent_VENTURE  \n",
       "0                      0.0                   0.0                  0.0  \n",
       "1                      1.0                   0.0                  0.0  \n",
       "2                      0.0                   1.0                  0.0  \n",
       "3                      0.0                   0.0                  1.0  \n",
       "4                      1.0                   0.0                  0.0  \n",
       "...                    ...                   ...                  ...  \n",
       "58640                  0.0                   0.0                  0.0  \n",
       "58641                  1.0                   0.0                  0.0  \n",
       "58642                  0.0                   0.0                  0.0  \n",
       "58643                  0.0                   0.0                  0.0  \n",
       "58644                  0.0                   0.0                  1.0  \n",
       "\n",
       "[58645 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "defaultOnFile = OrdinalEncoder(categories=[['Y', 'N']]) # Setting Y to 0 because it will not help you get approved for loan if on record\n",
    "data['cb_person_default_on_file'] = defaultOnFile.fit_transform(data[['cb_person_default_on_file']])\n",
    "print(defaultOnFile.categories_)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8b6dc8-2fd3-4cb1-be7a-bb6a323db894",
   "metadata": {},
   "source": [
    "Now that the data is represented as numerical values and interpretable by algorithms, lets check some statistics on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "992e63c8-245c-4297-84c6-c903dc754eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loan_intent_DEBTCONSOLIDATION</th>\n",
       "      <th>loan_intent_EDUCATION</th>\n",
       "      <th>loan_intent_HOMEIMPROVEMENT</th>\n",
       "      <th>loan_intent_MEDICAL</th>\n",
       "      <th>loan_intent_PERSONAL</th>\n",
       "      <th>loan_intent_VENTURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>58645.000000</td>\n",
       "      <td>58645.000000</td>\n",
       "      <td>5.864500e+04</td>\n",
       "      <td>58645.000000</td>\n",
       "      <td>58645.000000</td>\n",
       "      <td>58645.000000</td>\n",
       "      <td>58645.000000</td>\n",
       "      <td>58645.000000</td>\n",
       "      <td>58645.000000</td>\n",
       "      <td>58645.000000</td>\n",
       "      <td>58645.000000</td>\n",
       "      <td>58645.000000</td>\n",
       "      <td>58645.000000</td>\n",
       "      <td>58645.000000</td>\n",
       "      <td>58645.000000</td>\n",
       "      <td>58645.000000</td>\n",
       "      <td>58645.000000</td>\n",
       "      <td>58645.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29322.000000</td>\n",
       "      <td>27.550857</td>\n",
       "      <td>6.404617e+04</td>\n",
       "      <td>1.528792</td>\n",
       "      <td>4.701015</td>\n",
       "      <td>4.933362</td>\n",
       "      <td>9217.556518</td>\n",
       "      <td>10.677874</td>\n",
       "      <td>0.159238</td>\n",
       "      <td>0.851616</td>\n",
       "      <td>5.813556</td>\n",
       "      <td>0.142382</td>\n",
       "      <td>0.155734</td>\n",
       "      <td>0.209242</td>\n",
       "      <td>0.107085</td>\n",
       "      <td>0.186444</td>\n",
       "      <td>0.170790</td>\n",
       "      <td>0.170705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16929.497605</td>\n",
       "      <td>6.033216</td>\n",
       "      <td>3.793111e+04</td>\n",
       "      <td>0.599357</td>\n",
       "      <td>3.959784</td>\n",
       "      <td>1.046181</td>\n",
       "      <td>5563.807384</td>\n",
       "      <td>3.034697</td>\n",
       "      <td>0.091692</td>\n",
       "      <td>0.355484</td>\n",
       "      <td>4.029196</td>\n",
       "      <td>0.349445</td>\n",
       "      <td>0.362606</td>\n",
       "      <td>0.406771</td>\n",
       "      <td>0.309224</td>\n",
       "      <td>0.389468</td>\n",
       "      <td>0.376329</td>\n",
       "      <td>0.376254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.200000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>5.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14661.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>4.200000e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>7.880000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29322.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>5.800000e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>10.750000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>43983.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.560000e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>12.990000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>58644.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>1.900000e+06</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>23.220000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id    person_age  person_income  person_home_ownership  \\\n",
       "count  58645.000000  58645.000000   5.864500e+04           58645.000000   \n",
       "mean   29322.000000     27.550857   6.404617e+04               1.528792   \n",
       "std    16929.497605      6.033216   3.793111e+04               0.599357   \n",
       "min        0.000000     20.000000   4.200000e+03               0.000000   \n",
       "25%    14661.000000     23.000000   4.200000e+04               1.000000   \n",
       "50%    29322.000000     26.000000   5.800000e+04               1.000000   \n",
       "75%    43983.000000     30.000000   7.560000e+04               2.000000   \n",
       "max    58644.000000    123.000000   1.900000e+06               3.000000   \n",
       "\n",
       "       person_emp_length    loan_grade     loan_amnt  loan_int_rate  \\\n",
       "count       58645.000000  58645.000000  58645.000000   58645.000000   \n",
       "mean            4.701015      4.933362   9217.556518      10.677874   \n",
       "std             3.959784      1.046181   5563.807384       3.034697   \n",
       "min             0.000000      0.000000    500.000000       5.420000   \n",
       "25%             2.000000      4.000000   5000.000000       7.880000   \n",
       "50%             4.000000      5.000000   8000.000000      10.750000   \n",
       "75%             7.000000      6.000000  12000.000000      12.990000   \n",
       "max           123.000000      6.000000  35000.000000      23.220000   \n",
       "\n",
       "       loan_percent_income  cb_person_default_on_file  \\\n",
       "count         58645.000000               58645.000000   \n",
       "mean              0.159238                   0.851616   \n",
       "std               0.091692                   0.355484   \n",
       "min               0.000000                   0.000000   \n",
       "25%               0.090000                   1.000000   \n",
       "50%               0.140000                   1.000000   \n",
       "75%               0.210000                   1.000000   \n",
       "max               0.830000                   1.000000   \n",
       "\n",
       "       cb_person_cred_hist_length   loan_status  \\\n",
       "count                58645.000000  58645.000000   \n",
       "mean                     5.813556      0.142382   \n",
       "std                      4.029196      0.349445   \n",
       "min                      2.000000      0.000000   \n",
       "25%                      3.000000      0.000000   \n",
       "50%                      4.000000      0.000000   \n",
       "75%                      8.000000      0.000000   \n",
       "max                     30.000000      1.000000   \n",
       "\n",
       "       loan_intent_DEBTCONSOLIDATION  loan_intent_EDUCATION  \\\n",
       "count                   58645.000000           58645.000000   \n",
       "mean                        0.155734               0.209242   \n",
       "std                         0.362606               0.406771   \n",
       "min                         0.000000               0.000000   \n",
       "25%                         0.000000               0.000000   \n",
       "50%                         0.000000               0.000000   \n",
       "75%                         0.000000               0.000000   \n",
       "max                         1.000000               1.000000   \n",
       "\n",
       "       loan_intent_HOMEIMPROVEMENT  loan_intent_MEDICAL  loan_intent_PERSONAL  \\\n",
       "count                 58645.000000         58645.000000          58645.000000   \n",
       "mean                      0.107085             0.186444              0.170790   \n",
       "std                       0.309224             0.389468              0.376329   \n",
       "min                       0.000000             0.000000              0.000000   \n",
       "25%                       0.000000             0.000000              0.000000   \n",
       "50%                       0.000000             0.000000              0.000000   \n",
       "75%                       0.000000             0.000000              0.000000   \n",
       "max                       1.000000             1.000000              1.000000   \n",
       "\n",
       "       loan_intent_VENTURE  \n",
       "count         58645.000000  \n",
       "mean              0.170705  \n",
       "std               0.376254  \n",
       "min               0.000000  \n",
       "25%               0.000000  \n",
       "50%               0.000000  \n",
       "75%               0.000000  \n",
       "max               1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259a8e29-5dd3-4c6a-a7df-ec8ea5a21bfc",
   "metadata": {},
   "source": [
    "We see things like person_emp_length which has a max value of 123. We are going to assume that a person has not been working for 123 years and remove data above 70 years working because these cases are less likely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf3312ff-b520-45bd-b8bd-a60253c26f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58643, 18)\n"
     ]
    }
   ],
   "source": [
    "data = data[data['person_emp_length'] < 70]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38cda488-5403-4646-afa9-7272765a3970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loan_intent_DEBTCONSOLIDATION</th>\n",
       "      <th>loan_intent_EDUCATION</th>\n",
       "      <th>loan_intent_HOMEIMPROVEMENT</th>\n",
       "      <th>loan_intent_MEDICAL</th>\n",
       "      <th>loan_intent_PERSONAL</th>\n",
       "      <th>loan_intent_VENTURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>58643.000000</td>\n",
       "      <td>58643.000000</td>\n",
       "      <td>5.864300e+04</td>\n",
       "      <td>58643.000000</td>\n",
       "      <td>58643.000000</td>\n",
       "      <td>58643.000000</td>\n",
       "      <td>58643.000000</td>\n",
       "      <td>58643.000000</td>\n",
       "      <td>58643.000000</td>\n",
       "      <td>58643.000000</td>\n",
       "      <td>58643.000000</td>\n",
       "      <td>58643.000000</td>\n",
       "      <td>58643.000000</td>\n",
       "      <td>58643.000000</td>\n",
       "      <td>58643.000000</td>\n",
       "      <td>58643.000000</td>\n",
       "      <td>58643.000000</td>\n",
       "      <td>58643.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29321.459663</td>\n",
       "      <td>27.550961</td>\n",
       "      <td>6.404405e+04</td>\n",
       "      <td>1.528776</td>\n",
       "      <td>4.696980</td>\n",
       "      <td>4.933394</td>\n",
       "      <td>9217.103525</td>\n",
       "      <td>10.677771</td>\n",
       "      <td>0.159235</td>\n",
       "      <td>0.851628</td>\n",
       "      <td>5.813618</td>\n",
       "      <td>0.142370</td>\n",
       "      <td>0.155739</td>\n",
       "      <td>0.209249</td>\n",
       "      <td>0.107089</td>\n",
       "      <td>0.186433</td>\n",
       "      <td>0.170796</td>\n",
       "      <td>0.170694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16929.516626</td>\n",
       "      <td>6.033258</td>\n",
       "      <td>3.792807e+04</td>\n",
       "      <td>0.599361</td>\n",
       "      <td>3.899118</td>\n",
       "      <td>1.046169</td>\n",
       "      <td>5563.342345</td>\n",
       "      <td>3.034669</td>\n",
       "      <td>0.091690</td>\n",
       "      <td>0.355472</td>\n",
       "      <td>4.029234</td>\n",
       "      <td>0.349432</td>\n",
       "      <td>0.362611</td>\n",
       "      <td>0.406776</td>\n",
       "      <td>0.309229</td>\n",
       "      <td>0.389459</td>\n",
       "      <td>0.376334</td>\n",
       "      <td>0.376244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.200000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>5.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14660.500000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>4.200000e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>7.880000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29321.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>5.800000e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>10.750000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>43982.500000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.560000e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>12.990000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>58644.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>1.900000e+06</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>23.220000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id    person_age  person_income  person_home_ownership  \\\n",
       "count  58643.000000  58643.000000   5.864300e+04           58643.000000   \n",
       "mean   29321.459663     27.550961   6.404405e+04               1.528776   \n",
       "std    16929.516626      6.033258   3.792807e+04               0.599361   \n",
       "min        0.000000     20.000000   4.200000e+03               0.000000   \n",
       "25%    14660.500000     23.000000   4.200000e+04               1.000000   \n",
       "50%    29321.000000     26.000000   5.800000e+04               1.000000   \n",
       "75%    43982.500000     30.000000   7.560000e+04               2.000000   \n",
       "max    58644.000000    123.000000   1.900000e+06               3.000000   \n",
       "\n",
       "       person_emp_length    loan_grade     loan_amnt  loan_int_rate  \\\n",
       "count       58643.000000  58643.000000  58643.000000   58643.000000   \n",
       "mean            4.696980      4.933394   9217.103525      10.677771   \n",
       "std             3.899118      1.046169   5563.342345       3.034669   \n",
       "min             0.000000      0.000000    500.000000       5.420000   \n",
       "25%             2.000000      4.000000   5000.000000       7.880000   \n",
       "50%             4.000000      5.000000   8000.000000      10.750000   \n",
       "75%             7.000000      6.000000  12000.000000      12.990000   \n",
       "max            41.000000      6.000000  35000.000000      23.220000   \n",
       "\n",
       "       loan_percent_income  cb_person_default_on_file  \\\n",
       "count         58643.000000               58643.000000   \n",
       "mean              0.159235                   0.851628   \n",
       "std               0.091690                   0.355472   \n",
       "min               0.000000                   0.000000   \n",
       "25%               0.090000                   1.000000   \n",
       "50%               0.140000                   1.000000   \n",
       "75%               0.210000                   1.000000   \n",
       "max               0.830000                   1.000000   \n",
       "\n",
       "       cb_person_cred_hist_length   loan_status  \\\n",
       "count                58643.000000  58643.000000   \n",
       "mean                     5.813618      0.142370   \n",
       "std                      4.029234      0.349432   \n",
       "min                      2.000000      0.000000   \n",
       "25%                      3.000000      0.000000   \n",
       "50%                      4.000000      0.000000   \n",
       "75%                      8.000000      0.000000   \n",
       "max                     30.000000      1.000000   \n",
       "\n",
       "       loan_intent_DEBTCONSOLIDATION  loan_intent_EDUCATION  \\\n",
       "count                   58643.000000           58643.000000   \n",
       "mean                        0.155739               0.209249   \n",
       "std                         0.362611               0.406776   \n",
       "min                         0.000000               0.000000   \n",
       "25%                         0.000000               0.000000   \n",
       "50%                         0.000000               0.000000   \n",
       "75%                         0.000000               0.000000   \n",
       "max                         1.000000               1.000000   \n",
       "\n",
       "       loan_intent_HOMEIMPROVEMENT  loan_intent_MEDICAL  loan_intent_PERSONAL  \\\n",
       "count                 58643.000000         58643.000000          58643.000000   \n",
       "mean                      0.107089             0.186433              0.170796   \n",
       "std                       0.309229             0.389459              0.376334   \n",
       "min                       0.000000             0.000000              0.000000   \n",
       "25%                       0.000000             0.000000              0.000000   \n",
       "50%                       0.000000             0.000000              0.000000   \n",
       "75%                       0.000000             0.000000              0.000000   \n",
       "max                       1.000000             1.000000              1.000000   \n",
       "\n",
       "       loan_intent_VENTURE  \n",
       "count         58643.000000  \n",
       "mean              0.170694  \n",
       "std               0.376244  \n",
       "min               0.000000  \n",
       "25%               0.000000  \n",
       "50%               0.000000  \n",
       "75%               0.000000  \n",
       "max               1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2ae2821-8d93-463f-8d2c-69b363766806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(data.corr(), annot=True, fmt='.1f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6f85368-7bbc-433e-87bb-acff47474d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interestingly we see that loan_grade has a negative correlation with loan_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "68b60062-d027-4fc0-a2ae-c8e2d52b82d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# commenting out because there is too much data to get an accurate representation using pair plot\n",
    "# sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8a3c001-1791-4581-8b5a-2f7d1fa230be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdata = data.drop(columns=['loan_status', 'id'])\n",
    "Ydata = data['loan_status']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad221448-8ea7-48b5-8c29-34ed3c6b7b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_status\n",
      "0    50294\n",
      "1     8349\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(Ydata.value_counts())\n",
    "plt.bar(Ydata.unique(), Ydata.value_counts())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "89644a9c-0d11-43fe-b4e1-4000546ddbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  alpha_star, phi_star, old_fval, derphi_star = scalar_search_wolfe2(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:74: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:246: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "800 fits failed out of a total of 1200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "300 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2'} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 75, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1182, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan 0.90080996        nan        nan        nan 0.86957115\n",
      " 0.88577031 0.8696223  0.90132151 0.90144087 0.86957115 0.86957115\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.90116805        nan        nan        nan 0.86957115\n",
      " 0.88597493 0.8696223  0.9012192  0.90154318 0.86957115 0.86957115\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.90108279        nan        nan        nan 0.86957115\n",
      " 0.88607724 0.8696223  0.90137267 0.90135561 0.86957115 0.86957115\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.90106573        nan        nan        nan 0.86957115\n",
      " 0.88594083 0.8696223  0.90127036 0.90137267 0.86957115 0.86957115\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.90106573        nan        nan        nan 0.86957115\n",
      " 0.88599199 0.8696223  0.90144087 0.90132151 0.86957115 0.86957115\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.90106573        nan        nan        nan 0.86957115\n",
      " 0.88588968 0.8696223  0.90149203 0.90138972 0.86957115 0.86957115\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.90106573        nan        nan        nan 0.86957115\n",
      " 0.8861284  0.8696223  0.9012533  0.90138972 0.86957115 0.86957115\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.90108279        nan        nan        nan 0.86957115\n",
      " 0.88580442 0.8696223  0.90128741 0.90132151 0.86957115 0.86957115\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.90106573        nan        nan        nan 0.86957115\n",
      " 0.88599199 0.8696223  0.90115099 0.90130446 0.86957115 0.86957115\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.90106573        nan        nan        nan 0.86957115\n",
      " 0.88568505 0.8696223  0.90135561 0.90135561 0.86957115 0.86957115\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9015431835621109"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logRegModel = LogisticRegression()\n",
    "grid = {'penalty': ['None', 'l1', 'l2', 'elasticnet'], \n",
    "        'solver': ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n",
    "       'C': list(range(1,11)),\n",
    "       'random_state': [42]}\n",
    "search = GridSearchCV(logRegModel, grid, cv = 5).fit(Xdata, Ydata)\n",
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff127fda-6974-439e-98d9-78036d1a4c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 2, 'penalty': 'l2', 'random_state': 42, 'solver': 'newton-cholesky'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c989b682-6b38-4f92-b781-4e3f7bd1c089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "[CV 1/3; 1/72] START ccp_alpha=0.1, criterion=gini, max_depth=None, n_estimators=100, random_state=42\n",
      "[CV 1/3; 1/72] END ccp_alpha=0.1, criterion=gini, max_depth=None, n_estimators=100, random_state=42;, score=0.858 total time=  15.6s\n",
      "[CV 2/3; 1/72] START ccp_alpha=0.1, criterion=gini, max_depth=None, n_estimators=100, random_state=42\n",
      "[CV 2/3; 1/72] END ccp_alpha=0.1, criterion=gini, max_depth=None, n_estimators=100, random_state=42;, score=0.858 total time=  14.9s\n",
      "[CV 3/3; 1/72] START ccp_alpha=0.1, criterion=gini, max_depth=None, n_estimators=100, random_state=42\n",
      "[CV 3/3; 1/72] END ccp_alpha=0.1, criterion=gini, max_depth=None, n_estimators=100, random_state=42;, score=0.858 total time=  14.7s\n",
      "[CV 1/3; 2/72] START ccp_alpha=0.1, criterion=gini, max_depth=None, n_estimators=150, random_state=42\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 8\u001b[0m\n\u001b[0;32m      2\u001b[0m randomForest \u001b[38;5;241m=\u001b[39m RandomForestClassifier()\n\u001b[0;32m      3\u001b[0m randomForestGrid \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m300\u001b[39m,\u001b[38;5;241m50\u001b[39m)),\n\u001b[0;32m      4\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgini\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentropy\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      5\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m      6\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m42\u001b[39m],\n\u001b[0;32m      7\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mccp_alpha\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.1\u001b[39m,\u001b[38;5;241m0.2\u001b[39m,\u001b[38;5;241m0.3\u001b[39m]}\n\u001b[1;32m----> 8\u001b[0m randomForestSearch \u001b[38;5;241m=\u001b[39m GridSearchCV(randomForest, randomForestGrid, cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(Xdata, Ydata)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    917\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    918\u001b[0m         clone(base_estimator),\n\u001b[0;32m    919\u001b[0m         X,\n\u001b[0;32m    920\u001b[0m         y,\n\u001b[0;32m    921\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    922\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    923\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    924\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    925\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    927\u001b[0m     )\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    929\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    930\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    931\u001b[0m     )\n\u001b[0;32m    932\u001b[0m )\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    893\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 895\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[0;32m    490\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    491\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    492\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    493\u001b[0m )(\n\u001b[0;32m    494\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    495\u001b[0m         t,\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[0;32m    497\u001b[0m         X,\n\u001b[0;32m    498\u001b[0m         y,\n\u001b[0;32m    499\u001b[0m         sample_weight,\n\u001b[0;32m    500\u001b[0m         i,\n\u001b[0;32m    501\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[0;32m    502\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    503\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m    504\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[0;32m    505\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    506\u001b[0m     )\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[0;32m    508\u001b[0m )\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 192\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    193\u001b[0m         X,\n\u001b[0;32m    194\u001b[0m         y,\n\u001b[0;32m    195\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight,\n\u001b[0;32m    196\u001b[0m         check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    197\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    198\u001b[0m     )\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    201\u001b[0m         X,\n\u001b[0;32m    202\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    206\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "randomForest = RandomForestClassifier()\n",
    "randomForestGrid = {'n_estimators': list(range(100, 300,50)),\n",
    "                   'criterion': ['gini', 'entropy'],\n",
    "                   'max_depth': [None, 1, 2],\n",
    "                   'random_state': [42],\n",
    "                   'ccp_alpha': [0.1,0.2,0.3]}\n",
    "randomForestSearch = GridSearchCV(randomForest, randomForestGrid, cv = 3, verbose=10).fit(Xdata, Ydata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f774bb-015a-4c1b-bd46-1f7460b70a99",
   "metadata": {},
   "source": [
    "The Random Forest classifier took more than 3 hours to run before, therefore we will not be using it as it is not efficient enough for us to use in determining loan approval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3639e01b-ff74-4ce6-b605-0541ac66bcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(randomForestSearch.best_score_)\n",
    "print(randomForestSearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6de23db-810e-49a8-8865-597d3a7b797b",
   "metadata": {},
   "source": [
    "We Will try ADA boost however as on average it performs better than random forest since it learns from its mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0bb974c4-1293-44f1-96ba-9a248b7ed6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV 1/3; 1/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=50, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 1/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=50, random_state=42;, score=0.143 total time=   3.9s\n",
      "[CV 2/3; 1/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=50, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 1/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=50, random_state=42;, score=0.928 total time=   3.8s\n",
      "[CV 3/3; 1/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=50, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 1/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=50, random_state=42;, score=0.858 total time=   3.7s\n",
      "[CV 1/3; 2/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=100, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 2/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=100, random_state=42;, score=0.143 total time=   7.7s\n",
      "[CV 2/3; 2/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=100, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 2/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=100, random_state=42;, score=0.928 total time=   7.8s\n",
      "[CV 3/3; 2/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=100, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 2/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=100, random_state=42;, score=0.858 total time=   8.0s\n",
      "[CV 1/3; 3/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=150, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 3/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=150, random_state=42;, score=0.143 total time=  11.8s\n",
      "[CV 2/3; 3/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=150, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 3/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=150, random_state=42;, score=0.929 total time=  11.6s\n",
      "[CV 3/3; 3/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=150, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 3/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=150, random_state=42;, score=0.858 total time=  12.1s\n",
      "[CV 1/3; 4/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=200, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 4/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=200, random_state=42;, score=0.143 total time=  15.9s\n",
      "[CV 2/3; 4/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=200, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 4/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=200, random_state=42;, score=0.929 total time=  15.7s\n",
      "[CV 3/3; 4/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=200, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 4/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=200, random_state=42;, score=0.858 total time=  15.8s\n",
      "[CV 1/3; 5/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=250, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 5/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=250, random_state=42;, score=0.143 total time=  19.9s\n",
      "[CV 2/3; 5/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=250, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 5/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=250, random_state=42;, score=0.928 total time=  19.9s\n",
      "[CV 3/3; 5/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=250, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 5/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=250, random_state=42;, score=0.858 total time=  19.9s\n",
      "[CV 1/3; 6/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=300, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 6/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=300, random_state=42;, score=0.144 total time=  23.8s\n",
      "[CV 2/3; 6/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=300, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 6/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=300, random_state=42;, score=0.929 total time=  23.6s\n",
      "[CV 3/3; 6/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=300, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 6/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=300, random_state=42;, score=0.858 total time=  22.8s\n",
      "[CV 1/3; 7/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=50, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 7/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=50, random_state=42;, score=0.889 total time=   3.7s\n",
      "[CV 2/3; 7/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=50, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 7/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=50, random_state=42;, score=0.111 total time=   3.9s\n",
      "[CV 3/3; 7/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=50, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 7/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=50, random_state=42;, score=0.142 total time=   3.8s\n",
      "[CV 1/3; 8/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=100, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 8/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=100, random_state=42;, score=0.889 total time=   7.3s\n",
      "[CV 2/3; 8/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=100, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 8/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=100, random_state=42;, score=0.142 total time=   7.7s\n",
      "[CV 3/3; 8/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=100, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 8/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=100, random_state=42;, score=0.142 total time=   7.7s\n",
      "[CV 1/3; 9/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=150, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 9/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=150, random_state=42;, score=0.889 total time=  11.5s\n",
      "[CV 2/3; 9/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=150, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 9/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=150, random_state=42;, score=0.111 total time=  11.7s\n",
      "[CV 3/3; 9/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=150, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 9/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=150, random_state=42;, score=0.142 total time=  11.6s\n",
      "[CV 1/3; 10/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=200, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 10/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=200, random_state=42;, score=0.889 total time=  15.4s\n",
      "[CV 2/3; 10/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=200, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 10/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=200, random_state=42;, score=0.111 total time=  15.7s\n",
      "[CV 3/3; 10/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=200, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 10/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=200, random_state=42;, score=0.142 total time=  15.2s\n",
      "[CV 1/3; 11/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=250, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 11/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=250, random_state=42;, score=0.889 total time=  19.1s\n",
      "[CV 2/3; 11/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=250, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 11/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=250, random_state=42;, score=0.142 total time=  18.8s\n",
      "[CV 3/3; 11/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=250, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 11/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=250, random_state=42;, score=0.142 total time=  18.2s\n",
      "[CV 1/3; 12/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=300, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 12/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=300, random_state=42;, score=0.889 total time=  22.5s\n",
      "[CV 2/3; 12/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=300, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 12/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=300, random_state=42;, score=0.111 total time=  22.5s\n",
      "[CV 3/3; 12/24] START estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=300, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 12/24] END estimator=DecisionTreeClassifier(max_depth=1), learning_rate=2, n_estimators=300, random_state=42;, score=0.142 total time=  22.9s\n",
      "[CV 1/3; 13/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=50, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 13/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=50, random_state=42;, score=0.143 total time=   6.3s\n",
      "[CV 2/3; 13/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=50, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 13/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=50, random_state=42;, score=0.945 total time=   6.2s\n",
      "[CV 3/3; 13/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=50, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 13/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=50, random_state=42;, score=0.861 total time=   5.9s\n",
      "[CV 1/3; 14/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=100, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 14/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=100, random_state=42;, score=0.153 total time=  12.4s\n",
      "[CV 2/3; 14/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=100, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 14/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=100, random_state=42;, score=0.948 total time=  12.7s\n",
      "[CV 3/3; 14/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=100, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 14/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=100, random_state=42;, score=0.861 total time=  12.4s\n",
      "[CV 1/3; 15/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=150, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 15/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=150, random_state=42;, score=0.156 total time=  18.5s\n",
      "[CV 2/3; 15/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=150, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 15/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=150, random_state=42;, score=0.948 total time=  18.5s\n",
      "[CV 3/3; 15/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=150, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 15/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=150, random_state=42;, score=0.862 total time=  18.5s\n",
      "[CV 1/3; 16/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=200, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 16/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=200, random_state=42;, score=0.162 total time=  24.7s\n",
      "[CV 2/3; 16/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=200, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 16/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=200, random_state=42;, score=0.948 total time=  23.4s\n",
      "[CV 3/3; 16/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=200, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 16/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=200, random_state=42;, score=0.861 total time=  24.5s\n",
      "[CV 1/3; 17/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=250, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 17/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=250, random_state=42;, score=0.170 total time=  31.4s\n",
      "[CV 2/3; 17/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=250, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 17/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=250, random_state=42;, score=0.712 total time=  31.3s\n",
      "[CV 3/3; 17/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=250, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 17/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=250, random_state=42;, score=0.858 total time=  30.3s\n",
      "[CV 1/3; 18/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=300, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 18/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=300, random_state=42;, score=0.172 total time=  36.8s\n",
      "[CV 2/3; 18/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=300, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 18/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=300, random_state=42;, score=0.716 total time=  36.5s\n",
      "[CV 3/3; 18/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=300, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 18/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1, n_estimators=300, random_state=42;, score=0.858 total time=  37.6s\n",
      "[CV 1/3; 19/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=50, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 19/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=50, random_state=42;, score=0.840 total time=   6.3s\n",
      "[CV 2/3; 19/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=50, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 19/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=50, random_state=42;, score=0.160 total time=   6.2s\n",
      "[CV 3/3; 19/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=50, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 19/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=50, random_state=42;, score=0.110 total time=   6.3s\n",
      "[CV 1/3; 20/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=100, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 20/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=100, random_state=42;, score=0.840 total time=  12.6s\n",
      "[CV 2/3; 20/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=100, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 20/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=100, random_state=42;, score=0.160 total time=  12.4s\n",
      "[CV 3/3; 20/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=100, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 20/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=100, random_state=42;, score=0.110 total time=  12.6s\n",
      "[CV 1/3; 21/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=150, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 21/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=150, random_state=42;, score=0.840 total time=  18.9s\n",
      "[CV 2/3; 21/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=150, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 21/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=150, random_state=42;, score=0.160 total time=  19.0s\n",
      "[CV 3/3; 21/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=150, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 21/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=150, random_state=42;, score=0.110 total time=  18.7s\n",
      "[CV 1/3; 22/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=200, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 22/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=200, random_state=42;, score=0.840 total time=  25.1s\n",
      "[CV 2/3; 22/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=200, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 22/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=200, random_state=42;, score=0.160 total time=  24.8s\n",
      "[CV 3/3; 22/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=200, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 22/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=200, random_state=42;, score=0.110 total time=  24.5s\n",
      "[CV 1/3; 23/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=250, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 23/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=250, random_state=42;, score=0.840 total time=  31.0s\n",
      "[CV 2/3; 23/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=250, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 23/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=250, random_state=42;, score=0.160 total time=  31.0s\n",
      "[CV 3/3; 23/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=250, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 23/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=250, random_state=42;, score=0.142 total time=  31.1s\n",
      "[CV 1/3; 24/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=300, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 24/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=300, random_state=42;, score=0.840 total time=  36.9s\n",
      "[CV 2/3; 24/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=300, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 24/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=300, random_state=42;, score=0.160 total time=  37.3s\n",
      "[CV 3/3; 24/24] START estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=300, random_state=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 24/24] END estimator=DecisionTreeClassifier(max_depth=2), learning_rate=2, n_estimators=300, random_state=42;, score=0.142 total time=  36.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhurl\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "ada = AdaBoostClassifier(algorithm = 'SAMME')\n",
    "adaGrid = {'n_estimators': list(range(50,350, 50)),\n",
    "          'learning_rate': list(range(1,3)),\n",
    "          'random_state': [42],\n",
    "          'estimator': [DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=2)]}\n",
    "adaSearch = GridSearchCV(ada, adaGrid, cv = 3, verbose=10).fit(Xdata, Ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "83094401-b459-4e52-831c-2c75d81c9b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6569101287020052\n",
      "{'estimator': DecisionTreeClassifier(max_depth=2), 'learning_rate': 1, 'n_estimators': 200, 'random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "print(adaSearch.best_score_)\n",
    "print(adaSearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877a2346-3877-43ca-903e-94afff228669",
   "metadata": {},
   "source": [
    "We will also try using K nearest Neighbors to find the decision boundary or boundaries. KNN is fast, and has the ability to be rigid or flexible depending on the number we choose for N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b4faa9d-5cc1-4922-bec8-2eb480c76a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "[CV 1/3; 1/36] START n_neighbors=1, p=1, weights=uniform........................\n",
      "[CV 1/3; 1/36] END n_neighbors=1, p=1, weights=uniform;, score=0.876 total time=   2.2s\n",
      "[CV 2/3; 1/36] START n_neighbors=1, p=1, weights=uniform........................\n",
      "[CV 2/3; 1/36] END n_neighbors=1, p=1, weights=uniform;, score=0.875 total time=   1.9s\n",
      "[CV 3/3; 1/36] START n_neighbors=1, p=1, weights=uniform........................\n",
      "[CV 3/3; 1/36] END n_neighbors=1, p=1, weights=uniform;, score=0.873 total time=   1.9s\n",
      "[CV 1/3; 2/36] START n_neighbors=1, p=1, weights=distance.......................\n",
      "[CV 1/3; 2/36] END n_neighbors=1, p=1, weights=distance;, score=0.876 total time=   1.4s\n",
      "[CV 2/3; 2/36] START n_neighbors=1, p=1, weights=distance.......................\n",
      "[CV 2/3; 2/36] END n_neighbors=1, p=1, weights=distance;, score=0.875 total time=   1.3s\n",
      "[CV 3/3; 2/36] START n_neighbors=1, p=1, weights=distance.......................\n",
      "[CV 3/3; 2/36] END n_neighbors=1, p=1, weights=distance;, score=0.873 total time=   1.3s\n",
      "[CV 1/3; 3/36] START n_neighbors=1, p=2, weights=uniform........................\n",
      "[CV 1/3; 3/36] END n_neighbors=1, p=2, weights=uniform;, score=0.868 total time=   0.9s\n",
      "[CV 2/3; 3/36] START n_neighbors=1, p=2, weights=uniform........................\n",
      "[CV 2/3; 3/36] END n_neighbors=1, p=2, weights=uniform;, score=0.870 total time=   0.9s\n",
      "[CV 3/3; 3/36] START n_neighbors=1, p=2, weights=uniform........................\n",
      "[CV 3/3; 3/36] END n_neighbors=1, p=2, weights=uniform;, score=0.869 total time=   1.0s\n",
      "[CV 1/3; 4/36] START n_neighbors=1, p=2, weights=distance.......................\n",
      "[CV 1/3; 4/36] END n_neighbors=1, p=2, weights=distance;, score=0.868 total time=   0.5s\n",
      "[CV 2/3; 4/36] START n_neighbors=1, p=2, weights=distance.......................\n",
      "[CV 2/3; 4/36] END n_neighbors=1, p=2, weights=distance;, score=0.870 total time=   0.4s\n",
      "[CV 3/3; 4/36] START n_neighbors=1, p=2, weights=distance.......................\n",
      "[CV 3/3; 4/36] END n_neighbors=1, p=2, weights=distance;, score=0.869 total time=   0.4s\n",
      "[CV 1/3; 5/36] START n_neighbors=2, p=1, weights=uniform........................\n",
      "[CV 1/3; 5/36] END n_neighbors=2, p=1, weights=uniform;, score=0.890 total time=   2.0s\n",
      "[CV 2/3; 5/36] START n_neighbors=2, p=1, weights=uniform........................\n",
      "[CV 2/3; 5/36] END n_neighbors=2, p=1, weights=uniform;, score=0.888 total time=   1.9s\n",
      "[CV 3/3; 5/36] START n_neighbors=2, p=1, weights=uniform........................\n",
      "[CV 3/3; 5/36] END n_neighbors=2, p=1, weights=uniform;, score=0.887 total time=   2.0s\n",
      "[CV 1/3; 6/36] START n_neighbors=2, p=1, weights=distance.......................\n",
      "[CV 1/3; 6/36] END n_neighbors=2, p=1, weights=distance;, score=0.876 total time=   1.5s\n",
      "[CV 2/3; 6/36] START n_neighbors=2, p=1, weights=distance.......................\n",
      "[CV 2/3; 6/36] END n_neighbors=2, p=1, weights=distance;, score=0.875 total time=   1.5s\n",
      "[CV 3/3; 6/36] START n_neighbors=2, p=1, weights=distance.......................\n",
      "[CV 3/3; 6/36] END n_neighbors=2, p=1, weights=distance;, score=0.873 total time=   1.5s\n",
      "[CV 1/3; 7/36] START n_neighbors=2, p=2, weights=uniform........................\n",
      "[CV 1/3; 7/36] END n_neighbors=2, p=2, weights=uniform;, score=0.886 total time=   0.9s\n",
      "[CV 2/3; 7/36] START n_neighbors=2, p=2, weights=uniform........................\n",
      "[CV 2/3; 7/36] END n_neighbors=2, p=2, weights=uniform;, score=0.885 total time=   1.1s\n",
      "[CV 3/3; 7/36] START n_neighbors=2, p=2, weights=uniform........................\n",
      "[CV 3/3; 7/36] END n_neighbors=2, p=2, weights=uniform;, score=0.883 total time=   1.1s\n",
      "[CV 1/3; 8/36] START n_neighbors=2, p=2, weights=distance.......................\n",
      "[CV 1/3; 8/36] END n_neighbors=2, p=2, weights=distance;, score=0.868 total time=   0.6s\n",
      "[CV 2/3; 8/36] START n_neighbors=2, p=2, weights=distance.......................\n",
      "[CV 2/3; 8/36] END n_neighbors=2, p=2, weights=distance;, score=0.870 total time=   0.5s\n",
      "[CV 3/3; 8/36] START n_neighbors=2, p=2, weights=distance.......................\n",
      "[CV 3/3; 8/36] END n_neighbors=2, p=2, weights=distance;, score=0.869 total time=   0.5s\n",
      "[CV 1/3; 9/36] START n_neighbors=3, p=1, weights=uniform........................\n",
      "[CV 1/3; 9/36] END n_neighbors=3, p=1, weights=uniform;, score=0.893 total time=   1.9s\n",
      "[CV 2/3; 9/36] START n_neighbors=3, p=1, weights=uniform........................\n",
      "[CV 2/3; 9/36] END n_neighbors=3, p=1, weights=uniform;, score=0.891 total time=   2.0s\n",
      "[CV 3/3; 9/36] START n_neighbors=3, p=1, weights=uniform........................\n",
      "[CV 3/3; 9/36] END n_neighbors=3, p=1, weights=uniform;, score=0.892 total time=   2.1s\n",
      "[CV 1/3; 10/36] START n_neighbors=3, p=1, weights=distance......................\n",
      "[CV 1/3; 10/36] END n_neighbors=3, p=1, weights=distance;, score=0.889 total time=   1.6s\n",
      "[CV 2/3; 10/36] START n_neighbors=3, p=1, weights=distance......................\n",
      "[CV 2/3; 10/36] END n_neighbors=3, p=1, weights=distance;, score=0.888 total time=   1.5s\n",
      "[CV 3/3; 10/36] START n_neighbors=3, p=1, weights=distance......................\n",
      "[CV 3/3; 10/36] END n_neighbors=3, p=1, weights=distance;, score=0.888 total time=   1.5s\n",
      "[CV 1/3; 11/36] START n_neighbors=3, p=2, weights=uniform.......................\n",
      "[CV 1/3; 11/36] END n_neighbors=3, p=2, weights=uniform;, score=0.889 total time=   1.1s\n",
      "[CV 2/3; 11/36] START n_neighbors=3, p=2, weights=uniform.......................\n",
      "[CV 2/3; 11/36] END n_neighbors=3, p=2, weights=uniform;, score=0.886 total time=   1.1s\n",
      "[CV 3/3; 11/36] START n_neighbors=3, p=2, weights=uniform.......................\n",
      "[CV 3/3; 11/36] END n_neighbors=3, p=2, weights=uniform;, score=0.888 total time=   1.0s\n",
      "[CV 1/3; 12/36] START n_neighbors=3, p=2, weights=distance......................\n",
      "[CV 1/3; 12/36] END n_neighbors=3, p=2, weights=distance;, score=0.885 total time=   0.6s\n",
      "[CV 2/3; 12/36] START n_neighbors=3, p=2, weights=distance......................\n",
      "[CV 2/3; 12/36] END n_neighbors=3, p=2, weights=distance;, score=0.884 total time=   0.5s\n",
      "[CV 3/3; 12/36] START n_neighbors=3, p=2, weights=distance......................\n",
      "[CV 3/3; 12/36] END n_neighbors=3, p=2, weights=distance;, score=0.884 total time=   0.5s\n",
      "[CV 1/3; 13/36] START n_neighbors=4, p=1, weights=uniform.......................\n",
      "[CV 1/3; 13/36] END n_neighbors=4, p=1, weights=uniform;, score=0.898 total time=   1.9s\n",
      "[CV 2/3; 13/36] START n_neighbors=4, p=1, weights=uniform.......................\n",
      "[CV 2/3; 13/36] END n_neighbors=4, p=1, weights=uniform;, score=0.895 total time=   2.0s\n",
      "[CV 3/3; 13/36] START n_neighbors=4, p=1, weights=uniform.......................\n",
      "[CV 3/3; 13/36] END n_neighbors=4, p=1, weights=uniform;, score=0.893 total time=   2.1s\n",
      "[CV 1/3; 14/36] START n_neighbors=4, p=1, weights=distance......................\n",
      "[CV 1/3; 14/36] END n_neighbors=4, p=1, weights=distance;, score=0.891 total time=   1.6s\n",
      "[CV 2/3; 14/36] START n_neighbors=4, p=1, weights=distance......................\n",
      "[CV 2/3; 14/36] END n_neighbors=4, p=1, weights=distance;, score=0.891 total time=   1.5s\n",
      "[CV 3/3; 14/36] START n_neighbors=4, p=1, weights=distance......................\n",
      "[CV 3/3; 14/36] END n_neighbors=4, p=1, weights=distance;, score=0.891 total time=   1.5s\n",
      "[CV 1/3; 15/36] START n_neighbors=4, p=2, weights=uniform.......................\n",
      "[CV 1/3; 15/36] END n_neighbors=4, p=2, weights=uniform;, score=0.894 total time=   1.0s\n",
      "[CV 2/3; 15/36] START n_neighbors=4, p=2, weights=uniform.......................\n",
      "[CV 2/3; 15/36] END n_neighbors=4, p=2, weights=uniform;, score=0.890 total time=   1.0s\n",
      "[CV 3/3; 15/36] START n_neighbors=4, p=2, weights=uniform.......................\n",
      "[CV 3/3; 15/36] END n_neighbors=4, p=2, weights=uniform;, score=0.889 total time=   1.0s\n",
      "[CV 1/3; 16/36] START n_neighbors=4, p=2, weights=distance......................\n",
      "[CV 1/3; 16/36] END n_neighbors=4, p=2, weights=distance;, score=0.886 total time=   0.6s\n",
      "[CV 2/3; 16/36] START n_neighbors=4, p=2, weights=distance......................\n",
      "[CV 2/3; 16/36] END n_neighbors=4, p=2, weights=distance;, score=0.886 total time=   0.5s\n",
      "[CV 3/3; 16/36] START n_neighbors=4, p=2, weights=distance......................\n",
      "[CV 3/3; 16/36] END n_neighbors=4, p=2, weights=distance;, score=0.886 total time=   0.5s\n",
      "[CV 1/3; 17/36] START n_neighbors=5, p=1, weights=uniform.......................\n",
      "[CV 1/3; 17/36] END n_neighbors=5, p=1, weights=uniform;, score=0.898 total time=   1.9s\n",
      "[CV 2/3; 17/36] START n_neighbors=5, p=1, weights=uniform.......................\n",
      "[CV 2/3; 17/36] END n_neighbors=5, p=1, weights=uniform;, score=0.896 total time=   2.0s\n",
      "[CV 3/3; 17/36] START n_neighbors=5, p=1, weights=uniform.......................\n",
      "[CV 3/3; 17/36] END n_neighbors=5, p=1, weights=uniform;, score=0.895 total time=   1.9s\n",
      "[CV 1/3; 18/36] START n_neighbors=5, p=1, weights=distance......................\n",
      "[CV 1/3; 18/36] END n_neighbors=5, p=1, weights=distance;, score=0.893 total time=   1.6s\n",
      "[CV 2/3; 18/36] START n_neighbors=5, p=1, weights=distance......................\n",
      "[CV 2/3; 18/36] END n_neighbors=5, p=1, weights=distance;, score=0.893 total time=   1.5s\n",
      "[CV 3/3; 18/36] START n_neighbors=5, p=1, weights=distance......................\n",
      "[CV 3/3; 18/36] END n_neighbors=5, p=1, weights=distance;, score=0.892 total time=   1.6s\n",
      "[CV 1/3; 19/36] START n_neighbors=5, p=2, weights=uniform.......................\n",
      "[CV 1/3; 19/36] END n_neighbors=5, p=2, weights=uniform;, score=0.895 total time=   1.1s\n",
      "[CV 2/3; 19/36] START n_neighbors=5, p=2, weights=uniform.......................\n",
      "[CV 2/3; 19/36] END n_neighbors=5, p=2, weights=uniform;, score=0.892 total time=   1.1s\n",
      "[CV 3/3; 19/36] START n_neighbors=5, p=2, weights=uniform.......................\n",
      "[CV 3/3; 19/36] END n_neighbors=5, p=2, weights=uniform;, score=0.891 total time=   1.0s\n",
      "[CV 1/3; 20/36] START n_neighbors=5, p=2, weights=distance......................\n",
      "[CV 1/3; 20/36] END n_neighbors=5, p=2, weights=distance;, score=0.890 total time=   0.6s\n",
      "[CV 2/3; 20/36] START n_neighbors=5, p=2, weights=distance......................\n",
      "[CV 2/3; 20/36] END n_neighbors=5, p=2, weights=distance;, score=0.889 total time=   0.5s\n",
      "[CV 3/3; 20/36] START n_neighbors=5, p=2, weights=distance......................\n",
      "[CV 3/3; 20/36] END n_neighbors=5, p=2, weights=distance;, score=0.888 total time=   0.5s\n",
      "[CV 1/3; 21/36] START n_neighbors=6, p=1, weights=uniform.......................\n",
      "[CV 1/3; 21/36] END n_neighbors=6, p=1, weights=uniform;, score=0.898 total time=   1.9s\n",
      "[CV 2/3; 21/36] START n_neighbors=6, p=1, weights=uniform.......................\n",
      "[CV 2/3; 21/36] END n_neighbors=6, p=1, weights=uniform;, score=0.896 total time=   2.0s\n",
      "[CV 3/3; 21/36] START n_neighbors=6, p=1, weights=uniform.......................\n",
      "[CV 3/3; 21/36] END n_neighbors=6, p=1, weights=uniform;, score=0.896 total time=   2.0s\n",
      "[CV 1/3; 22/36] START n_neighbors=6, p=1, weights=distance......................\n",
      "[CV 1/3; 22/36] END n_neighbors=6, p=1, weights=distance;, score=0.893 total time=   1.6s\n",
      "[CV 2/3; 22/36] START n_neighbors=6, p=1, weights=distance......................\n",
      "[CV 2/3; 22/36] END n_neighbors=6, p=1, weights=distance;, score=0.893 total time=   1.6s\n",
      "[CV 3/3; 22/36] START n_neighbors=6, p=1, weights=distance......................\n",
      "[CV 3/3; 22/36] END n_neighbors=6, p=1, weights=distance;, score=0.893 total time=   1.6s\n",
      "[CV 1/3; 23/36] START n_neighbors=6, p=2, weights=uniform.......................\n",
      "[CV 1/3; 23/36] END n_neighbors=6, p=2, weights=uniform;, score=0.896 total time=   1.0s\n",
      "[CV 2/3; 23/36] START n_neighbors=6, p=2, weights=uniform.......................\n",
      "[CV 2/3; 23/36] END n_neighbors=6, p=2, weights=uniform;, score=0.893 total time=   1.0s\n",
      "[CV 3/3; 23/36] START n_neighbors=6, p=2, weights=uniform.......................\n",
      "[CV 3/3; 23/36] END n_neighbors=6, p=2, weights=uniform;, score=0.893 total time=   1.0s\n",
      "[CV 1/3; 24/36] START n_neighbors=6, p=2, weights=distance......................\n",
      "[CV 1/3; 24/36] END n_neighbors=6, p=2, weights=distance;, score=0.890 total time=   0.6s\n",
      "[CV 2/3; 24/36] START n_neighbors=6, p=2, weights=distance......................\n",
      "[CV 2/3; 24/36] END n_neighbors=6, p=2, weights=distance;, score=0.890 total time=   0.5s\n",
      "[CV 3/3; 24/36] START n_neighbors=6, p=2, weights=distance......................\n",
      "[CV 3/3; 24/36] END n_neighbors=6, p=2, weights=distance;, score=0.889 total time=   0.5s\n",
      "[CV 1/3; 25/36] START n_neighbors=7, p=1, weights=uniform.......................\n",
      "[CV 1/3; 25/36] END n_neighbors=7, p=1, weights=uniform;, score=0.898 total time=   2.0s\n",
      "[CV 2/3; 25/36] START n_neighbors=7, p=1, weights=uniform.......................\n",
      "[CV 2/3; 25/36] END n_neighbors=7, p=1, weights=uniform;, score=0.897 total time=   2.1s\n",
      "[CV 3/3; 25/36] START n_neighbors=7, p=1, weights=uniform.......................\n",
      "[CV 3/3; 25/36] END n_neighbors=7, p=1, weights=uniform;, score=0.897 total time=   2.0s\n",
      "[CV 1/3; 26/36] START n_neighbors=7, p=1, weights=distance......................\n",
      "[CV 1/3; 26/36] END n_neighbors=7, p=1, weights=distance;, score=0.895 total time=   1.5s\n",
      "[CV 2/3; 26/36] START n_neighbors=7, p=1, weights=distance......................\n",
      "[CV 2/3; 26/36] END n_neighbors=7, p=1, weights=distance;, score=0.894 total time=   1.5s\n",
      "[CV 3/3; 26/36] START n_neighbors=7, p=1, weights=distance......................\n",
      "[CV 3/3; 26/36] END n_neighbors=7, p=1, weights=distance;, score=0.894 total time=   1.5s\n",
      "[CV 1/3; 27/36] START n_neighbors=7, p=2, weights=uniform.......................\n",
      "[CV 1/3; 27/36] END n_neighbors=7, p=2, weights=uniform;, score=0.894 total time=   0.9s\n",
      "[CV 2/3; 27/36] START n_neighbors=7, p=2, weights=uniform.......................\n",
      "[CV 2/3; 27/36] END n_neighbors=7, p=2, weights=uniform;, score=0.894 total time=   1.0s\n",
      "[CV 3/3; 27/36] START n_neighbors=7, p=2, weights=uniform.......................\n",
      "[CV 3/3; 27/36] END n_neighbors=7, p=2, weights=uniform;, score=0.894 total time=   1.0s\n",
      "[CV 1/3; 28/36] START n_neighbors=7, p=2, weights=distance......................\n",
      "[CV 1/3; 28/36] END n_neighbors=7, p=2, weights=distance;, score=0.890 total time=   0.5s\n",
      "[CV 2/3; 28/36] START n_neighbors=7, p=2, weights=distance......................\n",
      "[CV 2/3; 28/36] END n_neighbors=7, p=2, weights=distance;, score=0.890 total time=   0.5s\n",
      "[CV 3/3; 28/36] START n_neighbors=7, p=2, weights=distance......................\n",
      "[CV 3/3; 28/36] END n_neighbors=7, p=2, weights=distance;, score=0.890 total time=   0.5s\n",
      "[CV 1/3; 29/36] START n_neighbors=8, p=1, weights=uniform.......................\n",
      "[CV 1/3; 29/36] END n_neighbors=8, p=1, weights=uniform;, score=0.898 total time=   2.0s\n",
      "[CV 2/3; 29/36] START n_neighbors=8, p=1, weights=uniform.......................\n",
      "[CV 2/3; 29/36] END n_neighbors=8, p=1, weights=uniform;, score=0.897 total time=   2.0s\n",
      "[CV 3/3; 29/36] START n_neighbors=8, p=1, weights=uniform.......................\n",
      "[CV 3/3; 29/36] END n_neighbors=8, p=1, weights=uniform;, score=0.896 total time=   2.1s\n",
      "[CV 1/3; 30/36] START n_neighbors=8, p=1, weights=distance......................\n",
      "[CV 1/3; 30/36] END n_neighbors=8, p=1, weights=distance;, score=0.895 total time=   1.7s\n",
      "[CV 2/3; 30/36] START n_neighbors=8, p=1, weights=distance......................\n",
      "[CV 2/3; 30/36] END n_neighbors=8, p=1, weights=distance;, score=0.894 total time=   1.6s\n",
      "[CV 3/3; 30/36] START n_neighbors=8, p=1, weights=distance......................\n",
      "[CV 3/3; 30/36] END n_neighbors=8, p=1, weights=distance;, score=0.895 total time=   1.8s\n",
      "[CV 1/3; 31/36] START n_neighbors=8, p=2, weights=uniform.......................\n",
      "[CV 1/3; 31/36] END n_neighbors=8, p=2, weights=uniform;, score=0.895 total time=   1.0s\n",
      "[CV 2/3; 31/36] START n_neighbors=8, p=2, weights=uniform.......................\n",
      "[CV 2/3; 31/36] END n_neighbors=8, p=2, weights=uniform;, score=0.895 total time=   1.0s\n",
      "[CV 3/3; 31/36] START n_neighbors=8, p=2, weights=uniform.......................\n",
      "[CV 3/3; 31/36] END n_neighbors=8, p=2, weights=uniform;, score=0.894 total time=   1.1s\n",
      "[CV 1/3; 32/36] START n_neighbors=8, p=2, weights=distance......................\n",
      "[CV 1/3; 32/36] END n_neighbors=8, p=2, weights=distance;, score=0.891 total time=   0.6s\n",
      "[CV 2/3; 32/36] START n_neighbors=8, p=2, weights=distance......................\n",
      "[CV 2/3; 32/36] END n_neighbors=8, p=2, weights=distance;, score=0.892 total time=   0.5s\n",
      "[CV 3/3; 32/36] START n_neighbors=8, p=2, weights=distance......................\n",
      "[CV 3/3; 32/36] END n_neighbors=8, p=2, weights=distance;, score=0.890 total time=   0.5s\n",
      "[CV 1/3; 33/36] START n_neighbors=9, p=1, weights=uniform.......................\n",
      "[CV 1/3; 33/36] END n_neighbors=9, p=1, weights=uniform;, score=0.897 total time=   2.1s\n",
      "[CV 2/3; 33/36] START n_neighbors=9, p=1, weights=uniform.......................\n",
      "[CV 2/3; 33/36] END n_neighbors=9, p=1, weights=uniform;, score=0.896 total time=   2.0s\n",
      "[CV 3/3; 33/36] START n_neighbors=9, p=1, weights=uniform.......................\n",
      "[CV 3/3; 33/36] END n_neighbors=9, p=1, weights=uniform;, score=0.897 total time=   2.0s\n",
      "[CV 1/3; 34/36] START n_neighbors=9, p=1, weights=distance......................\n",
      "[CV 1/3; 34/36] END n_neighbors=9, p=1, weights=distance;, score=0.895 total time=   1.6s\n",
      "[CV 2/3; 34/36] START n_neighbors=9, p=1, weights=distance......................\n",
      "[CV 2/3; 34/36] END n_neighbors=9, p=1, weights=distance;, score=0.895 total time=   1.9s\n",
      "[CV 3/3; 34/36] START n_neighbors=9, p=1, weights=distance......................\n",
      "[CV 3/3; 34/36] END n_neighbors=9, p=1, weights=distance;, score=0.894 total time=   1.8s\n",
      "[CV 1/3; 35/36] START n_neighbors=9, p=2, weights=uniform.......................\n",
      "[CV 1/3; 35/36] END n_neighbors=9, p=2, weights=uniform;, score=0.894 total time=   1.1s\n",
      "[CV 2/3; 35/36] START n_neighbors=9, p=2, weights=uniform.......................\n",
      "[CV 2/3; 35/36] END n_neighbors=9, p=2, weights=uniform;, score=0.895 total time=   1.0s\n",
      "[CV 3/3; 35/36] START n_neighbors=9, p=2, weights=uniform.......................\n",
      "[CV 3/3; 35/36] END n_neighbors=9, p=2, weights=uniform;, score=0.895 total time=   1.0s\n",
      "[CV 1/3; 36/36] START n_neighbors=9, p=2, weights=distance......................\n",
      "[CV 1/3; 36/36] END n_neighbors=9, p=2, weights=distance;, score=0.891 total time=   0.6s\n",
      "[CV 2/3; 36/36] START n_neighbors=9, p=2, weights=distance......................\n",
      "[CV 2/3; 36/36] END n_neighbors=9, p=2, weights=distance;, score=0.893 total time=   0.5s\n",
      "[CV 3/3; 36/36] START n_neighbors=9, p=2, weights=distance......................\n",
      "[CV 3/3; 36/36] END n_neighbors=9, p=2, weights=distance;, score=0.891 total time=   0.5s\n"
     ]
    }
   ],
   "source": [
    "neighborClassifier = KNeighborsClassifier()\n",
    "neighborGrid = {'n_neighbors': list(range(1,10)),\n",
    "               'weights': ['uniform', 'distance'],\n",
    "               'p': [1,2]\n",
    "               }\n",
    "neighborSearch = GridSearchCV(neighborClassifier, neighborGrid, cv = 3, verbose=10).fit(Xdata, Ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2a5abbc-f561-4ae5-8159-73707ff15b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8973961022004832\n",
      "{'n_neighbors': 7, 'p': 1, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "print(neighborSearch.best_score_)\n",
    "print(neighborSearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d641e1-dc63-423c-a6c3-b5aac804ddd0",
   "metadata": {},
   "source": [
    "Now we are going to try to scale the data to follow a normal distribution to show how the accuracy changes. We expect an improvement in algorithms such as KNN because of how the distance metric is used. We will also create a seperate train and test split to see how our data performs with unseen data at the end. This is used because if KNN is trained on all the data, it accurately predicts all the labels and we can not tell any measure metrics from it in this case. K-fold cross validation is still used to select paramaters for each algorithm however"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e22624d-929b-4158-90fe-c9b18282c2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>loan_intent_DEBTCONSOLIDATION</th>\n",
       "      <th>loan_intent_EDUCATION</th>\n",
       "      <th>loan_intent_HOMEIMPROVEMENT</th>\n",
       "      <th>loan_intent_MEDICAL</th>\n",
       "      <th>loan_intent_PERSONAL</th>\n",
       "      <th>loan_intent_VENTURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.566172</td>\n",
       "      <td>-0.765773</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.204637</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.578273</td>\n",
       "      <td>0.267652</td>\n",
       "      <td>0.117405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.031764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.920068</td>\n",
       "      <td>-0.212089</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.334186</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.937772</td>\n",
       "      <td>0.880574</td>\n",
       "      <td>-0.973240</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.946495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.240177</td>\n",
       "      <td>-0.929242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.847127</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.578273</td>\n",
       "      <td>-0.585825</td>\n",
       "      <td>0.553663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.039011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.405927</td>\n",
       "      <td>0.157034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.385950</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.500225</td>\n",
       "      <td>0.142432</td>\n",
       "      <td>0.117405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.201930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.920068</td>\n",
       "      <td>-0.106625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.691696</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.578273</td>\n",
       "      <td>-1.238291</td>\n",
       "      <td>-0.646047</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.698307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58640</th>\n",
       "      <td>1.068924</td>\n",
       "      <td>1.475330</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.077716</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.836969</td>\n",
       "      <td>1.737347</td>\n",
       "      <td>0.553663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.039011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58641</th>\n",
       "      <td>0.074428</td>\n",
       "      <td>-0.929242</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.204637</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.140725</td>\n",
       "      <td>0.676267</td>\n",
       "      <td>2.080566</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.542634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58642</th>\n",
       "      <td>-0.754319</td>\n",
       "      <td>-0.528480</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.590657</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.434473</td>\n",
       "      <td>1.753824</td>\n",
       "      <td>-0.100724</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.946495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58643</th>\n",
       "      <td>-0.920068</td>\n",
       "      <td>-0.897603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.691696</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.758023</td>\n",
       "      <td>-0.585825</td>\n",
       "      <td>0.117405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.698307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58644</th>\n",
       "      <td>0.571676</td>\n",
       "      <td>0.288864</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.691696</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.039473</td>\n",
       "      <td>0.142432</td>\n",
       "      <td>0.444598</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.201930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58643 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       person_age  person_income  person_home_ownership  person_emp_length  \\\n",
       "0        1.566172      -0.765773                    1.0          -1.204637   \n",
       "1       -0.920068      -0.212089                    3.0           0.334186   \n",
       "2        0.240177      -0.929242                    3.0           0.847127   \n",
       "3        0.405927       0.157034                    1.0           2.385950   \n",
       "4       -0.920068      -0.106625                    1.0          -0.691696   \n",
       "...           ...            ...                    ...                ...   \n",
       "58640    1.068924       1.475330                    2.0           0.077716   \n",
       "58641    0.074428      -0.929242                    1.0          -1.204637   \n",
       "58642   -0.754319      -0.528480                    1.0           0.590657   \n",
       "58643   -0.920068      -0.897603                    1.0          -0.691696   \n",
       "58644    0.571676       0.288864                    2.0          -0.691696   \n",
       "\n",
       "       loan_grade  loan_amnt  loan_int_rate  loan_percent_income  \\\n",
       "0             5.0  -0.578273       0.267652             0.117405   \n",
       "1             4.0  -0.937772       0.880574            -0.973240   \n",
       "2             6.0  -0.578273      -0.585825             0.553663   \n",
       "3             5.0   0.500225       0.142432             0.117405   \n",
       "4             6.0  -0.578273      -1.238291            -0.646047   \n",
       "...           ...        ...            ...                  ...   \n",
       "58640         3.0   2.836969       1.737347             0.553663   \n",
       "58641         4.0   0.140725       0.676267             2.080566   \n",
       "58642         3.0  -0.434473       1.753824            -0.100724   \n",
       "58643         6.0  -0.758023      -0.585825             0.117405   \n",
       "58644         5.0   1.039473       0.142432             0.444598   \n",
       "\n",
       "       cb_person_default_on_file  cb_person_cred_hist_length  \\\n",
       "0                            1.0                    2.031764   \n",
       "1                            1.0                   -0.946495   \n",
       "2                            1.0                    1.039011   \n",
       "3                            1.0                   -0.201930   \n",
       "4                            1.0                   -0.698307   \n",
       "...                          ...                         ...   \n",
       "58640                        0.0                    1.039011   \n",
       "58641                        1.0                    0.542634   \n",
       "58642                        1.0                   -0.946495   \n",
       "58643                        1.0                   -0.698307   \n",
       "58644                        1.0                   -0.201930   \n",
       "\n",
       "       loan_intent_DEBTCONSOLIDATION  loan_intent_EDUCATION  \\\n",
       "0                                0.0                    1.0   \n",
       "1                                0.0                    0.0   \n",
       "2                                0.0                    0.0   \n",
       "3                                0.0                    0.0   \n",
       "4                                0.0                    0.0   \n",
       "...                              ...                    ...   \n",
       "58640                            0.0                    1.0   \n",
       "58641                            0.0                    0.0   \n",
       "58642                            0.0                    1.0   \n",
       "58643                            0.0                    1.0   \n",
       "58644                            0.0                    0.0   \n",
       "\n",
       "       loan_intent_HOMEIMPROVEMENT  loan_intent_MEDICAL  loan_intent_PERSONAL  \\\n",
       "0                              0.0                  0.0                   0.0   \n",
       "1                              0.0                  1.0                   0.0   \n",
       "2                              0.0                  0.0                   1.0   \n",
       "3                              0.0                  0.0                   0.0   \n",
       "4                              0.0                  1.0                   0.0   \n",
       "...                            ...                  ...                   ...   \n",
       "58640                          0.0                  0.0                   0.0   \n",
       "58641                          0.0                  1.0                   0.0   \n",
       "58642                          0.0                  0.0                   0.0   \n",
       "58643                          0.0                  0.0                   0.0   \n",
       "58644                          0.0                  0.0                   0.0   \n",
       "\n",
       "       loan_intent_VENTURE  \n",
       "0                      0.0  \n",
       "1                      0.0  \n",
       "2                      0.0  \n",
       "3                      1.0  \n",
       "4                      0.0  \n",
       "...                    ...  \n",
       "58640                  0.0  \n",
       "58641                  0.0  \n",
       "58642                  0.0  \n",
       "58643                  0.0  \n",
       "58644                  1.0  \n",
       "\n",
       "[58643 rows x 16 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "Xscaled = Xdata.copy()\n",
    "Xscaled[continuousCols] = StandardScaler().fit_transform(Xscaled[continuousCols])\n",
    "display(Xscaled)\n",
    "Xscaled_train, Xscaled_val, y_train, y_val = train_test_split(Xscaled, Ydata, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead36e65-5ce5-4aaf-8882-c48e72449379",
   "metadata": {},
   "source": [
    "lets check to make sure there are about the same distribution of 1's and 0's in the train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "994af9e7-5f13-4725-bd4a-c80597e9fb22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_status\n",
       "0    40189\n",
       "1     6725\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "loan_status\n",
       "0    10105\n",
       "1     1624\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y_train.value_counts())\n",
    "display(y_val.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b01e8a9-569e-475c-9277-10f091449da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "[CV 1/3; 1/36] START n_neighbors=1, p=1, weights=uniform........................\n",
      "[CV 1/3; 1/36] END n_neighbors=1, p=1, weights=uniform;, score=0.899 total time=   1.3s\n",
      "[CV 2/3; 1/36] START n_neighbors=1, p=1, weights=uniform........................\n",
      "[CV 2/3; 1/36] END n_neighbors=1, p=1, weights=uniform;, score=0.901 total time=   1.4s\n",
      "[CV 3/3; 1/36] START n_neighbors=1, p=1, weights=uniform........................\n",
      "[CV 3/3; 1/36] END n_neighbors=1, p=1, weights=uniform;, score=0.900 total time=   1.5s\n",
      "[CV 1/3; 2/36] START n_neighbors=1, p=1, weights=distance.......................\n",
      "[CV 1/3; 2/36] END n_neighbors=1, p=1, weights=distance;, score=0.899 total time=   1.0s\n",
      "[CV 2/3; 2/36] START n_neighbors=1, p=1, weights=distance.......................\n",
      "[CV 2/3; 2/36] END n_neighbors=1, p=1, weights=distance;, score=0.901 total time=   0.9s\n",
      "[CV 3/3; 2/36] START n_neighbors=1, p=1, weights=distance.......................\n",
      "[CV 3/3; 2/36] END n_neighbors=1, p=1, weights=distance;, score=0.900 total time=   0.9s\n",
      "[CV 1/3; 3/36] START n_neighbors=1, p=2, weights=uniform........................\n",
      "[CV 1/3; 3/36] END n_neighbors=1, p=2, weights=uniform;, score=0.898 total time=   0.7s\n",
      "[CV 2/3; 3/36] START n_neighbors=1, p=2, weights=uniform........................\n",
      "[CV 2/3; 3/36] END n_neighbors=1, p=2, weights=uniform;, score=0.900 total time=   0.8s\n",
      "[CV 3/3; 3/36] START n_neighbors=1, p=2, weights=uniform........................\n",
      "[CV 3/3; 3/36] END n_neighbors=1, p=2, weights=uniform;, score=0.899 total time=   0.8s\n",
      "[CV 1/3; 4/36] START n_neighbors=1, p=2, weights=distance.......................\n",
      "[CV 1/3; 4/36] END n_neighbors=1, p=2, weights=distance;, score=0.898 total time=   0.4s\n",
      "[CV 2/3; 4/36] START n_neighbors=1, p=2, weights=distance.......................\n",
      "[CV 2/3; 4/36] END n_neighbors=1, p=2, weights=distance;, score=0.900 total time=   0.3s\n",
      "[CV 3/3; 4/36] START n_neighbors=1, p=2, weights=distance.......................\n",
      "[CV 3/3; 4/36] END n_neighbors=1, p=2, weights=distance;, score=0.899 total time=   0.3s\n",
      "[CV 1/3; 5/36] START n_neighbors=2, p=1, weights=uniform........................\n",
      "[CV 1/3; 5/36] END n_neighbors=2, p=1, weights=uniform;, score=0.918 total time=   1.3s\n",
      "[CV 2/3; 5/36] START n_neighbors=2, p=1, weights=uniform........................\n",
      "[CV 2/3; 5/36] END n_neighbors=2, p=1, weights=uniform;, score=0.917 total time=   1.4s\n",
      "[CV 3/3; 5/36] START n_neighbors=2, p=1, weights=uniform........................\n",
      "[CV 3/3; 5/36] END n_neighbors=2, p=1, weights=uniform;, score=0.920 total time=   1.4s\n",
      "[CV 1/3; 6/36] START n_neighbors=2, p=1, weights=distance.......................\n",
      "[CV 1/3; 6/36] END n_neighbors=2, p=1, weights=distance;, score=0.899 total time=   1.1s\n",
      "[CV 2/3; 6/36] START n_neighbors=2, p=1, weights=distance.......................\n",
      "[CV 2/3; 6/36] END n_neighbors=2, p=1, weights=distance;, score=0.901 total time=   1.0s\n",
      "[CV 3/3; 6/36] START n_neighbors=2, p=1, weights=distance.......................\n",
      "[CV 3/3; 6/36] END n_neighbors=2, p=1, weights=distance;, score=0.900 total time=   1.0s\n",
      "[CV 1/3; 7/36] START n_neighbors=2, p=2, weights=uniform........................\n",
      "[CV 1/3; 7/36] END n_neighbors=2, p=2, weights=uniform;, score=0.917 total time=   0.7s\n",
      "[CV 2/3; 7/36] START n_neighbors=2, p=2, weights=uniform........................\n",
      "[CV 2/3; 7/36] END n_neighbors=2, p=2, weights=uniform;, score=0.920 total time=   0.7s\n",
      "[CV 3/3; 7/36] START n_neighbors=2, p=2, weights=uniform........................\n",
      "[CV 3/3; 7/36] END n_neighbors=2, p=2, weights=uniform;, score=0.921 total time=   0.8s\n",
      "[CV 1/3; 8/36] START n_neighbors=2, p=2, weights=distance.......................\n",
      "[CV 1/3; 8/36] END n_neighbors=2, p=2, weights=distance;, score=0.898 total time=   0.3s\n",
      "[CV 2/3; 8/36] START n_neighbors=2, p=2, weights=distance.......................\n",
      "[CV 2/3; 8/36] END n_neighbors=2, p=2, weights=distance;, score=0.900 total time=   0.3s\n",
      "[CV 3/3; 8/36] START n_neighbors=2, p=2, weights=distance.......................\n",
      "[CV 3/3; 8/36] END n_neighbors=2, p=2, weights=distance;, score=0.899 total time=   0.3s\n",
      "[CV 1/3; 9/36] START n_neighbors=3, p=1, weights=uniform........................\n",
      "[CV 1/3; 9/36] END n_neighbors=3, p=1, weights=uniform;, score=0.923 total time=   1.3s\n",
      "[CV 2/3; 9/36] START n_neighbors=3, p=1, weights=uniform........................\n",
      "[CV 2/3; 9/36] END n_neighbors=3, p=1, weights=uniform;, score=0.926 total time=   1.5s\n",
      "[CV 3/3; 9/36] START n_neighbors=3, p=1, weights=uniform........................\n",
      "[CV 3/3; 9/36] END n_neighbors=3, p=1, weights=uniform;, score=0.924 total time=   1.4s\n",
      "[CV 1/3; 10/36] START n_neighbors=3, p=1, weights=distance......................\n",
      "[CV 1/3; 10/36] END n_neighbors=3, p=1, weights=distance;, score=0.922 total time=   1.0s\n",
      "[CV 2/3; 10/36] START n_neighbors=3, p=1, weights=distance......................\n",
      "[CV 2/3; 10/36] END n_neighbors=3, p=1, weights=distance;, score=0.925 total time=   1.0s\n",
      "[CV 3/3; 10/36] START n_neighbors=3, p=1, weights=distance......................\n",
      "[CV 3/3; 10/36] END n_neighbors=3, p=1, weights=distance;, score=0.924 total time=   0.9s\n",
      "[CV 1/3; 11/36] START n_neighbors=3, p=2, weights=uniform.......................\n",
      "[CV 1/3; 11/36] END n_neighbors=3, p=2, weights=uniform;, score=0.922 total time=   0.7s\n",
      "[CV 2/3; 11/36] START n_neighbors=3, p=2, weights=uniform.......................\n",
      "[CV 2/3; 11/36] END n_neighbors=3, p=2, weights=uniform;, score=0.925 total time=   0.8s\n",
      "[CV 3/3; 11/36] START n_neighbors=3, p=2, weights=uniform.......................\n",
      "[CV 3/3; 11/36] END n_neighbors=3, p=2, weights=uniform;, score=0.924 total time=   0.8s\n",
      "[CV 1/3; 12/36] START n_neighbors=3, p=2, weights=distance......................\n",
      "[CV 1/3; 12/36] END n_neighbors=3, p=2, weights=distance;, score=0.922 total time=   0.3s\n",
      "[CV 2/3; 12/36] START n_neighbors=3, p=2, weights=distance......................\n",
      "[CV 2/3; 12/36] END n_neighbors=3, p=2, weights=distance;, score=0.925 total time=   0.3s\n",
      "[CV 3/3; 12/36] START n_neighbors=3, p=2, weights=distance......................\n",
      "[CV 3/3; 12/36] END n_neighbors=3, p=2, weights=distance;, score=0.923 total time=   0.3s\n",
      "[CV 1/3; 13/36] START n_neighbors=4, p=1, weights=uniform.......................\n",
      "[CV 1/3; 13/36] END n_neighbors=4, p=1, weights=uniform;, score=0.925 total time=   1.4s\n",
      "[CV 2/3; 13/36] START n_neighbors=4, p=1, weights=uniform.......................\n",
      "[CV 2/3; 13/36] END n_neighbors=4, p=1, weights=uniform;, score=0.928 total time=   1.5s\n",
      "[CV 3/3; 13/36] START n_neighbors=4, p=1, weights=uniform.......................\n",
      "[CV 3/3; 13/36] END n_neighbors=4, p=1, weights=uniform;, score=0.928 total time=   1.4s\n",
      "[CV 1/3; 14/36] START n_neighbors=4, p=1, weights=distance......................\n",
      "[CV 1/3; 14/36] END n_neighbors=4, p=1, weights=distance;, score=0.923 total time=   1.1s\n",
      "[CV 2/3; 14/36] START n_neighbors=4, p=1, weights=distance......................\n",
      "[CV 2/3; 14/36] END n_neighbors=4, p=1, weights=distance;, score=0.927 total time=   1.0s\n",
      "[CV 3/3; 14/36] START n_neighbors=4, p=1, weights=distance......................\n",
      "[CV 3/3; 14/36] END n_neighbors=4, p=1, weights=distance;, score=0.927 total time=   1.0s\n",
      "[CV 1/3; 15/36] START n_neighbors=4, p=2, weights=uniform.......................\n",
      "[CV 1/3; 15/36] END n_neighbors=4, p=2, weights=uniform;, score=0.925 total time=   0.7s\n",
      "[CV 2/3; 15/36] START n_neighbors=4, p=2, weights=uniform.......................\n",
      "[CV 2/3; 15/36] END n_neighbors=4, p=2, weights=uniform;, score=0.927 total time=   0.7s\n",
      "[CV 3/3; 15/36] START n_neighbors=4, p=2, weights=uniform.......................\n",
      "[CV 3/3; 15/36] END n_neighbors=4, p=2, weights=uniform;, score=0.929 total time=   0.7s\n",
      "[CV 1/3; 16/36] START n_neighbors=4, p=2, weights=distance......................\n",
      "[CV 1/3; 16/36] END n_neighbors=4, p=2, weights=distance;, score=0.925 total time=   0.4s\n",
      "[CV 2/3; 16/36] START n_neighbors=4, p=2, weights=distance......................\n",
      "[CV 2/3; 16/36] END n_neighbors=4, p=2, weights=distance;, score=0.926 total time=   0.3s\n",
      "[CV 3/3; 16/36] START n_neighbors=4, p=2, weights=distance......................\n",
      "[CV 3/3; 16/36] END n_neighbors=4, p=2, weights=distance;, score=0.926 total time=   0.3s\n",
      "[CV 1/3; 17/36] START n_neighbors=5, p=1, weights=uniform.......................\n",
      "[CV 1/3; 17/36] END n_neighbors=5, p=1, weights=uniform;, score=0.929 total time=   1.3s\n",
      "[CV 2/3; 17/36] START n_neighbors=5, p=1, weights=uniform.......................\n",
      "[CV 2/3; 17/36] END n_neighbors=5, p=1, weights=uniform;, score=0.931 total time=   1.4s\n",
      "[CV 3/3; 17/36] START n_neighbors=5, p=1, weights=uniform.......................\n",
      "[CV 3/3; 17/36] END n_neighbors=5, p=1, weights=uniform;, score=0.932 total time=   1.5s\n",
      "[CV 1/3; 18/36] START n_neighbors=5, p=1, weights=distance......................\n",
      "[CV 1/3; 18/36] END n_neighbors=5, p=1, weights=distance;, score=0.929 total time=   1.2s\n",
      "[CV 2/3; 18/36] START n_neighbors=5, p=1, weights=distance......................\n",
      "[CV 2/3; 18/36] END n_neighbors=5, p=1, weights=distance;, score=0.931 total time=   1.0s\n",
      "[CV 3/3; 18/36] START n_neighbors=5, p=1, weights=distance......................\n",
      "[CV 3/3; 18/36] END n_neighbors=5, p=1, weights=distance;, score=0.931 total time=   0.9s\n",
      "[CV 1/3; 19/36] START n_neighbors=5, p=2, weights=uniform.......................\n",
      "[CV 1/3; 19/36] END n_neighbors=5, p=2, weights=uniform;, score=0.927 total time=   0.7s\n",
      "[CV 2/3; 19/36] START n_neighbors=5, p=2, weights=uniform.......................\n",
      "[CV 2/3; 19/36] END n_neighbors=5, p=2, weights=uniform;, score=0.930 total time=   0.8s\n",
      "[CV 3/3; 19/36] START n_neighbors=5, p=2, weights=uniform.......................\n",
      "[CV 3/3; 19/36] END n_neighbors=5, p=2, weights=uniform;, score=0.930 total time=   0.8s\n",
      "[CV 1/3; 20/36] START n_neighbors=5, p=2, weights=distance......................\n",
      "[CV 1/3; 20/36] END n_neighbors=5, p=2, weights=distance;, score=0.926 total time=   0.4s\n",
      "[CV 2/3; 20/36] START n_neighbors=5, p=2, weights=distance......................\n",
      "[CV 2/3; 20/36] END n_neighbors=5, p=2, weights=distance;, score=0.930 total time=   0.3s\n",
      "[CV 3/3; 20/36] START n_neighbors=5, p=2, weights=distance......................\n",
      "[CV 3/3; 20/36] END n_neighbors=5, p=2, weights=distance;, score=0.930 total time=   0.4s\n",
      "[CV 1/3; 21/36] START n_neighbors=6, p=1, weights=uniform.......................\n",
      "[CV 1/3; 21/36] END n_neighbors=6, p=1, weights=uniform;, score=0.929 total time=   1.4s\n",
      "[CV 2/3; 21/36] START n_neighbors=6, p=1, weights=uniform.......................\n",
      "[CV 2/3; 21/36] END n_neighbors=6, p=1, weights=uniform;, score=0.931 total time=   1.5s\n",
      "[CV 3/3; 21/36] START n_neighbors=6, p=1, weights=uniform.......................\n",
      "[CV 3/3; 21/36] END n_neighbors=6, p=1, weights=uniform;, score=0.930 total time=   1.4s\n",
      "[CV 1/3; 22/36] START n_neighbors=6, p=1, weights=distance......................\n",
      "[CV 1/3; 22/36] END n_neighbors=6, p=1, weights=distance;, score=0.930 total time=   1.1s\n",
      "[CV 2/3; 22/36] START n_neighbors=6, p=1, weights=distance......................\n",
      "[CV 2/3; 22/36] END n_neighbors=6, p=1, weights=distance;, score=0.932 total time=   1.1s\n",
      "[CV 3/3; 22/36] START n_neighbors=6, p=1, weights=distance......................\n",
      "[CV 3/3; 22/36] END n_neighbors=6, p=1, weights=distance;, score=0.932 total time=   1.0s\n",
      "[CV 1/3; 23/36] START n_neighbors=6, p=2, weights=uniform.......................\n",
      "[CV 1/3; 23/36] END n_neighbors=6, p=2, weights=uniform;, score=0.926 total time=   0.7s\n",
      "[CV 2/3; 23/36] START n_neighbors=6, p=2, weights=uniform.......................\n",
      "[CV 2/3; 23/36] END n_neighbors=6, p=2, weights=uniform;, score=0.931 total time=   0.8s\n",
      "[CV 3/3; 23/36] START n_neighbors=6, p=2, weights=uniform.......................\n",
      "[CV 3/3; 23/36] END n_neighbors=6, p=2, weights=uniform;, score=0.930 total time=   0.8s\n",
      "[CV 1/3; 24/36] START n_neighbors=6, p=2, weights=distance......................\n",
      "[CV 1/3; 24/36] END n_neighbors=6, p=2, weights=distance;, score=0.928 total time=   0.4s\n",
      "[CV 2/3; 24/36] START n_neighbors=6, p=2, weights=distance......................\n",
      "[CV 2/3; 24/36] END n_neighbors=6, p=2, weights=distance;, score=0.931 total time=   0.3s\n",
      "[CV 3/3; 24/36] START n_neighbors=6, p=2, weights=distance......................\n",
      "[CV 3/3; 24/36] END n_neighbors=6, p=2, weights=distance;, score=0.931 total time=   0.4s\n",
      "[CV 1/3; 25/36] START n_neighbors=7, p=1, weights=uniform.......................\n",
      "[CV 1/3; 25/36] END n_neighbors=7, p=1, weights=uniform;, score=0.931 total time=   1.3s\n",
      "[CV 2/3; 25/36] START n_neighbors=7, p=1, weights=uniform.......................\n",
      "[CV 2/3; 25/36] END n_neighbors=7, p=1, weights=uniform;, score=0.933 total time=   1.4s\n",
      "[CV 3/3; 25/36] START n_neighbors=7, p=1, weights=uniform.......................\n",
      "[CV 3/3; 25/36] END n_neighbors=7, p=1, weights=uniform;, score=0.932 total time=   1.4s\n",
      "[CV 1/3; 26/36] START n_neighbors=7, p=1, weights=distance......................\n",
      "[CV 1/3; 26/36] END n_neighbors=7, p=1, weights=distance;, score=0.931 total time=   1.1s\n",
      "[CV 2/3; 26/36] START n_neighbors=7, p=1, weights=distance......................\n",
      "[CV 2/3; 26/36] END n_neighbors=7, p=1, weights=distance;, score=0.933 total time=   1.0s\n",
      "[CV 3/3; 26/36] START n_neighbors=7, p=1, weights=distance......................\n",
      "[CV 3/3; 26/36] END n_neighbors=7, p=1, weights=distance;, score=0.931 total time=   1.0s\n",
      "[CV 1/3; 27/36] START n_neighbors=7, p=2, weights=uniform.......................\n",
      "[CV 1/3; 27/36] END n_neighbors=7, p=2, weights=uniform;, score=0.928 total time=   0.6s\n",
      "[CV 2/3; 27/36] START n_neighbors=7, p=2, weights=uniform.......................\n",
      "[CV 2/3; 27/36] END n_neighbors=7, p=2, weights=uniform;, score=0.932 total time=   0.7s\n",
      "[CV 3/3; 27/36] START n_neighbors=7, p=2, weights=uniform.......................\n",
      "[CV 3/3; 27/36] END n_neighbors=7, p=2, weights=uniform;, score=0.930 total time=   0.7s\n",
      "[CV 1/3; 28/36] START n_neighbors=7, p=2, weights=distance......................\n",
      "[CV 1/3; 28/36] END n_neighbors=7, p=2, weights=distance;, score=0.928 total time=   0.4s\n",
      "[CV 2/3; 28/36] START n_neighbors=7, p=2, weights=distance......................\n",
      "[CV 2/3; 28/36] END n_neighbors=7, p=2, weights=distance;, score=0.933 total time=   0.3s\n",
      "[CV 3/3; 28/36] START n_neighbors=7, p=2, weights=distance......................\n",
      "[CV 3/3; 28/36] END n_neighbors=7, p=2, weights=distance;, score=0.931 total time=   0.3s\n",
      "[CV 1/3; 29/36] START n_neighbors=8, p=1, weights=uniform.......................\n",
      "[CV 1/3; 29/36] END n_neighbors=8, p=1, weights=uniform;, score=0.929 total time=   1.3s\n",
      "[CV 2/3; 29/36] START n_neighbors=8, p=1, weights=uniform.......................\n",
      "[CV 2/3; 29/36] END n_neighbors=8, p=1, weights=uniform;, score=0.932 total time=   1.5s\n",
      "[CV 3/3; 29/36] START n_neighbors=8, p=1, weights=uniform.......................\n",
      "[CV 3/3; 29/36] END n_neighbors=8, p=1, weights=uniform;, score=0.930 total time=   1.5s\n",
      "[CV 1/3; 30/36] START n_neighbors=8, p=1, weights=distance......................\n",
      "[CV 1/3; 30/36] END n_neighbors=8, p=1, weights=distance;, score=0.932 total time=   1.1s\n",
      "[CV 2/3; 30/36] START n_neighbors=8, p=1, weights=distance......................\n",
      "[CV 2/3; 30/36] END n_neighbors=8, p=1, weights=distance;, score=0.934 total time=   1.0s\n",
      "[CV 3/3; 30/36] START n_neighbors=8, p=1, weights=distance......................\n",
      "[CV 3/3; 30/36] END n_neighbors=8, p=1, weights=distance;, score=0.933 total time=   1.0s\n",
      "[CV 1/3; 31/36] START n_neighbors=8, p=2, weights=uniform.......................\n",
      "[CV 1/3; 31/36] END n_neighbors=8, p=2, weights=uniform;, score=0.927 total time=   0.6s\n",
      "[CV 2/3; 31/36] START n_neighbors=8, p=2, weights=uniform.......................\n",
      "[CV 2/3; 31/36] END n_neighbors=8, p=2, weights=uniform;, score=0.930 total time=   0.7s\n",
      "[CV 3/3; 31/36] START n_neighbors=8, p=2, weights=uniform.......................\n",
      "[CV 3/3; 31/36] END n_neighbors=8, p=2, weights=uniform;, score=0.929 total time=   0.8s\n",
      "[CV 1/3; 32/36] START n_neighbors=8, p=2, weights=distance......................\n",
      "[CV 1/3; 32/36] END n_neighbors=8, p=2, weights=distance;, score=0.930 total time=   0.4s\n",
      "[CV 2/3; 32/36] START n_neighbors=8, p=2, weights=distance......................\n",
      "[CV 2/3; 32/36] END n_neighbors=8, p=2, weights=distance;, score=0.933 total time=   0.3s\n",
      "[CV 3/3; 32/36] START n_neighbors=8, p=2, weights=distance......................\n",
      "[CV 3/3; 32/36] END n_neighbors=8, p=2, weights=distance;, score=0.932 total time=   0.3s\n",
      "[CV 1/3; 33/36] START n_neighbors=9, p=1, weights=uniform.......................\n",
      "[CV 1/3; 33/36] END n_neighbors=9, p=1, weights=uniform;, score=0.932 total time=   1.3s\n",
      "[CV 2/3; 33/36] START n_neighbors=9, p=1, weights=uniform.......................\n",
      "[CV 2/3; 33/36] END n_neighbors=9, p=1, weights=uniform;, score=0.935 total time=   1.4s\n",
      "[CV 3/3; 33/36] START n_neighbors=9, p=1, weights=uniform.......................\n",
      "[CV 3/3; 33/36] END n_neighbors=9, p=1, weights=uniform;, score=0.932 total time=   1.4s\n",
      "[CV 1/3; 34/36] START n_neighbors=9, p=1, weights=distance......................\n",
      "[CV 1/3; 34/36] END n_neighbors=9, p=1, weights=distance;, score=0.932 total time=   1.0s\n",
      "[CV 2/3; 34/36] START n_neighbors=9, p=1, weights=distance......................\n",
      "[CV 2/3; 34/36] END n_neighbors=9, p=1, weights=distance;, score=0.935 total time=   1.1s\n",
      "[CV 3/3; 34/36] START n_neighbors=9, p=1, weights=distance......................\n",
      "[CV 3/3; 34/36] END n_neighbors=9, p=1, weights=distance;, score=0.932 total time=   1.0s\n",
      "[CV 1/3; 35/36] START n_neighbors=9, p=2, weights=uniform.......................\n",
      "[CV 1/3; 35/36] END n_neighbors=9, p=2, weights=uniform;, score=0.929 total time=   0.7s\n",
      "[CV 2/3; 35/36] START n_neighbors=9, p=2, weights=uniform.......................\n",
      "[CV 2/3; 35/36] END n_neighbors=9, p=2, weights=uniform;, score=0.932 total time=   0.8s\n",
      "[CV 3/3; 35/36] START n_neighbors=9, p=2, weights=uniform.......................\n",
      "[CV 3/3; 35/36] END n_neighbors=9, p=2, weights=uniform;, score=0.931 total time=   0.8s\n",
      "[CV 1/3; 36/36] START n_neighbors=9, p=2, weights=distance......................\n",
      "[CV 1/3; 36/36] END n_neighbors=9, p=2, weights=distance;, score=0.930 total time=   0.4s\n",
      "[CV 2/3; 36/36] START n_neighbors=9, p=2, weights=distance......................\n",
      "[CV 2/3; 36/36] END n_neighbors=9, p=2, weights=distance;, score=0.933 total time=   0.3s\n",
      "[CV 3/3; 36/36] START n_neighbors=9, p=2, weights=distance......................\n",
      "[CV 3/3; 36/36] END n_neighbors=9, p=2, weights=distance;, score=0.931 total time=   0.3s\n"
     ]
    }
   ],
   "source": [
    "neighborClassifier = KNeighborsClassifier()\n",
    "neighborGrid = {'n_neighbors': list(range(1,10)),\n",
    "               'weights': ['uniform', 'distance'],\n",
    "               'p': [1,2]\n",
    "               }\n",
    "neighborSearchScaled = GridSearchCV(neighborClassifier, neighborGrid, cv = 3, verbose=10).fit(Xscaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "12d6dcc7-c034-46e4-9e6d-95e0132a32ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333034914950761\n",
      "{'n_neighbors': 9, 'p': 1, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "print(neighborSearchScaled.best_score_)\n",
    "print(neighborSearchScaled.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb1c2602-d5c5-49c4-8a60-0e6402ed672a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV 1/3; 1/20] START n_neighbors=10, p=1, weights=uniform.......................\n",
      "[CV 1/3; 1/20] END n_neighbors=10, p=1, weights=uniform;, score=0.931 total time=   1.4s\n",
      "[CV 2/3; 1/20] START n_neighbors=10, p=1, weights=uniform.......................\n",
      "[CV 2/3; 1/20] END n_neighbors=10, p=1, weights=uniform;, score=0.933 total time=   1.5s\n",
      "[CV 3/3; 1/20] START n_neighbors=10, p=1, weights=uniform.......................\n",
      "[CV 3/3; 1/20] END n_neighbors=10, p=1, weights=uniform;, score=0.931 total time=   1.4s\n",
      "[CV 1/3; 2/20] START n_neighbors=10, p=1, weights=distance......................\n",
      "[CV 1/3; 2/20] END n_neighbors=10, p=1, weights=distance;, score=0.933 total time=   1.1s\n",
      "[CV 2/3; 2/20] START n_neighbors=10, p=1, weights=distance......................\n",
      "[CV 2/3; 2/20] END n_neighbors=10, p=1, weights=distance;, score=0.935 total time=   1.1s\n",
      "[CV 3/3; 2/20] START n_neighbors=10, p=1, weights=distance......................\n",
      "[CV 3/3; 2/20] END n_neighbors=10, p=1, weights=distance;, score=0.934 total time=   1.0s\n",
      "[CV 1/3; 3/20] START n_neighbors=10, p=2, weights=uniform.......................\n",
      "[CV 1/3; 3/20] END n_neighbors=10, p=2, weights=uniform;, score=0.928 total time=   0.7s\n",
      "[CV 2/3; 3/20] START n_neighbors=10, p=2, weights=uniform.......................\n",
      "[CV 2/3; 3/20] END n_neighbors=10, p=2, weights=uniform;, score=0.930 total time=   0.7s\n",
      "[CV 3/3; 3/20] START n_neighbors=10, p=2, weights=uniform.......................\n",
      "[CV 3/3; 3/20] END n_neighbors=10, p=2, weights=uniform;, score=0.929 total time=   0.7s\n",
      "[CV 1/3; 4/20] START n_neighbors=10, p=2, weights=distance......................\n",
      "[CV 1/3; 4/20] END n_neighbors=10, p=2, weights=distance;, score=0.930 total time=   0.4s\n",
      "[CV 2/3; 4/20] START n_neighbors=10, p=2, weights=distance......................\n",
      "[CV 2/3; 4/20] END n_neighbors=10, p=2, weights=distance;, score=0.934 total time=   0.3s\n",
      "[CV 3/3; 4/20] START n_neighbors=10, p=2, weights=distance......................\n",
      "[CV 3/3; 4/20] END n_neighbors=10, p=2, weights=distance;, score=0.933 total time=   0.3s\n",
      "[CV 1/3; 5/20] START n_neighbors=20, p=1, weights=uniform.......................\n",
      "[CV 1/3; 5/20] END n_neighbors=20, p=1, weights=uniform;, score=0.929 total time=   1.3s\n",
      "[CV 2/3; 5/20] START n_neighbors=20, p=1, weights=uniform.......................\n",
      "[CV 2/3; 5/20] END n_neighbors=20, p=1, weights=uniform;, score=0.935 total time=   1.4s\n",
      "[CV 3/3; 5/20] START n_neighbors=20, p=1, weights=uniform.......................\n",
      "[CV 3/3; 5/20] END n_neighbors=20, p=1, weights=uniform;, score=0.930 total time=   1.3s\n",
      "[CV 1/3; 6/20] START n_neighbors=20, p=1, weights=distance......................\n",
      "[CV 1/3; 6/20] END n_neighbors=20, p=1, weights=distance;, score=0.933 total time=   1.1s\n",
      "[CV 2/3; 6/20] START n_neighbors=20, p=1, weights=distance......................\n",
      "[CV 2/3; 6/20] END n_neighbors=20, p=1, weights=distance;, score=0.937 total time=   1.0s\n",
      "[CV 3/3; 6/20] START n_neighbors=20, p=1, weights=distance......................\n",
      "[CV 3/3; 6/20] END n_neighbors=20, p=1, weights=distance;, score=0.934 total time=   1.0s\n",
      "[CV 1/3; 7/20] START n_neighbors=20, p=2, weights=uniform.......................\n",
      "[CV 1/3; 7/20] END n_neighbors=20, p=2, weights=uniform;, score=0.926 total time=   0.8s\n",
      "[CV 2/3; 7/20] START n_neighbors=20, p=2, weights=uniform.......................\n",
      "[CV 2/3; 7/20] END n_neighbors=20, p=2, weights=uniform;, score=0.932 total time=   0.8s\n",
      "[CV 3/3; 7/20] START n_neighbors=20, p=2, weights=uniform.......................\n",
      "[CV 3/3; 7/20] END n_neighbors=20, p=2, weights=uniform;, score=0.928 total time=   0.8s\n",
      "[CV 1/3; 8/20] START n_neighbors=20, p=2, weights=distance......................\n",
      "[CV 1/3; 8/20] END n_neighbors=20, p=2, weights=distance;, score=0.928 total time=   0.5s\n",
      "[CV 2/3; 8/20] START n_neighbors=20, p=2, weights=distance......................\n",
      "[CV 2/3; 8/20] END n_neighbors=20, p=2, weights=distance;, score=0.934 total time=   0.4s\n",
      "[CV 3/3; 8/20] START n_neighbors=20, p=2, weights=distance......................\n",
      "[CV 3/3; 8/20] END n_neighbors=20, p=2, weights=distance;, score=0.932 total time=   0.3s\n",
      "[CV 1/3; 9/20] START n_neighbors=30, p=1, weights=uniform.......................\n",
      "[CV 1/3; 9/20] END n_neighbors=30, p=1, weights=uniform;, score=0.927 total time=   1.4s\n",
      "[CV 2/3; 9/20] START n_neighbors=30, p=1, weights=uniform.......................\n",
      "[CV 2/3; 9/20] END n_neighbors=30, p=1, weights=uniform;, score=0.933 total time=   1.4s\n",
      "[CV 3/3; 9/20] START n_neighbors=30, p=1, weights=uniform.......................\n",
      "[CV 3/3; 9/20] END n_neighbors=30, p=1, weights=uniform;, score=0.929 total time=   1.5s\n",
      "[CV 1/3; 10/20] START n_neighbors=30, p=1, weights=distance.....................\n",
      "[CV 1/3; 10/20] END n_neighbors=30, p=1, weights=distance;, score=0.931 total time=   1.1s\n",
      "[CV 2/3; 10/20] START n_neighbors=30, p=1, weights=distance.....................\n",
      "[CV 2/3; 10/20] END n_neighbors=30, p=1, weights=distance;, score=0.937 total time=   1.0s\n",
      "[CV 3/3; 10/20] START n_neighbors=30, p=1, weights=distance.....................\n",
      "[CV 3/3; 10/20] END n_neighbors=30, p=1, weights=distance;, score=0.933 total time=   1.0s\n",
      "[CV 1/3; 11/20] START n_neighbors=30, p=2, weights=uniform......................\n",
      "[CV 1/3; 11/20] END n_neighbors=30, p=2, weights=uniform;, score=0.925 total time=   0.7s\n",
      "[CV 2/3; 11/20] START n_neighbors=30, p=2, weights=uniform......................\n",
      "[CV 2/3; 11/20] END n_neighbors=30, p=2, weights=uniform;, score=0.929 total time=   0.8s\n",
      "[CV 3/3; 11/20] START n_neighbors=30, p=2, weights=uniform......................\n",
      "[CV 3/3; 11/20] END n_neighbors=30, p=2, weights=uniform;, score=0.927 total time=   0.8s\n",
      "[CV 1/3; 12/20] START n_neighbors=30, p=2, weights=distance.....................\n",
      "[CV 1/3; 12/20] END n_neighbors=30, p=2, weights=distance;, score=0.928 total time=   0.4s\n",
      "[CV 2/3; 12/20] START n_neighbors=30, p=2, weights=distance.....................\n",
      "[CV 2/3; 12/20] END n_neighbors=30, p=2, weights=distance;, score=0.933 total time=   0.4s\n",
      "[CV 3/3; 12/20] START n_neighbors=30, p=2, weights=distance.....................\n",
      "[CV 3/3; 12/20] END n_neighbors=30, p=2, weights=distance;, score=0.930 total time=   0.3s\n",
      "[CV 1/3; 13/20] START n_neighbors=40, p=1, weights=uniform......................\n",
      "[CV 1/3; 13/20] END n_neighbors=40, p=1, weights=uniform;, score=0.926 total time=   1.3s\n",
      "[CV 2/3; 13/20] START n_neighbors=40, p=1, weights=uniform......................\n",
      "[CV 2/3; 13/20] END n_neighbors=40, p=1, weights=uniform;, score=0.932 total time=   1.4s\n",
      "[CV 3/3; 13/20] START n_neighbors=40, p=1, weights=uniform......................\n",
      "[CV 3/3; 13/20] END n_neighbors=40, p=1, weights=uniform;, score=0.928 total time=   1.5s\n",
      "[CV 1/3; 14/20] START n_neighbors=40, p=1, weights=distance.....................\n",
      "[CV 1/3; 14/20] END n_neighbors=40, p=1, weights=distance;, score=0.930 total time=   1.2s\n",
      "[CV 2/3; 14/20] START n_neighbors=40, p=1, weights=distance.....................\n",
      "[CV 2/3; 14/20] END n_neighbors=40, p=1, weights=distance;, score=0.935 total time=   1.1s\n",
      "[CV 3/3; 14/20] START n_neighbors=40, p=1, weights=distance.....................\n",
      "[CV 3/3; 14/20] END n_neighbors=40, p=1, weights=distance;, score=0.932 total time=   1.0s\n",
      "[CV 1/3; 15/20] START n_neighbors=40, p=2, weights=uniform......................\n",
      "[CV 1/3; 15/20] END n_neighbors=40, p=2, weights=uniform;, score=0.923 total time=   0.8s\n",
      "[CV 2/3; 15/20] START n_neighbors=40, p=2, weights=uniform......................\n",
      "[CV 2/3; 15/20] END n_neighbors=40, p=2, weights=uniform;, score=0.928 total time=   0.8s\n",
      "[CV 3/3; 15/20] START n_neighbors=40, p=2, weights=uniform......................\n",
      "[CV 3/3; 15/20] END n_neighbors=40, p=2, weights=uniform;, score=0.925 total time=   0.8s\n",
      "[CV 1/3; 16/20] START n_neighbors=40, p=2, weights=distance.....................\n",
      "[CV 1/3; 16/20] END n_neighbors=40, p=2, weights=distance;, score=0.925 total time=   0.4s\n",
      "[CV 2/3; 16/20] START n_neighbors=40, p=2, weights=distance.....................\n",
      "[CV 2/3; 16/20] END n_neighbors=40, p=2, weights=distance;, score=0.931 total time=   0.3s\n",
      "[CV 3/3; 16/20] START n_neighbors=40, p=2, weights=distance.....................\n",
      "[CV 3/3; 16/20] END n_neighbors=40, p=2, weights=distance;, score=0.928 total time=   0.4s\n",
      "[CV 1/3; 17/20] START n_neighbors=50, p=1, weights=uniform......................\n",
      "[CV 1/3; 17/20] END n_neighbors=50, p=1, weights=uniform;, score=0.925 total time=   1.3s\n",
      "[CV 2/3; 17/20] START n_neighbors=50, p=1, weights=uniform......................\n",
      "[CV 2/3; 17/20] END n_neighbors=50, p=1, weights=uniform;, score=0.930 total time=   1.4s\n",
      "[CV 3/3; 17/20] START n_neighbors=50, p=1, weights=uniform......................\n",
      "[CV 3/3; 17/20] END n_neighbors=50, p=1, weights=uniform;, score=0.927 total time=   1.5s\n",
      "[CV 1/3; 18/20] START n_neighbors=50, p=1, weights=distance.....................\n",
      "[CV 1/3; 18/20] END n_neighbors=50, p=1, weights=distance;, score=0.929 total time=   1.1s\n",
      "[CV 2/3; 18/20] START n_neighbors=50, p=1, weights=distance.....................\n",
      "[CV 2/3; 18/20] END n_neighbors=50, p=1, weights=distance;, score=0.934 total time=   1.0s\n",
      "[CV 3/3; 18/20] START n_neighbors=50, p=1, weights=distance.....................\n",
      "[CV 3/3; 18/20] END n_neighbors=50, p=1, weights=distance;, score=0.931 total time=   1.1s\n",
      "[CV 1/3; 19/20] START n_neighbors=50, p=2, weights=uniform......................\n",
      "[CV 1/3; 19/20] END n_neighbors=50, p=2, weights=uniform;, score=0.920 total time=   0.7s\n",
      "[CV 2/3; 19/20] START n_neighbors=50, p=2, weights=uniform......................\n",
      "[CV 2/3; 19/20] END n_neighbors=50, p=2, weights=uniform;, score=0.926 total time=   0.8s\n",
      "[CV 3/3; 19/20] START n_neighbors=50, p=2, weights=uniform......................\n",
      "[CV 3/3; 19/20] END n_neighbors=50, p=2, weights=uniform;, score=0.923 total time=   0.8s\n",
      "[CV 1/3; 20/20] START n_neighbors=50, p=2, weights=distance.....................\n",
      "[CV 1/3; 20/20] END n_neighbors=50, p=2, weights=distance;, score=0.924 total time=   0.4s\n",
      "[CV 2/3; 20/20] START n_neighbors=50, p=2, weights=distance.....................\n",
      "[CV 2/3; 20/20] END n_neighbors=50, p=2, weights=distance;, score=0.930 total time=   0.4s\n",
      "[CV 3/3; 20/20] START n_neighbors=50, p=2, weights=distance.....................\n",
      "[CV 3/3; 20/20] END n_neighbors=50, p=2, weights=distance;, score=0.927 total time=   0.4s\n"
     ]
    }
   ],
   "source": [
    "neighborGrid2 = {'n_neighbors': list(range(10,60, 10)),\n",
    "               'weights': ['uniform', 'distance'],\n",
    "               'p': [1,2]\n",
    "               }\n",
    "neighborSearchScaled2 = GridSearchCV(neighborClassifier, neighborGrid2, cv = 3, verbose=10).fit(Xscaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68d6df57-feb4-40f3-afbe-722507dcc622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9346037430191414\n",
      "{'n_neighbors': 20, 'p': 1, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "print(neighborSearchScaled2.best_score_)\n",
    "print(neighborSearchScaled2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197822ad-0609-4c47-bd91-a7373f367e84",
   "metadata": {},
   "source": [
    "We will try to fit an extreme Gradient boost classifier to the data and see how well it performs. Extreme gradient boosting trees have become popular lately and have a tendency to be very fast and not overfit so they are well suited for many different problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc9a9d50-ba7f-446b-8d8c-bab8737a9496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "[CV 1/5; 1/120] START colsample_bytree=0.0, max_depth=1, n_estimators=50........\n",
      "[CV 1/5; 1/120] END colsample_bytree=0.0, max_depth=1, n_estimators=50;, score=0.898 total time=   0.0s\n",
      "[CV 2/5; 1/120] START colsample_bytree=0.0, max_depth=1, n_estimators=50........\n",
      "[CV 2/5; 1/120] END colsample_bytree=0.0, max_depth=1, n_estimators=50;, score=0.893 total time=   0.0s\n",
      "[CV 3/5; 1/120] START colsample_bytree=0.0, max_depth=1, n_estimators=50........\n",
      "[CV 3/5; 1/120] END colsample_bytree=0.0, max_depth=1, n_estimators=50;, score=0.909 total time=   0.0s\n",
      "[CV 4/5; 1/120] START colsample_bytree=0.0, max_depth=1, n_estimators=50........\n",
      "[CV 4/5; 1/120] END colsample_bytree=0.0, max_depth=1, n_estimators=50;, score=0.900 total time=   0.0s\n",
      "[CV 5/5; 1/120] START colsample_bytree=0.0, max_depth=1, n_estimators=50........\n",
      "[CV 5/5; 1/120] END colsample_bytree=0.0, max_depth=1, n_estimators=50;, score=0.902 total time=   0.0s\n",
      "[CV 1/5; 2/120] START colsample_bytree=0.0, max_depth=1, n_estimators=100.......\n",
      "[CV 1/5; 2/120] END colsample_bytree=0.0, max_depth=1, n_estimators=100;, score=0.924 total time=   0.0s\n",
      "[CV 2/5; 2/120] START colsample_bytree=0.0, max_depth=1, n_estimators=100.......\n",
      "[CV 2/5; 2/120] END colsample_bytree=0.0, max_depth=1, n_estimators=100;, score=0.922 total time=   0.0s\n",
      "[CV 3/5; 2/120] START colsample_bytree=0.0, max_depth=1, n_estimators=100.......\n",
      "[CV 3/5; 2/120] END colsample_bytree=0.0, max_depth=1, n_estimators=100;, score=0.930 total time=   0.0s\n",
      "[CV 4/5; 2/120] START colsample_bytree=0.0, max_depth=1, n_estimators=100.......\n",
      "[CV 4/5; 2/120] END colsample_bytree=0.0, max_depth=1, n_estimators=100;, score=0.925 total time=   0.0s\n",
      "[CV 5/5; 2/120] START colsample_bytree=0.0, max_depth=1, n_estimators=100.......\n",
      "[CV 5/5; 2/120] END colsample_bytree=0.0, max_depth=1, n_estimators=100;, score=0.925 total time=   0.0s\n",
      "[CV 1/5; 3/120] START colsample_bytree=0.0, max_depth=1, n_estimators=150.......\n",
      "[CV 1/5; 3/120] END colsample_bytree=0.0, max_depth=1, n_estimators=150;, score=0.925 total time=   0.0s\n",
      "[CV 2/5; 3/120] START colsample_bytree=0.0, max_depth=1, n_estimators=150.......\n",
      "[CV 2/5; 3/120] END colsample_bytree=0.0, max_depth=1, n_estimators=150;, score=0.925 total time=   0.0s\n",
      "[CV 3/5; 3/120] START colsample_bytree=0.0, max_depth=1, n_estimators=150.......\n",
      "[CV 3/5; 3/120] END colsample_bytree=0.0, max_depth=1, n_estimators=150;, score=0.932 total time=   0.0s\n",
      "[CV 4/5; 3/120] START colsample_bytree=0.0, max_depth=1, n_estimators=150.......\n",
      "[CV 4/5; 3/120] END colsample_bytree=0.0, max_depth=1, n_estimators=150;, score=0.927 total time=   0.0s\n",
      "[CV 5/5; 3/120] START colsample_bytree=0.0, max_depth=1, n_estimators=150.......\n",
      "[CV 5/5; 3/120] END colsample_bytree=0.0, max_depth=1, n_estimators=150;, score=0.926 total time=   0.0s\n",
      "[CV 1/5; 4/120] START colsample_bytree=0.0, max_depth=1, n_estimators=200.......\n",
      "[CV 1/5; 4/120] END colsample_bytree=0.0, max_depth=1, n_estimators=200;, score=0.926 total time=   0.0s\n",
      "[CV 2/5; 4/120] START colsample_bytree=0.0, max_depth=1, n_estimators=200.......\n",
      "[CV 2/5; 4/120] END colsample_bytree=0.0, max_depth=1, n_estimators=200;, score=0.926 total time=   0.0s\n",
      "[CV 3/5; 4/120] START colsample_bytree=0.0, max_depth=1, n_estimators=200.......\n",
      "[CV 3/5; 4/120] END colsample_bytree=0.0, max_depth=1, n_estimators=200;, score=0.932 total time=   0.0s\n",
      "[CV 4/5; 4/120] START colsample_bytree=0.0, max_depth=1, n_estimators=200.......\n",
      "[CV 4/5; 4/120] END colsample_bytree=0.0, max_depth=1, n_estimators=200;, score=0.927 total time=   0.0s\n",
      "[CV 5/5; 4/120] START colsample_bytree=0.0, max_depth=1, n_estimators=200.......\n",
      "[CV 5/5; 4/120] END colsample_bytree=0.0, max_depth=1, n_estimators=200;, score=0.925 total time=   0.0s\n",
      "[CV 1/5; 5/120] START colsample_bytree=0.0, max_depth=1, n_estimators=250.......\n",
      "[CV 1/5; 5/120] END colsample_bytree=0.0, max_depth=1, n_estimators=250;, score=0.927 total time=   0.0s\n",
      "[CV 2/5; 5/120] START colsample_bytree=0.0, max_depth=1, n_estimators=250.......\n",
      "[CV 2/5; 5/120] END colsample_bytree=0.0, max_depth=1, n_estimators=250;, score=0.926 total time=   0.0s\n",
      "[CV 3/5; 5/120] START colsample_bytree=0.0, max_depth=1, n_estimators=250.......\n",
      "[CV 3/5; 5/120] END colsample_bytree=0.0, max_depth=1, n_estimators=250;, score=0.933 total time=   0.1s\n",
      "[CV 4/5; 5/120] START colsample_bytree=0.0, max_depth=1, n_estimators=250.......\n",
      "[CV 4/5; 5/120] END colsample_bytree=0.0, max_depth=1, n_estimators=250;, score=0.928 total time=   0.1s\n",
      "[CV 5/5; 5/120] START colsample_bytree=0.0, max_depth=1, n_estimators=250.......\n",
      "[CV 5/5; 5/120] END colsample_bytree=0.0, max_depth=1, n_estimators=250;, score=0.925 total time=   0.1s\n",
      "[CV 1/5; 6/120] START colsample_bytree=0.0, max_depth=1, n_estimators=300.......\n",
      "[CV 1/5; 6/120] END colsample_bytree=0.0, max_depth=1, n_estimators=300;, score=0.927 total time=   0.1s\n",
      "[CV 2/5; 6/120] START colsample_bytree=0.0, max_depth=1, n_estimators=300.......\n",
      "[CV 2/5; 6/120] END colsample_bytree=0.0, max_depth=1, n_estimators=300;, score=0.926 total time=   0.1s\n",
      "[CV 3/5; 6/120] START colsample_bytree=0.0, max_depth=1, n_estimators=300.......\n",
      "[CV 3/5; 6/120] END colsample_bytree=0.0, max_depth=1, n_estimators=300;, score=0.934 total time=   0.1s\n",
      "[CV 4/5; 6/120] START colsample_bytree=0.0, max_depth=1, n_estimators=300.......\n",
      "[CV 4/5; 6/120] END colsample_bytree=0.0, max_depth=1, n_estimators=300;, score=0.928 total time=   0.1s\n",
      "[CV 5/5; 6/120] START colsample_bytree=0.0, max_depth=1, n_estimators=300.......\n",
      "[CV 5/5; 6/120] END colsample_bytree=0.0, max_depth=1, n_estimators=300;, score=0.927 total time=   0.1s\n",
      "[CV 1/5; 7/120] START colsample_bytree=0.0, max_depth=2, n_estimators=50........\n",
      "[CV 1/5; 7/120] END colsample_bytree=0.0, max_depth=2, n_estimators=50;, score=0.902 total time=   0.0s\n",
      "[CV 2/5; 7/120] START colsample_bytree=0.0, max_depth=2, n_estimators=50........\n",
      "[CV 2/5; 7/120] END colsample_bytree=0.0, max_depth=2, n_estimators=50;, score=0.898 total time=   0.0s\n",
      "[CV 3/5; 7/120] START colsample_bytree=0.0, max_depth=2, n_estimators=50........\n",
      "[CV 3/5; 7/120] END colsample_bytree=0.0, max_depth=2, n_estimators=50;, score=0.908 total time=   0.0s\n",
      "[CV 4/5; 7/120] START colsample_bytree=0.0, max_depth=2, n_estimators=50........\n",
      "[CV 4/5; 7/120] END colsample_bytree=0.0, max_depth=2, n_estimators=50;, score=0.905 total time=   0.0s\n",
      "[CV 5/5; 7/120] START colsample_bytree=0.0, max_depth=2, n_estimators=50........\n",
      "[CV 5/5; 7/120] END colsample_bytree=0.0, max_depth=2, n_estimators=50;, score=0.903 total time=   0.0s\n",
      "[CV 1/5; 8/120] START colsample_bytree=0.0, max_depth=2, n_estimators=100.......\n",
      "[CV 1/5; 8/120] END colsample_bytree=0.0, max_depth=2, n_estimators=100;, score=0.925 total time=   0.0s\n",
      "[CV 2/5; 8/120] START colsample_bytree=0.0, max_depth=2, n_estimators=100.......\n",
      "[CV 2/5; 8/120] END colsample_bytree=0.0, max_depth=2, n_estimators=100;, score=0.923 total time=   0.0s\n",
      "[CV 3/5; 8/120] START colsample_bytree=0.0, max_depth=2, n_estimators=100.......\n",
      "[CV 3/5; 8/120] END colsample_bytree=0.0, max_depth=2, n_estimators=100;, score=0.932 total time=   0.0s\n",
      "[CV 4/5; 8/120] START colsample_bytree=0.0, max_depth=2, n_estimators=100.......\n",
      "[CV 4/5; 8/120] END colsample_bytree=0.0, max_depth=2, n_estimators=100;, score=0.927 total time=   0.0s\n",
      "[CV 5/5; 8/120] START colsample_bytree=0.0, max_depth=2, n_estimators=100.......\n",
      "[CV 5/5; 8/120] END colsample_bytree=0.0, max_depth=2, n_estimators=100;, score=0.925 total time=   0.0s\n",
      "[CV 1/5; 9/120] START colsample_bytree=0.0, max_depth=2, n_estimators=150.......\n",
      "[CV 1/5; 9/120] END colsample_bytree=0.0, max_depth=2, n_estimators=150;, score=0.928 total time=   0.0s\n",
      "[CV 2/5; 9/120] START colsample_bytree=0.0, max_depth=2, n_estimators=150.......\n",
      "[CV 2/5; 9/120] END colsample_bytree=0.0, max_depth=2, n_estimators=150;, score=0.928 total time=   0.0s\n",
      "[CV 3/5; 9/120] START colsample_bytree=0.0, max_depth=2, n_estimators=150.......\n",
      "[CV 3/5; 9/120] END colsample_bytree=0.0, max_depth=2, n_estimators=150;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 9/120] START colsample_bytree=0.0, max_depth=2, n_estimators=150.......\n",
      "[CV 4/5; 9/120] END colsample_bytree=0.0, max_depth=2, n_estimators=150;, score=0.930 total time=   0.0s\n",
      "[CV 5/5; 9/120] START colsample_bytree=0.0, max_depth=2, n_estimators=150.......\n",
      "[CV 5/5; 9/120] END colsample_bytree=0.0, max_depth=2, n_estimators=150;, score=0.928 total time=   0.0s\n",
      "[CV 1/5; 10/120] START colsample_bytree=0.0, max_depth=2, n_estimators=200......\n",
      "[CV 1/5; 10/120] END colsample_bytree=0.0, max_depth=2, n_estimators=200;, score=0.930 total time=   0.0s\n",
      "[CV 2/5; 10/120] START colsample_bytree=0.0, max_depth=2, n_estimators=200......\n",
      "[CV 2/5; 10/120] END colsample_bytree=0.0, max_depth=2, n_estimators=200;, score=0.929 total time=   0.1s\n",
      "[CV 3/5; 10/120] START colsample_bytree=0.0, max_depth=2, n_estimators=200......\n",
      "[CV 3/5; 10/120] END colsample_bytree=0.0, max_depth=2, n_estimators=200;, score=0.935 total time=   0.0s\n",
      "[CV 4/5; 10/120] START colsample_bytree=0.0, max_depth=2, n_estimators=200......\n",
      "[CV 4/5; 10/120] END colsample_bytree=0.0, max_depth=2, n_estimators=200;, score=0.930 total time=   0.0s\n",
      "[CV 5/5; 10/120] START colsample_bytree=0.0, max_depth=2, n_estimators=200......\n",
      "[CV 5/5; 10/120] END colsample_bytree=0.0, max_depth=2, n_estimators=200;, score=0.929 total time=   0.0s\n",
      "[CV 1/5; 11/120] START colsample_bytree=0.0, max_depth=2, n_estimators=250......\n",
      "[CV 1/5; 11/120] END colsample_bytree=0.0, max_depth=2, n_estimators=250;, score=0.930 total time=   0.1s\n",
      "[CV 2/5; 11/120] START colsample_bytree=0.0, max_depth=2, n_estimators=250......\n",
      "[CV 2/5; 11/120] END colsample_bytree=0.0, max_depth=2, n_estimators=250;, score=0.930 total time=   0.1s\n",
      "[CV 3/5; 11/120] START colsample_bytree=0.0, max_depth=2, n_estimators=250......\n",
      "[CV 3/5; 11/120] END colsample_bytree=0.0, max_depth=2, n_estimators=250;, score=0.935 total time=   0.1s\n",
      "[CV 4/5; 11/120] START colsample_bytree=0.0, max_depth=2, n_estimators=250......\n",
      "[CV 4/5; 11/120] END colsample_bytree=0.0, max_depth=2, n_estimators=250;, score=0.930 total time=   0.1s\n",
      "[CV 5/5; 11/120] START colsample_bytree=0.0, max_depth=2, n_estimators=250......\n",
      "[CV 5/5; 11/120] END colsample_bytree=0.0, max_depth=2, n_estimators=250;, score=0.928 total time=   0.1s\n",
      "[CV 1/5; 12/120] START colsample_bytree=0.0, max_depth=2, n_estimators=300......\n",
      "[CV 1/5; 12/120] END colsample_bytree=0.0, max_depth=2, n_estimators=300;, score=0.929 total time=   0.1s\n",
      "[CV 2/5; 12/120] START colsample_bytree=0.0, max_depth=2, n_estimators=300......\n",
      "[CV 2/5; 12/120] END colsample_bytree=0.0, max_depth=2, n_estimators=300;, score=0.930 total time=   0.1s\n",
      "[CV 3/5; 12/120] START colsample_bytree=0.0, max_depth=2, n_estimators=300......\n",
      "[CV 3/5; 12/120] END colsample_bytree=0.0, max_depth=2, n_estimators=300;, score=0.935 total time=   0.1s\n",
      "[CV 4/5; 12/120] START colsample_bytree=0.0, max_depth=2, n_estimators=300......\n",
      "[CV 4/5; 12/120] END colsample_bytree=0.0, max_depth=2, n_estimators=300;, score=0.930 total time=   0.1s\n",
      "[CV 5/5; 12/120] START colsample_bytree=0.0, max_depth=2, n_estimators=300......\n",
      "[CV 5/5; 12/120] END colsample_bytree=0.0, max_depth=2, n_estimators=300;, score=0.929 total time=   0.1s\n",
      "[CV 1/5; 13/120] START colsample_bytree=0.1, max_depth=1, n_estimators=50.......\n",
      "[CV 1/5; 13/120] END colsample_bytree=0.1, max_depth=1, n_estimators=50;, score=0.898 total time=   0.0s\n",
      "[CV 2/5; 13/120] START colsample_bytree=0.1, max_depth=1, n_estimators=50.......\n",
      "[CV 2/5; 13/120] END colsample_bytree=0.1, max_depth=1, n_estimators=50;, score=0.893 total time=   0.0s\n",
      "[CV 3/5; 13/120] START colsample_bytree=0.1, max_depth=1, n_estimators=50.......\n",
      "[CV 3/5; 13/120] END colsample_bytree=0.1, max_depth=1, n_estimators=50;, score=0.909 total time=   0.0s\n",
      "[CV 4/5; 13/120] START colsample_bytree=0.1, max_depth=1, n_estimators=50.......\n",
      "[CV 4/5; 13/120] END colsample_bytree=0.1, max_depth=1, n_estimators=50;, score=0.900 total time=   0.0s\n",
      "[CV 5/5; 13/120] START colsample_bytree=0.1, max_depth=1, n_estimators=50.......\n",
      "[CV 5/5; 13/120] END colsample_bytree=0.1, max_depth=1, n_estimators=50;, score=0.902 total time=   0.0s\n",
      "[CV 1/5; 14/120] START colsample_bytree=0.1, max_depth=1, n_estimators=100......\n",
      "[CV 1/5; 14/120] END colsample_bytree=0.1, max_depth=1, n_estimators=100;, score=0.924 total time=   0.0s\n",
      "[CV 2/5; 14/120] START colsample_bytree=0.1, max_depth=1, n_estimators=100......\n",
      "[CV 2/5; 14/120] END colsample_bytree=0.1, max_depth=1, n_estimators=100;, score=0.922 total time=   0.0s\n",
      "[CV 3/5; 14/120] START colsample_bytree=0.1, max_depth=1, n_estimators=100......\n",
      "[CV 3/5; 14/120] END colsample_bytree=0.1, max_depth=1, n_estimators=100;, score=0.930 total time=   0.0s\n",
      "[CV 4/5; 14/120] START colsample_bytree=0.1, max_depth=1, n_estimators=100......\n",
      "[CV 4/5; 14/120] END colsample_bytree=0.1, max_depth=1, n_estimators=100;, score=0.925 total time=   0.0s\n",
      "[CV 5/5; 14/120] START colsample_bytree=0.1, max_depth=1, n_estimators=100......\n",
      "[CV 5/5; 14/120] END colsample_bytree=0.1, max_depth=1, n_estimators=100;, score=0.925 total time=   0.0s\n",
      "[CV 1/5; 15/120] START colsample_bytree=0.1, max_depth=1, n_estimators=150......\n",
      "[CV 1/5; 15/120] END colsample_bytree=0.1, max_depth=1, n_estimators=150;, score=0.925 total time=   0.0s\n",
      "[CV 2/5; 15/120] START colsample_bytree=0.1, max_depth=1, n_estimators=150......\n",
      "[CV 2/5; 15/120] END colsample_bytree=0.1, max_depth=1, n_estimators=150;, score=0.925 total time=   0.0s\n",
      "[CV 3/5; 15/120] START colsample_bytree=0.1, max_depth=1, n_estimators=150......\n",
      "[CV 3/5; 15/120] END colsample_bytree=0.1, max_depth=1, n_estimators=150;, score=0.932 total time=   0.0s\n",
      "[CV 4/5; 15/120] START colsample_bytree=0.1, max_depth=1, n_estimators=150......\n",
      "[CV 4/5; 15/120] END colsample_bytree=0.1, max_depth=1, n_estimators=150;, score=0.927 total time=   0.0s\n",
      "[CV 5/5; 15/120] START colsample_bytree=0.1, max_depth=1, n_estimators=150......\n",
      "[CV 5/5; 15/120] END colsample_bytree=0.1, max_depth=1, n_estimators=150;, score=0.926 total time=   0.1s\n",
      "[CV 1/5; 16/120] START colsample_bytree=0.1, max_depth=1, n_estimators=200......\n",
      "[CV 1/5; 16/120] END colsample_bytree=0.1, max_depth=1, n_estimators=200;, score=0.926 total time=   0.0s\n",
      "[CV 2/5; 16/120] START colsample_bytree=0.1, max_depth=1, n_estimators=200......\n",
      "[CV 2/5; 16/120] END colsample_bytree=0.1, max_depth=1, n_estimators=200;, score=0.926 total time=   0.0s\n",
      "[CV 3/5; 16/120] START colsample_bytree=0.1, max_depth=1, n_estimators=200......\n",
      "[CV 3/5; 16/120] END colsample_bytree=0.1, max_depth=1, n_estimators=200;, score=0.932 total time=   0.1s\n",
      "[CV 4/5; 16/120] START colsample_bytree=0.1, max_depth=1, n_estimators=200......\n",
      "[CV 4/5; 16/120] END colsample_bytree=0.1, max_depth=1, n_estimators=200;, score=0.927 total time=   0.1s\n",
      "[CV 5/5; 16/120] START colsample_bytree=0.1, max_depth=1, n_estimators=200......\n",
      "[CV 5/5; 16/120] END colsample_bytree=0.1, max_depth=1, n_estimators=200;, score=0.925 total time=   0.1s\n",
      "[CV 1/5; 17/120] START colsample_bytree=0.1, max_depth=1, n_estimators=250......\n",
      "[CV 1/5; 17/120] END colsample_bytree=0.1, max_depth=1, n_estimators=250;, score=0.927 total time=   0.1s\n",
      "[CV 2/5; 17/120] START colsample_bytree=0.1, max_depth=1, n_estimators=250......\n",
      "[CV 2/5; 17/120] END colsample_bytree=0.1, max_depth=1, n_estimators=250;, score=0.926 total time=   0.0s\n",
      "[CV 3/5; 17/120] START colsample_bytree=0.1, max_depth=1, n_estimators=250......\n",
      "[CV 3/5; 17/120] END colsample_bytree=0.1, max_depth=1, n_estimators=250;, score=0.933 total time=   0.0s\n",
      "[CV 4/5; 17/120] START colsample_bytree=0.1, max_depth=1, n_estimators=250......\n",
      "[CV 4/5; 17/120] END colsample_bytree=0.1, max_depth=1, n_estimators=250;, score=0.928 total time=   0.1s\n",
      "[CV 5/5; 17/120] START colsample_bytree=0.1, max_depth=1, n_estimators=250......\n",
      "[CV 5/5; 17/120] END colsample_bytree=0.1, max_depth=1, n_estimators=250;, score=0.925 total time=   0.1s\n",
      "[CV 1/5; 18/120] START colsample_bytree=0.1, max_depth=1, n_estimators=300......\n",
      "[CV 1/5; 18/120] END colsample_bytree=0.1, max_depth=1, n_estimators=300;, score=0.927 total time=   0.1s\n",
      "[CV 2/5; 18/120] START colsample_bytree=0.1, max_depth=1, n_estimators=300......\n",
      "[CV 2/5; 18/120] END colsample_bytree=0.1, max_depth=1, n_estimators=300;, score=0.926 total time=   0.1s\n",
      "[CV 3/5; 18/120] START colsample_bytree=0.1, max_depth=1, n_estimators=300......\n",
      "[CV 3/5; 18/120] END colsample_bytree=0.1, max_depth=1, n_estimators=300;, score=0.934 total time=   0.1s\n",
      "[CV 4/5; 18/120] START colsample_bytree=0.1, max_depth=1, n_estimators=300......\n",
      "[CV 4/5; 18/120] END colsample_bytree=0.1, max_depth=1, n_estimators=300;, score=0.928 total time=   0.1s\n",
      "[CV 5/5; 18/120] START colsample_bytree=0.1, max_depth=1, n_estimators=300......\n",
      "[CV 5/5; 18/120] END colsample_bytree=0.1, max_depth=1, n_estimators=300;, score=0.927 total time=   0.1s\n",
      "[CV 1/5; 19/120] START colsample_bytree=0.1, max_depth=2, n_estimators=50.......\n",
      "[CV 1/5; 19/120] END colsample_bytree=0.1, max_depth=2, n_estimators=50;, score=0.902 total time=   0.0s\n",
      "[CV 2/5; 19/120] START colsample_bytree=0.1, max_depth=2, n_estimators=50.......\n",
      "[CV 2/5; 19/120] END colsample_bytree=0.1, max_depth=2, n_estimators=50;, score=0.898 total time=   0.0s\n",
      "[CV 3/5; 19/120] START colsample_bytree=0.1, max_depth=2, n_estimators=50.......\n",
      "[CV 3/5; 19/120] END colsample_bytree=0.1, max_depth=2, n_estimators=50;, score=0.908 total time=   0.0s\n",
      "[CV 4/5; 19/120] START colsample_bytree=0.1, max_depth=2, n_estimators=50.......\n",
      "[CV 4/5; 19/120] END colsample_bytree=0.1, max_depth=2, n_estimators=50;, score=0.905 total time=   0.0s\n",
      "[CV 5/5; 19/120] START colsample_bytree=0.1, max_depth=2, n_estimators=50.......\n",
      "[CV 5/5; 19/120] END colsample_bytree=0.1, max_depth=2, n_estimators=50;, score=0.903 total time=   0.0s\n",
      "[CV 1/5; 20/120] START colsample_bytree=0.1, max_depth=2, n_estimators=100......\n",
      "[CV 1/5; 20/120] END colsample_bytree=0.1, max_depth=2, n_estimators=100;, score=0.925 total time=   0.0s\n",
      "[CV 2/5; 20/120] START colsample_bytree=0.1, max_depth=2, n_estimators=100......\n",
      "[CV 2/5; 20/120] END colsample_bytree=0.1, max_depth=2, n_estimators=100;, score=0.923 total time=   0.0s\n",
      "[CV 3/5; 20/120] START colsample_bytree=0.1, max_depth=2, n_estimators=100......\n",
      "[CV 3/5; 20/120] END colsample_bytree=0.1, max_depth=2, n_estimators=100;, score=0.932 total time=   0.0s\n",
      "[CV 4/5; 20/120] START colsample_bytree=0.1, max_depth=2, n_estimators=100......\n",
      "[CV 4/5; 20/120] END colsample_bytree=0.1, max_depth=2, n_estimators=100;, score=0.927 total time=   0.0s\n",
      "[CV 5/5; 20/120] START colsample_bytree=0.1, max_depth=2, n_estimators=100......\n",
      "[CV 5/5; 20/120] END colsample_bytree=0.1, max_depth=2, n_estimators=100;, score=0.925 total time=   0.0s\n",
      "[CV 1/5; 21/120] START colsample_bytree=0.1, max_depth=2, n_estimators=150......\n",
      "[CV 1/5; 21/120] END colsample_bytree=0.1, max_depth=2, n_estimators=150;, score=0.928 total time=   0.1s\n",
      "[CV 2/5; 21/120] START colsample_bytree=0.1, max_depth=2, n_estimators=150......\n",
      "[CV 2/5; 21/120] END colsample_bytree=0.1, max_depth=2, n_estimators=150;, score=0.928 total time=   0.1s\n",
      "[CV 3/5; 21/120] START colsample_bytree=0.1, max_depth=2, n_estimators=150......\n",
      "[CV 3/5; 21/120] END colsample_bytree=0.1, max_depth=2, n_estimators=150;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 21/120] START colsample_bytree=0.1, max_depth=2, n_estimators=150......\n",
      "[CV 4/5; 21/120] END colsample_bytree=0.1, max_depth=2, n_estimators=150;, score=0.930 total time=   0.0s\n",
      "[CV 5/5; 21/120] START colsample_bytree=0.1, max_depth=2, n_estimators=150......\n",
      "[CV 5/5; 21/120] END colsample_bytree=0.1, max_depth=2, n_estimators=150;, score=0.928 total time=   0.0s\n",
      "[CV 1/5; 22/120] START colsample_bytree=0.1, max_depth=2, n_estimators=200......\n",
      "[CV 1/5; 22/120] END colsample_bytree=0.1, max_depth=2, n_estimators=200;, score=0.930 total time=   0.0s\n",
      "[CV 2/5; 22/120] START colsample_bytree=0.1, max_depth=2, n_estimators=200......\n",
      "[CV 2/5; 22/120] END colsample_bytree=0.1, max_depth=2, n_estimators=200;, score=0.929 total time=   0.0s\n",
      "[CV 3/5; 22/120] START colsample_bytree=0.1, max_depth=2, n_estimators=200......\n",
      "[CV 3/5; 22/120] END colsample_bytree=0.1, max_depth=2, n_estimators=200;, score=0.935 total time=   0.1s\n",
      "[CV 4/5; 22/120] START colsample_bytree=0.1, max_depth=2, n_estimators=200......\n",
      "[CV 4/5; 22/120] END colsample_bytree=0.1, max_depth=2, n_estimators=200;, score=0.930 total time=   0.0s\n",
      "[CV 5/5; 22/120] START colsample_bytree=0.1, max_depth=2, n_estimators=200......\n",
      "[CV 5/5; 22/120] END colsample_bytree=0.1, max_depth=2, n_estimators=200;, score=0.929 total time=   0.1s\n",
      "[CV 1/5; 23/120] START colsample_bytree=0.1, max_depth=2, n_estimators=250......\n",
      "[CV 1/5; 23/120] END colsample_bytree=0.1, max_depth=2, n_estimators=250;, score=0.930 total time=   0.1s\n",
      "[CV 2/5; 23/120] START colsample_bytree=0.1, max_depth=2, n_estimators=250......\n",
      "[CV 2/5; 23/120] END colsample_bytree=0.1, max_depth=2, n_estimators=250;, score=0.930 total time=   0.1s\n",
      "[CV 3/5; 23/120] START colsample_bytree=0.1, max_depth=2, n_estimators=250......\n",
      "[CV 3/5; 23/120] END colsample_bytree=0.1, max_depth=2, n_estimators=250;, score=0.935 total time=   0.1s\n",
      "[CV 4/5; 23/120] START colsample_bytree=0.1, max_depth=2, n_estimators=250......\n",
      "[CV 4/5; 23/120] END colsample_bytree=0.1, max_depth=2, n_estimators=250;, score=0.930 total time=   0.1s\n",
      "[CV 5/5; 23/120] START colsample_bytree=0.1, max_depth=2, n_estimators=250......\n",
      "[CV 5/5; 23/120] END colsample_bytree=0.1, max_depth=2, n_estimators=250;, score=0.928 total time=   0.0s\n",
      "[CV 1/5; 24/120] START colsample_bytree=0.1, max_depth=2, n_estimators=300......\n",
      "[CV 1/5; 24/120] END colsample_bytree=0.1, max_depth=2, n_estimators=300;, score=0.929 total time=   0.1s\n",
      "[CV 2/5; 24/120] START colsample_bytree=0.1, max_depth=2, n_estimators=300......\n",
      "[CV 2/5; 24/120] END colsample_bytree=0.1, max_depth=2, n_estimators=300;, score=0.930 total time=   0.1s\n",
      "[CV 3/5; 24/120] START colsample_bytree=0.1, max_depth=2, n_estimators=300......\n",
      "[CV 3/5; 24/120] END colsample_bytree=0.1, max_depth=2, n_estimators=300;, score=0.935 total time=   0.1s\n",
      "[CV 4/5; 24/120] START colsample_bytree=0.1, max_depth=2, n_estimators=300......\n",
      "[CV 4/5; 24/120] END colsample_bytree=0.1, max_depth=2, n_estimators=300;, score=0.930 total time=   0.2s\n",
      "[CV 5/5; 24/120] START colsample_bytree=0.1, max_depth=2, n_estimators=300......\n",
      "[CV 5/5; 24/120] END colsample_bytree=0.1, max_depth=2, n_estimators=300;, score=0.929 total time=   0.1s\n",
      "[CV 1/5; 25/120] START colsample_bytree=0.2, max_depth=1, n_estimators=50.......\n",
      "[CV 1/5; 25/120] END colsample_bytree=0.2, max_depth=1, n_estimators=50;, score=0.926 total time=   0.0s\n",
      "[CV 2/5; 25/120] START colsample_bytree=0.2, max_depth=1, n_estimators=50.......\n",
      "[CV 2/5; 25/120] END colsample_bytree=0.2, max_depth=1, n_estimators=50;, score=0.924 total time=   0.0s\n",
      "[CV 3/5; 25/120] START colsample_bytree=0.2, max_depth=1, n_estimators=50.......\n",
      "[CV 3/5; 25/120] END colsample_bytree=0.2, max_depth=1, n_estimators=50;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 25/120] START colsample_bytree=0.2, max_depth=1, n_estimators=50.......\n",
      "[CV 4/5; 25/120] END colsample_bytree=0.2, max_depth=1, n_estimators=50;, score=0.929 total time=   0.0s\n",
      "[CV 5/5; 25/120] START colsample_bytree=0.2, max_depth=1, n_estimators=50.......\n",
      "[CV 5/5; 25/120] END colsample_bytree=0.2, max_depth=1, n_estimators=50;, score=0.925 total time=   0.0s\n",
      "[CV 1/5; 26/120] START colsample_bytree=0.2, max_depth=1, n_estimators=100......\n",
      "[CV 1/5; 26/120] END colsample_bytree=0.2, max_depth=1, n_estimators=100;, score=0.927 total time=   0.0s\n",
      "[CV 2/5; 26/120] START colsample_bytree=0.2, max_depth=1, n_estimators=100......\n",
      "[CV 2/5; 26/120] END colsample_bytree=0.2, max_depth=1, n_estimators=100;, score=0.926 total time=   0.0s\n",
      "[CV 3/5; 26/120] START colsample_bytree=0.2, max_depth=1, n_estimators=100......\n",
      "[CV 3/5; 26/120] END colsample_bytree=0.2, max_depth=1, n_estimators=100;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 26/120] START colsample_bytree=0.2, max_depth=1, n_estimators=100......\n",
      "[CV 4/5; 26/120] END colsample_bytree=0.2, max_depth=1, n_estimators=100;, score=0.928 total time=   0.0s\n",
      "[CV 5/5; 26/120] START colsample_bytree=0.2, max_depth=1, n_estimators=100......\n",
      "[CV 5/5; 26/120] END colsample_bytree=0.2, max_depth=1, n_estimators=100;, score=0.927 total time=   0.0s\n",
      "[CV 1/5; 27/120] START colsample_bytree=0.2, max_depth=1, n_estimators=150......\n",
      "[CV 1/5; 27/120] END colsample_bytree=0.2, max_depth=1, n_estimators=150;, score=0.928 total time=   0.1s\n",
      "[CV 2/5; 27/120] START colsample_bytree=0.2, max_depth=1, n_estimators=150......\n",
      "[CV 2/5; 27/120] END colsample_bytree=0.2, max_depth=1, n_estimators=150;, score=0.927 total time=   0.0s\n",
      "[CV 3/5; 27/120] START colsample_bytree=0.2, max_depth=1, n_estimators=150......\n",
      "[CV 3/5; 27/120] END colsample_bytree=0.2, max_depth=1, n_estimators=150;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 27/120] START colsample_bytree=0.2, max_depth=1, n_estimators=150......\n",
      "[CV 4/5; 27/120] END colsample_bytree=0.2, max_depth=1, n_estimators=150;, score=0.929 total time=   0.0s\n",
      "[CV 5/5; 27/120] START colsample_bytree=0.2, max_depth=1, n_estimators=150......\n",
      "[CV 5/5; 27/120] END colsample_bytree=0.2, max_depth=1, n_estimators=150;, score=0.926 total time=   0.0s\n",
      "[CV 1/5; 28/120] START colsample_bytree=0.2, max_depth=1, n_estimators=200......\n",
      "[CV 1/5; 28/120] END colsample_bytree=0.2, max_depth=1, n_estimators=200;, score=0.928 total time=   0.1s\n",
      "[CV 2/5; 28/120] START colsample_bytree=0.2, max_depth=1, n_estimators=200......\n",
      "[CV 2/5; 28/120] END colsample_bytree=0.2, max_depth=1, n_estimators=200;, score=0.927 total time=   0.1s\n",
      "[CV 3/5; 28/120] START colsample_bytree=0.2, max_depth=1, n_estimators=200......\n",
      "[CV 3/5; 28/120] END colsample_bytree=0.2, max_depth=1, n_estimators=200;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 28/120] START colsample_bytree=0.2, max_depth=1, n_estimators=200......\n",
      "[CV 4/5; 28/120] END colsample_bytree=0.2, max_depth=1, n_estimators=200;, score=0.928 total time=   0.0s\n",
      "[CV 5/5; 28/120] START colsample_bytree=0.2, max_depth=1, n_estimators=200......\n",
      "[CV 5/5; 28/120] END colsample_bytree=0.2, max_depth=1, n_estimators=200;, score=0.926 total time=   0.0s\n",
      "[CV 1/5; 29/120] START colsample_bytree=0.2, max_depth=1, n_estimators=250......\n",
      "[CV 1/5; 29/120] END colsample_bytree=0.2, max_depth=1, n_estimators=250;, score=0.929 total time=   0.0s\n",
      "[CV 2/5; 29/120] START colsample_bytree=0.2, max_depth=1, n_estimators=250......\n",
      "[CV 2/5; 29/120] END colsample_bytree=0.2, max_depth=1, n_estimators=250;, score=0.927 total time=   0.0s\n",
      "[CV 3/5; 29/120] START colsample_bytree=0.2, max_depth=1, n_estimators=250......\n",
      "[CV 3/5; 29/120] END colsample_bytree=0.2, max_depth=1, n_estimators=250;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 29/120] START colsample_bytree=0.2, max_depth=1, n_estimators=250......\n",
      "[CV 4/5; 29/120] END colsample_bytree=0.2, max_depth=1, n_estimators=250;, score=0.929 total time=   0.0s\n",
      "[CV 5/5; 29/120] START colsample_bytree=0.2, max_depth=1, n_estimators=250......\n",
      "[CV 5/5; 29/120] END colsample_bytree=0.2, max_depth=1, n_estimators=250;, score=0.927 total time=   0.0s\n",
      "[CV 1/5; 30/120] START colsample_bytree=0.2, max_depth=1, n_estimators=300......\n",
      "[CV 1/5; 30/120] END colsample_bytree=0.2, max_depth=1, n_estimators=300;, score=0.929 total time=   0.0s\n",
      "[CV 2/5; 30/120] START colsample_bytree=0.2, max_depth=1, n_estimators=300......\n",
      "[CV 2/5; 30/120] END colsample_bytree=0.2, max_depth=1, n_estimators=300;, score=0.927 total time=   0.1s\n",
      "[CV 3/5; 30/120] START colsample_bytree=0.2, max_depth=1, n_estimators=300......\n",
      "[CV 3/5; 30/120] END colsample_bytree=0.2, max_depth=1, n_estimators=300;, score=0.934 total time=   0.1s\n",
      "[CV 4/5; 30/120] START colsample_bytree=0.2, max_depth=1, n_estimators=300......\n",
      "[CV 4/5; 30/120] END colsample_bytree=0.2, max_depth=1, n_estimators=300;, score=0.929 total time=   0.1s\n",
      "[CV 5/5; 30/120] START colsample_bytree=0.2, max_depth=1, n_estimators=300......\n",
      "[CV 5/5; 30/120] END colsample_bytree=0.2, max_depth=1, n_estimators=300;, score=0.927 total time=   0.1s\n",
      "[CV 1/5; 31/120] START colsample_bytree=0.2, max_depth=2, n_estimators=50.......\n",
      "[CV 1/5; 31/120] END colsample_bytree=0.2, max_depth=2, n_estimators=50;, score=0.933 total time=   0.0s\n",
      "[CV 2/5; 31/120] START colsample_bytree=0.2, max_depth=2, n_estimators=50.......\n",
      "[CV 2/5; 31/120] END colsample_bytree=0.2, max_depth=2, n_estimators=50;, score=0.931 total time=   0.0s\n",
      "[CV 3/5; 31/120] START colsample_bytree=0.2, max_depth=2, n_estimators=50.......\n",
      "[CV 3/5; 31/120] END colsample_bytree=0.2, max_depth=2, n_estimators=50;, score=0.938 total time=   0.0s\n",
      "[CV 4/5; 31/120] START colsample_bytree=0.2, max_depth=2, n_estimators=50.......\n",
      "[CV 4/5; 31/120] END colsample_bytree=0.2, max_depth=2, n_estimators=50;, score=0.935 total time=   0.0s\n",
      "[CV 5/5; 31/120] START colsample_bytree=0.2, max_depth=2, n_estimators=50.......\n",
      "[CV 5/5; 31/120] END colsample_bytree=0.2, max_depth=2, n_estimators=50;, score=0.933 total time=   0.0s\n",
      "[CV 1/5; 32/120] START colsample_bytree=0.2, max_depth=2, n_estimators=100......\n",
      "[CV 1/5; 32/120] END colsample_bytree=0.2, max_depth=2, n_estimators=100;, score=0.944 total time=   0.0s\n",
      "[CV 2/5; 32/120] START colsample_bytree=0.2, max_depth=2, n_estimators=100......\n",
      "[CV 2/5; 32/120] END colsample_bytree=0.2, max_depth=2, n_estimators=100;, score=0.943 total time=   0.0s\n",
      "[CV 3/5; 32/120] START colsample_bytree=0.2, max_depth=2, n_estimators=100......\n",
      "[CV 3/5; 32/120] END colsample_bytree=0.2, max_depth=2, n_estimators=100;, score=0.943 total time=   0.0s\n",
      "[CV 4/5; 32/120] START colsample_bytree=0.2, max_depth=2, n_estimators=100......\n",
      "[CV 4/5; 32/120] END colsample_bytree=0.2, max_depth=2, n_estimators=100;, score=0.942 total time=   0.0s\n",
      "[CV 5/5; 32/120] START colsample_bytree=0.2, max_depth=2, n_estimators=100......\n",
      "[CV 5/5; 32/120] END colsample_bytree=0.2, max_depth=2, n_estimators=100;, score=0.939 total time=   0.0s\n",
      "[CV 1/5; 33/120] START colsample_bytree=0.2, max_depth=2, n_estimators=150......\n",
      "[CV 1/5; 33/120] END colsample_bytree=0.2, max_depth=2, n_estimators=150;, score=0.949 total time=   0.0s\n",
      "[CV 2/5; 33/120] START colsample_bytree=0.2, max_depth=2, n_estimators=150......\n",
      "[CV 2/5; 33/120] END colsample_bytree=0.2, max_depth=2, n_estimators=150;, score=0.944 total time=   0.0s\n",
      "[CV 3/5; 33/120] START colsample_bytree=0.2, max_depth=2, n_estimators=150......\n",
      "[CV 3/5; 33/120] END colsample_bytree=0.2, max_depth=2, n_estimators=150;, score=0.951 total time=   0.0s\n",
      "[CV 4/5; 33/120] START colsample_bytree=0.2, max_depth=2, n_estimators=150......\n",
      "[CV 4/5; 33/120] END colsample_bytree=0.2, max_depth=2, n_estimators=150;, score=0.945 total time=   0.0s\n",
      "[CV 5/5; 33/120] START colsample_bytree=0.2, max_depth=2, n_estimators=150......\n",
      "[CV 5/5; 33/120] END colsample_bytree=0.2, max_depth=2, n_estimators=150;, score=0.947 total time=   0.0s\n",
      "[CV 1/5; 34/120] START colsample_bytree=0.2, max_depth=2, n_estimators=200......\n",
      "[CV 1/5; 34/120] END colsample_bytree=0.2, max_depth=2, n_estimators=200;, score=0.948 total time=   0.0s\n",
      "[CV 2/5; 34/120] START colsample_bytree=0.2, max_depth=2, n_estimators=200......\n",
      "[CV 2/5; 34/120] END colsample_bytree=0.2, max_depth=2, n_estimators=200;, score=0.946 total time=   0.1s\n",
      "[CV 3/5; 34/120] START colsample_bytree=0.2, max_depth=2, n_estimators=200......\n",
      "[CV 3/5; 34/120] END colsample_bytree=0.2, max_depth=2, n_estimators=200;, score=0.952 total time=   0.0s\n",
      "[CV 4/5; 34/120] START colsample_bytree=0.2, max_depth=2, n_estimators=200......\n",
      "[CV 4/5; 34/120] END colsample_bytree=0.2, max_depth=2, n_estimators=200;, score=0.946 total time=   0.0s\n",
      "[CV 5/5; 34/120] START colsample_bytree=0.2, max_depth=2, n_estimators=200......\n",
      "[CV 5/5; 34/120] END colsample_bytree=0.2, max_depth=2, n_estimators=200;, score=0.947 total time=   0.0s\n",
      "[CV 1/5; 35/120] START colsample_bytree=0.2, max_depth=2, n_estimators=250......\n",
      "[CV 1/5; 35/120] END colsample_bytree=0.2, max_depth=2, n_estimators=250;, score=0.949 total time=   0.1s\n",
      "[CV 2/5; 35/120] START colsample_bytree=0.2, max_depth=2, n_estimators=250......\n",
      "[CV 2/5; 35/120] END colsample_bytree=0.2, max_depth=2, n_estimators=250;, score=0.946 total time=   0.0s\n",
      "[CV 3/5; 35/120] START colsample_bytree=0.2, max_depth=2, n_estimators=250......\n",
      "[CV 3/5; 35/120] END colsample_bytree=0.2, max_depth=2, n_estimators=250;, score=0.953 total time=   0.1s\n",
      "[CV 4/5; 35/120] START colsample_bytree=0.2, max_depth=2, n_estimators=250......\n",
      "[CV 4/5; 35/120] END colsample_bytree=0.2, max_depth=2, n_estimators=250;, score=0.946 total time=   0.1s\n",
      "[CV 5/5; 35/120] START colsample_bytree=0.2, max_depth=2, n_estimators=250......\n",
      "[CV 5/5; 35/120] END colsample_bytree=0.2, max_depth=2, n_estimators=250;, score=0.949 total time=   0.1s\n",
      "[CV 1/5; 36/120] START colsample_bytree=0.2, max_depth=2, n_estimators=300......\n",
      "[CV 1/5; 36/120] END colsample_bytree=0.2, max_depth=2, n_estimators=300;, score=0.949 total time=   0.1s\n",
      "[CV 2/5; 36/120] START colsample_bytree=0.2, max_depth=2, n_estimators=300......\n",
      "[CV 2/5; 36/120] END colsample_bytree=0.2, max_depth=2, n_estimators=300;, score=0.947 total time=   0.1s\n",
      "[CV 3/5; 36/120] START colsample_bytree=0.2, max_depth=2, n_estimators=300......\n",
      "[CV 3/5; 36/120] END colsample_bytree=0.2, max_depth=2, n_estimators=300;, score=0.953 total time=   0.1s\n",
      "[CV 4/5; 36/120] START colsample_bytree=0.2, max_depth=2, n_estimators=300......\n",
      "[CV 4/5; 36/120] END colsample_bytree=0.2, max_depth=2, n_estimators=300;, score=0.946 total time=   0.1s\n",
      "[CV 5/5; 36/120] START colsample_bytree=0.2, max_depth=2, n_estimators=300......\n",
      "[CV 5/5; 36/120] END colsample_bytree=0.2, max_depth=2, n_estimators=300;, score=0.949 total time=   0.1s\n",
      "[CV 1/5; 37/120] START colsample_bytree=0.3, max_depth=1, n_estimators=50.......\n",
      "[CV 1/5; 37/120] END colsample_bytree=0.3, max_depth=1, n_estimators=50;, score=0.927 total time=   0.0s\n",
      "[CV 2/5; 37/120] START colsample_bytree=0.3, max_depth=1, n_estimators=50.......\n",
      "[CV 2/5; 37/120] END colsample_bytree=0.3, max_depth=1, n_estimators=50;, score=0.924 total time=   0.0s\n",
      "[CV 3/5; 37/120] START colsample_bytree=0.3, max_depth=1, n_estimators=50.......\n",
      "[CV 3/5; 37/120] END colsample_bytree=0.3, max_depth=1, n_estimators=50;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 37/120] START colsample_bytree=0.3, max_depth=1, n_estimators=50.......\n",
      "[CV 4/5; 37/120] END colsample_bytree=0.3, max_depth=1, n_estimators=50;, score=0.929 total time=   0.0s\n",
      "[CV 5/5; 37/120] START colsample_bytree=0.3, max_depth=1, n_estimators=50.......\n",
      "[CV 5/5; 37/120] END colsample_bytree=0.3, max_depth=1, n_estimators=50;, score=0.927 total time=   0.0s\n",
      "[CV 1/5; 38/120] START colsample_bytree=0.3, max_depth=1, n_estimators=100......\n",
      "[CV 1/5; 38/120] END colsample_bytree=0.3, max_depth=1, n_estimators=100;, score=0.927 total time=   0.0s\n",
      "[CV 2/5; 38/120] START colsample_bytree=0.3, max_depth=1, n_estimators=100......\n",
      "[CV 2/5; 38/120] END colsample_bytree=0.3, max_depth=1, n_estimators=100;, score=0.926 total time=   0.0s\n",
      "[CV 3/5; 38/120] START colsample_bytree=0.3, max_depth=1, n_estimators=100......\n",
      "[CV 3/5; 38/120] END colsample_bytree=0.3, max_depth=1, n_estimators=100;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 38/120] START colsample_bytree=0.3, max_depth=1, n_estimators=100......\n",
      "[CV 4/5; 38/120] END colsample_bytree=0.3, max_depth=1, n_estimators=100;, score=0.929 total time=   0.0s\n",
      "[CV 5/5; 38/120] START colsample_bytree=0.3, max_depth=1, n_estimators=100......\n",
      "[CV 5/5; 38/120] END colsample_bytree=0.3, max_depth=1, n_estimators=100;, score=0.926 total time=   0.0s\n",
      "[CV 1/5; 39/120] START colsample_bytree=0.3, max_depth=1, n_estimators=150......\n",
      "[CV 1/5; 39/120] END colsample_bytree=0.3, max_depth=1, n_estimators=150;, score=0.928 total time=   0.0s\n",
      "[CV 2/5; 39/120] START colsample_bytree=0.3, max_depth=1, n_estimators=150......\n",
      "[CV 2/5; 39/120] END colsample_bytree=0.3, max_depth=1, n_estimators=150;, score=0.927 total time=   0.0s\n",
      "[CV 3/5; 39/120] START colsample_bytree=0.3, max_depth=1, n_estimators=150......\n",
      "[CV 3/5; 39/120] END colsample_bytree=0.3, max_depth=1, n_estimators=150;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 39/120] START colsample_bytree=0.3, max_depth=1, n_estimators=150......\n",
      "[CV 4/5; 39/120] END colsample_bytree=0.3, max_depth=1, n_estimators=150;, score=0.929 total time=   0.0s\n",
      "[CV 5/5; 39/120] START colsample_bytree=0.3, max_depth=1, n_estimators=150......\n",
      "[CV 5/5; 39/120] END colsample_bytree=0.3, max_depth=1, n_estimators=150;, score=0.926 total time=   0.0s\n",
      "[CV 1/5; 40/120] START colsample_bytree=0.3, max_depth=1, n_estimators=200......\n",
      "[CV 1/5; 40/120] END colsample_bytree=0.3, max_depth=1, n_estimators=200;, score=0.928 total time=   0.0s\n",
      "[CV 2/5; 40/120] START colsample_bytree=0.3, max_depth=1, n_estimators=200......\n",
      "[CV 2/5; 40/120] END colsample_bytree=0.3, max_depth=1, n_estimators=200;, score=0.927 total time=   0.0s\n",
      "[CV 3/5; 40/120] START colsample_bytree=0.3, max_depth=1, n_estimators=200......\n",
      "[CV 3/5; 40/120] END colsample_bytree=0.3, max_depth=1, n_estimators=200;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 40/120] START colsample_bytree=0.3, max_depth=1, n_estimators=200......\n",
      "[CV 4/5; 40/120] END colsample_bytree=0.3, max_depth=1, n_estimators=200;, score=0.929 total time=   0.0s\n",
      "[CV 5/5; 40/120] START colsample_bytree=0.3, max_depth=1, n_estimators=200......\n",
      "[CV 5/5; 40/120] END colsample_bytree=0.3, max_depth=1, n_estimators=200;, score=0.926 total time=   0.0s\n",
      "[CV 1/5; 41/120] START colsample_bytree=0.3, max_depth=1, n_estimators=250......\n",
      "[CV 1/5; 41/120] END colsample_bytree=0.3, max_depth=1, n_estimators=250;, score=0.929 total time=   0.1s\n",
      "[CV 2/5; 41/120] START colsample_bytree=0.3, max_depth=1, n_estimators=250......\n",
      "[CV 2/5; 41/120] END colsample_bytree=0.3, max_depth=1, n_estimators=250;, score=0.928 total time=   0.0s\n",
      "[CV 3/5; 41/120] START colsample_bytree=0.3, max_depth=1, n_estimators=250......\n",
      "[CV 3/5; 41/120] END colsample_bytree=0.3, max_depth=1, n_estimators=250;, score=0.934 total time=   0.1s\n",
      "[CV 4/5; 41/120] START colsample_bytree=0.3, max_depth=1, n_estimators=250......\n",
      "[CV 4/5; 41/120] END colsample_bytree=0.3, max_depth=1, n_estimators=250;, score=0.929 total time=   0.0s\n",
      "[CV 5/5; 41/120] START colsample_bytree=0.3, max_depth=1, n_estimators=250......\n",
      "[CV 5/5; 41/120] END colsample_bytree=0.3, max_depth=1, n_estimators=250;, score=0.927 total time=   0.0s\n",
      "[CV 1/5; 42/120] START colsample_bytree=0.3, max_depth=1, n_estimators=300......\n",
      "[CV 1/5; 42/120] END colsample_bytree=0.3, max_depth=1, n_estimators=300;, score=0.929 total time=   0.1s\n",
      "[CV 2/5; 42/120] START colsample_bytree=0.3, max_depth=1, n_estimators=300......\n",
      "[CV 2/5; 42/120] END colsample_bytree=0.3, max_depth=1, n_estimators=300;, score=0.928 total time=   0.1s\n",
      "[CV 3/5; 42/120] START colsample_bytree=0.3, max_depth=1, n_estimators=300......\n",
      "[CV 3/5; 42/120] END colsample_bytree=0.3, max_depth=1, n_estimators=300;, score=0.934 total time=   0.1s\n",
      "[CV 4/5; 42/120] START colsample_bytree=0.3, max_depth=1, n_estimators=300......\n",
      "[CV 4/5; 42/120] END colsample_bytree=0.3, max_depth=1, n_estimators=300;, score=0.929 total time=   0.1s\n",
      "[CV 5/5; 42/120] START colsample_bytree=0.3, max_depth=1, n_estimators=300......\n",
      "[CV 5/5; 42/120] END colsample_bytree=0.3, max_depth=1, n_estimators=300;, score=0.927 total time=   0.1s\n",
      "[CV 1/5; 43/120] START colsample_bytree=0.3, max_depth=2, n_estimators=50.......\n",
      "[CV 1/5; 43/120] END colsample_bytree=0.3, max_depth=2, n_estimators=50;, score=0.940 total time=   0.0s\n",
      "[CV 2/5; 43/120] START colsample_bytree=0.3, max_depth=2, n_estimators=50.......\n",
      "[CV 2/5; 43/120] END colsample_bytree=0.3, max_depth=2, n_estimators=50;, score=0.938 total time=   0.0s\n",
      "[CV 3/5; 43/120] START colsample_bytree=0.3, max_depth=2, n_estimators=50.......\n",
      "[CV 3/5; 43/120] END colsample_bytree=0.3, max_depth=2, n_estimators=50;, score=0.944 total time=   0.0s\n",
      "[CV 4/5; 43/120] START colsample_bytree=0.3, max_depth=2, n_estimators=50.......\n",
      "[CV 4/5; 43/120] END colsample_bytree=0.3, max_depth=2, n_estimators=50;, score=0.942 total time=   0.0s\n",
      "[CV 5/5; 43/120] START colsample_bytree=0.3, max_depth=2, n_estimators=50.......\n",
      "[CV 5/5; 43/120] END colsample_bytree=0.3, max_depth=2, n_estimators=50;, score=0.941 total time=   0.0s\n",
      "[CV 1/5; 44/120] START colsample_bytree=0.3, max_depth=2, n_estimators=100......\n",
      "[CV 1/5; 44/120] END colsample_bytree=0.3, max_depth=2, n_estimators=100;, score=0.945 total time=   0.0s\n",
      "[CV 2/5; 44/120] START colsample_bytree=0.3, max_depth=2, n_estimators=100......\n",
      "[CV 2/5; 44/120] END colsample_bytree=0.3, max_depth=2, n_estimators=100;, score=0.942 total time=   0.0s\n",
      "[CV 3/5; 44/120] START colsample_bytree=0.3, max_depth=2, n_estimators=100......\n",
      "[CV 3/5; 44/120] END colsample_bytree=0.3, max_depth=2, n_estimators=100;, score=0.951 total time=   0.0s\n",
      "[CV 4/5; 44/120] START colsample_bytree=0.3, max_depth=2, n_estimators=100......\n",
      "[CV 4/5; 44/120] END colsample_bytree=0.3, max_depth=2, n_estimators=100;, score=0.948 total time=   0.0s\n",
      "[CV 5/5; 44/120] START colsample_bytree=0.3, max_depth=2, n_estimators=100......\n",
      "[CV 5/5; 44/120] END colsample_bytree=0.3, max_depth=2, n_estimators=100;, score=0.944 total time=   0.0s\n",
      "[CV 1/5; 45/120] START colsample_bytree=0.3, max_depth=2, n_estimators=150......\n",
      "[CV 1/5; 45/120] END colsample_bytree=0.3, max_depth=2, n_estimators=150;, score=0.948 total time=   0.0s\n",
      "[CV 2/5; 45/120] START colsample_bytree=0.3, max_depth=2, n_estimators=150......\n",
      "[CV 2/5; 45/120] END colsample_bytree=0.3, max_depth=2, n_estimators=150;, score=0.946 total time=   0.0s\n",
      "[CV 3/5; 45/120] START colsample_bytree=0.3, max_depth=2, n_estimators=150......\n",
      "[CV 3/5; 45/120] END colsample_bytree=0.3, max_depth=2, n_estimators=150;, score=0.953 total time=   0.0s\n",
      "[CV 4/5; 45/120] START colsample_bytree=0.3, max_depth=2, n_estimators=150......\n",
      "[CV 4/5; 45/120] END colsample_bytree=0.3, max_depth=2, n_estimators=150;, score=0.949 total time=   0.0s\n",
      "[CV 5/5; 45/120] START colsample_bytree=0.3, max_depth=2, n_estimators=150......\n",
      "[CV 5/5; 45/120] END colsample_bytree=0.3, max_depth=2, n_estimators=150;, score=0.946 total time=   0.0s\n",
      "[CV 1/5; 46/120] START colsample_bytree=0.3, max_depth=2, n_estimators=200......\n",
      "[CV 1/5; 46/120] END colsample_bytree=0.3, max_depth=2, n_estimators=200;, score=0.948 total time=   0.0s\n",
      "[CV 2/5; 46/120] START colsample_bytree=0.3, max_depth=2, n_estimators=200......\n",
      "[CV 2/5; 46/120] END colsample_bytree=0.3, max_depth=2, n_estimators=200;, score=0.947 total time=   0.0s\n",
      "[CV 3/5; 46/120] START colsample_bytree=0.3, max_depth=2, n_estimators=200......\n",
      "[CV 3/5; 46/120] END colsample_bytree=0.3, max_depth=2, n_estimators=200;, score=0.954 total time=   0.0s\n",
      "[CV 4/5; 46/120] START colsample_bytree=0.3, max_depth=2, n_estimators=200......\n",
      "[CV 4/5; 46/120] END colsample_bytree=0.3, max_depth=2, n_estimators=200;, score=0.948 total time=   0.0s\n",
      "[CV 5/5; 46/120] START colsample_bytree=0.3, max_depth=2, n_estimators=200......\n",
      "[CV 5/5; 46/120] END colsample_bytree=0.3, max_depth=2, n_estimators=200;, score=0.946 total time=   0.0s\n",
      "[CV 1/5; 47/120] START colsample_bytree=0.3, max_depth=2, n_estimators=250......\n",
      "[CV 1/5; 47/120] END colsample_bytree=0.3, max_depth=2, n_estimators=250;, score=0.949 total time=   0.1s\n",
      "[CV 2/5; 47/120] START colsample_bytree=0.3, max_depth=2, n_estimators=250......\n",
      "[CV 2/5; 47/120] END colsample_bytree=0.3, max_depth=2, n_estimators=250;, score=0.948 total time=   0.1s\n",
      "[CV 3/5; 47/120] START colsample_bytree=0.3, max_depth=2, n_estimators=250......\n",
      "[CV 3/5; 47/120] END colsample_bytree=0.3, max_depth=2, n_estimators=250;, score=0.955 total time=   0.1s\n",
      "[CV 4/5; 47/120] START colsample_bytree=0.3, max_depth=2, n_estimators=250......\n",
      "[CV 4/5; 47/120] END colsample_bytree=0.3, max_depth=2, n_estimators=250;, score=0.949 total time=   0.1s\n",
      "[CV 5/5; 47/120] START colsample_bytree=0.3, max_depth=2, n_estimators=250......\n",
      "[CV 5/5; 47/120] END colsample_bytree=0.3, max_depth=2, n_estimators=250;, score=0.948 total time=   0.1s\n",
      "[CV 1/5; 48/120] START colsample_bytree=0.3, max_depth=2, n_estimators=300......\n",
      "[CV 1/5; 48/120] END colsample_bytree=0.3, max_depth=2, n_estimators=300;, score=0.950 total time=   0.1s\n",
      "[CV 2/5; 48/120] START colsample_bytree=0.3, max_depth=2, n_estimators=300......\n",
      "[CV 2/5; 48/120] END colsample_bytree=0.3, max_depth=2, n_estimators=300;, score=0.949 total time=   0.1s\n",
      "[CV 3/5; 48/120] START colsample_bytree=0.3, max_depth=2, n_estimators=300......\n",
      "[CV 3/5; 48/120] END colsample_bytree=0.3, max_depth=2, n_estimators=300;, score=0.955 total time=   0.1s\n",
      "[CV 4/5; 48/120] START colsample_bytree=0.3, max_depth=2, n_estimators=300......\n",
      "[CV 4/5; 48/120] END colsample_bytree=0.3, max_depth=2, n_estimators=300;, score=0.949 total time=   0.1s\n",
      "[CV 5/5; 48/120] START colsample_bytree=0.3, max_depth=2, n_estimators=300......\n",
      "[CV 5/5; 48/120] END colsample_bytree=0.3, max_depth=2, n_estimators=300;, score=0.948 total time=   0.1s\n",
      "[CV 1/5; 49/120] START colsample_bytree=0.4, max_depth=1, n_estimators=50.......\n",
      "[CV 1/5; 49/120] END colsample_bytree=0.4, max_depth=1, n_estimators=50;, score=0.928 total time=   0.0s\n",
      "[CV 2/5; 49/120] START colsample_bytree=0.4, max_depth=1, n_estimators=50.......\n",
      "[CV 2/5; 49/120] END colsample_bytree=0.4, max_depth=1, n_estimators=50;, score=0.927 total time=   0.0s\n",
      "[CV 3/5; 49/120] START colsample_bytree=0.4, max_depth=1, n_estimators=50.......\n",
      "[CV 3/5; 49/120] END colsample_bytree=0.4, max_depth=1, n_estimators=50;, score=0.933 total time=   0.0s\n",
      "[CV 4/5; 49/120] START colsample_bytree=0.4, max_depth=1, n_estimators=50.......\n",
      "[CV 4/5; 49/120] END colsample_bytree=0.4, max_depth=1, n_estimators=50;, score=0.928 total time=   0.0s\n",
      "[CV 5/5; 49/120] START colsample_bytree=0.4, max_depth=1, n_estimators=50.......\n",
      "[CV 5/5; 49/120] END colsample_bytree=0.4, max_depth=1, n_estimators=50;, score=0.926 total time=   0.0s\n",
      "[CV 1/5; 50/120] START colsample_bytree=0.4, max_depth=1, n_estimators=100......\n",
      "[CV 1/5; 50/120] END colsample_bytree=0.4, max_depth=1, n_estimators=100;, score=0.927 total time=   0.0s\n",
      "[CV 2/5; 50/120] START colsample_bytree=0.4, max_depth=1, n_estimators=100......\n",
      "[CV 2/5; 50/120] END colsample_bytree=0.4, max_depth=1, n_estimators=100;, score=0.927 total time=   0.0s\n",
      "[CV 3/5; 50/120] START colsample_bytree=0.4, max_depth=1, n_estimators=100......\n",
      "[CV 3/5; 50/120] END colsample_bytree=0.4, max_depth=1, n_estimators=100;, score=0.935 total time=   0.0s\n",
      "[CV 4/5; 50/120] START colsample_bytree=0.4, max_depth=1, n_estimators=100......\n",
      "[CV 4/5; 50/120] END colsample_bytree=0.4, max_depth=1, n_estimators=100;, score=0.929 total time=   0.0s\n",
      "[CV 5/5; 50/120] START colsample_bytree=0.4, max_depth=1, n_estimators=100......\n",
      "[CV 5/5; 50/120] END colsample_bytree=0.4, max_depth=1, n_estimators=100;, score=0.926 total time=   0.0s\n",
      "[CV 1/5; 51/120] START colsample_bytree=0.4, max_depth=1, n_estimators=150......\n",
      "[CV 1/5; 51/120] END colsample_bytree=0.4, max_depth=1, n_estimators=150;, score=0.928 total time=   0.0s\n",
      "[CV 2/5; 51/120] START colsample_bytree=0.4, max_depth=1, n_estimators=150......\n",
      "[CV 2/5; 51/120] END colsample_bytree=0.4, max_depth=1, n_estimators=150;, score=0.927 total time=   0.0s\n",
      "[CV 3/5; 51/120] START colsample_bytree=0.4, max_depth=1, n_estimators=150......\n",
      "[CV 3/5; 51/120] END colsample_bytree=0.4, max_depth=1, n_estimators=150;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 51/120] START colsample_bytree=0.4, max_depth=1, n_estimators=150......\n",
      "[CV 4/5; 51/120] END colsample_bytree=0.4, max_depth=1, n_estimators=150;, score=0.928 total time=   0.0s\n",
      "[CV 5/5; 51/120] START colsample_bytree=0.4, max_depth=1, n_estimators=150......\n",
      "[CV 5/5; 51/120] END colsample_bytree=0.4, max_depth=1, n_estimators=150;, score=0.926 total time=   0.0s\n",
      "[CV 1/5; 52/120] START colsample_bytree=0.4, max_depth=1, n_estimators=200......\n",
      "[CV 1/5; 52/120] END colsample_bytree=0.4, max_depth=1, n_estimators=200;, score=0.929 total time=   0.0s\n",
      "[CV 2/5; 52/120] START colsample_bytree=0.4, max_depth=1, n_estimators=200......\n",
      "[CV 2/5; 52/120] END colsample_bytree=0.4, max_depth=1, n_estimators=200;, score=0.927 total time=   0.0s\n",
      "[CV 3/5; 52/120] START colsample_bytree=0.4, max_depth=1, n_estimators=200......\n",
      "[CV 3/5; 52/120] END colsample_bytree=0.4, max_depth=1, n_estimators=200;, score=0.934 total time=   0.1s\n",
      "[CV 4/5; 52/120] START colsample_bytree=0.4, max_depth=1, n_estimators=200......\n",
      "[CV 4/5; 52/120] END colsample_bytree=0.4, max_depth=1, n_estimators=200;, score=0.929 total time=   0.1s\n",
      "[CV 5/5; 52/120] START colsample_bytree=0.4, max_depth=1, n_estimators=200......\n",
      "[CV 5/5; 52/120] END colsample_bytree=0.4, max_depth=1, n_estimators=200;, score=0.927 total time=   0.0s\n",
      "[CV 1/5; 53/120] START colsample_bytree=0.4, max_depth=1, n_estimators=250......\n",
      "[CV 1/5; 53/120] END colsample_bytree=0.4, max_depth=1, n_estimators=250;, score=0.929 total time=   0.1s\n",
      "[CV 2/5; 53/120] START colsample_bytree=0.4, max_depth=1, n_estimators=250......\n",
      "[CV 2/5; 53/120] END colsample_bytree=0.4, max_depth=1, n_estimators=250;, score=0.928 total time=   0.1s\n",
      "[CV 3/5; 53/120] START colsample_bytree=0.4, max_depth=1, n_estimators=250......\n",
      "[CV 3/5; 53/120] END colsample_bytree=0.4, max_depth=1, n_estimators=250;, score=0.934 total time=   0.1s\n",
      "[CV 4/5; 53/120] START colsample_bytree=0.4, max_depth=1, n_estimators=250......\n",
      "[CV 4/5; 53/120] END colsample_bytree=0.4, max_depth=1, n_estimators=250;, score=0.929 total time=   0.1s\n",
      "[CV 5/5; 53/120] START colsample_bytree=0.4, max_depth=1, n_estimators=250......\n",
      "[CV 5/5; 53/120] END colsample_bytree=0.4, max_depth=1, n_estimators=250;, score=0.927 total time=   0.1s\n",
      "[CV 1/5; 54/120] START colsample_bytree=0.4, max_depth=1, n_estimators=300......\n",
      "[CV 1/5; 54/120] END colsample_bytree=0.4, max_depth=1, n_estimators=300;, score=0.929 total time=   0.1s\n",
      "[CV 2/5; 54/120] START colsample_bytree=0.4, max_depth=1, n_estimators=300......\n",
      "[CV 2/5; 54/120] END colsample_bytree=0.4, max_depth=1, n_estimators=300;, score=0.928 total time=   0.1s\n",
      "[CV 3/5; 54/120] START colsample_bytree=0.4, max_depth=1, n_estimators=300......\n",
      "[CV 3/5; 54/120] END colsample_bytree=0.4, max_depth=1, n_estimators=300;, score=0.934 total time=   0.1s\n",
      "[CV 4/5; 54/120] START colsample_bytree=0.4, max_depth=1, n_estimators=300......\n",
      "[CV 4/5; 54/120] END colsample_bytree=0.4, max_depth=1, n_estimators=300;, score=0.929 total time=   0.1s\n",
      "[CV 5/5; 54/120] START colsample_bytree=0.4, max_depth=1, n_estimators=300......\n",
      "[CV 5/5; 54/120] END colsample_bytree=0.4, max_depth=1, n_estimators=300;, score=0.927 total time=   0.1s\n",
      "[CV 1/5; 55/120] START colsample_bytree=0.4, max_depth=2, n_estimators=50.......\n",
      "[CV 1/5; 55/120] END colsample_bytree=0.4, max_depth=2, n_estimators=50;, score=0.936 total time=   0.0s\n",
      "[CV 2/5; 55/120] START colsample_bytree=0.4, max_depth=2, n_estimators=50.......\n",
      "[CV 2/5; 55/120] END colsample_bytree=0.4, max_depth=2, n_estimators=50;, score=0.936 total time=   0.0s\n",
      "[CV 3/5; 55/120] START colsample_bytree=0.4, max_depth=2, n_estimators=50.......\n",
      "[CV 3/5; 55/120] END colsample_bytree=0.4, max_depth=2, n_estimators=50;, score=0.942 total time=   0.0s\n",
      "[CV 4/5; 55/120] START colsample_bytree=0.4, max_depth=2, n_estimators=50.......\n",
      "[CV 4/5; 55/120] END colsample_bytree=0.4, max_depth=2, n_estimators=50;, score=0.941 total time=   0.0s\n",
      "[CV 5/5; 55/120] START colsample_bytree=0.4, max_depth=2, n_estimators=50.......\n",
      "[CV 5/5; 55/120] END colsample_bytree=0.4, max_depth=2, n_estimators=50;, score=0.941 total time=   0.0s\n",
      "[CV 1/5; 56/120] START colsample_bytree=0.4, max_depth=2, n_estimators=100......\n",
      "[CV 1/5; 56/120] END colsample_bytree=0.4, max_depth=2, n_estimators=100;, score=0.941 total time=   0.0s\n",
      "[CV 2/5; 56/120] START colsample_bytree=0.4, max_depth=2, n_estimators=100......\n",
      "[CV 2/5; 56/120] END colsample_bytree=0.4, max_depth=2, n_estimators=100;, score=0.945 total time=   0.0s\n",
      "[CV 3/5; 56/120] START colsample_bytree=0.4, max_depth=2, n_estimators=100......\n",
      "[CV 3/5; 56/120] END colsample_bytree=0.4, max_depth=2, n_estimators=100;, score=0.952 total time=   0.0s\n",
      "[CV 4/5; 56/120] START colsample_bytree=0.4, max_depth=2, n_estimators=100......\n",
      "[CV 4/5; 56/120] END colsample_bytree=0.4, max_depth=2, n_estimators=100;, score=0.949 total time=   0.0s\n",
      "[CV 5/5; 56/120] START colsample_bytree=0.4, max_depth=2, n_estimators=100......\n",
      "[CV 5/5; 56/120] END colsample_bytree=0.4, max_depth=2, n_estimators=100;, score=0.947 total time=   0.0s\n",
      "[CV 1/5; 57/120] START colsample_bytree=0.4, max_depth=2, n_estimators=150......\n",
      "[CV 1/5; 57/120] END colsample_bytree=0.4, max_depth=2, n_estimators=150;, score=0.948 total time=   0.0s\n",
      "[CV 2/5; 57/120] START colsample_bytree=0.4, max_depth=2, n_estimators=150......\n",
      "[CV 2/5; 57/120] END colsample_bytree=0.4, max_depth=2, n_estimators=150;, score=0.946 total time=   0.0s\n",
      "[CV 3/5; 57/120] START colsample_bytree=0.4, max_depth=2, n_estimators=150......\n",
      "[CV 3/5; 57/120] END colsample_bytree=0.4, max_depth=2, n_estimators=150;, score=0.954 total time=   0.0s\n",
      "[CV 4/5; 57/120] START colsample_bytree=0.4, max_depth=2, n_estimators=150......\n",
      "[CV 4/5; 57/120] END colsample_bytree=0.4, max_depth=2, n_estimators=150;, score=0.949 total time=   0.0s\n",
      "[CV 5/5; 57/120] START colsample_bytree=0.4, max_depth=2, n_estimators=150......\n",
      "[CV 5/5; 57/120] END colsample_bytree=0.4, max_depth=2, n_estimators=150;, score=0.949 total time=   0.0s\n",
      "[CV 1/5; 58/120] START colsample_bytree=0.4, max_depth=2, n_estimators=200......\n",
      "[CV 1/5; 58/120] END colsample_bytree=0.4, max_depth=2, n_estimators=200;, score=0.949 total time=   0.0s\n",
      "[CV 2/5; 58/120] START colsample_bytree=0.4, max_depth=2, n_estimators=200......\n",
      "[CV 2/5; 58/120] END colsample_bytree=0.4, max_depth=2, n_estimators=200;, score=0.947 total time=   0.0s\n",
      "[CV 3/5; 58/120] START colsample_bytree=0.4, max_depth=2, n_estimators=200......\n",
      "[CV 3/5; 58/120] END colsample_bytree=0.4, max_depth=2, n_estimators=200;, score=0.955 total time=   0.0s\n",
      "[CV 4/5; 58/120] START colsample_bytree=0.4, max_depth=2, n_estimators=200......\n",
      "[CV 4/5; 58/120] END colsample_bytree=0.4, max_depth=2, n_estimators=200;, score=0.950 total time=   0.0s\n",
      "[CV 5/5; 58/120] START colsample_bytree=0.4, max_depth=2, n_estimators=200......\n",
      "[CV 5/5; 58/120] END colsample_bytree=0.4, max_depth=2, n_estimators=200;, score=0.950 total time=   0.1s\n",
      "[CV 1/5; 59/120] START colsample_bytree=0.4, max_depth=2, n_estimators=250......\n",
      "[CV 1/5; 59/120] END colsample_bytree=0.4, max_depth=2, n_estimators=250;, score=0.949 total time=   0.1s\n",
      "[CV 2/5; 59/120] START colsample_bytree=0.4, max_depth=2, n_estimators=250......\n",
      "[CV 2/5; 59/120] END colsample_bytree=0.4, max_depth=2, n_estimators=250;, score=0.947 total time=   0.1s\n",
      "[CV 3/5; 59/120] START colsample_bytree=0.4, max_depth=2, n_estimators=250......\n",
      "[CV 3/5; 59/120] END colsample_bytree=0.4, max_depth=2, n_estimators=250;, score=0.954 total time=   0.0s\n",
      "[CV 4/5; 59/120] START colsample_bytree=0.4, max_depth=2, n_estimators=250......\n",
      "[CV 4/5; 59/120] END colsample_bytree=0.4, max_depth=2, n_estimators=250;, score=0.951 total time=   0.1s\n",
      "[CV 5/5; 59/120] START colsample_bytree=0.4, max_depth=2, n_estimators=250......\n",
      "[CV 5/5; 59/120] END colsample_bytree=0.4, max_depth=2, n_estimators=250;, score=0.950 total time=   0.1s\n",
      "[CV 1/5; 60/120] START colsample_bytree=0.4, max_depth=2, n_estimators=300......\n",
      "[CV 1/5; 60/120] END colsample_bytree=0.4, max_depth=2, n_estimators=300;, score=0.949 total time=   0.1s\n",
      "[CV 2/5; 60/120] START colsample_bytree=0.4, max_depth=2, n_estimators=300......\n",
      "[CV 2/5; 60/120] END colsample_bytree=0.4, max_depth=2, n_estimators=300;, score=0.948 total time=   0.1s\n",
      "[CV 3/5; 60/120] START colsample_bytree=0.4, max_depth=2, n_estimators=300......\n",
      "[CV 3/5; 60/120] END colsample_bytree=0.4, max_depth=2, n_estimators=300;, score=0.955 total time=   0.1s\n",
      "[CV 4/5; 60/120] START colsample_bytree=0.4, max_depth=2, n_estimators=300......\n",
      "[CV 4/5; 60/120] END colsample_bytree=0.4, max_depth=2, n_estimators=300;, score=0.950 total time=   0.1s\n",
      "[CV 5/5; 60/120] START colsample_bytree=0.4, max_depth=2, n_estimators=300......\n",
      "[CV 5/5; 60/120] END colsample_bytree=0.4, max_depth=2, n_estimators=300;, score=0.951 total time=   0.1s\n",
      "[CV 1/5; 61/120] START colsample_bytree=0.5, max_depth=1, n_estimators=50.......\n",
      "[CV 1/5; 61/120] END colsample_bytree=0.5, max_depth=1, n_estimators=50;, score=0.929 total time=   0.0s\n",
      "[CV 2/5; 61/120] START colsample_bytree=0.5, max_depth=1, n_estimators=50.......\n",
      "[CV 2/5; 61/120] END colsample_bytree=0.5, max_depth=1, n_estimators=50;, score=0.927 total time=   0.0s\n",
      "[CV 3/5; 61/120] START colsample_bytree=0.5, max_depth=1, n_estimators=50.......\n",
      "[CV 3/5; 61/120] END colsample_bytree=0.5, max_depth=1, n_estimators=50;, score=0.935 total time=   0.0s\n",
      "[CV 4/5; 61/120] START colsample_bytree=0.5, max_depth=1, n_estimators=50.......\n",
      "[CV 4/5; 61/120] END colsample_bytree=0.5, max_depth=1, n_estimators=50;, score=0.930 total time=   0.0s\n",
      "[CV 5/5; 61/120] START colsample_bytree=0.5, max_depth=1, n_estimators=50.......\n",
      "[CV 5/5; 61/120] END colsample_bytree=0.5, max_depth=1, n_estimators=50;, score=0.925 total time=   0.0s\n",
      "[CV 1/5; 62/120] START colsample_bytree=0.5, max_depth=1, n_estimators=100......\n",
      "[CV 1/5; 62/120] END colsample_bytree=0.5, max_depth=1, n_estimators=100;, score=0.928 total time=   0.0s\n",
      "[CV 2/5; 62/120] START colsample_bytree=0.5, max_depth=1, n_estimators=100......\n",
      "[CV 2/5; 62/120] END colsample_bytree=0.5, max_depth=1, n_estimators=100;, score=0.927 total time=   0.0s\n",
      "[CV 3/5; 62/120] START colsample_bytree=0.5, max_depth=1, n_estimators=100......\n",
      "[CV 3/5; 62/120] END colsample_bytree=0.5, max_depth=1, n_estimators=100;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 62/120] START colsample_bytree=0.5, max_depth=1, n_estimators=100......\n",
      "[CV 4/5; 62/120] END colsample_bytree=0.5, max_depth=1, n_estimators=100;, score=0.929 total time=   0.0s\n",
      "[CV 5/5; 62/120] START colsample_bytree=0.5, max_depth=1, n_estimators=100......\n",
      "[CV 5/5; 62/120] END colsample_bytree=0.5, max_depth=1, n_estimators=100;, score=0.927 total time=   0.0s\n",
      "[CV 1/5; 63/120] START colsample_bytree=0.5, max_depth=1, n_estimators=150......\n",
      "[CV 1/5; 63/120] END colsample_bytree=0.5, max_depth=1, n_estimators=150;, score=0.928 total time=   0.0s\n",
      "[CV 2/5; 63/120] START colsample_bytree=0.5, max_depth=1, n_estimators=150......\n",
      "[CV 2/5; 63/120] END colsample_bytree=0.5, max_depth=1, n_estimators=150;, score=0.928 total time=   0.0s\n",
      "[CV 3/5; 63/120] START colsample_bytree=0.5, max_depth=1, n_estimators=150......\n",
      "[CV 3/5; 63/120] END colsample_bytree=0.5, max_depth=1, n_estimators=150;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 63/120] START colsample_bytree=0.5, max_depth=1, n_estimators=150......\n",
      "[CV 4/5; 63/120] END colsample_bytree=0.5, max_depth=1, n_estimators=150;, score=0.929 total time=   0.0s\n",
      "[CV 5/5; 63/120] START colsample_bytree=0.5, max_depth=1, n_estimators=150......\n",
      "[CV 5/5; 63/120] END colsample_bytree=0.5, max_depth=1, n_estimators=150;, score=0.926 total time=   0.0s\n",
      "[CV 1/5; 64/120] START colsample_bytree=0.5, max_depth=1, n_estimators=200......\n",
      "[CV 1/5; 64/120] END colsample_bytree=0.5, max_depth=1, n_estimators=200;, score=0.929 total time=   0.0s\n",
      "[CV 2/5; 64/120] START colsample_bytree=0.5, max_depth=1, n_estimators=200......\n",
      "[CV 2/5; 64/120] END colsample_bytree=0.5, max_depth=1, n_estimators=200;, score=0.928 total time=   0.0s\n",
      "[CV 3/5; 64/120] START colsample_bytree=0.5, max_depth=1, n_estimators=200......\n",
      "[CV 3/5; 64/120] END colsample_bytree=0.5, max_depth=1, n_estimators=200;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 64/120] START colsample_bytree=0.5, max_depth=1, n_estimators=200......\n",
      "[CV 4/5; 64/120] END colsample_bytree=0.5, max_depth=1, n_estimators=200;, score=0.928 total time=   0.0s\n",
      "[CV 5/5; 64/120] START colsample_bytree=0.5, max_depth=1, n_estimators=200......\n",
      "[CV 5/5; 64/120] END colsample_bytree=0.5, max_depth=1, n_estimators=200;, score=0.927 total time=   0.0s\n",
      "[CV 1/5; 65/120] START colsample_bytree=0.5, max_depth=1, n_estimators=250......\n",
      "[CV 1/5; 65/120] END colsample_bytree=0.5, max_depth=1, n_estimators=250;, score=0.929 total time=   0.0s\n",
      "[CV 2/5; 65/120] START colsample_bytree=0.5, max_depth=1, n_estimators=250......\n",
      "[CV 2/5; 65/120] END colsample_bytree=0.5, max_depth=1, n_estimators=250;, score=0.928 total time=   0.0s\n",
      "[CV 3/5; 65/120] START colsample_bytree=0.5, max_depth=1, n_estimators=250......\n",
      "[CV 3/5; 65/120] END colsample_bytree=0.5, max_depth=1, n_estimators=250;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 65/120] START colsample_bytree=0.5, max_depth=1, n_estimators=250......\n",
      "[CV 4/5; 65/120] END colsample_bytree=0.5, max_depth=1, n_estimators=250;, score=0.929 total time=   0.1s\n",
      "[CV 5/5; 65/120] START colsample_bytree=0.5, max_depth=1, n_estimators=250......\n",
      "[CV 5/5; 65/120] END colsample_bytree=0.5, max_depth=1, n_estimators=250;, score=0.928 total time=   0.0s\n",
      "[CV 1/5; 66/120] START colsample_bytree=0.5, max_depth=1, n_estimators=300......\n",
      "[CV 1/5; 66/120] END colsample_bytree=0.5, max_depth=1, n_estimators=300;, score=0.929 total time=   0.1s\n",
      "[CV 2/5; 66/120] START colsample_bytree=0.5, max_depth=1, n_estimators=300......\n",
      "[CV 2/5; 66/120] END colsample_bytree=0.5, max_depth=1, n_estimators=300;, score=0.928 total time=   0.1s\n",
      "[CV 3/5; 66/120] START colsample_bytree=0.5, max_depth=1, n_estimators=300......\n",
      "[CV 3/5; 66/120] END colsample_bytree=0.5, max_depth=1, n_estimators=300;, score=0.934 total time=   0.1s\n",
      "[CV 4/5; 66/120] START colsample_bytree=0.5, max_depth=1, n_estimators=300......\n",
      "[CV 4/5; 66/120] END colsample_bytree=0.5, max_depth=1, n_estimators=300;, score=0.929 total time=   0.1s\n",
      "[CV 5/5; 66/120] START colsample_bytree=0.5, max_depth=1, n_estimators=300......\n",
      "[CV 5/5; 66/120] END colsample_bytree=0.5, max_depth=1, n_estimators=300;, score=0.927 total time=   0.1s\n",
      "[CV 1/5; 67/120] START colsample_bytree=0.5, max_depth=2, n_estimators=50.......\n",
      "[CV 1/5; 67/120] END colsample_bytree=0.5, max_depth=2, n_estimators=50;, score=0.944 total time=   0.0s\n",
      "[CV 2/5; 67/120] START colsample_bytree=0.5, max_depth=2, n_estimators=50.......\n",
      "[CV 2/5; 67/120] END colsample_bytree=0.5, max_depth=2, n_estimators=50;, score=0.942 total time=   0.0s\n",
      "[CV 3/5; 67/120] START colsample_bytree=0.5, max_depth=2, n_estimators=50.......\n",
      "[CV 3/5; 67/120] END colsample_bytree=0.5, max_depth=2, n_estimators=50;, score=0.949 total time=   0.0s\n",
      "[CV 4/5; 67/120] START colsample_bytree=0.5, max_depth=2, n_estimators=50.......\n",
      "[CV 4/5; 67/120] END colsample_bytree=0.5, max_depth=2, n_estimators=50;, score=0.944 total time=   0.0s\n",
      "[CV 5/5; 67/120] START colsample_bytree=0.5, max_depth=2, n_estimators=50.......\n",
      "[CV 5/5; 67/120] END colsample_bytree=0.5, max_depth=2, n_estimators=50;, score=0.945 total time=   0.0s\n",
      "[CV 1/5; 68/120] START colsample_bytree=0.5, max_depth=2, n_estimators=100......\n",
      "[CV 1/5; 68/120] END colsample_bytree=0.5, max_depth=2, n_estimators=100;, score=0.948 total time=   0.0s\n",
      "[CV 2/5; 68/120] START colsample_bytree=0.5, max_depth=2, n_estimators=100......\n",
      "[CV 2/5; 68/120] END colsample_bytree=0.5, max_depth=2, n_estimators=100;, score=0.945 total time=   0.0s\n",
      "[CV 3/5; 68/120] START colsample_bytree=0.5, max_depth=2, n_estimators=100......\n",
      "[CV 3/5; 68/120] END colsample_bytree=0.5, max_depth=2, n_estimators=100;, score=0.952 total time=   0.0s\n",
      "[CV 4/5; 68/120] START colsample_bytree=0.5, max_depth=2, n_estimators=100......\n",
      "[CV 4/5; 68/120] END colsample_bytree=0.5, max_depth=2, n_estimators=100;, score=0.949 total time=   0.0s\n",
      "[CV 5/5; 68/120] START colsample_bytree=0.5, max_depth=2, n_estimators=100......\n",
      "[CV 5/5; 68/120] END colsample_bytree=0.5, max_depth=2, n_estimators=100;, score=0.947 total time=   0.0s\n",
      "[CV 1/5; 69/120] START colsample_bytree=0.5, max_depth=2, n_estimators=150......\n",
      "[CV 1/5; 69/120] END colsample_bytree=0.5, max_depth=2, n_estimators=150;, score=0.948 total time=   0.0s\n",
      "[CV 2/5; 69/120] START colsample_bytree=0.5, max_depth=2, n_estimators=150......\n",
      "[CV 2/5; 69/120] END colsample_bytree=0.5, max_depth=2, n_estimators=150;, score=0.947 total time=   0.0s\n",
      "[CV 3/5; 69/120] START colsample_bytree=0.5, max_depth=2, n_estimators=150......\n",
      "[CV 3/5; 69/120] END colsample_bytree=0.5, max_depth=2, n_estimators=150;, score=0.956 total time=   0.0s\n",
      "[CV 4/5; 69/120] START colsample_bytree=0.5, max_depth=2, n_estimators=150......\n",
      "[CV 4/5; 69/120] END colsample_bytree=0.5, max_depth=2, n_estimators=150;, score=0.950 total time=   0.0s\n",
      "[CV 5/5; 69/120] START colsample_bytree=0.5, max_depth=2, n_estimators=150......\n",
      "[CV 5/5; 69/120] END colsample_bytree=0.5, max_depth=2, n_estimators=150;, score=0.949 total time=   0.0s\n",
      "[CV 1/5; 70/120] START colsample_bytree=0.5, max_depth=2, n_estimators=200......\n",
      "[CV 1/5; 70/120] END colsample_bytree=0.5, max_depth=2, n_estimators=200;, score=0.949 total time=   0.0s\n",
      "[CV 2/5; 70/120] START colsample_bytree=0.5, max_depth=2, n_estimators=200......\n",
      "[CV 2/5; 70/120] END colsample_bytree=0.5, max_depth=2, n_estimators=200;, score=0.948 total time=   0.0s\n",
      "[CV 3/5; 70/120] START colsample_bytree=0.5, max_depth=2, n_estimators=200......\n",
      "[CV 3/5; 70/120] END colsample_bytree=0.5, max_depth=2, n_estimators=200;, score=0.955 total time=   0.1s\n",
      "[CV 4/5; 70/120] START colsample_bytree=0.5, max_depth=2, n_estimators=200......\n",
      "[CV 4/5; 70/120] END colsample_bytree=0.5, max_depth=2, n_estimators=200;, score=0.951 total time=   0.0s\n",
      "[CV 5/5; 70/120] START colsample_bytree=0.5, max_depth=2, n_estimators=200......\n",
      "[CV 5/5; 70/120] END colsample_bytree=0.5, max_depth=2, n_estimators=200;, score=0.950 total time=   0.0s\n",
      "[CV 1/5; 71/120] START colsample_bytree=0.5, max_depth=2, n_estimators=250......\n",
      "[CV 1/5; 71/120] END colsample_bytree=0.5, max_depth=2, n_estimators=250;, score=0.949 total time=   0.1s\n",
      "[CV 2/5; 71/120] START colsample_bytree=0.5, max_depth=2, n_estimators=250......\n",
      "[CV 2/5; 71/120] END colsample_bytree=0.5, max_depth=2, n_estimators=250;, score=0.948 total time=   0.1s\n",
      "[CV 3/5; 71/120] START colsample_bytree=0.5, max_depth=2, n_estimators=250......\n",
      "[CV 3/5; 71/120] END colsample_bytree=0.5, max_depth=2, n_estimators=250;, score=0.955 total time=   0.1s\n",
      "[CV 4/5; 71/120] START colsample_bytree=0.5, max_depth=2, n_estimators=250......\n",
      "[CV 4/5; 71/120] END colsample_bytree=0.5, max_depth=2, n_estimators=250;, score=0.951 total time=   0.1s\n",
      "[CV 5/5; 71/120] START colsample_bytree=0.5, max_depth=2, n_estimators=250......\n",
      "[CV 5/5; 71/120] END colsample_bytree=0.5, max_depth=2, n_estimators=250;, score=0.951 total time=   0.1s\n",
      "[CV 1/5; 72/120] START colsample_bytree=0.5, max_depth=2, n_estimators=300......\n",
      "[CV 1/5; 72/120] END colsample_bytree=0.5, max_depth=2, n_estimators=300;, score=0.950 total time=   0.1s\n",
      "[CV 2/5; 72/120] START colsample_bytree=0.5, max_depth=2, n_estimators=300......\n",
      "[CV 2/5; 72/120] END colsample_bytree=0.5, max_depth=2, n_estimators=300;, score=0.948 total time=   0.1s\n",
      "[CV 3/5; 72/120] START colsample_bytree=0.5, max_depth=2, n_estimators=300......\n",
      "[CV 3/5; 72/120] END colsample_bytree=0.5, max_depth=2, n_estimators=300;, score=0.955 total time=   0.1s\n",
      "[CV 4/5; 72/120] START colsample_bytree=0.5, max_depth=2, n_estimators=300......\n",
      "[CV 4/5; 72/120] END colsample_bytree=0.5, max_depth=2, n_estimators=300;, score=0.951 total time=   0.1s\n",
      "[CV 5/5; 72/120] START colsample_bytree=0.5, max_depth=2, n_estimators=300......\n",
      "[CV 5/5; 72/120] END colsample_bytree=0.5, max_depth=2, n_estimators=300;, score=0.952 total time=   0.1s\n",
      "[CV 1/5; 73/120] START colsample_bytree=0.6, max_depth=1, n_estimators=50.......\n",
      "[CV 1/5; 73/120] END colsample_bytree=0.6, max_depth=1, n_estimators=50;, score=0.928 total time=   0.0s\n",
      "[CV 2/5; 73/120] START colsample_bytree=0.6, max_depth=1, n_estimators=50.......\n",
      "[CV 2/5; 73/120] END colsample_bytree=0.6, max_depth=1, n_estimators=50;, score=0.928 total time=   0.0s\n",
      "[CV 3/5; 73/120] START colsample_bytree=0.6, max_depth=1, n_estimators=50.......\n",
      "[CV 3/5; 73/120] END colsample_bytree=0.6, max_depth=1, n_estimators=50;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 73/120] START colsample_bytree=0.6, max_depth=1, n_estimators=50.......\n",
      "[CV 4/5; 73/120] END colsample_bytree=0.6, max_depth=1, n_estimators=50;, score=0.928 total time=   0.0s\n",
      "[CV 5/5; 73/120] START colsample_bytree=0.6, max_depth=1, n_estimators=50.......\n",
      "[CV 5/5; 73/120] END colsample_bytree=0.6, max_depth=1, n_estimators=50;, score=0.926 total time=   0.0s\n",
      "[CV 1/5; 74/120] START colsample_bytree=0.6, max_depth=1, n_estimators=100......\n",
      "[CV 1/5; 74/120] END colsample_bytree=0.6, max_depth=1, n_estimators=100;, score=0.928 total time=   0.0s\n",
      "[CV 2/5; 74/120] START colsample_bytree=0.6, max_depth=1, n_estimators=100......\n",
      "[CV 2/5; 74/120] END colsample_bytree=0.6, max_depth=1, n_estimators=100;, score=0.927 total time=   0.0s\n",
      "[CV 3/5; 74/120] START colsample_bytree=0.6, max_depth=1, n_estimators=100......\n",
      "[CV 3/5; 74/120] END colsample_bytree=0.6, max_depth=1, n_estimators=100;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 74/120] START colsample_bytree=0.6, max_depth=1, n_estimators=100......\n",
      "[CV 4/5; 74/120] END colsample_bytree=0.6, max_depth=1, n_estimators=100;, score=0.929 total time=   0.0s\n",
      "[CV 5/5; 74/120] START colsample_bytree=0.6, max_depth=1, n_estimators=100......\n",
      "[CV 5/5; 74/120] END colsample_bytree=0.6, max_depth=1, n_estimators=100;, score=0.926 total time=   0.0s\n",
      "[CV 1/5; 75/120] START colsample_bytree=0.6, max_depth=1, n_estimators=150......\n",
      "[CV 1/5; 75/120] END colsample_bytree=0.6, max_depth=1, n_estimators=150;, score=0.927 total time=   0.0s\n",
      "[CV 2/5; 75/120] START colsample_bytree=0.6, max_depth=1, n_estimators=150......\n",
      "[CV 2/5; 75/120] END colsample_bytree=0.6, max_depth=1, n_estimators=150;, score=0.927 total time=   0.0s\n",
      "[CV 3/5; 75/120] START colsample_bytree=0.6, max_depth=1, n_estimators=150......\n",
      "[CV 3/5; 75/120] END colsample_bytree=0.6, max_depth=1, n_estimators=150;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 75/120] START colsample_bytree=0.6, max_depth=1, n_estimators=150......\n",
      "[CV 4/5; 75/120] END colsample_bytree=0.6, max_depth=1, n_estimators=150;, score=0.929 total time=   0.0s\n",
      "[CV 5/5; 75/120] START colsample_bytree=0.6, max_depth=1, n_estimators=150......\n",
      "[CV 5/5; 75/120] END colsample_bytree=0.6, max_depth=1, n_estimators=150;, score=0.926 total time=   0.0s\n",
      "[CV 1/5; 76/120] START colsample_bytree=0.6, max_depth=1, n_estimators=200......\n",
      "[CV 1/5; 76/120] END colsample_bytree=0.6, max_depth=1, n_estimators=200;, score=0.928 total time=   0.1s\n",
      "[CV 2/5; 76/120] START colsample_bytree=0.6, max_depth=1, n_estimators=200......\n",
      "[CV 2/5; 76/120] END colsample_bytree=0.6, max_depth=1, n_estimators=200;, score=0.928 total time=   0.0s\n",
      "[CV 3/5; 76/120] START colsample_bytree=0.6, max_depth=1, n_estimators=200......\n",
      "[CV 3/5; 76/120] END colsample_bytree=0.6, max_depth=1, n_estimators=200;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 76/120] START colsample_bytree=0.6, max_depth=1, n_estimators=200......\n",
      "[CV 4/5; 76/120] END colsample_bytree=0.6, max_depth=1, n_estimators=200;, score=0.929 total time=   0.0s\n",
      "[CV 5/5; 76/120] START colsample_bytree=0.6, max_depth=1, n_estimators=200......\n",
      "[CV 5/5; 76/120] END colsample_bytree=0.6, max_depth=1, n_estimators=200;, score=0.927 total time=   0.0s\n",
      "[CV 1/5; 77/120] START colsample_bytree=0.6, max_depth=1, n_estimators=250......\n",
      "[CV 1/5; 77/120] END colsample_bytree=0.6, max_depth=1, n_estimators=250;, score=0.929 total time=   0.1s\n",
      "[CV 2/5; 77/120] START colsample_bytree=0.6, max_depth=1, n_estimators=250......\n",
      "[CV 2/5; 77/120] END colsample_bytree=0.6, max_depth=1, n_estimators=250;, score=0.929 total time=   0.1s\n",
      "[CV 3/5; 77/120] START colsample_bytree=0.6, max_depth=1, n_estimators=250......\n",
      "[CV 3/5; 77/120] END colsample_bytree=0.6, max_depth=1, n_estimators=250;, score=0.934 total time=   0.1s\n",
      "[CV 4/5; 77/120] START colsample_bytree=0.6, max_depth=1, n_estimators=250......\n",
      "[CV 4/5; 77/120] END colsample_bytree=0.6, max_depth=1, n_estimators=250;, score=0.929 total time=   0.1s\n",
      "[CV 5/5; 77/120] START colsample_bytree=0.6, max_depth=1, n_estimators=250......\n",
      "[CV 5/5; 77/120] END colsample_bytree=0.6, max_depth=1, n_estimators=250;, score=0.928 total time=   0.1s\n",
      "[CV 1/5; 78/120] START colsample_bytree=0.6, max_depth=1, n_estimators=300......\n",
      "[CV 1/5; 78/120] END colsample_bytree=0.6, max_depth=1, n_estimators=300;, score=0.930 total time=   0.1s\n",
      "[CV 2/5; 78/120] START colsample_bytree=0.6, max_depth=1, n_estimators=300......\n",
      "[CV 2/5; 78/120] END colsample_bytree=0.6, max_depth=1, n_estimators=300;, score=0.928 total time=   0.1s\n",
      "[CV 3/5; 78/120] START colsample_bytree=0.6, max_depth=1, n_estimators=300......\n",
      "[CV 3/5; 78/120] END colsample_bytree=0.6, max_depth=1, n_estimators=300;, score=0.935 total time=   0.1s\n",
      "[CV 4/5; 78/120] START colsample_bytree=0.6, max_depth=1, n_estimators=300......\n",
      "[CV 4/5; 78/120] END colsample_bytree=0.6, max_depth=1, n_estimators=300;, score=0.930 total time=   0.1s\n",
      "[CV 5/5; 78/120] START colsample_bytree=0.6, max_depth=1, n_estimators=300......\n",
      "[CV 5/5; 78/120] END colsample_bytree=0.6, max_depth=1, n_estimators=300;, score=0.928 total time=   0.1s\n",
      "[CV 1/5; 79/120] START colsample_bytree=0.6, max_depth=2, n_estimators=50.......\n",
      "[CV 1/5; 79/120] END colsample_bytree=0.6, max_depth=2, n_estimators=50;, score=0.946 total time=   0.0s\n",
      "[CV 2/5; 79/120] START colsample_bytree=0.6, max_depth=2, n_estimators=50.......\n",
      "[CV 2/5; 79/120] END colsample_bytree=0.6, max_depth=2, n_estimators=50;, score=0.942 total time=   0.0s\n",
      "[CV 3/5; 79/120] START colsample_bytree=0.6, max_depth=2, n_estimators=50.......\n",
      "[CV 3/5; 79/120] END colsample_bytree=0.6, max_depth=2, n_estimators=50;, score=0.952 total time=   0.0s\n",
      "[CV 4/5; 79/120] START colsample_bytree=0.6, max_depth=2, n_estimators=50.......\n",
      "[CV 4/5; 79/120] END colsample_bytree=0.6, max_depth=2, n_estimators=50;, score=0.947 total time=   0.0s\n",
      "[CV 5/5; 79/120] START colsample_bytree=0.6, max_depth=2, n_estimators=50.......\n",
      "[CV 5/5; 79/120] END colsample_bytree=0.6, max_depth=2, n_estimators=50;, score=0.944 total time=   0.0s\n",
      "[CV 1/5; 80/120] START colsample_bytree=0.6, max_depth=2, n_estimators=100......\n",
      "[CV 1/5; 80/120] END colsample_bytree=0.6, max_depth=2, n_estimators=100;, score=0.949 total time=   0.0s\n",
      "[CV 2/5; 80/120] START colsample_bytree=0.6, max_depth=2, n_estimators=100......\n",
      "[CV 2/5; 80/120] END colsample_bytree=0.6, max_depth=2, n_estimators=100;, score=0.946 total time=   0.0s\n",
      "[CV 3/5; 80/120] START colsample_bytree=0.6, max_depth=2, n_estimators=100......\n",
      "[CV 3/5; 80/120] END colsample_bytree=0.6, max_depth=2, n_estimators=100;, score=0.955 total time=   0.0s\n",
      "[CV 4/5; 80/120] START colsample_bytree=0.6, max_depth=2, n_estimators=100......\n",
      "[CV 4/5; 80/120] END colsample_bytree=0.6, max_depth=2, n_estimators=100;, score=0.950 total time=   0.0s\n",
      "[CV 5/5; 80/120] START colsample_bytree=0.6, max_depth=2, n_estimators=100......\n",
      "[CV 5/5; 80/120] END colsample_bytree=0.6, max_depth=2, n_estimators=100;, score=0.949 total time=   0.0s\n",
      "[CV 1/5; 81/120] START colsample_bytree=0.6, max_depth=2, n_estimators=150......\n",
      "[CV 1/5; 81/120] END colsample_bytree=0.6, max_depth=2, n_estimators=150;, score=0.950 total time=   0.0s\n",
      "[CV 2/5; 81/120] START colsample_bytree=0.6, max_depth=2, n_estimators=150......\n",
      "[CV 2/5; 81/120] END colsample_bytree=0.6, max_depth=2, n_estimators=150;, score=0.948 total time=   0.0s\n",
      "[CV 3/5; 81/120] START colsample_bytree=0.6, max_depth=2, n_estimators=150......\n",
      "[CV 3/5; 81/120] END colsample_bytree=0.6, max_depth=2, n_estimators=150;, score=0.955 total time=   0.0s\n",
      "[CV 4/5; 81/120] START colsample_bytree=0.6, max_depth=2, n_estimators=150......\n",
      "[CV 4/5; 81/120] END colsample_bytree=0.6, max_depth=2, n_estimators=150;, score=0.949 total time=   0.0s\n",
      "[CV 5/5; 81/120] START colsample_bytree=0.6, max_depth=2, n_estimators=150......\n",
      "[CV 5/5; 81/120] END colsample_bytree=0.6, max_depth=2, n_estimators=150;, score=0.951 total time=   0.0s\n",
      "[CV 1/5; 82/120] START colsample_bytree=0.6, max_depth=2, n_estimators=200......\n",
      "[CV 1/5; 82/120] END colsample_bytree=0.6, max_depth=2, n_estimators=200;, score=0.950 total time=   0.0s\n",
      "[CV 2/5; 82/120] START colsample_bytree=0.6, max_depth=2, n_estimators=200......\n",
      "[CV 2/5; 82/120] END colsample_bytree=0.6, max_depth=2, n_estimators=200;, score=0.948 total time=   0.0s\n",
      "[CV 3/5; 82/120] START colsample_bytree=0.6, max_depth=2, n_estimators=200......\n",
      "[CV 3/5; 82/120] END colsample_bytree=0.6, max_depth=2, n_estimators=200;, score=0.957 total time=   0.1s\n",
      "[CV 4/5; 82/120] START colsample_bytree=0.6, max_depth=2, n_estimators=200......\n",
      "[CV 4/5; 82/120] END colsample_bytree=0.6, max_depth=2, n_estimators=200;, score=0.950 total time=   0.0s\n",
      "[CV 5/5; 82/120] START colsample_bytree=0.6, max_depth=2, n_estimators=200......\n",
      "[CV 5/5; 82/120] END colsample_bytree=0.6, max_depth=2, n_estimators=200;, score=0.951 total time=   0.0s\n",
      "[CV 1/5; 83/120] START colsample_bytree=0.6, max_depth=2, n_estimators=250......\n",
      "[CV 1/5; 83/120] END colsample_bytree=0.6, max_depth=2, n_estimators=250;, score=0.950 total time=   0.1s\n",
      "[CV 2/5; 83/120] START colsample_bytree=0.6, max_depth=2, n_estimators=250......\n",
      "[CV 2/5; 83/120] END colsample_bytree=0.6, max_depth=2, n_estimators=250;, score=0.948 total time=   0.1s\n",
      "[CV 3/5; 83/120] START colsample_bytree=0.6, max_depth=2, n_estimators=250......\n",
      "[CV 3/5; 83/120] END colsample_bytree=0.6, max_depth=2, n_estimators=250;, score=0.955 total time=   0.1s\n",
      "[CV 4/5; 83/120] START colsample_bytree=0.6, max_depth=2, n_estimators=250......\n",
      "[CV 4/5; 83/120] END colsample_bytree=0.6, max_depth=2, n_estimators=250;, score=0.950 total time=   0.1s\n",
      "[CV 5/5; 83/120] START colsample_bytree=0.6, max_depth=2, n_estimators=250......\n",
      "[CV 5/5; 83/120] END colsample_bytree=0.6, max_depth=2, n_estimators=250;, score=0.952 total time=   0.1s\n",
      "[CV 1/5; 84/120] START colsample_bytree=0.6, max_depth=2, n_estimators=300......\n",
      "[CV 1/5; 84/120] END colsample_bytree=0.6, max_depth=2, n_estimators=300;, score=0.950 total time=   0.1s\n",
      "[CV 2/5; 84/120] START colsample_bytree=0.6, max_depth=2, n_estimators=300......\n",
      "[CV 2/5; 84/120] END colsample_bytree=0.6, max_depth=2, n_estimators=300;, score=0.947 total time=   0.1s\n",
      "[CV 3/5; 84/120] START colsample_bytree=0.6, max_depth=2, n_estimators=300......\n",
      "[CV 3/5; 84/120] END colsample_bytree=0.6, max_depth=2, n_estimators=300;, score=0.955 total time=   0.1s\n",
      "[CV 4/5; 84/120] START colsample_bytree=0.6, max_depth=2, n_estimators=300......\n",
      "[CV 4/5; 84/120] END colsample_bytree=0.6, max_depth=2, n_estimators=300;, score=0.950 total time=   0.1s\n",
      "[CV 5/5; 84/120] START colsample_bytree=0.6, max_depth=2, n_estimators=300......\n",
      "[CV 5/5; 84/120] END colsample_bytree=0.6, max_depth=2, n_estimators=300;, score=0.952 total time=   0.1s\n",
      "[CV 1/5; 85/120] START colsample_bytree=0.7, max_depth=1, n_estimators=50.......\n",
      "[CV 1/5; 85/120] END colsample_bytree=0.7, max_depth=1, n_estimators=50;, score=0.928 total time=   0.0s\n",
      "[CV 2/5; 85/120] START colsample_bytree=0.7, max_depth=1, n_estimators=50.......\n",
      "[CV 2/5; 85/120] END colsample_bytree=0.7, max_depth=1, n_estimators=50;, score=0.927 total time=   0.0s\n",
      "[CV 3/5; 85/120] START colsample_bytree=0.7, max_depth=1, n_estimators=50.......\n",
      "[CV 3/5; 85/120] END colsample_bytree=0.7, max_depth=1, n_estimators=50;, score=0.933 total time=   0.0s\n",
      "[CV 4/5; 85/120] START colsample_bytree=0.7, max_depth=1, n_estimators=50.......\n",
      "[CV 4/5; 85/120] END colsample_bytree=0.7, max_depth=1, n_estimators=50;, score=0.928 total time=   0.0s\n",
      "[CV 5/5; 85/120] START colsample_bytree=0.7, max_depth=1, n_estimators=50.......\n",
      "[CV 5/5; 85/120] END colsample_bytree=0.7, max_depth=1, n_estimators=50;, score=0.926 total time=   0.0s\n",
      "[CV 1/5; 86/120] START colsample_bytree=0.7, max_depth=1, n_estimators=100......\n",
      "[CV 1/5; 86/120] END colsample_bytree=0.7, max_depth=1, n_estimators=100;, score=0.928 total time=   0.0s\n",
      "[CV 2/5; 86/120] START colsample_bytree=0.7, max_depth=1, n_estimators=100......\n",
      "[CV 2/5; 86/120] END colsample_bytree=0.7, max_depth=1, n_estimators=100;, score=0.927 total time=   0.0s\n",
      "[CV 3/5; 86/120] START colsample_bytree=0.7, max_depth=1, n_estimators=100......\n",
      "[CV 3/5; 86/120] END colsample_bytree=0.7, max_depth=1, n_estimators=100;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 86/120] START colsample_bytree=0.7, max_depth=1, n_estimators=100......\n",
      "[CV 4/5; 86/120] END colsample_bytree=0.7, max_depth=1, n_estimators=100;, score=0.929 total time=   0.0s\n",
      "[CV 5/5; 86/120] START colsample_bytree=0.7, max_depth=1, n_estimators=100......\n",
      "[CV 5/5; 86/120] END colsample_bytree=0.7, max_depth=1, n_estimators=100;, score=0.927 total time=   0.0s\n",
      "[CV 1/5; 87/120] START colsample_bytree=0.7, max_depth=1, n_estimators=150......\n",
      "[CV 1/5; 87/120] END colsample_bytree=0.7, max_depth=1, n_estimators=150;, score=0.928 total time=   0.0s\n",
      "[CV 2/5; 87/120] START colsample_bytree=0.7, max_depth=1, n_estimators=150......\n",
      "[CV 2/5; 87/120] END colsample_bytree=0.7, max_depth=1, n_estimators=150;, score=0.927 total time=   0.0s\n",
      "[CV 3/5; 87/120] START colsample_bytree=0.7, max_depth=1, n_estimators=150......\n",
      "[CV 3/5; 87/120] END colsample_bytree=0.7, max_depth=1, n_estimators=150;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 87/120] START colsample_bytree=0.7, max_depth=1, n_estimators=150......\n",
      "[CV 4/5; 87/120] END colsample_bytree=0.7, max_depth=1, n_estimators=150;, score=0.929 total time=   0.0s\n",
      "[CV 5/5; 87/120] START colsample_bytree=0.7, max_depth=1, n_estimators=150......\n",
      "[CV 5/5; 87/120] END colsample_bytree=0.7, max_depth=1, n_estimators=150;, score=0.927 total time=   0.0s\n",
      "[CV 1/5; 88/120] START colsample_bytree=0.7, max_depth=1, n_estimators=200......\n",
      "[CV 1/5; 88/120] END colsample_bytree=0.7, max_depth=1, n_estimators=200;, score=0.928 total time=   0.0s\n",
      "[CV 2/5; 88/120] START colsample_bytree=0.7, max_depth=1, n_estimators=200......\n",
      "[CV 2/5; 88/120] END colsample_bytree=0.7, max_depth=1, n_estimators=200;, score=0.928 total time=   0.0s\n",
      "[CV 3/5; 88/120] START colsample_bytree=0.7, max_depth=1, n_estimators=200......\n",
      "[CV 3/5; 88/120] END colsample_bytree=0.7, max_depth=1, n_estimators=200;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 88/120] START colsample_bytree=0.7, max_depth=1, n_estimators=200......\n",
      "[CV 4/5; 88/120] END colsample_bytree=0.7, max_depth=1, n_estimators=200;, score=0.930 total time=   0.0s\n",
      "[CV 5/5; 88/120] START colsample_bytree=0.7, max_depth=1, n_estimators=200......\n",
      "[CV 5/5; 88/120] END colsample_bytree=0.7, max_depth=1, n_estimators=200;, score=0.927 total time=   0.0s\n",
      "[CV 1/5; 89/120] START colsample_bytree=0.7, max_depth=1, n_estimators=250......\n",
      "[CV 1/5; 89/120] END colsample_bytree=0.7, max_depth=1, n_estimators=250;, score=0.929 total time=   0.1s\n",
      "[CV 2/5; 89/120] START colsample_bytree=0.7, max_depth=1, n_estimators=250......\n",
      "[CV 2/5; 89/120] END colsample_bytree=0.7, max_depth=1, n_estimators=250;, score=0.929 total time=   0.0s\n",
      "[CV 3/5; 89/120] START colsample_bytree=0.7, max_depth=1, n_estimators=250......\n",
      "[CV 3/5; 89/120] END colsample_bytree=0.7, max_depth=1, n_estimators=250;, score=0.934 total time=   0.1s\n",
      "[CV 4/5; 89/120] START colsample_bytree=0.7, max_depth=1, n_estimators=250......\n",
      "[CV 4/5; 89/120] END colsample_bytree=0.7, max_depth=1, n_estimators=250;, score=0.930 total time=   0.1s\n",
      "[CV 5/5; 89/120] START colsample_bytree=0.7, max_depth=1, n_estimators=250......\n",
      "[CV 5/5; 89/120] END colsample_bytree=0.7, max_depth=1, n_estimators=250;, score=0.928 total time=   0.1s\n",
      "[CV 1/5; 90/120] START colsample_bytree=0.7, max_depth=1, n_estimators=300......\n",
      "[CV 1/5; 90/120] END colsample_bytree=0.7, max_depth=1, n_estimators=300;, score=0.930 total time=   0.1s\n",
      "[CV 2/5; 90/120] START colsample_bytree=0.7, max_depth=1, n_estimators=300......\n",
      "[CV 2/5; 90/120] END colsample_bytree=0.7, max_depth=1, n_estimators=300;, score=0.929 total time=   0.1s\n",
      "[CV 3/5; 90/120] START colsample_bytree=0.7, max_depth=1, n_estimators=300......\n",
      "[CV 3/5; 90/120] END colsample_bytree=0.7, max_depth=1, n_estimators=300;, score=0.934 total time=   0.1s\n",
      "[CV 4/5; 90/120] START colsample_bytree=0.7, max_depth=1, n_estimators=300......\n",
      "[CV 4/5; 90/120] END colsample_bytree=0.7, max_depth=1, n_estimators=300;, score=0.930 total time=   0.1s\n",
      "[CV 5/5; 90/120] START colsample_bytree=0.7, max_depth=1, n_estimators=300......\n",
      "[CV 5/5; 90/120] END colsample_bytree=0.7, max_depth=1, n_estimators=300;, score=0.928 total time=   0.1s\n",
      "[CV 1/5; 91/120] START colsample_bytree=0.7, max_depth=2, n_estimators=50.......\n",
      "[CV 1/5; 91/120] END colsample_bytree=0.7, max_depth=2, n_estimators=50;, score=0.947 total time=   0.0s\n",
      "[CV 2/5; 91/120] START colsample_bytree=0.7, max_depth=2, n_estimators=50.......\n",
      "[CV 2/5; 91/120] END colsample_bytree=0.7, max_depth=2, n_estimators=50;, score=0.940 total time=   0.0s\n",
      "[CV 3/5; 91/120] START colsample_bytree=0.7, max_depth=2, n_estimators=50.......\n",
      "[CV 3/5; 91/120] END colsample_bytree=0.7, max_depth=2, n_estimators=50;, score=0.950 total time=   0.0s\n",
      "[CV 4/5; 91/120] START colsample_bytree=0.7, max_depth=2, n_estimators=50.......\n",
      "[CV 4/5; 91/120] END colsample_bytree=0.7, max_depth=2, n_estimators=50;, score=0.945 total time=   0.0s\n",
      "[CV 5/5; 91/120] START colsample_bytree=0.7, max_depth=2, n_estimators=50.......\n",
      "[CV 5/5; 91/120] END colsample_bytree=0.7, max_depth=2, n_estimators=50;, score=0.945 total time=   0.0s\n",
      "[CV 1/5; 92/120] START colsample_bytree=0.7, max_depth=2, n_estimators=100......\n",
      "[CV 1/5; 92/120] END colsample_bytree=0.7, max_depth=2, n_estimators=100;, score=0.950 total time=   0.0s\n",
      "[CV 2/5; 92/120] START colsample_bytree=0.7, max_depth=2, n_estimators=100......\n",
      "[CV 2/5; 92/120] END colsample_bytree=0.7, max_depth=2, n_estimators=100;, score=0.945 total time=   0.0s\n",
      "[CV 3/5; 92/120] START colsample_bytree=0.7, max_depth=2, n_estimators=100......\n",
      "[CV 3/5; 92/120] END colsample_bytree=0.7, max_depth=2, n_estimators=100;, score=0.955 total time=   0.0s\n",
      "[CV 4/5; 92/120] START colsample_bytree=0.7, max_depth=2, n_estimators=100......\n",
      "[CV 4/5; 92/120] END colsample_bytree=0.7, max_depth=2, n_estimators=100;, score=0.949 total time=   0.0s\n",
      "[CV 5/5; 92/120] START colsample_bytree=0.7, max_depth=2, n_estimators=100......\n",
      "[CV 5/5; 92/120] END colsample_bytree=0.7, max_depth=2, n_estimators=100;, score=0.949 total time=   0.0s\n",
      "[CV 1/5; 93/120] START colsample_bytree=0.7, max_depth=2, n_estimators=150......\n",
      "[CV 1/5; 93/120] END colsample_bytree=0.7, max_depth=2, n_estimators=150;, score=0.950 total time=   0.0s\n",
      "[CV 2/5; 93/120] START colsample_bytree=0.7, max_depth=2, n_estimators=150......\n",
      "[CV 2/5; 93/120] END colsample_bytree=0.7, max_depth=2, n_estimators=150;, score=0.946 total time=   0.0s\n",
      "[CV 3/5; 93/120] START colsample_bytree=0.7, max_depth=2, n_estimators=150......\n",
      "[CV 3/5; 93/120] END colsample_bytree=0.7, max_depth=2, n_estimators=150;, score=0.956 total time=   0.0s\n",
      "[CV 4/5; 93/120] START colsample_bytree=0.7, max_depth=2, n_estimators=150......\n",
      "[CV 4/5; 93/120] END colsample_bytree=0.7, max_depth=2, n_estimators=150;, score=0.951 total time=   0.0s\n",
      "[CV 5/5; 93/120] START colsample_bytree=0.7, max_depth=2, n_estimators=150......\n",
      "[CV 5/5; 93/120] END colsample_bytree=0.7, max_depth=2, n_estimators=150;, score=0.951 total time=   0.0s\n",
      "[CV 1/5; 94/120] START colsample_bytree=0.7, max_depth=2, n_estimators=200......\n",
      "[CV 1/5; 94/120] END colsample_bytree=0.7, max_depth=2, n_estimators=200;, score=0.950 total time=   0.0s\n",
      "[CV 2/5; 94/120] START colsample_bytree=0.7, max_depth=2, n_estimators=200......\n",
      "[CV 2/5; 94/120] END colsample_bytree=0.7, max_depth=2, n_estimators=200;, score=0.947 total time=   0.1s\n",
      "[CV 3/5; 94/120] START colsample_bytree=0.7, max_depth=2, n_estimators=200......\n",
      "[CV 3/5; 94/120] END colsample_bytree=0.7, max_depth=2, n_estimators=200;, score=0.956 total time=   0.0s\n",
      "[CV 4/5; 94/120] START colsample_bytree=0.7, max_depth=2, n_estimators=200......\n",
      "[CV 4/5; 94/120] END colsample_bytree=0.7, max_depth=2, n_estimators=200;, score=0.950 total time=   0.1s\n",
      "[CV 5/5; 94/120] START colsample_bytree=0.7, max_depth=2, n_estimators=200......\n",
      "[CV 5/5; 94/120] END colsample_bytree=0.7, max_depth=2, n_estimators=200;, score=0.951 total time=   0.1s\n",
      "[CV 1/5; 95/120] START colsample_bytree=0.7, max_depth=2, n_estimators=250......\n",
      "[CV 1/5; 95/120] END colsample_bytree=0.7, max_depth=2, n_estimators=250;, score=0.950 total time=   0.1s\n",
      "[CV 2/5; 95/120] START colsample_bytree=0.7, max_depth=2, n_estimators=250......\n",
      "[CV 2/5; 95/120] END colsample_bytree=0.7, max_depth=2, n_estimators=250;, score=0.948 total time=   0.1s\n",
      "[CV 3/5; 95/120] START colsample_bytree=0.7, max_depth=2, n_estimators=250......\n",
      "[CV 3/5; 95/120] END colsample_bytree=0.7, max_depth=2, n_estimators=250;, score=0.955 total time=   0.1s\n",
      "[CV 4/5; 95/120] START colsample_bytree=0.7, max_depth=2, n_estimators=250......\n",
      "[CV 4/5; 95/120] END colsample_bytree=0.7, max_depth=2, n_estimators=250;, score=0.950 total time=   0.1s\n",
      "[CV 5/5; 95/120] START colsample_bytree=0.7, max_depth=2, n_estimators=250......\n",
      "[CV 5/5; 95/120] END colsample_bytree=0.7, max_depth=2, n_estimators=250;, score=0.952 total time=   0.1s\n",
      "[CV 1/5; 96/120] START colsample_bytree=0.7, max_depth=2, n_estimators=300......\n",
      "[CV 1/5; 96/120] END colsample_bytree=0.7, max_depth=2, n_estimators=300;, score=0.950 total time=   0.1s\n",
      "[CV 2/5; 96/120] START colsample_bytree=0.7, max_depth=2, n_estimators=300......\n",
      "[CV 2/5; 96/120] END colsample_bytree=0.7, max_depth=2, n_estimators=300;, score=0.948 total time=   0.1s\n",
      "[CV 3/5; 96/120] START colsample_bytree=0.7, max_depth=2, n_estimators=300......\n",
      "[CV 3/5; 96/120] END colsample_bytree=0.7, max_depth=2, n_estimators=300;, score=0.956 total time=   0.2s\n",
      "[CV 4/5; 96/120] START colsample_bytree=0.7, max_depth=2, n_estimators=300......\n",
      "[CV 4/5; 96/120] END colsample_bytree=0.7, max_depth=2, n_estimators=300;, score=0.950 total time=   0.2s\n",
      "[CV 5/5; 96/120] START colsample_bytree=0.7, max_depth=2, n_estimators=300......\n",
      "[CV 5/5; 96/120] END colsample_bytree=0.7, max_depth=2, n_estimators=300;, score=0.951 total time=   0.1s\n",
      "[CV 1/5; 97/120] START colsample_bytree=0.8, max_depth=1, n_estimators=50.......\n",
      "[CV 1/5; 97/120] END colsample_bytree=0.8, max_depth=1, n_estimators=50;, score=0.928 total time=   0.0s\n",
      "[CV 2/5; 97/120] START colsample_bytree=0.8, max_depth=1, n_estimators=50.......\n",
      "[CV 2/5; 97/120] END colsample_bytree=0.8, max_depth=1, n_estimators=50;, score=0.927 total time=   0.0s\n",
      "[CV 3/5; 97/120] START colsample_bytree=0.8, max_depth=1, n_estimators=50.......\n",
      "[CV 3/5; 97/120] END colsample_bytree=0.8, max_depth=1, n_estimators=50;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 97/120] START colsample_bytree=0.8, max_depth=1, n_estimators=50.......\n",
      "[CV 4/5; 97/120] END colsample_bytree=0.8, max_depth=1, n_estimators=50;, score=0.929 total time=   0.0s\n",
      "[CV 5/5; 97/120] START colsample_bytree=0.8, max_depth=1, n_estimators=50.......\n",
      "[CV 5/5; 97/120] END colsample_bytree=0.8, max_depth=1, n_estimators=50;, score=0.925 total time=   0.0s\n",
      "[CV 1/5; 98/120] START colsample_bytree=0.8, max_depth=1, n_estimators=100......\n",
      "[CV 1/5; 98/120] END colsample_bytree=0.8, max_depth=1, n_estimators=100;, score=0.928 total time=   0.0s\n",
      "[CV 2/5; 98/120] START colsample_bytree=0.8, max_depth=1, n_estimators=100......\n",
      "[CV 2/5; 98/120] END colsample_bytree=0.8, max_depth=1, n_estimators=100;, score=0.927 total time=   0.0s\n",
      "[CV 3/5; 98/120] START colsample_bytree=0.8, max_depth=1, n_estimators=100......\n",
      "[CV 3/5; 98/120] END colsample_bytree=0.8, max_depth=1, n_estimators=100;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 98/120] START colsample_bytree=0.8, max_depth=1, n_estimators=100......\n",
      "[CV 4/5; 98/120] END colsample_bytree=0.8, max_depth=1, n_estimators=100;, score=0.929 total time=   0.0s\n",
      "[CV 5/5; 98/120] START colsample_bytree=0.8, max_depth=1, n_estimators=100......\n",
      "[CV 5/5; 98/120] END colsample_bytree=0.8, max_depth=1, n_estimators=100;, score=0.926 total time=   0.0s\n",
      "[CV 1/5; 99/120] START colsample_bytree=0.8, max_depth=1, n_estimators=150......\n",
      "[CV 1/5; 99/120] END colsample_bytree=0.8, max_depth=1, n_estimators=150;, score=0.928 total time=   0.0s\n",
      "[CV 2/5; 99/120] START colsample_bytree=0.8, max_depth=1, n_estimators=150......\n",
      "[CV 2/5; 99/120] END colsample_bytree=0.8, max_depth=1, n_estimators=150;, score=0.927 total time=   0.0s\n",
      "[CV 3/5; 99/120] START colsample_bytree=0.8, max_depth=1, n_estimators=150......\n",
      "[CV 3/5; 99/120] END colsample_bytree=0.8, max_depth=1, n_estimators=150;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 99/120] START colsample_bytree=0.8, max_depth=1, n_estimators=150......\n",
      "[CV 4/5; 99/120] END colsample_bytree=0.8, max_depth=1, n_estimators=150;, score=0.929 total time=   0.0s\n",
      "[CV 5/5; 99/120] START colsample_bytree=0.8, max_depth=1, n_estimators=150......\n",
      "[CV 5/5; 99/120] END colsample_bytree=0.8, max_depth=1, n_estimators=150;, score=0.927 total time=   0.0s\n",
      "[CV 1/5; 100/120] START colsample_bytree=0.8, max_depth=1, n_estimators=200.....\n",
      "[CV 1/5; 100/120] END colsample_bytree=0.8, max_depth=1, n_estimators=200;, score=0.928 total time=   0.0s\n",
      "[CV 2/5; 100/120] START colsample_bytree=0.8, max_depth=1, n_estimators=200.....\n",
      "[CV 2/5; 100/120] END colsample_bytree=0.8, max_depth=1, n_estimators=200;, score=0.928 total time=   0.1s\n",
      "[CV 3/5; 100/120] START colsample_bytree=0.8, max_depth=1, n_estimators=200.....\n",
      "[CV 3/5; 100/120] END colsample_bytree=0.8, max_depth=1, n_estimators=200;, score=0.934 total time=   0.1s\n",
      "[CV 4/5; 100/120] START colsample_bytree=0.8, max_depth=1, n_estimators=200.....\n",
      "[CV 4/5; 100/120] END colsample_bytree=0.8, max_depth=1, n_estimators=200;, score=0.929 total time=   0.1s\n",
      "[CV 5/5; 100/120] START colsample_bytree=0.8, max_depth=1, n_estimators=200.....\n",
      "[CV 5/5; 100/120] END colsample_bytree=0.8, max_depth=1, n_estimators=200;, score=0.926 total time=   0.1s\n",
      "[CV 1/5; 101/120] START colsample_bytree=0.8, max_depth=1, n_estimators=250.....\n",
      "[CV 1/5; 101/120] END colsample_bytree=0.8, max_depth=1, n_estimators=250;, score=0.929 total time=   0.1s\n",
      "[CV 2/5; 101/120] START colsample_bytree=0.8, max_depth=1, n_estimators=250.....\n",
      "[CV 2/5; 101/120] END colsample_bytree=0.8, max_depth=1, n_estimators=250;, score=0.929 total time=   0.1s\n",
      "[CV 3/5; 101/120] START colsample_bytree=0.8, max_depth=1, n_estimators=250.....\n",
      "[CV 3/5; 101/120] END colsample_bytree=0.8, max_depth=1, n_estimators=250;, score=0.934 total time=   0.1s\n",
      "[CV 4/5; 101/120] START colsample_bytree=0.8, max_depth=1, n_estimators=250.....\n",
      "[CV 4/5; 101/120] END colsample_bytree=0.8, max_depth=1, n_estimators=250;, score=0.929 total time=   0.1s\n",
      "[CV 5/5; 101/120] START colsample_bytree=0.8, max_depth=1, n_estimators=250.....\n",
      "[CV 5/5; 101/120] END colsample_bytree=0.8, max_depth=1, n_estimators=250;, score=0.927 total time=   0.1s\n",
      "[CV 1/5; 102/120] START colsample_bytree=0.8, max_depth=1, n_estimators=300.....\n",
      "[CV 1/5; 102/120] END colsample_bytree=0.8, max_depth=1, n_estimators=300;, score=0.930 total time=   0.1s\n",
      "[CV 2/5; 102/120] START colsample_bytree=0.8, max_depth=1, n_estimators=300.....\n",
      "[CV 2/5; 102/120] END colsample_bytree=0.8, max_depth=1, n_estimators=300;, score=0.929 total time=   0.1s\n",
      "[CV 3/5; 102/120] START colsample_bytree=0.8, max_depth=1, n_estimators=300.....\n",
      "[CV 3/5; 102/120] END colsample_bytree=0.8, max_depth=1, n_estimators=300;, score=0.934 total time=   0.1s\n",
      "[CV 4/5; 102/120] START colsample_bytree=0.8, max_depth=1, n_estimators=300.....\n",
      "[CV 4/5; 102/120] END colsample_bytree=0.8, max_depth=1, n_estimators=300;, score=0.930 total time=   0.1s\n",
      "[CV 5/5; 102/120] START colsample_bytree=0.8, max_depth=1, n_estimators=300.....\n",
      "[CV 5/5; 102/120] END colsample_bytree=0.8, max_depth=1, n_estimators=300;, score=0.927 total time=   0.1s\n",
      "[CV 1/5; 103/120] START colsample_bytree=0.8, max_depth=2, n_estimators=50......\n",
      "[CV 1/5; 103/120] END colsample_bytree=0.8, max_depth=2, n_estimators=50;, score=0.946 total time=   0.0s\n",
      "[CV 2/5; 103/120] START colsample_bytree=0.8, max_depth=2, n_estimators=50......\n",
      "[CV 2/5; 103/120] END colsample_bytree=0.8, max_depth=2, n_estimators=50;, score=0.943 total time=   0.0s\n",
      "[CV 3/5; 103/120] START colsample_bytree=0.8, max_depth=2, n_estimators=50......\n",
      "[CV 3/5; 103/120] END colsample_bytree=0.8, max_depth=2, n_estimators=50;, score=0.950 total time=   0.0s\n",
      "[CV 4/5; 103/120] START colsample_bytree=0.8, max_depth=2, n_estimators=50......\n",
      "[CV 4/5; 103/120] END colsample_bytree=0.8, max_depth=2, n_estimators=50;, score=0.946 total time=   0.0s\n",
      "[CV 5/5; 103/120] START colsample_bytree=0.8, max_depth=2, n_estimators=50......\n",
      "[CV 5/5; 103/120] END colsample_bytree=0.8, max_depth=2, n_estimators=50;, score=0.945 total time=   0.0s\n",
      "[CV 1/5; 104/120] START colsample_bytree=0.8, max_depth=2, n_estimators=100.....\n",
      "[CV 1/5; 104/120] END colsample_bytree=0.8, max_depth=2, n_estimators=100;, score=0.949 total time=   0.0s\n",
      "[CV 2/5; 104/120] START colsample_bytree=0.8, max_depth=2, n_estimators=100.....\n",
      "[CV 2/5; 104/120] END colsample_bytree=0.8, max_depth=2, n_estimators=100;, score=0.946 total time=   0.0s\n",
      "[CV 3/5; 104/120] START colsample_bytree=0.8, max_depth=2, n_estimators=100.....\n",
      "[CV 3/5; 104/120] END colsample_bytree=0.8, max_depth=2, n_estimators=100;, score=0.955 total time=   0.0s\n",
      "[CV 4/5; 104/120] START colsample_bytree=0.8, max_depth=2, n_estimators=100.....\n",
      "[CV 4/5; 104/120] END colsample_bytree=0.8, max_depth=2, n_estimators=100;, score=0.950 total time=   0.0s\n",
      "[CV 5/5; 104/120] START colsample_bytree=0.8, max_depth=2, n_estimators=100.....\n",
      "[CV 5/5; 104/120] END colsample_bytree=0.8, max_depth=2, n_estimators=100;, score=0.949 total time=   0.0s\n",
      "[CV 1/5; 105/120] START colsample_bytree=0.8, max_depth=2, n_estimators=150.....\n",
      "[CV 1/5; 105/120] END colsample_bytree=0.8, max_depth=2, n_estimators=150;, score=0.950 total time=   0.0s\n",
      "[CV 2/5; 105/120] START colsample_bytree=0.8, max_depth=2, n_estimators=150.....\n",
      "[CV 2/5; 105/120] END colsample_bytree=0.8, max_depth=2, n_estimators=150;, score=0.948 total time=   0.0s\n",
      "[CV 3/5; 105/120] START colsample_bytree=0.8, max_depth=2, n_estimators=150.....\n",
      "[CV 3/5; 105/120] END colsample_bytree=0.8, max_depth=2, n_estimators=150;, score=0.957 total time=   0.0s\n",
      "[CV 4/5; 105/120] START colsample_bytree=0.8, max_depth=2, n_estimators=150.....\n",
      "[CV 4/5; 105/120] END colsample_bytree=0.8, max_depth=2, n_estimators=150;, score=0.950 total time=   0.0s\n",
      "[CV 5/5; 105/120] START colsample_bytree=0.8, max_depth=2, n_estimators=150.....\n",
      "[CV 5/5; 105/120] END colsample_bytree=0.8, max_depth=2, n_estimators=150;, score=0.951 total time=   0.0s\n",
      "[CV 1/5; 106/120] START colsample_bytree=0.8, max_depth=2, n_estimators=200.....\n",
      "[CV 1/5; 106/120] END colsample_bytree=0.8, max_depth=2, n_estimators=200;, score=0.950 total time=   0.1s\n",
      "[CV 2/5; 106/120] START colsample_bytree=0.8, max_depth=2, n_estimators=200.....\n",
      "[CV 2/5; 106/120] END colsample_bytree=0.8, max_depth=2, n_estimators=200;, score=0.948 total time=   0.0s\n",
      "[CV 3/5; 106/120] START colsample_bytree=0.8, max_depth=2, n_estimators=200.....\n",
      "[CV 3/5; 106/120] END colsample_bytree=0.8, max_depth=2, n_estimators=200;, score=0.956 total time=   0.1s\n",
      "[CV 4/5; 106/120] START colsample_bytree=0.8, max_depth=2, n_estimators=200.....\n",
      "[CV 4/5; 106/120] END colsample_bytree=0.8, max_depth=2, n_estimators=200;, score=0.950 total time=   0.1s\n",
      "[CV 5/5; 106/120] START colsample_bytree=0.8, max_depth=2, n_estimators=200.....\n",
      "[CV 5/5; 106/120] END colsample_bytree=0.8, max_depth=2, n_estimators=200;, score=0.951 total time=   0.1s\n",
      "[CV 1/5; 107/120] START colsample_bytree=0.8, max_depth=2, n_estimators=250.....\n",
      "[CV 1/5; 107/120] END colsample_bytree=0.8, max_depth=2, n_estimators=250;, score=0.950 total time=   0.1s\n",
      "[CV 2/5; 107/120] START colsample_bytree=0.8, max_depth=2, n_estimators=250.....\n",
      "[CV 2/5; 107/120] END colsample_bytree=0.8, max_depth=2, n_estimators=250;, score=0.948 total time=   0.1s\n",
      "[CV 3/5; 107/120] START colsample_bytree=0.8, max_depth=2, n_estimators=250.....\n",
      "[CV 3/5; 107/120] END colsample_bytree=0.8, max_depth=2, n_estimators=250;, score=0.955 total time=   0.1s\n",
      "[CV 4/5; 107/120] START colsample_bytree=0.8, max_depth=2, n_estimators=250.....\n",
      "[CV 4/5; 107/120] END colsample_bytree=0.8, max_depth=2, n_estimators=250;, score=0.950 total time=   0.1s\n",
      "[CV 5/5; 107/120] START colsample_bytree=0.8, max_depth=2, n_estimators=250.....\n",
      "[CV 5/5; 107/120] END colsample_bytree=0.8, max_depth=2, n_estimators=250;, score=0.951 total time=   0.1s\n",
      "[CV 1/5; 108/120] START colsample_bytree=0.8, max_depth=2, n_estimators=300.....\n",
      "[CV 1/5; 108/120] END colsample_bytree=0.8, max_depth=2, n_estimators=300;, score=0.950 total time=   0.1s\n",
      "[CV 2/5; 108/120] START colsample_bytree=0.8, max_depth=2, n_estimators=300.....\n",
      "[CV 2/5; 108/120] END colsample_bytree=0.8, max_depth=2, n_estimators=300;, score=0.949 total time=   0.1s\n",
      "[CV 3/5; 108/120] START colsample_bytree=0.8, max_depth=2, n_estimators=300.....\n",
      "[CV 3/5; 108/120] END colsample_bytree=0.8, max_depth=2, n_estimators=300;, score=0.956 total time=   0.1s\n",
      "[CV 4/5; 108/120] START colsample_bytree=0.8, max_depth=2, n_estimators=300.....\n",
      "[CV 4/5; 108/120] END colsample_bytree=0.8, max_depth=2, n_estimators=300;, score=0.950 total time=   0.1s\n",
      "[CV 5/5; 108/120] START colsample_bytree=0.8, max_depth=2, n_estimators=300.....\n",
      "[CV 5/5; 108/120] END colsample_bytree=0.8, max_depth=2, n_estimators=300;, score=0.952 total time=   0.1s\n",
      "[CV 1/5; 109/120] START colsample_bytree=0.9, max_depth=1, n_estimators=50......\n",
      "[CV 1/5; 109/120] END colsample_bytree=0.9, max_depth=1, n_estimators=50;, score=0.928 total time=   0.0s\n",
      "[CV 2/5; 109/120] START colsample_bytree=0.9, max_depth=1, n_estimators=50......\n",
      "[CV 2/5; 109/120] END colsample_bytree=0.9, max_depth=1, n_estimators=50;, score=0.927 total time=   0.0s\n",
      "[CV 3/5; 109/120] START colsample_bytree=0.9, max_depth=1, n_estimators=50......\n",
      "[CV 3/5; 109/120] END colsample_bytree=0.9, max_depth=1, n_estimators=50;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 109/120] START colsample_bytree=0.9, max_depth=1, n_estimators=50......\n",
      "[CV 4/5; 109/120] END colsample_bytree=0.9, max_depth=1, n_estimators=50;, score=0.928 total time=   0.0s\n",
      "[CV 5/5; 109/120] START colsample_bytree=0.9, max_depth=1, n_estimators=50......\n",
      "[CV 5/5; 109/120] END colsample_bytree=0.9, max_depth=1, n_estimators=50;, score=0.926 total time=   0.0s\n",
      "[CV 1/5; 110/120] START colsample_bytree=0.9, max_depth=1, n_estimators=100.....\n",
      "[CV 1/5; 110/120] END colsample_bytree=0.9, max_depth=1, n_estimators=100;, score=0.928 total time=   0.0s\n",
      "[CV 2/5; 110/120] START colsample_bytree=0.9, max_depth=1, n_estimators=100.....\n",
      "[CV 2/5; 110/120] END colsample_bytree=0.9, max_depth=1, n_estimators=100;, score=0.927 total time=   0.0s\n",
      "[CV 3/5; 110/120] START colsample_bytree=0.9, max_depth=1, n_estimators=100.....\n",
      "[CV 3/5; 110/120] END colsample_bytree=0.9, max_depth=1, n_estimators=100;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 110/120] START colsample_bytree=0.9, max_depth=1, n_estimators=100.....\n",
      "[CV 4/5; 110/120] END colsample_bytree=0.9, max_depth=1, n_estimators=100;, score=0.929 total time=   0.0s\n",
      "[CV 5/5; 110/120] START colsample_bytree=0.9, max_depth=1, n_estimators=100.....\n",
      "[CV 5/5; 110/120] END colsample_bytree=0.9, max_depth=1, n_estimators=100;, score=0.927 total time=   0.0s\n",
      "[CV 1/5; 111/120] START colsample_bytree=0.9, max_depth=1, n_estimators=150.....\n",
      "[CV 1/5; 111/120] END colsample_bytree=0.9, max_depth=1, n_estimators=150;, score=0.928 total time=   0.0s\n",
      "[CV 2/5; 111/120] START colsample_bytree=0.9, max_depth=1, n_estimators=150.....\n",
      "[CV 2/5; 111/120] END colsample_bytree=0.9, max_depth=1, n_estimators=150;, score=0.927 total time=   0.0s\n",
      "[CV 3/5; 111/120] START colsample_bytree=0.9, max_depth=1, n_estimators=150.....\n",
      "[CV 3/5; 111/120] END colsample_bytree=0.9, max_depth=1, n_estimators=150;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 111/120] START colsample_bytree=0.9, max_depth=1, n_estimators=150.....\n",
      "[CV 4/5; 111/120] END colsample_bytree=0.9, max_depth=1, n_estimators=150;, score=0.929 total time=   0.0s\n",
      "[CV 5/5; 111/120] START colsample_bytree=0.9, max_depth=1, n_estimators=150.....\n",
      "[CV 5/5; 111/120] END colsample_bytree=0.9, max_depth=1, n_estimators=150;, score=0.926 total time=   0.0s\n",
      "[CV 1/5; 112/120] START colsample_bytree=0.9, max_depth=1, n_estimators=200.....\n",
      "[CV 1/5; 112/120] END colsample_bytree=0.9, max_depth=1, n_estimators=200;, score=0.929 total time=   0.0s\n",
      "[CV 2/5; 112/120] START colsample_bytree=0.9, max_depth=1, n_estimators=200.....\n",
      "[CV 2/5; 112/120] END colsample_bytree=0.9, max_depth=1, n_estimators=200;, score=0.928 total time=   0.0s\n",
      "[CV 3/5; 112/120] START colsample_bytree=0.9, max_depth=1, n_estimators=200.....\n",
      "[CV 3/5; 112/120] END colsample_bytree=0.9, max_depth=1, n_estimators=200;, score=0.934 total time=   0.0s\n",
      "[CV 4/5; 112/120] START colsample_bytree=0.9, max_depth=1, n_estimators=200.....\n",
      "[CV 4/5; 112/120] END colsample_bytree=0.9, max_depth=1, n_estimators=200;, score=0.930 total time=   0.0s\n",
      "[CV 5/5; 112/120] START colsample_bytree=0.9, max_depth=1, n_estimators=200.....\n",
      "[CV 5/5; 112/120] END colsample_bytree=0.9, max_depth=1, n_estimators=200;, score=0.926 total time=   0.0s\n",
      "[CV 1/5; 113/120] START colsample_bytree=0.9, max_depth=1, n_estimators=250.....\n",
      "[CV 1/5; 113/120] END colsample_bytree=0.9, max_depth=1, n_estimators=250;, score=0.930 total time=   0.1s\n",
      "[CV 2/5; 113/120] START colsample_bytree=0.9, max_depth=1, n_estimators=250.....\n",
      "[CV 2/5; 113/120] END colsample_bytree=0.9, max_depth=1, n_estimators=250;, score=0.928 total time=   0.1s\n",
      "[CV 3/5; 113/120] START colsample_bytree=0.9, max_depth=1, n_estimators=250.....\n",
      "[CV 3/5; 113/120] END colsample_bytree=0.9, max_depth=1, n_estimators=250;, score=0.934 total time=   0.1s\n",
      "[CV 4/5; 113/120] START colsample_bytree=0.9, max_depth=1, n_estimators=250.....\n",
      "[CV 4/5; 113/120] END colsample_bytree=0.9, max_depth=1, n_estimators=250;, score=0.930 total time=   0.1s\n",
      "[CV 5/5; 113/120] START colsample_bytree=0.9, max_depth=1, n_estimators=250.....\n",
      "[CV 5/5; 113/120] END colsample_bytree=0.9, max_depth=1, n_estimators=250;, score=0.927 total time=   0.0s\n",
      "[CV 1/5; 114/120] START colsample_bytree=0.9, max_depth=1, n_estimators=300.....\n",
      "[CV 1/5; 114/120] END colsample_bytree=0.9, max_depth=1, n_estimators=300;, score=0.930 total time=   0.1s\n",
      "[CV 2/5; 114/120] START colsample_bytree=0.9, max_depth=1, n_estimators=300.....\n",
      "[CV 2/5; 114/120] END colsample_bytree=0.9, max_depth=1, n_estimators=300;, score=0.929 total time=   0.1s\n",
      "[CV 3/5; 114/120] START colsample_bytree=0.9, max_depth=1, n_estimators=300.....\n",
      "[CV 3/5; 114/120] END colsample_bytree=0.9, max_depth=1, n_estimators=300;, score=0.934 total time=   0.1s\n",
      "[CV 4/5; 114/120] START colsample_bytree=0.9, max_depth=1, n_estimators=300.....\n",
      "[CV 4/5; 114/120] END colsample_bytree=0.9, max_depth=1, n_estimators=300;, score=0.931 total time=   0.1s\n",
      "[CV 5/5; 114/120] START colsample_bytree=0.9, max_depth=1, n_estimators=300.....\n",
      "[CV 5/5; 114/120] END colsample_bytree=0.9, max_depth=1, n_estimators=300;, score=0.927 total time=   0.1s\n",
      "[CV 1/5; 115/120] START colsample_bytree=0.9, max_depth=2, n_estimators=50......\n",
      "[CV 1/5; 115/120] END colsample_bytree=0.9, max_depth=2, n_estimators=50;, score=0.944 total time=   0.0s\n",
      "[CV 2/5; 115/120] START colsample_bytree=0.9, max_depth=2, n_estimators=50......\n",
      "[CV 2/5; 115/120] END colsample_bytree=0.9, max_depth=2, n_estimators=50;, score=0.943 total time=   0.0s\n",
      "[CV 3/5; 115/120] START colsample_bytree=0.9, max_depth=2, n_estimators=50......\n",
      "[CV 3/5; 115/120] END colsample_bytree=0.9, max_depth=2, n_estimators=50;, score=0.950 total time=   0.0s\n",
      "[CV 4/5; 115/120] START colsample_bytree=0.9, max_depth=2, n_estimators=50......\n",
      "[CV 4/5; 115/120] END colsample_bytree=0.9, max_depth=2, n_estimators=50;, score=0.944 total time=   0.0s\n",
      "[CV 5/5; 115/120] START colsample_bytree=0.9, max_depth=2, n_estimators=50......\n",
      "[CV 5/5; 115/120] END colsample_bytree=0.9, max_depth=2, n_estimators=50;, score=0.944 total time=   0.0s\n",
      "[CV 1/5; 116/120] START colsample_bytree=0.9, max_depth=2, n_estimators=100.....\n",
      "[CV 1/5; 116/120] END colsample_bytree=0.9, max_depth=2, n_estimators=100;, score=0.949 total time=   0.0s\n",
      "[CV 2/5; 116/120] START colsample_bytree=0.9, max_depth=2, n_estimators=100.....\n",
      "[CV 2/5; 116/120] END colsample_bytree=0.9, max_depth=2, n_estimators=100;, score=0.945 total time=   0.0s\n",
      "[CV 3/5; 116/120] START colsample_bytree=0.9, max_depth=2, n_estimators=100.....\n",
      "[CV 3/5; 116/120] END colsample_bytree=0.9, max_depth=2, n_estimators=100;, score=0.954 total time=   0.0s\n",
      "[CV 4/5; 116/120] START colsample_bytree=0.9, max_depth=2, n_estimators=100.....\n",
      "[CV 4/5; 116/120] END colsample_bytree=0.9, max_depth=2, n_estimators=100;, score=0.948 total time=   0.0s\n",
      "[CV 5/5; 116/120] START colsample_bytree=0.9, max_depth=2, n_estimators=100.....\n",
      "[CV 5/5; 116/120] END colsample_bytree=0.9, max_depth=2, n_estimators=100;, score=0.948 total time=   0.0s\n",
      "[CV 1/5; 117/120] START colsample_bytree=0.9, max_depth=2, n_estimators=150.....\n",
      "[CV 1/5; 117/120] END colsample_bytree=0.9, max_depth=2, n_estimators=150;, score=0.949 total time=   0.0s\n",
      "[CV 2/5; 117/120] START colsample_bytree=0.9, max_depth=2, n_estimators=150.....\n",
      "[CV 2/5; 117/120] END colsample_bytree=0.9, max_depth=2, n_estimators=150;, score=0.946 total time=   0.0s\n",
      "[CV 3/5; 117/120] START colsample_bytree=0.9, max_depth=2, n_estimators=150.....\n",
      "[CV 3/5; 117/120] END colsample_bytree=0.9, max_depth=2, n_estimators=150;, score=0.955 total time=   0.0s\n",
      "[CV 4/5; 117/120] START colsample_bytree=0.9, max_depth=2, n_estimators=150.....\n",
      "[CV 4/5; 117/120] END colsample_bytree=0.9, max_depth=2, n_estimators=150;, score=0.948 total time=   0.0s\n",
      "[CV 5/5; 117/120] START colsample_bytree=0.9, max_depth=2, n_estimators=150.....\n",
      "[CV 5/5; 117/120] END colsample_bytree=0.9, max_depth=2, n_estimators=150;, score=0.950 total time=   0.0s\n",
      "[CV 1/5; 118/120] START colsample_bytree=0.9, max_depth=2, n_estimators=200.....\n",
      "[CV 1/5; 118/120] END colsample_bytree=0.9, max_depth=2, n_estimators=200;, score=0.950 total time=   0.0s\n",
      "[CV 2/5; 118/120] START colsample_bytree=0.9, max_depth=2, n_estimators=200.....\n",
      "[CV 2/5; 118/120] END colsample_bytree=0.9, max_depth=2, n_estimators=200;, score=0.946 total time=   0.0s\n",
      "[CV 3/5; 118/120] START colsample_bytree=0.9, max_depth=2, n_estimators=200.....\n",
      "[CV 3/5; 118/120] END colsample_bytree=0.9, max_depth=2, n_estimators=200;, score=0.955 total time=   0.1s\n",
      "[CV 4/5; 118/120] START colsample_bytree=0.9, max_depth=2, n_estimators=200.....\n",
      "[CV 4/5; 118/120] END colsample_bytree=0.9, max_depth=2, n_estimators=200;, score=0.949 total time=   0.0s\n",
      "[CV 5/5; 118/120] START colsample_bytree=0.9, max_depth=2, n_estimators=200.....\n",
      "[CV 5/5; 118/120] END colsample_bytree=0.9, max_depth=2, n_estimators=200;, score=0.950 total time=   0.0s\n",
      "[CV 1/5; 119/120] START colsample_bytree=0.9, max_depth=2, n_estimators=250.....\n",
      "[CV 1/5; 119/120] END colsample_bytree=0.9, max_depth=2, n_estimators=250;, score=0.950 total time=   0.1s\n",
      "[CV 2/5; 119/120] START colsample_bytree=0.9, max_depth=2, n_estimators=250.....\n",
      "[CV 2/5; 119/120] END colsample_bytree=0.9, max_depth=2, n_estimators=250;, score=0.947 total time=   0.1s\n",
      "[CV 3/5; 119/120] START colsample_bytree=0.9, max_depth=2, n_estimators=250.....\n",
      "[CV 3/5; 119/120] END colsample_bytree=0.9, max_depth=2, n_estimators=250;, score=0.955 total time=   0.1s\n",
      "[CV 4/5; 119/120] START colsample_bytree=0.9, max_depth=2, n_estimators=250.....\n",
      "[CV 4/5; 119/120] END colsample_bytree=0.9, max_depth=2, n_estimators=250;, score=0.949 total time=   0.1s\n",
      "[CV 5/5; 119/120] START colsample_bytree=0.9, max_depth=2, n_estimators=250.....\n",
      "[CV 5/5; 119/120] END colsample_bytree=0.9, max_depth=2, n_estimators=250;, score=0.951 total time=   0.1s\n",
      "[CV 1/5; 120/120] START colsample_bytree=0.9, max_depth=2, n_estimators=300.....\n",
      "[CV 1/5; 120/120] END colsample_bytree=0.9, max_depth=2, n_estimators=300;, score=0.950 total time=   0.1s\n",
      "[CV 2/5; 120/120] START colsample_bytree=0.9, max_depth=2, n_estimators=300.....\n",
      "[CV 2/5; 120/120] END colsample_bytree=0.9, max_depth=2, n_estimators=300;, score=0.947 total time=   0.1s\n",
      "[CV 3/5; 120/120] START colsample_bytree=0.9, max_depth=2, n_estimators=300.....\n",
      "[CV 3/5; 120/120] END colsample_bytree=0.9, max_depth=2, n_estimators=300;, score=0.955 total time=   0.1s\n",
      "[CV 4/5; 120/120] START colsample_bytree=0.9, max_depth=2, n_estimators=300.....\n",
      "[CV 4/5; 120/120] END colsample_bytree=0.9, max_depth=2, n_estimators=300;, score=0.949 total time=   0.1s\n",
      "[CV 5/5; 120/120] START colsample_bytree=0.9, max_depth=2, n_estimators=300.....\n",
      "[CV 5/5; 120/120] END colsample_bytree=0.9, max_depth=2, n_estimators=300;, score=0.951 total time=   0.1s\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgbModel = XGBClassifier(objective = 'binary:logistic')\n",
    "xgbGrid = {'n_estimators': list(range(50, 350, 50)),\n",
    "          'max_depth': list(range(1,3)),\n",
    "          'colsample_bytree' : [x / 10 for x in range(0,10)]}\n",
    "xgbSearch = GridSearchCV(xgbModel, xgbGrid, cv=5, verbose=10).fit(Xscaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da21ea2f-b77c-4839-8f86-30b305a39e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9512725484272606\n",
      "{'colsample_bytree': 0.8, 'max_depth': 2, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "print(xgbSearch.best_score_)\n",
    "print(xgbSearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d373b7a4-3a07-4901-94d2-06fd0eb4b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# because our best score was at the maximums for both of our ranges, we will rerun with them increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b413779e-6f26-46e1-8d80-7388f1262dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n",
      "[CV 1/5; 1/360] START colsample_bytree=0.0, max_depth=1, n_estimators=300.......\n",
      "[CV 1/5; 1/360] END colsample_bytree=0.0, max_depth=1, n_estimators=300;, score=0.928 total time=   0.2s\n",
      "[CV 2/5; 1/360] START colsample_bytree=0.0, max_depth=1, n_estimators=300.......\n",
      "[CV 2/5; 1/360] END colsample_bytree=0.0, max_depth=1, n_estimators=300;, score=0.927 total time=   0.1s\n",
      "[CV 3/5; 1/360] START colsample_bytree=0.0, max_depth=1, n_estimators=300.......\n",
      "[CV 3/5; 1/360] END colsample_bytree=0.0, max_depth=1, n_estimators=300;, score=0.930 total time=   0.1s\n",
      "[CV 4/5; 1/360] START colsample_bytree=0.0, max_depth=1, n_estimators=300.......\n",
      "[CV 4/5; 1/360] END colsample_bytree=0.0, max_depth=1, n_estimators=300;, score=0.932 total time=   0.1s\n",
      "[CV 5/5; 1/360] START colsample_bytree=0.0, max_depth=1, n_estimators=300.......\n",
      "[CV 5/5; 1/360] END colsample_bytree=0.0, max_depth=1, n_estimators=300;, score=0.927 total time=   0.1s\n",
      "[CV 1/5; 2/360] START colsample_bytree=0.0, max_depth=1, n_estimators=350.......\n",
      "[CV 1/5; 2/360] END colsample_bytree=0.0, max_depth=1, n_estimators=350;, score=0.927 total time=   0.1s\n",
      "[CV 2/5; 2/360] START colsample_bytree=0.0, max_depth=1, n_estimators=350.......\n",
      "[CV 2/5; 2/360] END colsample_bytree=0.0, max_depth=1, n_estimators=350;, score=0.927 total time=   0.1s\n",
      "[CV 3/5; 2/360] START colsample_bytree=0.0, max_depth=1, n_estimators=350.......\n",
      "[CV 3/5; 2/360] END colsample_bytree=0.0, max_depth=1, n_estimators=350;, score=0.930 total time=   0.1s\n",
      "[CV 4/5; 2/360] START colsample_bytree=0.0, max_depth=1, n_estimators=350.......\n",
      "[CV 4/5; 2/360] END colsample_bytree=0.0, max_depth=1, n_estimators=350;, score=0.931 total time=   0.1s\n",
      "[CV 5/5; 2/360] START colsample_bytree=0.0, max_depth=1, n_estimators=350.......\n",
      "[CV 5/5; 2/360] END colsample_bytree=0.0, max_depth=1, n_estimators=350;, score=0.928 total time=   0.1s\n",
      "[CV 1/5; 3/360] START colsample_bytree=0.0, max_depth=1, n_estimators=400.......\n",
      "[CV 1/5; 3/360] END colsample_bytree=0.0, max_depth=1, n_estimators=400;, score=0.928 total time=   0.1s\n",
      "[CV 2/5; 3/360] START colsample_bytree=0.0, max_depth=1, n_estimators=400.......\n",
      "[CV 2/5; 3/360] END colsample_bytree=0.0, max_depth=1, n_estimators=400;, score=0.927 total time=   0.1s\n",
      "[CV 3/5; 3/360] START colsample_bytree=0.0, max_depth=1, n_estimators=400.......\n",
      "[CV 3/5; 3/360] END colsample_bytree=0.0, max_depth=1, n_estimators=400;, score=0.930 total time=   0.1s\n",
      "[CV 4/5; 3/360] START colsample_bytree=0.0, max_depth=1, n_estimators=400.......\n",
      "[CV 4/5; 3/360] END colsample_bytree=0.0, max_depth=1, n_estimators=400;, score=0.931 total time=   0.1s\n",
      "[CV 5/5; 3/360] START colsample_bytree=0.0, max_depth=1, n_estimators=400.......\n",
      "[CV 5/5; 3/360] END colsample_bytree=0.0, max_depth=1, n_estimators=400;, score=0.928 total time=   0.1s\n",
      "[CV 1/5; 4/360] START colsample_bytree=0.0, max_depth=1, n_estimators=450.......\n",
      "[CV 1/5; 4/360] END colsample_bytree=0.0, max_depth=1, n_estimators=450;, score=0.927 total time=   0.1s\n",
      "[CV 2/5; 4/360] START colsample_bytree=0.0, max_depth=1, n_estimators=450.......\n",
      "[CV 2/5; 4/360] END colsample_bytree=0.0, max_depth=1, n_estimators=450;, score=0.927 total time=   0.1s\n",
      "[CV 3/5; 4/360] START colsample_bytree=0.0, max_depth=1, n_estimators=450.......\n",
      "[CV 3/5; 4/360] END colsample_bytree=0.0, max_depth=1, n_estimators=450;, score=0.931 total time=   0.1s\n",
      "[CV 4/5; 4/360] START colsample_bytree=0.0, max_depth=1, n_estimators=450.......\n",
      "[CV 4/5; 4/360] END colsample_bytree=0.0, max_depth=1, n_estimators=450;, score=0.932 total time=   0.1s\n",
      "[CV 5/5; 4/360] START colsample_bytree=0.0, max_depth=1, n_estimators=450.......\n",
      "[CV 5/5; 4/360] END colsample_bytree=0.0, max_depth=1, n_estimators=450;, score=0.928 total time=   0.2s\n",
      "[CV 1/5; 5/360] START colsample_bytree=0.0, max_depth=1, n_estimators=500.......\n",
      "[CV 1/5; 5/360] END colsample_bytree=0.0, max_depth=1, n_estimators=500;, score=0.928 total time=   0.2s\n",
      "[CV 2/5; 5/360] START colsample_bytree=0.0, max_depth=1, n_estimators=500.......\n",
      "[CV 2/5; 5/360] END colsample_bytree=0.0, max_depth=1, n_estimators=500;, score=0.928 total time=   0.2s\n",
      "[CV 3/5; 5/360] START colsample_bytree=0.0, max_depth=1, n_estimators=500.......\n",
      "[CV 3/5; 5/360] END colsample_bytree=0.0, max_depth=1, n_estimators=500;, score=0.930 total time=   0.2s\n",
      "[CV 4/5; 5/360] START colsample_bytree=0.0, max_depth=1, n_estimators=500.......\n",
      "[CV 4/5; 5/360] END colsample_bytree=0.0, max_depth=1, n_estimators=500;, score=0.932 total time=   0.2s\n",
      "[CV 5/5; 5/360] START colsample_bytree=0.0, max_depth=1, n_estimators=500.......\n",
      "[CV 5/5; 5/360] END colsample_bytree=0.0, max_depth=1, n_estimators=500;, score=0.928 total time=   0.2s\n",
      "[CV 1/5; 6/360] START colsample_bytree=0.0, max_depth=1, n_estimators=550.......\n",
      "[CV 1/5; 6/360] END colsample_bytree=0.0, max_depth=1, n_estimators=550;, score=0.928 total time=   0.2s\n",
      "[CV 2/5; 6/360] START colsample_bytree=0.0, max_depth=1, n_estimators=550.......\n",
      "[CV 2/5; 6/360] END colsample_bytree=0.0, max_depth=1, n_estimators=550;, score=0.928 total time=   0.2s\n",
      "[CV 3/5; 6/360] START colsample_bytree=0.0, max_depth=1, n_estimators=550.......\n",
      "[CV 3/5; 6/360] END colsample_bytree=0.0, max_depth=1, n_estimators=550;, score=0.931 total time=   0.2s\n",
      "[CV 4/5; 6/360] START colsample_bytree=0.0, max_depth=1, n_estimators=550.......\n",
      "[CV 4/5; 6/360] END colsample_bytree=0.0, max_depth=1, n_estimators=550;, score=0.932 total time=   0.2s\n",
      "[CV 5/5; 6/360] START colsample_bytree=0.0, max_depth=1, n_estimators=550.......\n",
      "[CV 5/5; 6/360] END colsample_bytree=0.0, max_depth=1, n_estimators=550;, score=0.928 total time=   0.2s\n",
      "[CV 1/5; 7/360] START colsample_bytree=0.0, max_depth=2, n_estimators=300.......\n",
      "[CV 1/5; 7/360] END colsample_bytree=0.0, max_depth=2, n_estimators=300;, score=0.930 total time=   0.1s\n",
      "[CV 2/5; 7/360] START colsample_bytree=0.0, max_depth=2, n_estimators=300.......\n",
      "[CV 2/5; 7/360] END colsample_bytree=0.0, max_depth=2, n_estimators=300;, score=0.931 total time=   0.1s\n",
      "[CV 3/5; 7/360] START colsample_bytree=0.0, max_depth=2, n_estimators=300.......\n",
      "[CV 3/5; 7/360] END colsample_bytree=0.0, max_depth=2, n_estimators=300;, score=0.932 total time=   0.1s\n",
      "[CV 4/5; 7/360] START colsample_bytree=0.0, max_depth=2, n_estimators=300.......\n",
      "[CV 4/5; 7/360] END colsample_bytree=0.0, max_depth=2, n_estimators=300;, score=0.932 total time=   0.1s\n",
      "[CV 5/5; 7/360] START colsample_bytree=0.0, max_depth=2, n_estimators=300.......\n",
      "[CV 5/5; 7/360] END colsample_bytree=0.0, max_depth=2, n_estimators=300;, score=0.932 total time=   0.1s\n",
      "[CV 1/5; 8/360] START colsample_bytree=0.0, max_depth=2, n_estimators=350.......\n",
      "[CV 1/5; 8/360] END colsample_bytree=0.0, max_depth=2, n_estimators=350;, score=0.930 total time=   0.1s\n",
      "[CV 2/5; 8/360] START colsample_bytree=0.0, max_depth=2, n_estimators=350.......\n",
      "[CV 2/5; 8/360] END colsample_bytree=0.0, max_depth=2, n_estimators=350;, score=0.931 total time=   0.1s\n",
      "[CV 3/5; 8/360] START colsample_bytree=0.0, max_depth=2, n_estimators=350.......\n",
      "[CV 3/5; 8/360] END colsample_bytree=0.0, max_depth=2, n_estimators=350;, score=0.932 total time=   0.1s\n",
      "[CV 4/5; 8/360] START colsample_bytree=0.0, max_depth=2, n_estimators=350.......\n",
      "[CV 4/5; 8/360] END colsample_bytree=0.0, max_depth=2, n_estimators=350;, score=0.932 total time=   0.1s\n",
      "[CV 5/5; 8/360] START colsample_bytree=0.0, max_depth=2, n_estimators=350.......\n",
      "[CV 5/5; 8/360] END colsample_bytree=0.0, max_depth=2, n_estimators=350;, score=0.932 total time=   0.1s\n",
      "[CV 1/5; 9/360] START colsample_bytree=0.0, max_depth=2, n_estimators=400.......\n",
      "[CV 1/5; 9/360] END colsample_bytree=0.0, max_depth=2, n_estimators=400;, score=0.929 total time=   0.2s\n",
      "[CV 2/5; 9/360] START colsample_bytree=0.0, max_depth=2, n_estimators=400.......\n",
      "[CV 2/5; 9/360] END colsample_bytree=0.0, max_depth=2, n_estimators=400;, score=0.931 total time=   0.1s\n",
      "[CV 3/5; 9/360] START colsample_bytree=0.0, max_depth=2, n_estimators=400.......\n",
      "[CV 3/5; 9/360] END colsample_bytree=0.0, max_depth=2, n_estimators=400;, score=0.933 total time=   0.2s\n",
      "[CV 4/5; 9/360] START colsample_bytree=0.0, max_depth=2, n_estimators=400.......\n",
      "[CV 4/5; 9/360] END colsample_bytree=0.0, max_depth=2, n_estimators=400;, score=0.933 total time=   0.2s\n",
      "[CV 5/5; 9/360] START colsample_bytree=0.0, max_depth=2, n_estimators=400.......\n",
      "[CV 5/5; 9/360] END colsample_bytree=0.0, max_depth=2, n_estimators=400;, score=0.933 total time=   0.2s\n",
      "[CV 1/5; 10/360] START colsample_bytree=0.0, max_depth=2, n_estimators=450......\n",
      "[CV 1/5; 10/360] END colsample_bytree=0.0, max_depth=2, n_estimators=450;, score=0.930 total time=   0.2s\n",
      "[CV 2/5; 10/360] START colsample_bytree=0.0, max_depth=2, n_estimators=450......\n",
      "[CV 2/5; 10/360] END colsample_bytree=0.0, max_depth=2, n_estimators=450;, score=0.930 total time=   0.2s\n",
      "[CV 3/5; 10/360] START colsample_bytree=0.0, max_depth=2, n_estimators=450......\n",
      "[CV 3/5; 10/360] END colsample_bytree=0.0, max_depth=2, n_estimators=450;, score=0.933 total time=   0.2s\n",
      "[CV 4/5; 10/360] START colsample_bytree=0.0, max_depth=2, n_estimators=450......\n",
      "[CV 4/5; 10/360] END colsample_bytree=0.0, max_depth=2, n_estimators=450;, score=0.933 total time=   0.3s\n",
      "[CV 5/5; 10/360] START colsample_bytree=0.0, max_depth=2, n_estimators=450......\n",
      "[CV 5/5; 10/360] END colsample_bytree=0.0, max_depth=2, n_estimators=450;, score=0.933 total time=   0.3s\n",
      "[CV 1/5; 11/360] START colsample_bytree=0.0, max_depth=2, n_estimators=500......\n",
      "[CV 1/5; 11/360] END colsample_bytree=0.0, max_depth=2, n_estimators=500;, score=0.930 total time=   0.3s\n",
      "[CV 2/5; 11/360] START colsample_bytree=0.0, max_depth=2, n_estimators=500......\n",
      "[CV 2/5; 11/360] END colsample_bytree=0.0, max_depth=2, n_estimators=500;, score=0.930 total time=   0.3s\n",
      "[CV 3/5; 11/360] START colsample_bytree=0.0, max_depth=2, n_estimators=500......\n",
      "[CV 3/5; 11/360] END colsample_bytree=0.0, max_depth=2, n_estimators=500;, score=0.933 total time=   0.3s\n",
      "[CV 4/5; 11/360] START colsample_bytree=0.0, max_depth=2, n_estimators=500......\n",
      "[CV 4/5; 11/360] END colsample_bytree=0.0, max_depth=2, n_estimators=500;, score=0.933 total time=   0.3s\n",
      "[CV 5/5; 11/360] START colsample_bytree=0.0, max_depth=2, n_estimators=500......\n",
      "[CV 5/5; 11/360] END colsample_bytree=0.0, max_depth=2, n_estimators=500;, score=0.933 total time=   0.2s\n",
      "[CV 1/5; 12/360] START colsample_bytree=0.0, max_depth=2, n_estimators=550......\n",
      "[CV 1/5; 12/360] END colsample_bytree=0.0, max_depth=2, n_estimators=550;, score=0.930 total time=   0.3s\n",
      "[CV 2/5; 12/360] START colsample_bytree=0.0, max_depth=2, n_estimators=550......\n",
      "[CV 2/5; 12/360] END colsample_bytree=0.0, max_depth=2, n_estimators=550;, score=0.931 total time=   0.4s\n",
      "[CV 3/5; 12/360] START colsample_bytree=0.0, max_depth=2, n_estimators=550......\n",
      "[CV 3/5; 12/360] END colsample_bytree=0.0, max_depth=2, n_estimators=550;, score=0.934 total time=   0.2s\n",
      "[CV 4/5; 12/360] START colsample_bytree=0.0, max_depth=2, n_estimators=550......\n",
      "[CV 4/5; 12/360] END colsample_bytree=0.0, max_depth=2, n_estimators=550;, score=0.933 total time=   0.2s\n",
      "[CV 5/5; 12/360] START colsample_bytree=0.0, max_depth=2, n_estimators=550......\n",
      "[CV 5/5; 12/360] END colsample_bytree=0.0, max_depth=2, n_estimators=550;, score=0.933 total time=   0.2s\n",
      "[CV 1/5; 13/360] START colsample_bytree=0.0, max_depth=3, n_estimators=300......\n",
      "[CV 1/5; 13/360] END colsample_bytree=0.0, max_depth=3, n_estimators=300;, score=0.931 total time=   0.1s\n",
      "[CV 2/5; 13/360] START colsample_bytree=0.0, max_depth=3, n_estimators=300......\n",
      "[CV 2/5; 13/360] END colsample_bytree=0.0, max_depth=3, n_estimators=300;, score=0.931 total time=   0.1s\n",
      "[CV 3/5; 13/360] START colsample_bytree=0.0, max_depth=3, n_estimators=300......\n",
      "[CV 3/5; 13/360] END colsample_bytree=0.0, max_depth=3, n_estimators=300;, score=0.933 total time=   0.1s\n",
      "[CV 4/5; 13/360] START colsample_bytree=0.0, max_depth=3, n_estimators=300......\n",
      "[CV 4/5; 13/360] END colsample_bytree=0.0, max_depth=3, n_estimators=300;, score=0.932 total time=   0.1s\n",
      "[CV 5/5; 13/360] START colsample_bytree=0.0, max_depth=3, n_estimators=300......\n",
      "[CV 5/5; 13/360] END colsample_bytree=0.0, max_depth=3, n_estimators=300;, score=0.933 total time=   0.1s\n",
      "[CV 1/5; 14/360] START colsample_bytree=0.0, max_depth=3, n_estimators=350......\n",
      "[CV 1/5; 14/360] END colsample_bytree=0.0, max_depth=3, n_estimators=350;, score=0.931 total time=   0.2s\n",
      "[CV 2/5; 14/360] START colsample_bytree=0.0, max_depth=3, n_estimators=350......\n",
      "[CV 2/5; 14/360] END colsample_bytree=0.0, max_depth=3, n_estimators=350;, score=0.931 total time=   0.2s\n",
      "[CV 3/5; 14/360] START colsample_bytree=0.0, max_depth=3, n_estimators=350......\n",
      "[CV 3/5; 14/360] END colsample_bytree=0.0, max_depth=3, n_estimators=350;, score=0.933 total time=   0.2s\n",
      "[CV 4/5; 14/360] START colsample_bytree=0.0, max_depth=3, n_estimators=350......\n",
      "[CV 4/5; 14/360] END colsample_bytree=0.0, max_depth=3, n_estimators=350;, score=0.932 total time=   0.2s\n",
      "[CV 5/5; 14/360] START colsample_bytree=0.0, max_depth=3, n_estimators=350......\n",
      "[CV 5/5; 14/360] END colsample_bytree=0.0, max_depth=3, n_estimators=350;, score=0.933 total time=   0.2s\n",
      "[CV 1/5; 15/360] START colsample_bytree=0.0, max_depth=3, n_estimators=400......\n",
      "[CV 1/5; 15/360] END colsample_bytree=0.0, max_depth=3, n_estimators=400;, score=0.931 total time=   0.2s\n",
      "[CV 2/5; 15/360] START colsample_bytree=0.0, max_depth=3, n_estimators=400......\n",
      "[CV 2/5; 15/360] END colsample_bytree=0.0, max_depth=3, n_estimators=400;, score=0.931 total time=   0.2s\n",
      "[CV 3/5; 15/360] START colsample_bytree=0.0, max_depth=3, n_estimators=400......\n",
      "[CV 3/5; 15/360] END colsample_bytree=0.0, max_depth=3, n_estimators=400;, score=0.934 total time=   0.2s\n",
      "[CV 4/5; 15/360] START colsample_bytree=0.0, max_depth=3, n_estimators=400......\n",
      "[CV 4/5; 15/360] END colsample_bytree=0.0, max_depth=3, n_estimators=400;, score=0.931 total time=   0.2s\n",
      "[CV 5/5; 15/360] START colsample_bytree=0.0, max_depth=3, n_estimators=400......\n",
      "[CV 5/5; 15/360] END colsample_bytree=0.0, max_depth=3, n_estimators=400;, score=0.933 total time=   0.2s\n",
      "[CV 1/5; 16/360] START colsample_bytree=0.0, max_depth=3, n_estimators=450......\n",
      "[CV 1/5; 16/360] END colsample_bytree=0.0, max_depth=3, n_estimators=450;, score=0.931 total time=   0.2s\n",
      "[CV 2/5; 16/360] START colsample_bytree=0.0, max_depth=3, n_estimators=450......\n",
      "[CV 2/5; 16/360] END colsample_bytree=0.0, max_depth=3, n_estimators=450;, score=0.932 total time=   0.2s\n",
      "[CV 3/5; 16/360] START colsample_bytree=0.0, max_depth=3, n_estimators=450......\n",
      "[CV 3/5; 16/360] END colsample_bytree=0.0, max_depth=3, n_estimators=450;, score=0.934 total time=   0.2s\n",
      "[CV 4/5; 16/360] START colsample_bytree=0.0, max_depth=3, n_estimators=450......\n",
      "[CV 4/5; 16/360] END colsample_bytree=0.0, max_depth=3, n_estimators=450;, score=0.932 total time=   0.2s\n",
      "[CV 5/5; 16/360] START colsample_bytree=0.0, max_depth=3, n_estimators=450......\n",
      "[CV 5/5; 16/360] END colsample_bytree=0.0, max_depth=3, n_estimators=450;, score=0.933 total time=   0.2s\n",
      "[CV 1/5; 17/360] START colsample_bytree=0.0, max_depth=3, n_estimators=500......\n",
      "[CV 1/5; 17/360] END colsample_bytree=0.0, max_depth=3, n_estimators=500;, score=0.931 total time=   0.3s\n",
      "[CV 2/5; 17/360] START colsample_bytree=0.0, max_depth=3, n_estimators=500......\n",
      "[CV 2/5; 17/360] END colsample_bytree=0.0, max_depth=3, n_estimators=500;, score=0.932 total time=   0.2s\n",
      "[CV 3/5; 17/360] START colsample_bytree=0.0, max_depth=3, n_estimators=500......\n",
      "[CV 3/5; 17/360] END colsample_bytree=0.0, max_depth=3, n_estimators=500;, score=0.934 total time=   0.2s\n",
      "[CV 4/5; 17/360] START colsample_bytree=0.0, max_depth=3, n_estimators=500......\n",
      "[CV 4/5; 17/360] END colsample_bytree=0.0, max_depth=3, n_estimators=500;, score=0.932 total time=   0.2s\n",
      "[CV 5/5; 17/360] START colsample_bytree=0.0, max_depth=3, n_estimators=500......\n",
      "[CV 5/5; 17/360] END colsample_bytree=0.0, max_depth=3, n_estimators=500;, score=0.934 total time=   0.2s\n",
      "[CV 1/5; 18/360] START colsample_bytree=0.0, max_depth=3, n_estimators=550......\n",
      "[CV 1/5; 18/360] END colsample_bytree=0.0, max_depth=3, n_estimators=550;, score=0.932 total time=   0.3s\n",
      "[CV 2/5; 18/360] START colsample_bytree=0.0, max_depth=3, n_estimators=550......\n",
      "[CV 2/5; 18/360] END colsample_bytree=0.0, max_depth=3, n_estimators=550;, score=0.931 total time=   0.3s\n",
      "[CV 3/5; 18/360] START colsample_bytree=0.0, max_depth=3, n_estimators=550......\n",
      "[CV 3/5; 18/360] END colsample_bytree=0.0, max_depth=3, n_estimators=550;, score=0.934 total time=   0.3s\n",
      "[CV 4/5; 18/360] START colsample_bytree=0.0, max_depth=3, n_estimators=550......\n",
      "[CV 4/5; 18/360] END colsample_bytree=0.0, max_depth=3, n_estimators=550;, score=0.932 total time=   0.3s\n",
      "[CV 5/5; 18/360] START colsample_bytree=0.0, max_depth=3, n_estimators=550......\n",
      "[CV 5/5; 18/360] END colsample_bytree=0.0, max_depth=3, n_estimators=550;, score=0.934 total time=   0.3s\n",
      "[CV 1/5; 19/360] START colsample_bytree=0.0, max_depth=4, n_estimators=300......\n",
      "[CV 1/5; 19/360] END colsample_bytree=0.0, max_depth=4, n_estimators=300;, score=0.931 total time=   0.1s\n",
      "[CV 2/5; 19/360] START colsample_bytree=0.0, max_depth=4, n_estimators=300......\n",
      "[CV 2/5; 19/360] END colsample_bytree=0.0, max_depth=4, n_estimators=300;, score=0.932 total time=   0.2s\n",
      "[CV 3/5; 19/360] START colsample_bytree=0.0, max_depth=4, n_estimators=300......\n",
      "[CV 3/5; 19/360] END colsample_bytree=0.0, max_depth=4, n_estimators=300;, score=0.934 total time=   0.2s\n",
      "[CV 4/5; 19/360] START colsample_bytree=0.0, max_depth=4, n_estimators=300......\n",
      "[CV 4/5; 19/360] END colsample_bytree=0.0, max_depth=4, n_estimators=300;, score=0.931 total time=   0.1s\n",
      "[CV 5/5; 19/360] START colsample_bytree=0.0, max_depth=4, n_estimators=300......\n",
      "[CV 5/5; 19/360] END colsample_bytree=0.0, max_depth=4, n_estimators=300;, score=0.933 total time=   0.1s\n",
      "[CV 1/5; 20/360] START colsample_bytree=0.0, max_depth=4, n_estimators=350......\n",
      "[CV 1/5; 20/360] END colsample_bytree=0.0, max_depth=4, n_estimators=350;, score=0.931 total time=   0.2s\n",
      "[CV 2/5; 20/360] START colsample_bytree=0.0, max_depth=4, n_estimators=350......\n",
      "[CV 2/5; 20/360] END colsample_bytree=0.0, max_depth=4, n_estimators=350;, score=0.931 total time=   0.2s\n",
      "[CV 3/5; 20/360] START colsample_bytree=0.0, max_depth=4, n_estimators=350......\n",
      "[CV 3/5; 20/360] END colsample_bytree=0.0, max_depth=4, n_estimators=350;, score=0.934 total time=   0.2s\n",
      "[CV 4/5; 20/360] START colsample_bytree=0.0, max_depth=4, n_estimators=350......\n",
      "[CV 4/5; 20/360] END colsample_bytree=0.0, max_depth=4, n_estimators=350;, score=0.931 total time=   0.2s\n",
      "[CV 5/5; 20/360] START colsample_bytree=0.0, max_depth=4, n_estimators=350......\n",
      "[CV 5/5; 20/360] END colsample_bytree=0.0, max_depth=4, n_estimators=350;, score=0.933 total time=   0.3s\n",
      "[CV 1/5; 21/360] START colsample_bytree=0.0, max_depth=4, n_estimators=400......\n",
      "[CV 1/5; 21/360] END colsample_bytree=0.0, max_depth=4, n_estimators=400;, score=0.931 total time=   0.3s\n",
      "[CV 2/5; 21/360] START colsample_bytree=0.0, max_depth=4, n_estimators=400......\n",
      "[CV 2/5; 21/360] END colsample_bytree=0.0, max_depth=4, n_estimators=400;, score=0.932 total time=   0.3s\n",
      "[CV 3/5; 21/360] START colsample_bytree=0.0, max_depth=4, n_estimators=400......\n",
      "[CV 3/5; 21/360] END colsample_bytree=0.0, max_depth=4, n_estimators=400;, score=0.934 total time=   0.3s\n",
      "[CV 4/5; 21/360] START colsample_bytree=0.0, max_depth=4, n_estimators=400......\n",
      "[CV 4/5; 21/360] END colsample_bytree=0.0, max_depth=4, n_estimators=400;, score=0.931 total time=   0.3s\n",
      "[CV 5/5; 21/360] START colsample_bytree=0.0, max_depth=4, n_estimators=400......\n",
      "[CV 5/5; 21/360] END colsample_bytree=0.0, max_depth=4, n_estimators=400;, score=0.933 total time=   0.3s\n",
      "[CV 1/5; 22/360] START colsample_bytree=0.0, max_depth=4, n_estimators=450......\n",
      "[CV 1/5; 22/360] END colsample_bytree=0.0, max_depth=4, n_estimators=450;, score=0.931 total time=   0.3s\n",
      "[CV 2/5; 22/360] START colsample_bytree=0.0, max_depth=4, n_estimators=450......\n",
      "[CV 2/5; 22/360] END colsample_bytree=0.0, max_depth=4, n_estimators=450;, score=0.932 total time=   0.2s\n",
      "[CV 3/5; 22/360] START colsample_bytree=0.0, max_depth=4, n_estimators=450......\n",
      "[CV 3/5; 22/360] END colsample_bytree=0.0, max_depth=4, n_estimators=450;, score=0.934 total time=   0.2s\n",
      "[CV 4/5; 22/360] START colsample_bytree=0.0, max_depth=4, n_estimators=450......\n",
      "[CV 4/5; 22/360] END colsample_bytree=0.0, max_depth=4, n_estimators=450;, score=0.931 total time=   0.2s\n",
      "[CV 5/5; 22/360] START colsample_bytree=0.0, max_depth=4, n_estimators=450......\n",
      "[CV 5/5; 22/360] END colsample_bytree=0.0, max_depth=4, n_estimators=450;, score=0.933 total time=   0.2s\n",
      "[CV 1/5; 23/360] START colsample_bytree=0.0, max_depth=4, n_estimators=500......\n",
      "[CV 1/5; 23/360] END colsample_bytree=0.0, max_depth=4, n_estimators=500;, score=0.931 total time=   0.3s\n",
      "[CV 2/5; 23/360] START colsample_bytree=0.0, max_depth=4, n_estimators=500......\n",
      "[CV 2/5; 23/360] END colsample_bytree=0.0, max_depth=4, n_estimators=500;, score=0.932 total time=   0.3s\n",
      "[CV 3/5; 23/360] START colsample_bytree=0.0, max_depth=4, n_estimators=500......\n",
      "[CV 3/5; 23/360] END colsample_bytree=0.0, max_depth=4, n_estimators=500;, score=0.933 total time=   0.3s\n",
      "[CV 4/5; 23/360] START colsample_bytree=0.0, max_depth=4, n_estimators=500......\n",
      "[CV 4/5; 23/360] END colsample_bytree=0.0, max_depth=4, n_estimators=500;, score=0.931 total time=   0.3s\n",
      "[CV 5/5; 23/360] START colsample_bytree=0.0, max_depth=4, n_estimators=500......\n",
      "[CV 5/5; 23/360] END colsample_bytree=0.0, max_depth=4, n_estimators=500;, score=0.933 total time=   0.3s\n",
      "[CV 1/5; 24/360] START colsample_bytree=0.0, max_depth=4, n_estimators=550......\n",
      "[CV 1/5; 24/360] END colsample_bytree=0.0, max_depth=4, n_estimators=550;, score=0.931 total time=   0.3s\n",
      "[CV 2/5; 24/360] START colsample_bytree=0.0, max_depth=4, n_estimators=550......\n",
      "[CV 2/5; 24/360] END colsample_bytree=0.0, max_depth=4, n_estimators=550;, score=0.931 total time=   0.3s\n",
      "[CV 3/5; 24/360] START colsample_bytree=0.0, max_depth=4, n_estimators=550......\n",
      "[CV 3/5; 24/360] END colsample_bytree=0.0, max_depth=4, n_estimators=550;, score=0.934 total time=   0.3s\n",
      "[CV 4/5; 24/360] START colsample_bytree=0.0, max_depth=4, n_estimators=550......\n",
      "[CV 4/5; 24/360] END colsample_bytree=0.0, max_depth=4, n_estimators=550;, score=0.931 total time=   0.3s\n",
      "[CV 5/5; 24/360] START colsample_bytree=0.0, max_depth=4, n_estimators=550......\n",
      "[CV 5/5; 24/360] END colsample_bytree=0.0, max_depth=4, n_estimators=550;, score=0.933 total time=   0.3s\n",
      "[CV 1/5; 25/360] START colsample_bytree=0.0, max_depth=5, n_estimators=300......\n",
      "[CV 1/5; 25/360] END colsample_bytree=0.0, max_depth=5, n_estimators=300;, score=0.931 total time=   0.2s\n",
      "[CV 2/5; 25/360] START colsample_bytree=0.0, max_depth=5, n_estimators=300......\n",
      "[CV 2/5; 25/360] END colsample_bytree=0.0, max_depth=5, n_estimators=300;, score=0.931 total time=   0.2s\n",
      "[CV 3/5; 25/360] START colsample_bytree=0.0, max_depth=5, n_estimators=300......\n",
      "[CV 3/5; 25/360] END colsample_bytree=0.0, max_depth=5, n_estimators=300;, score=0.933 total time=   0.2s\n",
      "[CV 4/5; 25/360] START colsample_bytree=0.0, max_depth=5, n_estimators=300......\n",
      "[CV 4/5; 25/360] END colsample_bytree=0.0, max_depth=5, n_estimators=300;, score=0.931 total time=   0.2s\n",
      "[CV 5/5; 25/360] START colsample_bytree=0.0, max_depth=5, n_estimators=300......\n",
      "[CV 5/5; 25/360] END colsample_bytree=0.0, max_depth=5, n_estimators=300;, score=0.932 total time=   0.1s\n",
      "[CV 1/5; 26/360] START colsample_bytree=0.0, max_depth=5, n_estimators=350......\n",
      "[CV 1/5; 26/360] END colsample_bytree=0.0, max_depth=5, n_estimators=350;, score=0.931 total time=   0.2s\n",
      "[CV 2/5; 26/360] START colsample_bytree=0.0, max_depth=5, n_estimators=350......\n",
      "[CV 2/5; 26/360] END colsample_bytree=0.0, max_depth=5, n_estimators=350;, score=0.931 total time=   0.2s\n",
      "[CV 3/5; 26/360] START colsample_bytree=0.0, max_depth=5, n_estimators=350......\n",
      "[CV 3/5; 26/360] END colsample_bytree=0.0, max_depth=5, n_estimators=350;, score=0.933 total time=   0.2s\n",
      "[CV 4/5; 26/360] START colsample_bytree=0.0, max_depth=5, n_estimators=350......\n",
      "[CV 4/5; 26/360] END colsample_bytree=0.0, max_depth=5, n_estimators=350;, score=0.931 total time=   0.2s\n",
      "[CV 5/5; 26/360] START colsample_bytree=0.0, max_depth=5, n_estimators=350......\n",
      "[CV 5/5; 26/360] END colsample_bytree=0.0, max_depth=5, n_estimators=350;, score=0.933 total time=   0.2s\n",
      "[CV 1/5; 27/360] START colsample_bytree=0.0, max_depth=5, n_estimators=400......\n",
      "[CV 1/5; 27/360] END colsample_bytree=0.0, max_depth=5, n_estimators=400;, score=0.932 total time=   0.3s\n",
      "[CV 2/5; 27/360] START colsample_bytree=0.0, max_depth=5, n_estimators=400......\n",
      "[CV 2/5; 27/360] END colsample_bytree=0.0, max_depth=5, n_estimators=400;, score=0.932 total time=   0.2s\n",
      "[CV 3/5; 27/360] START colsample_bytree=0.0, max_depth=5, n_estimators=400......\n",
      "[CV 3/5; 27/360] END colsample_bytree=0.0, max_depth=5, n_estimators=400;, score=0.933 total time=   0.2s\n",
      "[CV 4/5; 27/360] START colsample_bytree=0.0, max_depth=5, n_estimators=400......\n",
      "[CV 4/5; 27/360] END colsample_bytree=0.0, max_depth=5, n_estimators=400;, score=0.932 total time=   0.2s\n",
      "[CV 5/5; 27/360] START colsample_bytree=0.0, max_depth=5, n_estimators=400......\n",
      "[CV 5/5; 27/360] END colsample_bytree=0.0, max_depth=5, n_estimators=400;, score=0.934 total time=   0.2s\n",
      "[CV 1/5; 28/360] START colsample_bytree=0.0, max_depth=5, n_estimators=450......\n",
      "[CV 1/5; 28/360] END colsample_bytree=0.0, max_depth=5, n_estimators=450;, score=0.931 total time=   0.3s\n",
      "[CV 2/5; 28/360] START colsample_bytree=0.0, max_depth=5, n_estimators=450......\n",
      "[CV 2/5; 28/360] END colsample_bytree=0.0, max_depth=5, n_estimators=450;, score=0.931 total time=   0.3s\n",
      "[CV 3/5; 28/360] START colsample_bytree=0.0, max_depth=5, n_estimators=450......\n",
      "[CV 3/5; 28/360] END colsample_bytree=0.0, max_depth=5, n_estimators=450;, score=0.933 total time=   0.3s\n",
      "[CV 4/5; 28/360] START colsample_bytree=0.0, max_depth=5, n_estimators=450......\n",
      "[CV 4/5; 28/360] END colsample_bytree=0.0, max_depth=5, n_estimators=450;, score=0.932 total time=   0.2s\n",
      "[CV 5/5; 28/360] START colsample_bytree=0.0, max_depth=5, n_estimators=450......\n",
      "[CV 5/5; 28/360] END colsample_bytree=0.0, max_depth=5, n_estimators=450;, score=0.933 total time=   0.3s\n",
      "[CV 1/5; 29/360] START colsample_bytree=0.0, max_depth=5, n_estimators=500......\n",
      "[CV 1/5; 29/360] END colsample_bytree=0.0, max_depth=5, n_estimators=500;, score=0.931 total time=   0.3s\n",
      "[CV 2/5; 29/360] START colsample_bytree=0.0, max_depth=5, n_estimators=500......\n",
      "[CV 2/5; 29/360] END colsample_bytree=0.0, max_depth=5, n_estimators=500;, score=0.931 total time=   0.3s\n",
      "[CV 3/5; 29/360] START colsample_bytree=0.0, max_depth=5, n_estimators=500......\n",
      "[CV 3/5; 29/360] END colsample_bytree=0.0, max_depth=5, n_estimators=500;, score=0.933 total time=   0.3s\n",
      "[CV 4/5; 29/360] START colsample_bytree=0.0, max_depth=5, n_estimators=500......\n",
      "[CV 4/5; 29/360] END colsample_bytree=0.0, max_depth=5, n_estimators=500;, score=0.931 total time=   0.3s\n",
      "[CV 5/5; 29/360] START colsample_bytree=0.0, max_depth=5, n_estimators=500......\n",
      "[CV 5/5; 29/360] END colsample_bytree=0.0, max_depth=5, n_estimators=500;, score=0.933 total time=   0.4s\n",
      "[CV 1/5; 30/360] START colsample_bytree=0.0, max_depth=5, n_estimators=550......\n",
      "[CV 1/5; 30/360] END colsample_bytree=0.0, max_depth=5, n_estimators=550;, score=0.931 total time=   0.5s\n",
      "[CV 2/5; 30/360] START colsample_bytree=0.0, max_depth=5, n_estimators=550......\n",
      "[CV 2/5; 30/360] END colsample_bytree=0.0, max_depth=5, n_estimators=550;, score=0.931 total time=   0.5s\n",
      "[CV 3/5; 30/360] START colsample_bytree=0.0, max_depth=5, n_estimators=550......\n",
      "[CV 3/5; 30/360] END colsample_bytree=0.0, max_depth=5, n_estimators=550;, score=0.933 total time=   0.5s\n",
      "[CV 4/5; 30/360] START colsample_bytree=0.0, max_depth=5, n_estimators=550......\n",
      "[CV 4/5; 30/360] END colsample_bytree=0.0, max_depth=5, n_estimators=550;, score=0.932 total time=   0.4s\n",
      "[CV 5/5; 30/360] START colsample_bytree=0.0, max_depth=5, n_estimators=550......\n",
      "[CV 5/5; 30/360] END colsample_bytree=0.0, max_depth=5, n_estimators=550;, score=0.933 total time=   0.3s\n",
      "[CV 1/5; 31/360] START colsample_bytree=0.0, max_depth=6, n_estimators=300......\n",
      "[CV 1/5; 31/360] END colsample_bytree=0.0, max_depth=6, n_estimators=300;, score=0.931 total time=   0.2s\n",
      "[CV 2/5; 31/360] START colsample_bytree=0.0, max_depth=6, n_estimators=300......\n",
      "[CV 2/5; 31/360] END colsample_bytree=0.0, max_depth=6, n_estimators=300;, score=0.932 total time=   0.2s\n",
      "[CV 3/5; 31/360] START colsample_bytree=0.0, max_depth=6, n_estimators=300......\n",
      "[CV 3/5; 31/360] END colsample_bytree=0.0, max_depth=6, n_estimators=300;, score=0.933 total time=   0.2s\n",
      "[CV 4/5; 31/360] START colsample_bytree=0.0, max_depth=6, n_estimators=300......\n",
      "[CV 4/5; 31/360] END colsample_bytree=0.0, max_depth=6, n_estimators=300;, score=0.931 total time=   0.2s\n",
      "[CV 5/5; 31/360] START colsample_bytree=0.0, max_depth=6, n_estimators=300......\n",
      "[CV 5/5; 31/360] END colsample_bytree=0.0, max_depth=6, n_estimators=300;, score=0.933 total time=   0.2s\n",
      "[CV 1/5; 32/360] START colsample_bytree=0.0, max_depth=6, n_estimators=350......\n",
      "[CV 1/5; 32/360] END colsample_bytree=0.0, max_depth=6, n_estimators=350;, score=0.931 total time=   0.2s\n",
      "[CV 2/5; 32/360] START colsample_bytree=0.0, max_depth=6, n_estimators=350......\n",
      "[CV 2/5; 32/360] END colsample_bytree=0.0, max_depth=6, n_estimators=350;, score=0.931 total time=   0.3s\n",
      "[CV 3/5; 32/360] START colsample_bytree=0.0, max_depth=6, n_estimators=350......\n",
      "[CV 3/5; 32/360] END colsample_bytree=0.0, max_depth=6, n_estimators=350;, score=0.932 total time=   0.2s\n",
      "[CV 4/5; 32/360] START colsample_bytree=0.0, max_depth=6, n_estimators=350......\n",
      "[CV 4/5; 32/360] END colsample_bytree=0.0, max_depth=6, n_estimators=350;, score=0.931 total time=   0.2s\n",
      "[CV 5/5; 32/360] START colsample_bytree=0.0, max_depth=6, n_estimators=350......\n",
      "[CV 5/5; 32/360] END colsample_bytree=0.0, max_depth=6, n_estimators=350;, score=0.933 total time=   0.2s\n",
      "[CV 1/5; 33/360] START colsample_bytree=0.0, max_depth=6, n_estimators=400......\n",
      "[CV 1/5; 33/360] END colsample_bytree=0.0, max_depth=6, n_estimators=400;, score=0.931 total time=   0.3s\n",
      "[CV 2/5; 33/360] START colsample_bytree=0.0, max_depth=6, n_estimators=400......\n",
      "[CV 2/5; 33/360] END colsample_bytree=0.0, max_depth=6, n_estimators=400;, score=0.931 total time=   0.2s\n",
      "[CV 3/5; 33/360] START colsample_bytree=0.0, max_depth=6, n_estimators=400......\n",
      "[CV 3/5; 33/360] END colsample_bytree=0.0, max_depth=6, n_estimators=400;, score=0.932 total time=   0.3s\n",
      "[CV 4/5; 33/360] START colsample_bytree=0.0, max_depth=6, n_estimators=400......\n",
      "[CV 4/5; 33/360] END colsample_bytree=0.0, max_depth=6, n_estimators=400;, score=0.932 total time=   0.3s\n",
      "[CV 5/5; 33/360] START colsample_bytree=0.0, max_depth=6, n_estimators=400......\n",
      "[CV 5/5; 33/360] END colsample_bytree=0.0, max_depth=6, n_estimators=400;, score=0.933 total time=   0.2s\n",
      "[CV 1/5; 34/360] START colsample_bytree=0.0, max_depth=6, n_estimators=450......\n",
      "[CV 1/5; 34/360] END colsample_bytree=0.0, max_depth=6, n_estimators=450;, score=0.931 total time=   0.3s\n",
      "[CV 2/5; 34/360] START colsample_bytree=0.0, max_depth=6, n_estimators=450......\n",
      "[CV 2/5; 34/360] END colsample_bytree=0.0, max_depth=6, n_estimators=450;, score=0.931 total time=   0.3s\n",
      "[CV 3/5; 34/360] START colsample_bytree=0.0, max_depth=6, n_estimators=450......\n",
      "[CV 3/5; 34/360] END colsample_bytree=0.0, max_depth=6, n_estimators=450;, score=0.932 total time=   0.3s\n",
      "[CV 4/5; 34/360] START colsample_bytree=0.0, max_depth=6, n_estimators=450......\n",
      "[CV 4/5; 34/360] END colsample_bytree=0.0, max_depth=6, n_estimators=450;, score=0.933 total time=   0.3s\n",
      "[CV 5/5; 34/360] START colsample_bytree=0.0, max_depth=6, n_estimators=450......\n",
      "[CV 5/5; 34/360] END colsample_bytree=0.0, max_depth=6, n_estimators=450;, score=0.933 total time=   0.3s\n",
      "[CV 1/5; 35/360] START colsample_bytree=0.0, max_depth=6, n_estimators=500......\n",
      "[CV 1/5; 35/360] END colsample_bytree=0.0, max_depth=6, n_estimators=500;, score=0.931 total time=   0.3s\n",
      "[CV 2/5; 35/360] START colsample_bytree=0.0, max_depth=6, n_estimators=500......\n",
      "[CV 2/5; 35/360] END colsample_bytree=0.0, max_depth=6, n_estimators=500;, score=0.931 total time=   0.3s\n",
      "[CV 3/5; 35/360] START colsample_bytree=0.0, max_depth=6, n_estimators=500......\n",
      "[CV 3/5; 35/360] END colsample_bytree=0.0, max_depth=6, n_estimators=500;, score=0.932 total time=   0.4s\n",
      "[CV 4/5; 35/360] START colsample_bytree=0.0, max_depth=6, n_estimators=500......\n",
      "[CV 4/5; 35/360] END colsample_bytree=0.0, max_depth=6, n_estimators=500;, score=0.932 total time=   0.4s\n",
      "[CV 5/5; 35/360] START colsample_bytree=0.0, max_depth=6, n_estimators=500......\n",
      "[CV 5/5; 35/360] END colsample_bytree=0.0, max_depth=6, n_estimators=500;, score=0.933 total time=   0.4s\n",
      "[CV 1/5; 36/360] START colsample_bytree=0.0, max_depth=6, n_estimators=550......\n",
      "[CV 1/5; 36/360] END colsample_bytree=0.0, max_depth=6, n_estimators=550;, score=0.931 total time=   0.4s\n",
      "[CV 2/5; 36/360] START colsample_bytree=0.0, max_depth=6, n_estimators=550......\n",
      "[CV 2/5; 36/360] END colsample_bytree=0.0, max_depth=6, n_estimators=550;, score=0.931 total time=   0.5s\n",
      "[CV 3/5; 36/360] START colsample_bytree=0.0, max_depth=6, n_estimators=550......\n",
      "[CV 3/5; 36/360] END colsample_bytree=0.0, max_depth=6, n_estimators=550;, score=0.932 total time=   0.5s\n",
      "[CV 4/5; 36/360] START colsample_bytree=0.0, max_depth=6, n_estimators=550......\n",
      "[CV 4/5; 36/360] END colsample_bytree=0.0, max_depth=6, n_estimators=550;, score=0.933 total time=   0.4s\n",
      "[CV 5/5; 36/360] START colsample_bytree=0.0, max_depth=6, n_estimators=550......\n",
      "[CV 5/5; 36/360] END colsample_bytree=0.0, max_depth=6, n_estimators=550;, score=0.933 total time=   0.4s\n",
      "[CV 1/5; 37/360] START colsample_bytree=0.1, max_depth=1, n_estimators=300......\n",
      "[CV 1/5; 37/360] END colsample_bytree=0.1, max_depth=1, n_estimators=300;, score=0.928 total time=   0.1s\n",
      "[CV 2/5; 37/360] START colsample_bytree=0.1, max_depth=1, n_estimators=300......\n",
      "[CV 2/5; 37/360] END colsample_bytree=0.1, max_depth=1, n_estimators=300;, score=0.927 total time=   0.1s\n",
      "[CV 3/5; 37/360] START colsample_bytree=0.1, max_depth=1, n_estimators=300......\n",
      "[CV 3/5; 37/360] END colsample_bytree=0.1, max_depth=1, n_estimators=300;, score=0.930 total time=   0.1s\n",
      "[CV 4/5; 37/360] START colsample_bytree=0.1, max_depth=1, n_estimators=300......\n",
      "[CV 4/5; 37/360] END colsample_bytree=0.1, max_depth=1, n_estimators=300;, score=0.932 total time=   0.1s\n",
      "[CV 5/5; 37/360] START colsample_bytree=0.1, max_depth=1, n_estimators=300......\n",
      "[CV 5/5; 37/360] END colsample_bytree=0.1, max_depth=1, n_estimators=300;, score=0.927 total time=   0.1s\n",
      "[CV 1/5; 38/360] START colsample_bytree=0.1, max_depth=1, n_estimators=350......\n",
      "[CV 1/5; 38/360] END colsample_bytree=0.1, max_depth=1, n_estimators=350;, score=0.927 total time=   0.2s\n",
      "[CV 2/5; 38/360] START colsample_bytree=0.1, max_depth=1, n_estimators=350......\n",
      "[CV 2/5; 38/360] END colsample_bytree=0.1, max_depth=1, n_estimators=350;, score=0.927 total time=   0.2s\n",
      "[CV 3/5; 38/360] START colsample_bytree=0.1, max_depth=1, n_estimators=350......\n",
      "[CV 3/5; 38/360] END colsample_bytree=0.1, max_depth=1, n_estimators=350;, score=0.930 total time=   0.2s\n",
      "[CV 4/5; 38/360] START colsample_bytree=0.1, max_depth=1, n_estimators=350......\n",
      "[CV 4/5; 38/360] END colsample_bytree=0.1, max_depth=1, n_estimators=350;, score=0.931 total time=   0.2s\n",
      "[CV 5/5; 38/360] START colsample_bytree=0.1, max_depth=1, n_estimators=350......\n",
      "[CV 5/5; 38/360] END colsample_bytree=0.1, max_depth=1, n_estimators=350;, score=0.928 total time=   0.2s\n",
      "[CV 1/5; 39/360] START colsample_bytree=0.1, max_depth=1, n_estimators=400......\n",
      "[CV 1/5; 39/360] END colsample_bytree=0.1, max_depth=1, n_estimators=400;, score=0.928 total time=   0.2s\n",
      "[CV 2/5; 39/360] START colsample_bytree=0.1, max_depth=1, n_estimators=400......\n",
      "[CV 2/5; 39/360] END colsample_bytree=0.1, max_depth=1, n_estimators=400;, score=0.927 total time=   0.2s\n",
      "[CV 3/5; 39/360] START colsample_bytree=0.1, max_depth=1, n_estimators=400......\n",
      "[CV 3/5; 39/360] END colsample_bytree=0.1, max_depth=1, n_estimators=400;, score=0.930 total time=   0.2s\n",
      "[CV 4/5; 39/360] START colsample_bytree=0.1, max_depth=1, n_estimators=400......\n",
      "[CV 4/5; 39/360] END colsample_bytree=0.1, max_depth=1, n_estimators=400;, score=0.931 total time=   0.2s\n",
      "[CV 5/5; 39/360] START colsample_bytree=0.1, max_depth=1, n_estimators=400......\n",
      "[CV 5/5; 39/360] END colsample_bytree=0.1, max_depth=1, n_estimators=400;, score=0.928 total time=   0.2s\n",
      "[CV 1/5; 40/360] START colsample_bytree=0.1, max_depth=1, n_estimators=450......\n",
      "[CV 1/5; 40/360] END colsample_bytree=0.1, max_depth=1, n_estimators=450;, score=0.927 total time=   0.3s\n",
      "[CV 2/5; 40/360] START colsample_bytree=0.1, max_depth=1, n_estimators=450......\n",
      "[CV 2/5; 40/360] END colsample_bytree=0.1, max_depth=1, n_estimators=450;, score=0.927 total time=   0.2s\n",
      "[CV 3/5; 40/360] START colsample_bytree=0.1, max_depth=1, n_estimators=450......\n",
      "[CV 3/5; 40/360] END colsample_bytree=0.1, max_depth=1, n_estimators=450;, score=0.931 total time=   0.1s\n",
      "[CV 4/5; 40/360] START colsample_bytree=0.1, max_depth=1, n_estimators=450......\n",
      "[CV 4/5; 40/360] END colsample_bytree=0.1, max_depth=1, n_estimators=450;, score=0.932 total time=   0.2s\n",
      "[CV 5/5; 40/360] START colsample_bytree=0.1, max_depth=1, n_estimators=450......\n",
      "[CV 5/5; 40/360] END colsample_bytree=0.1, max_depth=1, n_estimators=450;, score=0.928 total time=   0.2s\n",
      "[CV 1/5; 41/360] START colsample_bytree=0.1, max_depth=1, n_estimators=500......\n",
      "[CV 1/5; 41/360] END colsample_bytree=0.1, max_depth=1, n_estimators=500;, score=0.928 total time=   0.2s\n",
      "[CV 2/5; 41/360] START colsample_bytree=0.1, max_depth=1, n_estimators=500......\n",
      "[CV 2/5; 41/360] END colsample_bytree=0.1, max_depth=1, n_estimators=500;, score=0.928 total time=   0.2s\n",
      "[CV 3/5; 41/360] START colsample_bytree=0.1, max_depth=1, n_estimators=500......\n",
      "[CV 3/5; 41/360] END colsample_bytree=0.1, max_depth=1, n_estimators=500;, score=0.930 total time=   0.2s\n",
      "[CV 4/5; 41/360] START colsample_bytree=0.1, max_depth=1, n_estimators=500......\n",
      "[CV 4/5; 41/360] END colsample_bytree=0.1, max_depth=1, n_estimators=500;, score=0.932 total time=   0.2s\n",
      "[CV 5/5; 41/360] START colsample_bytree=0.1, max_depth=1, n_estimators=500......\n",
      "[CV 5/5; 41/360] END colsample_bytree=0.1, max_depth=1, n_estimators=500;, score=0.928 total time=   0.2s\n",
      "[CV 1/5; 42/360] START colsample_bytree=0.1, max_depth=1, n_estimators=550......\n",
      "[CV 1/5; 42/360] END colsample_bytree=0.1, max_depth=1, n_estimators=550;, score=0.928 total time=   0.3s\n",
      "[CV 2/5; 42/360] START colsample_bytree=0.1, max_depth=1, n_estimators=550......\n",
      "[CV 2/5; 42/360] END colsample_bytree=0.1, max_depth=1, n_estimators=550;, score=0.928 total time=   0.2s\n",
      "[CV 3/5; 42/360] START colsample_bytree=0.1, max_depth=1, n_estimators=550......\n",
      "[CV 3/5; 42/360] END colsample_bytree=0.1, max_depth=1, n_estimators=550;, score=0.931 total time=   0.2s\n",
      "[CV 4/5; 42/360] START colsample_bytree=0.1, max_depth=1, n_estimators=550......\n",
      "[CV 4/5; 42/360] END colsample_bytree=0.1, max_depth=1, n_estimators=550;, score=0.932 total time=   0.2s\n",
      "[CV 5/5; 42/360] START colsample_bytree=0.1, max_depth=1, n_estimators=550......\n",
      "[CV 5/5; 42/360] END colsample_bytree=0.1, max_depth=1, n_estimators=550;, score=0.928 total time=   0.2s\n",
      "[CV 1/5; 43/360] START colsample_bytree=0.1, max_depth=2, n_estimators=300......\n",
      "[CV 1/5; 43/360] END colsample_bytree=0.1, max_depth=2, n_estimators=300;, score=0.930 total time=   0.1s\n",
      "[CV 2/5; 43/360] START colsample_bytree=0.1, max_depth=2, n_estimators=300......\n",
      "[CV 2/5; 43/360] END colsample_bytree=0.1, max_depth=2, n_estimators=300;, score=0.931 total time=   0.1s\n",
      "[CV 3/5; 43/360] START colsample_bytree=0.1, max_depth=2, n_estimators=300......\n",
      "[CV 3/5; 43/360] END colsample_bytree=0.1, max_depth=2, n_estimators=300;, score=0.932 total time=   0.1s\n",
      "[CV 4/5; 43/360] START colsample_bytree=0.1, max_depth=2, n_estimators=300......\n",
      "[CV 4/5; 43/360] END colsample_bytree=0.1, max_depth=2, n_estimators=300;, score=0.932 total time=   0.1s\n",
      "[CV 5/5; 43/360] START colsample_bytree=0.1, max_depth=2, n_estimators=300......\n",
      "[CV 5/5; 43/360] END colsample_bytree=0.1, max_depth=2, n_estimators=300;, score=0.932 total time=   0.1s\n",
      "[CV 1/5; 44/360] START colsample_bytree=0.1, max_depth=2, n_estimators=350......\n",
      "[CV 1/5; 44/360] END colsample_bytree=0.1, max_depth=2, n_estimators=350;, score=0.930 total time=   0.1s\n",
      "[CV 2/5; 44/360] START colsample_bytree=0.1, max_depth=2, n_estimators=350......\n",
      "[CV 2/5; 44/360] END colsample_bytree=0.1, max_depth=2, n_estimators=350;, score=0.931 total time=   0.1s\n",
      "[CV 3/5; 44/360] START colsample_bytree=0.1, max_depth=2, n_estimators=350......\n",
      "[CV 3/5; 44/360] END colsample_bytree=0.1, max_depth=2, n_estimators=350;, score=0.932 total time=   0.1s\n",
      "[CV 4/5; 44/360] START colsample_bytree=0.1, max_depth=2, n_estimators=350......\n",
      "[CV 4/5; 44/360] END colsample_bytree=0.1, max_depth=2, n_estimators=350;, score=0.932 total time=   0.1s\n",
      "[CV 5/5; 44/360] START colsample_bytree=0.1, max_depth=2, n_estimators=350......\n",
      "[CV 5/5; 44/360] END colsample_bytree=0.1, max_depth=2, n_estimators=350;, score=0.932 total time=   0.1s\n",
      "[CV 1/5; 45/360] START colsample_bytree=0.1, max_depth=2, n_estimators=400......\n",
      "[CV 1/5; 45/360] END colsample_bytree=0.1, max_depth=2, n_estimators=400;, score=0.929 total time=   0.2s\n",
      "[CV 2/5; 45/360] START colsample_bytree=0.1, max_depth=2, n_estimators=400......\n",
      "[CV 2/5; 45/360] END colsample_bytree=0.1, max_depth=2, n_estimators=400;, score=0.931 total time=   0.2s\n",
      "[CV 3/5; 45/360] START colsample_bytree=0.1, max_depth=2, n_estimators=400......\n",
      "[CV 3/5; 45/360] END colsample_bytree=0.1, max_depth=2, n_estimators=400;, score=0.933 total time=   0.1s\n",
      "[CV 4/5; 45/360] START colsample_bytree=0.1, max_depth=2, n_estimators=400......\n",
      "[CV 4/5; 45/360] END colsample_bytree=0.1, max_depth=2, n_estimators=400;, score=0.933 total time=   0.2s\n",
      "[CV 5/5; 45/360] START colsample_bytree=0.1, max_depth=2, n_estimators=400......\n",
      "[CV 5/5; 45/360] END colsample_bytree=0.1, max_depth=2, n_estimators=400;, score=0.933 total time=   0.2s\n",
      "[CV 1/5; 46/360] START colsample_bytree=0.1, max_depth=2, n_estimators=450......\n",
      "[CV 1/5; 46/360] END colsample_bytree=0.1, max_depth=2, n_estimators=450;, score=0.930 total time=   0.2s\n",
      "[CV 2/5; 46/360] START colsample_bytree=0.1, max_depth=2, n_estimators=450......\n",
      "[CV 2/5; 46/360] END colsample_bytree=0.1, max_depth=2, n_estimators=450;, score=0.930 total time=   0.2s\n",
      "[CV 3/5; 46/360] START colsample_bytree=0.1, max_depth=2, n_estimators=450......\n",
      "[CV 3/5; 46/360] END colsample_bytree=0.1, max_depth=2, n_estimators=450;, score=0.933 total time=   0.2s\n",
      "[CV 4/5; 46/360] START colsample_bytree=0.1, max_depth=2, n_estimators=450......\n",
      "[CV 4/5; 46/360] END colsample_bytree=0.1, max_depth=2, n_estimators=450;, score=0.933 total time=   0.2s\n",
      "[CV 5/5; 46/360] START colsample_bytree=0.1, max_depth=2, n_estimators=450......\n",
      "[CV 5/5; 46/360] END colsample_bytree=0.1, max_depth=2, n_estimators=450;, score=0.933 total time=   0.2s\n",
      "[CV 1/5; 47/360] START colsample_bytree=0.1, max_depth=2, n_estimators=500......\n",
      "[CV 1/5; 47/360] END colsample_bytree=0.1, max_depth=2, n_estimators=500;, score=0.930 total time=   0.2s\n",
      "[CV 2/5; 47/360] START colsample_bytree=0.1, max_depth=2, n_estimators=500......\n",
      "[CV 2/5; 47/360] END colsample_bytree=0.1, max_depth=2, n_estimators=500;, score=0.930 total time=   0.2s\n",
      "[CV 3/5; 47/360] START colsample_bytree=0.1, max_depth=2, n_estimators=500......\n",
      "[CV 3/5; 47/360] END colsample_bytree=0.1, max_depth=2, n_estimators=500;, score=0.933 total time=   0.2s\n",
      "[CV 4/5; 47/360] START colsample_bytree=0.1, max_depth=2, n_estimators=500......\n",
      "[CV 4/5; 47/360] END colsample_bytree=0.1, max_depth=2, n_estimators=500;, score=0.933 total time=   0.2s\n",
      "[CV 5/5; 47/360] START colsample_bytree=0.1, max_depth=2, n_estimators=500......\n",
      "[CV 5/5; 47/360] END colsample_bytree=0.1, max_depth=2, n_estimators=500;, score=0.933 total time=   0.2s\n",
      "[CV 1/5; 48/360] START colsample_bytree=0.1, max_depth=2, n_estimators=550......\n",
      "[CV 1/5; 48/360] END colsample_bytree=0.1, max_depth=2, n_estimators=550;, score=0.930 total time=   0.3s\n",
      "[CV 2/5; 48/360] START colsample_bytree=0.1, max_depth=2, n_estimators=550......\n",
      "[CV 2/5; 48/360] END colsample_bytree=0.1, max_depth=2, n_estimators=550;, score=0.931 total time=   0.2s\n",
      "[CV 3/5; 48/360] START colsample_bytree=0.1, max_depth=2, n_estimators=550......\n",
      "[CV 3/5; 48/360] END colsample_bytree=0.1, max_depth=2, n_estimators=550;, score=0.934 total time=   0.2s\n",
      "[CV 4/5; 48/360] START colsample_bytree=0.1, max_depth=2, n_estimators=550......\n",
      "[CV 4/5; 48/360] END colsample_bytree=0.1, max_depth=2, n_estimators=550;, score=0.933 total time=   0.2s\n",
      "[CV 5/5; 48/360] START colsample_bytree=0.1, max_depth=2, n_estimators=550......\n",
      "[CV 5/5; 48/360] END colsample_bytree=0.1, max_depth=2, n_estimators=550;, score=0.933 total time=   0.2s\n",
      "[CV 1/5; 49/360] START colsample_bytree=0.1, max_depth=3, n_estimators=300......\n",
      "[CV 1/5; 49/360] END colsample_bytree=0.1, max_depth=3, n_estimators=300;, score=0.931 total time=   0.1s\n",
      "[CV 2/5; 49/360] START colsample_bytree=0.1, max_depth=3, n_estimators=300......\n",
      "[CV 2/5; 49/360] END colsample_bytree=0.1, max_depth=3, n_estimators=300;, score=0.931 total time=   0.1s\n",
      "[CV 3/5; 49/360] START colsample_bytree=0.1, max_depth=3, n_estimators=300......\n",
      "[CV 3/5; 49/360] END colsample_bytree=0.1, max_depth=3, n_estimators=300;, score=0.933 total time=   0.1s\n",
      "[CV 4/5; 49/360] START colsample_bytree=0.1, max_depth=3, n_estimators=300......\n",
      "[CV 4/5; 49/360] END colsample_bytree=0.1, max_depth=3, n_estimators=300;, score=0.932 total time=   0.2s\n",
      "[CV 5/5; 49/360] START colsample_bytree=0.1, max_depth=3, n_estimators=300......\n",
      "[CV 5/5; 49/360] END colsample_bytree=0.1, max_depth=3, n_estimators=300;, score=0.933 total time=   0.2s\n",
      "[CV 1/5; 50/360] START colsample_bytree=0.1, max_depth=3, n_estimators=350......\n",
      "[CV 1/5; 50/360] END colsample_bytree=0.1, max_depth=3, n_estimators=350;, score=0.931 total time=   0.2s\n",
      "[CV 2/5; 50/360] START colsample_bytree=0.1, max_depth=3, n_estimators=350......\n",
      "[CV 2/5; 50/360] END colsample_bytree=0.1, max_depth=3, n_estimators=350;, score=0.931 total time=   0.2s\n",
      "[CV 3/5; 50/360] START colsample_bytree=0.1, max_depth=3, n_estimators=350......\n",
      "[CV 3/5; 50/360] END colsample_bytree=0.1, max_depth=3, n_estimators=350;, score=0.933 total time=   0.2s\n",
      "[CV 4/5; 50/360] START colsample_bytree=0.1, max_depth=3, n_estimators=350......\n",
      "[CV 4/5; 50/360] END colsample_bytree=0.1, max_depth=3, n_estimators=350;, score=0.932 total time=   0.2s\n",
      "[CV 5/5; 50/360] START colsample_bytree=0.1, max_depth=3, n_estimators=350......\n",
      "[CV 5/5; 50/360] END colsample_bytree=0.1, max_depth=3, n_estimators=350;, score=0.933 total time=   0.2s\n",
      "[CV 1/5; 51/360] START colsample_bytree=0.1, max_depth=3, n_estimators=400......\n",
      "[CV 1/5; 51/360] END colsample_bytree=0.1, max_depth=3, n_estimators=400;, score=0.931 total time=   0.3s\n",
      "[CV 2/5; 51/360] START colsample_bytree=0.1, max_depth=3, n_estimators=400......\n",
      "[CV 2/5; 51/360] END colsample_bytree=0.1, max_depth=3, n_estimators=400;, score=0.931 total time=   0.2s\n",
      "[CV 3/5; 51/360] START colsample_bytree=0.1, max_depth=3, n_estimators=400......\n",
      "[CV 3/5; 51/360] END colsample_bytree=0.1, max_depth=3, n_estimators=400;, score=0.934 total time=   0.3s\n",
      "[CV 4/5; 51/360] START colsample_bytree=0.1, max_depth=3, n_estimators=400......\n",
      "[CV 4/5; 51/360] END colsample_bytree=0.1, max_depth=3, n_estimators=400;, score=0.931 total time=   0.2s\n",
      "[CV 5/5; 51/360] START colsample_bytree=0.1, max_depth=3, n_estimators=400......\n",
      "[CV 5/5; 51/360] END colsample_bytree=0.1, max_depth=3, n_estimators=400;, score=0.933 total time=   0.2s\n",
      "[CV 1/5; 52/360] START colsample_bytree=0.1, max_depth=3, n_estimators=450......\n",
      "[CV 1/5; 52/360] END colsample_bytree=0.1, max_depth=3, n_estimators=450;, score=0.931 total time=   0.2s\n",
      "[CV 2/5; 52/360] START colsample_bytree=0.1, max_depth=3, n_estimators=450......\n",
      "[CV 2/5; 52/360] END colsample_bytree=0.1, max_depth=3, n_estimators=450;, score=0.932 total time=   0.2s\n",
      "[CV 3/5; 52/360] START colsample_bytree=0.1, max_depth=3, n_estimators=450......\n",
      "[CV 3/5; 52/360] END colsample_bytree=0.1, max_depth=3, n_estimators=450;, score=0.934 total time=   0.2s\n",
      "[CV 4/5; 52/360] START colsample_bytree=0.1, max_depth=3, n_estimators=450......\n",
      "[CV 4/5; 52/360] END colsample_bytree=0.1, max_depth=3, n_estimators=450;, score=0.932 total time=   0.2s\n",
      "[CV 5/5; 52/360] START colsample_bytree=0.1, max_depth=3, n_estimators=450......\n",
      "[CV 5/5; 52/360] END colsample_bytree=0.1, max_depth=3, n_estimators=450;, score=0.933 total time=   0.2s\n",
      "[CV 1/5; 53/360] START colsample_bytree=0.1, max_depth=3, n_estimators=500......\n",
      "[CV 1/5; 53/360] END colsample_bytree=0.1, max_depth=3, n_estimators=500;, score=0.931 total time=   0.2s\n",
      "[CV 2/5; 53/360] START colsample_bytree=0.1, max_depth=3, n_estimators=500......\n",
      "[CV 2/5; 53/360] END colsample_bytree=0.1, max_depth=3, n_estimators=500;, score=0.932 total time=   0.2s\n",
      "[CV 3/5; 53/360] START colsample_bytree=0.1, max_depth=3, n_estimators=500......\n",
      "[CV 3/5; 53/360] END colsample_bytree=0.1, max_depth=3, n_estimators=500;, score=0.934 total time=   0.2s\n",
      "[CV 4/5; 53/360] START colsample_bytree=0.1, max_depth=3, n_estimators=500......\n",
      "[CV 4/5; 53/360] END colsample_bytree=0.1, max_depth=3, n_estimators=500;, score=0.932 total time=   0.2s\n",
      "[CV 5/5; 53/360] START colsample_bytree=0.1, max_depth=3, n_estimators=500......\n",
      "[CV 5/5; 53/360] END colsample_bytree=0.1, max_depth=3, n_estimators=500;, score=0.934 total time=   0.2s\n",
      "[CV 1/5; 54/360] START colsample_bytree=0.1, max_depth=3, n_estimators=550......\n",
      "[CV 1/5; 54/360] END colsample_bytree=0.1, max_depth=3, n_estimators=550;, score=0.932 total time=   0.3s\n",
      "[CV 2/5; 54/360] START colsample_bytree=0.1, max_depth=3, n_estimators=550......\n",
      "[CV 2/5; 54/360] END colsample_bytree=0.1, max_depth=3, n_estimators=550;, score=0.931 total time=   0.3s\n",
      "[CV 3/5; 54/360] START colsample_bytree=0.1, max_depth=3, n_estimators=550......\n",
      "[CV 3/5; 54/360] END colsample_bytree=0.1, max_depth=3, n_estimators=550;, score=0.934 total time=   0.3s\n",
      "[CV 4/5; 54/360] START colsample_bytree=0.1, max_depth=3, n_estimators=550......\n",
      "[CV 4/5; 54/360] END colsample_bytree=0.1, max_depth=3, n_estimators=550;, score=0.932 total time=   0.3s\n",
      "[CV 5/5; 54/360] START colsample_bytree=0.1, max_depth=3, n_estimators=550......\n",
      "[CV 5/5; 54/360] END colsample_bytree=0.1, max_depth=3, n_estimators=550;, score=0.934 total time=   0.3s\n",
      "[CV 1/5; 55/360] START colsample_bytree=0.1, max_depth=4, n_estimators=300......\n",
      "[CV 1/5; 55/360] END colsample_bytree=0.1, max_depth=4, n_estimators=300;, score=0.931 total time=   0.1s\n",
      "[CV 2/5; 55/360] START colsample_bytree=0.1, max_depth=4, n_estimators=300......\n",
      "[CV 2/5; 55/360] END colsample_bytree=0.1, max_depth=4, n_estimators=300;, score=0.932 total time=   0.1s\n",
      "[CV 3/5; 55/360] START colsample_bytree=0.1, max_depth=4, n_estimators=300......\n",
      "[CV 3/5; 55/360] END colsample_bytree=0.1, max_depth=4, n_estimators=300;, score=0.934 total time=   0.1s\n",
      "[CV 4/5; 55/360] START colsample_bytree=0.1, max_depth=4, n_estimators=300......\n",
      "[CV 4/5; 55/360] END colsample_bytree=0.1, max_depth=4, n_estimators=300;, score=0.931 total time=   0.1s\n",
      "[CV 5/5; 55/360] START colsample_bytree=0.1, max_depth=4, n_estimators=300......\n",
      "[CV 5/5; 55/360] END colsample_bytree=0.1, max_depth=4, n_estimators=300;, score=0.933 total time=   0.1s\n",
      "[CV 1/5; 56/360] START colsample_bytree=0.1, max_depth=4, n_estimators=350......\n",
      "[CV 1/5; 56/360] END colsample_bytree=0.1, max_depth=4, n_estimators=350;, score=0.931 total time=   0.2s\n",
      "[CV 2/5; 56/360] START colsample_bytree=0.1, max_depth=4, n_estimators=350......\n",
      "[CV 2/5; 56/360] END colsample_bytree=0.1, max_depth=4, n_estimators=350;, score=0.931 total time=   0.2s\n",
      "[CV 3/5; 56/360] START colsample_bytree=0.1, max_depth=4, n_estimators=350......\n",
      "[CV 3/5; 56/360] END colsample_bytree=0.1, max_depth=4, n_estimators=350;, score=0.934 total time=   0.2s\n",
      "[CV 4/5; 56/360] START colsample_bytree=0.1, max_depth=4, n_estimators=350......\n",
      "[CV 4/5; 56/360] END colsample_bytree=0.1, max_depth=4, n_estimators=350;, score=0.931 total time=   0.2s\n",
      "[CV 5/5; 56/360] START colsample_bytree=0.1, max_depth=4, n_estimators=350......\n",
      "[CV 5/5; 56/360] END colsample_bytree=0.1, max_depth=4, n_estimators=350;, score=0.933 total time=   0.2s\n",
      "[CV 1/5; 57/360] START colsample_bytree=0.1, max_depth=4, n_estimators=400......\n",
      "[CV 1/5; 57/360] END colsample_bytree=0.1, max_depth=4, n_estimators=400;, score=0.931 total time=   0.2s\n",
      "[CV 2/5; 57/360] START colsample_bytree=0.1, max_depth=4, n_estimators=400......\n",
      "[CV 2/5; 57/360] END colsample_bytree=0.1, max_depth=4, n_estimators=400;, score=0.932 total time=   0.2s\n",
      "[CV 3/5; 57/360] START colsample_bytree=0.1, max_depth=4, n_estimators=400......\n",
      "[CV 3/5; 57/360] END colsample_bytree=0.1, max_depth=4, n_estimators=400;, score=0.934 total time=   0.2s\n",
      "[CV 4/5; 57/360] START colsample_bytree=0.1, max_depth=4, n_estimators=400......\n",
      "[CV 4/5; 57/360] END colsample_bytree=0.1, max_depth=4, n_estimators=400;, score=0.931 total time=   0.2s\n",
      "[CV 5/5; 57/360] START colsample_bytree=0.1, max_depth=4, n_estimators=400......\n",
      "[CV 5/5; 57/360] END colsample_bytree=0.1, max_depth=4, n_estimators=400;, score=0.933 total time=   0.2s\n",
      "[CV 1/5; 58/360] START colsample_bytree=0.1, max_depth=4, n_estimators=450......\n",
      "[CV 1/5; 58/360] END colsample_bytree=0.1, max_depth=4, n_estimators=450;, score=0.931 total time=   0.2s\n",
      "[CV 2/5; 58/360] START colsample_bytree=0.1, max_depth=4, n_estimators=450......\n",
      "[CV 2/5; 58/360] END colsample_bytree=0.1, max_depth=4, n_estimators=450;, score=0.932 total time=   0.2s\n",
      "[CV 3/5; 58/360] START colsample_bytree=0.1, max_depth=4, n_estimators=450......\n",
      "[CV 3/5; 58/360] END colsample_bytree=0.1, max_depth=4, n_estimators=450;, score=0.934 total time=   0.2s\n",
      "[CV 4/5; 58/360] START colsample_bytree=0.1, max_depth=4, n_estimators=450......\n",
      "[CV 4/5; 58/360] END colsample_bytree=0.1, max_depth=4, n_estimators=450;, score=0.931 total time=   0.3s\n",
      "[CV 5/5; 58/360] START colsample_bytree=0.1, max_depth=4, n_estimators=450......\n",
      "[CV 5/5; 58/360] END colsample_bytree=0.1, max_depth=4, n_estimators=450;, score=0.933 total time=   0.2s\n",
      "[CV 1/5; 59/360] START colsample_bytree=0.1, max_depth=4, n_estimators=500......\n",
      "[CV 1/5; 59/360] END colsample_bytree=0.1, max_depth=4, n_estimators=500;, score=0.931 total time=   0.3s\n",
      "[CV 2/5; 59/360] START colsample_bytree=0.1, max_depth=4, n_estimators=500......\n",
      "[CV 2/5; 59/360] END colsample_bytree=0.1, max_depth=4, n_estimators=500;, score=0.932 total time=   0.3s\n",
      "[CV 3/5; 59/360] START colsample_bytree=0.1, max_depth=4, n_estimators=500......\n",
      "[CV 3/5; 59/360] END colsample_bytree=0.1, max_depth=4, n_estimators=500;, score=0.933 total time=   0.3s\n",
      "[CV 4/5; 59/360] START colsample_bytree=0.1, max_depth=4, n_estimators=500......\n",
      "[CV 4/5; 59/360] END colsample_bytree=0.1, max_depth=4, n_estimators=500;, score=0.931 total time=   0.4s\n",
      "[CV 5/5; 59/360] START colsample_bytree=0.1, max_depth=4, n_estimators=500......\n",
      "[CV 5/5; 59/360] END colsample_bytree=0.1, max_depth=4, n_estimators=500;, score=0.933 total time=   0.4s\n",
      "[CV 1/5; 60/360] START colsample_bytree=0.1, max_depth=4, n_estimators=550......\n",
      "[CV 1/5; 60/360] END colsample_bytree=0.1, max_depth=4, n_estimators=550;, score=0.931 total time=   0.4s\n",
      "[CV 2/5; 60/360] START colsample_bytree=0.1, max_depth=4, n_estimators=550......\n",
      "[CV 2/5; 60/360] END colsample_bytree=0.1, max_depth=4, n_estimators=550;, score=0.931 total time=   0.4s\n",
      "[CV 3/5; 60/360] START colsample_bytree=0.1, max_depth=4, n_estimators=550......\n",
      "[CV 3/5; 60/360] END colsample_bytree=0.1, max_depth=4, n_estimators=550;, score=0.934 total time=   0.3s\n",
      "[CV 4/5; 60/360] START colsample_bytree=0.1, max_depth=4, n_estimators=550......\n",
      "[CV 4/5; 60/360] END colsample_bytree=0.1, max_depth=4, n_estimators=550;, score=0.931 total time=   0.3s\n",
      "[CV 5/5; 60/360] START colsample_bytree=0.1, max_depth=4, n_estimators=550......\n",
      "[CV 5/5; 60/360] END colsample_bytree=0.1, max_depth=4, n_estimators=550;, score=0.933 total time=   0.3s\n",
      "[CV 1/5; 61/360] START colsample_bytree=0.1, max_depth=5, n_estimators=300......\n",
      "[CV 1/5; 61/360] END colsample_bytree=0.1, max_depth=5, n_estimators=300;, score=0.931 total time=   0.2s\n",
      "[CV 2/5; 61/360] START colsample_bytree=0.1, max_depth=5, n_estimators=300......\n",
      "[CV 2/5; 61/360] END colsample_bytree=0.1, max_depth=5, n_estimators=300;, score=0.931 total time=   0.2s\n",
      "[CV 3/5; 61/360] START colsample_bytree=0.1, max_depth=5, n_estimators=300......\n",
      "[CV 3/5; 61/360] END colsample_bytree=0.1, max_depth=5, n_estimators=300;, score=0.933 total time=   0.2s\n",
      "[CV 4/5; 61/360] START colsample_bytree=0.1, max_depth=5, n_estimators=300......\n",
      "[CV 4/5; 61/360] END colsample_bytree=0.1, max_depth=5, n_estimators=300;, score=0.931 total time=   0.2s\n",
      "[CV 5/5; 61/360] START colsample_bytree=0.1, max_depth=5, n_estimators=300......\n",
      "[CV 5/5; 61/360] END colsample_bytree=0.1, max_depth=5, n_estimators=300;, score=0.932 total time=   0.2s\n",
      "[CV 1/5; 62/360] START colsample_bytree=0.1, max_depth=5, n_estimators=350......\n",
      "[CV 1/5; 62/360] END colsample_bytree=0.1, max_depth=5, n_estimators=350;, score=0.931 total time=   0.2s\n",
      "[CV 2/5; 62/360] START colsample_bytree=0.1, max_depth=5, n_estimators=350......\n",
      "[CV 2/5; 62/360] END colsample_bytree=0.1, max_depth=5, n_estimators=350;, score=0.931 total time=   0.2s\n",
      "[CV 3/5; 62/360] START colsample_bytree=0.1, max_depth=5, n_estimators=350......\n",
      "[CV 3/5; 62/360] END colsample_bytree=0.1, max_depth=5, n_estimators=350;, score=0.933 total time=   0.2s\n",
      "[CV 4/5; 62/360] START colsample_bytree=0.1, max_depth=5, n_estimators=350......\n",
      "[CV 4/5; 62/360] END colsample_bytree=0.1, max_depth=5, n_estimators=350;, score=0.931 total time=   0.2s\n",
      "[CV 5/5; 62/360] START colsample_bytree=0.1, max_depth=5, n_estimators=350......\n",
      "[CV 5/5; 62/360] END colsample_bytree=0.1, max_depth=5, n_estimators=350;, score=0.933 total time=   0.2s\n",
      "[CV 1/5; 63/360] START colsample_bytree=0.1, max_depth=5, n_estimators=400......\n",
      "[CV 1/5; 63/360] END colsample_bytree=0.1, max_depth=5, n_estimators=400;, score=0.932 total time=   0.2s\n",
      "[CV 2/5; 63/360] START colsample_bytree=0.1, max_depth=5, n_estimators=400......\n",
      "[CV 2/5; 63/360] END colsample_bytree=0.1, max_depth=5, n_estimators=400;, score=0.932 total time=   0.2s\n",
      "[CV 3/5; 63/360] START colsample_bytree=0.1, max_depth=5, n_estimators=400......\n",
      "[CV 3/5; 63/360] END colsample_bytree=0.1, max_depth=5, n_estimators=400;, score=0.933 total time=   0.2s\n",
      "[CV 4/5; 63/360] START colsample_bytree=0.1, max_depth=5, n_estimators=400......\n",
      "[CV 4/5; 63/360] END colsample_bytree=0.1, max_depth=5, n_estimators=400;, score=0.932 total time=   0.2s\n",
      "[CV 5/5; 63/360] START colsample_bytree=0.1, max_depth=5, n_estimators=400......\n",
      "[CV 5/5; 63/360] END colsample_bytree=0.1, max_depth=5, n_estimators=400;, score=0.934 total time=   0.2s\n",
      "[CV 1/5; 64/360] START colsample_bytree=0.1, max_depth=5, n_estimators=450......\n",
      "[CV 1/5; 64/360] END colsample_bytree=0.1, max_depth=5, n_estimators=450;, score=0.931 total time=   0.3s\n",
      "[CV 2/5; 64/360] START colsample_bytree=0.1, max_depth=5, n_estimators=450......\n",
      "[CV 2/5; 64/360] END colsample_bytree=0.1, max_depth=5, n_estimators=450;, score=0.931 total time=   0.3s\n",
      "[CV 3/5; 64/360] START colsample_bytree=0.1, max_depth=5, n_estimators=450......\n",
      "[CV 3/5; 64/360] END colsample_bytree=0.1, max_depth=5, n_estimators=450;, score=0.933 total time=   0.3s\n",
      "[CV 4/5; 64/360] START colsample_bytree=0.1, max_depth=5, n_estimators=450......\n",
      "[CV 4/5; 64/360] END colsample_bytree=0.1, max_depth=5, n_estimators=450;, score=0.932 total time=   0.3s\n",
      "[CV 5/5; 64/360] START colsample_bytree=0.1, max_depth=5, n_estimators=450......\n",
      "[CV 5/5; 64/360] END colsample_bytree=0.1, max_depth=5, n_estimators=450;, score=0.933 total time=   0.3s\n",
      "[CV 1/5; 65/360] START colsample_bytree=0.1, max_depth=5, n_estimators=500......\n",
      "[CV 1/5; 65/360] END colsample_bytree=0.1, max_depth=5, n_estimators=500;, score=0.931 total time=   0.3s\n",
      "[CV 2/5; 65/360] START colsample_bytree=0.1, max_depth=5, n_estimators=500......\n",
      "[CV 2/5; 65/360] END colsample_bytree=0.1, max_depth=5, n_estimators=500;, score=0.931 total time=   0.3s\n",
      "[CV 3/5; 65/360] START colsample_bytree=0.1, max_depth=5, n_estimators=500......\n",
      "[CV 3/5; 65/360] END colsample_bytree=0.1, max_depth=5, n_estimators=500;, score=0.933 total time=   0.3s\n",
      "[CV 4/5; 65/360] START colsample_bytree=0.1, max_depth=5, n_estimators=500......\n",
      "[CV 4/5; 65/360] END colsample_bytree=0.1, max_depth=5, n_estimators=500;, score=0.931 total time=   0.3s\n",
      "[CV 5/5; 65/360] START colsample_bytree=0.1, max_depth=5, n_estimators=500......\n",
      "[CV 5/5; 65/360] END colsample_bytree=0.1, max_depth=5, n_estimators=500;, score=0.933 total time=   0.3s\n",
      "[CV 1/5; 66/360] START colsample_bytree=0.1, max_depth=5, n_estimators=550......\n",
      "[CV 1/5; 66/360] END colsample_bytree=0.1, max_depth=5, n_estimators=550;, score=0.931 total time=   0.3s\n",
      "[CV 2/5; 66/360] START colsample_bytree=0.1, max_depth=5, n_estimators=550......\n",
      "[CV 2/5; 66/360] END colsample_bytree=0.1, max_depth=5, n_estimators=550;, score=0.931 total time=   0.4s\n",
      "[CV 3/5; 66/360] START colsample_bytree=0.1, max_depth=5, n_estimators=550......\n",
      "[CV 3/5; 66/360] END colsample_bytree=0.1, max_depth=5, n_estimators=550;, score=0.933 total time=   0.4s\n",
      "[CV 4/5; 66/360] START colsample_bytree=0.1, max_depth=5, n_estimators=550......\n",
      "[CV 4/5; 66/360] END colsample_bytree=0.1, max_depth=5, n_estimators=550;, score=0.932 total time=   0.3s\n",
      "[CV 5/5; 66/360] START colsample_bytree=0.1, max_depth=5, n_estimators=550......\n",
      "[CV 5/5; 66/360] END colsample_bytree=0.1, max_depth=5, n_estimators=550;, score=0.933 total time=   0.3s\n",
      "[CV 1/5; 67/360] START colsample_bytree=0.1, max_depth=6, n_estimators=300......\n",
      "[CV 1/5; 67/360] END colsample_bytree=0.1, max_depth=6, n_estimators=300;, score=0.931 total time=   0.2s\n",
      "[CV 2/5; 67/360] START colsample_bytree=0.1, max_depth=6, n_estimators=300......\n",
      "[CV 2/5; 67/360] END colsample_bytree=0.1, max_depth=6, n_estimators=300;, score=0.932 total time=   0.2s\n",
      "[CV 3/5; 67/360] START colsample_bytree=0.1, max_depth=6, n_estimators=300......\n",
      "[CV 3/5; 67/360] END colsample_bytree=0.1, max_depth=6, n_estimators=300;, score=0.933 total time=   0.2s\n",
      "[CV 4/5; 67/360] START colsample_bytree=0.1, max_depth=6, n_estimators=300......\n",
      "[CV 4/5; 67/360] END colsample_bytree=0.1, max_depth=6, n_estimators=300;, score=0.931 total time=   0.2s\n",
      "[CV 5/5; 67/360] START colsample_bytree=0.1, max_depth=6, n_estimators=300......\n",
      "[CV 5/5; 67/360] END colsample_bytree=0.1, max_depth=6, n_estimators=300;, score=0.933 total time=   0.2s\n",
      "[CV 1/5; 68/360] START colsample_bytree=0.1, max_depth=6, n_estimators=350......\n",
      "[CV 1/5; 68/360] END colsample_bytree=0.1, max_depth=6, n_estimators=350;, score=0.931 total time=   0.2s\n",
      "[CV 2/5; 68/360] START colsample_bytree=0.1, max_depth=6, n_estimators=350......\n",
      "[CV 2/5; 68/360] END colsample_bytree=0.1, max_depth=6, n_estimators=350;, score=0.931 total time=   0.3s\n",
      "[CV 3/5; 68/360] START colsample_bytree=0.1, max_depth=6, n_estimators=350......\n",
      "[CV 3/5; 68/360] END colsample_bytree=0.1, max_depth=6, n_estimators=350;, score=0.932 total time=   0.3s\n",
      "[CV 4/5; 68/360] START colsample_bytree=0.1, max_depth=6, n_estimators=350......\n",
      "[CV 4/5; 68/360] END colsample_bytree=0.1, max_depth=6, n_estimators=350;, score=0.931 total time=   0.3s\n",
      "[CV 5/5; 68/360] START colsample_bytree=0.1, max_depth=6, n_estimators=350......\n",
      "[CV 5/5; 68/360] END colsample_bytree=0.1, max_depth=6, n_estimators=350;, score=0.933 total time=   0.3s\n",
      "[CV 1/5; 69/360] START colsample_bytree=0.1, max_depth=6, n_estimators=400......\n",
      "[CV 1/5; 69/360] END colsample_bytree=0.1, max_depth=6, n_estimators=400;, score=0.931 total time=   0.4s\n",
      "[CV 2/5; 69/360] START colsample_bytree=0.1, max_depth=6, n_estimators=400......\n",
      "[CV 2/5; 69/360] END colsample_bytree=0.1, max_depth=6, n_estimators=400;, score=0.931 total time=   0.3s\n",
      "[CV 3/5; 69/360] START colsample_bytree=0.1, max_depth=6, n_estimators=400......\n",
      "[CV 3/5; 69/360] END colsample_bytree=0.1, max_depth=6, n_estimators=400;, score=0.932 total time=   0.3s\n",
      "[CV 4/5; 69/360] START colsample_bytree=0.1, max_depth=6, n_estimators=400......\n",
      "[CV 4/5; 69/360] END colsample_bytree=0.1, max_depth=6, n_estimators=400;, score=0.932 total time=   0.3s\n",
      "[CV 5/5; 69/360] START colsample_bytree=0.1, max_depth=6, n_estimators=400......\n",
      "[CV 5/5; 69/360] END colsample_bytree=0.1, max_depth=6, n_estimators=400;, score=0.933 total time=   0.3s\n",
      "[CV 1/5; 70/360] START colsample_bytree=0.1, max_depth=6, n_estimators=450......\n",
      "[CV 1/5; 70/360] END colsample_bytree=0.1, max_depth=6, n_estimators=450;, score=0.931 total time=   0.3s\n",
      "[CV 2/5; 70/360] START colsample_bytree=0.1, max_depth=6, n_estimators=450......\n",
      "[CV 2/5; 70/360] END colsample_bytree=0.1, max_depth=6, n_estimators=450;, score=0.931 total time=   0.3s\n",
      "[CV 3/5; 70/360] START colsample_bytree=0.1, max_depth=6, n_estimators=450......\n",
      "[CV 3/5; 70/360] END colsample_bytree=0.1, max_depth=6, n_estimators=450;, score=0.932 total time=   0.3s\n",
      "[CV 4/5; 70/360] START colsample_bytree=0.1, max_depth=6, n_estimators=450......\n",
      "[CV 4/5; 70/360] END colsample_bytree=0.1, max_depth=6, n_estimators=450;, score=0.933 total time=   0.3s\n",
      "[CV 5/5; 70/360] START colsample_bytree=0.1, max_depth=6, n_estimators=450......\n",
      "[CV 5/5; 70/360] END colsample_bytree=0.1, max_depth=6, n_estimators=450;, score=0.933 total time=   0.3s\n",
      "[CV 1/5; 71/360] START colsample_bytree=0.1, max_depth=6, n_estimators=500......\n",
      "[CV 1/5; 71/360] END colsample_bytree=0.1, max_depth=6, n_estimators=500;, score=0.931 total time=   0.3s\n",
      "[CV 2/5; 71/360] START colsample_bytree=0.1, max_depth=6, n_estimators=500......\n",
      "[CV 2/5; 71/360] END colsample_bytree=0.1, max_depth=6, n_estimators=500;, score=0.931 total time=   0.4s\n",
      "[CV 3/5; 71/360] START colsample_bytree=0.1, max_depth=6, n_estimators=500......\n",
      "[CV 3/5; 71/360] END colsample_bytree=0.1, max_depth=6, n_estimators=500;, score=0.932 total time=   0.4s\n",
      "[CV 4/5; 71/360] START colsample_bytree=0.1, max_depth=6, n_estimators=500......\n",
      "[CV 4/5; 71/360] END colsample_bytree=0.1, max_depth=6, n_estimators=500;, score=0.932 total time=   0.4s\n",
      "[CV 5/5; 71/360] START colsample_bytree=0.1, max_depth=6, n_estimators=500......\n",
      "[CV 5/5; 71/360] END colsample_bytree=0.1, max_depth=6, n_estimators=500;, score=0.933 total time=   0.5s\n",
      "[CV 1/5; 72/360] START colsample_bytree=0.1, max_depth=6, n_estimators=550......\n",
      "[CV 1/5; 72/360] END colsample_bytree=0.1, max_depth=6, n_estimators=550;, score=0.931 total time=   0.5s\n",
      "[CV 2/5; 72/360] START colsample_bytree=0.1, max_depth=6, n_estimators=550......\n",
      "[CV 2/5; 72/360] END colsample_bytree=0.1, max_depth=6, n_estimators=550;, score=0.931 total time=   0.4s\n",
      "[CV 3/5; 72/360] START colsample_bytree=0.1, max_depth=6, n_estimators=550......\n",
      "[CV 3/5; 72/360] END colsample_bytree=0.1, max_depth=6, n_estimators=550;, score=0.932 total time=   0.6s\n",
      "[CV 4/5; 72/360] START colsample_bytree=0.1, max_depth=6, n_estimators=550......\n",
      "[CV 4/5; 72/360] END colsample_bytree=0.1, max_depth=6, n_estimators=550;, score=0.933 total time=   0.4s\n",
      "[CV 5/5; 72/360] START colsample_bytree=0.1, max_depth=6, n_estimators=550......\n",
      "[CV 5/5; 72/360] END colsample_bytree=0.1, max_depth=6, n_estimators=550;, score=0.933 total time=   0.4s\n",
      "[CV 1/5; 73/360] START colsample_bytree=0.2, max_depth=1, n_estimators=300......\n",
      "[CV 1/5; 73/360] END colsample_bytree=0.2, max_depth=1, n_estimators=300;, score=0.928 total time=   0.1s\n",
      "[CV 2/5; 73/360] START colsample_bytree=0.2, max_depth=1, n_estimators=300......\n",
      "[CV 2/5; 73/360] END colsample_bytree=0.2, max_depth=1, n_estimators=300;, score=0.928 total time=   0.1s\n",
      "[CV 3/5; 73/360] START colsample_bytree=0.2, max_depth=1, n_estimators=300......\n",
      "[CV 3/5; 73/360] END colsample_bytree=0.2, max_depth=1, n_estimators=300;, score=0.931 total time=   0.1s\n",
      "[CV 4/5; 73/360] START colsample_bytree=0.2, max_depth=1, n_estimators=300......\n",
      "[CV 4/5; 73/360] END colsample_bytree=0.2, max_depth=1, n_estimators=300;, score=0.932 total time=   0.1s\n",
      "[CV 5/5; 73/360] START colsample_bytree=0.2, max_depth=1, n_estimators=300......\n",
      "[CV 5/5; 73/360] END colsample_bytree=0.2, max_depth=1, n_estimators=300;, score=0.929 total time=   0.1s\n",
      "[CV 1/5; 74/360] START colsample_bytree=0.2, max_depth=1, n_estimators=350......\n",
      "[CV 1/5; 74/360] END colsample_bytree=0.2, max_depth=1, n_estimators=350;, score=0.928 total time=   0.1s\n",
      "[CV 2/5; 74/360] START colsample_bytree=0.2, max_depth=1, n_estimators=350......\n",
      "[CV 2/5; 74/360] END colsample_bytree=0.2, max_depth=1, n_estimators=350;, score=0.928 total time=   0.1s\n",
      "[CV 3/5; 74/360] START colsample_bytree=0.2, max_depth=1, n_estimators=350......\n",
      "[CV 3/5; 74/360] END colsample_bytree=0.2, max_depth=1, n_estimators=350;, score=0.931 total time=   0.1s\n",
      "[CV 4/5; 74/360] START colsample_bytree=0.2, max_depth=1, n_estimators=350......\n",
      "[CV 4/5; 74/360] END colsample_bytree=0.2, max_depth=1, n_estimators=350;, score=0.932 total time=   0.1s\n",
      "[CV 5/5; 74/360] START colsample_bytree=0.2, max_depth=1, n_estimators=350......\n",
      "[CV 5/5; 74/360] END colsample_bytree=0.2, max_depth=1, n_estimators=350;, score=0.929 total time=   0.1s\n",
      "[CV 1/5; 75/360] START colsample_bytree=0.2, max_depth=1, n_estimators=400......\n",
      "[CV 1/5; 75/360] END colsample_bytree=0.2, max_depth=1, n_estimators=400;, score=0.928 total time=   0.1s\n",
      "[CV 2/5; 75/360] START colsample_bytree=0.2, max_depth=1, n_estimators=400......\n",
      "[CV 2/5; 75/360] END colsample_bytree=0.2, max_depth=1, n_estimators=400;, score=0.928 total time=   0.1s\n",
      "[CV 3/5; 75/360] START colsample_bytree=0.2, max_depth=1, n_estimators=400......\n",
      "[CV 3/5; 75/360] END colsample_bytree=0.2, max_depth=1, n_estimators=400;, score=0.931 total time=   0.1s\n",
      "[CV 4/5; 75/360] START colsample_bytree=0.2, max_depth=1, n_estimators=400......\n",
      "[CV 4/5; 75/360] END colsample_bytree=0.2, max_depth=1, n_estimators=400;, score=0.933 total time=   0.1s\n",
      "[CV 5/5; 75/360] START colsample_bytree=0.2, max_depth=1, n_estimators=400......\n",
      "[CV 5/5; 75/360] END colsample_bytree=0.2, max_depth=1, n_estimators=400;, score=0.930 total time=   0.1s\n",
      "[CV 1/5; 76/360] START colsample_bytree=0.2, max_depth=1, n_estimators=450......\n",
      "[CV 1/5; 76/360] END colsample_bytree=0.2, max_depth=1, n_estimators=450;, score=0.928 total time=   0.2s\n",
      "[CV 2/5; 76/360] START colsample_bytree=0.2, max_depth=1, n_estimators=450......\n",
      "[CV 2/5; 76/360] END colsample_bytree=0.2, max_depth=1, n_estimators=450;, score=0.928 total time=   0.1s\n",
      "[CV 3/5; 76/360] START colsample_bytree=0.2, max_depth=1, n_estimators=450......\n",
      "[CV 3/5; 76/360] END colsample_bytree=0.2, max_depth=1, n_estimators=450;, score=0.931 total time=   0.2s\n",
      "[CV 4/5; 76/360] START colsample_bytree=0.2, max_depth=1, n_estimators=450......\n",
      "[CV 4/5; 76/360] END colsample_bytree=0.2, max_depth=1, n_estimators=450;, score=0.932 total time=   0.2s\n",
      "[CV 5/5; 76/360] START colsample_bytree=0.2, max_depth=1, n_estimators=450......\n",
      "[CV 5/5; 76/360] END colsample_bytree=0.2, max_depth=1, n_estimators=450;, score=0.930 total time=   0.2s\n",
      "[CV 1/5; 77/360] START colsample_bytree=0.2, max_depth=1, n_estimators=500......\n",
      "[CV 1/5; 77/360] END colsample_bytree=0.2, max_depth=1, n_estimators=500;, score=0.929 total time=   0.2s\n",
      "[CV 2/5; 77/360] START colsample_bytree=0.2, max_depth=1, n_estimators=500......\n",
      "[CV 2/5; 77/360] END colsample_bytree=0.2, max_depth=1, n_estimators=500;, score=0.928 total time=   0.3s\n",
      "[CV 3/5; 77/360] START colsample_bytree=0.2, max_depth=1, n_estimators=500......\n",
      "[CV 3/5; 77/360] END colsample_bytree=0.2, max_depth=1, n_estimators=500;, score=0.931 total time=   0.3s\n",
      "[CV 4/5; 77/360] START colsample_bytree=0.2, max_depth=1, n_estimators=500......\n",
      "[CV 4/5; 77/360] END colsample_bytree=0.2, max_depth=1, n_estimators=500;, score=0.932 total time=   0.3s\n",
      "[CV 5/5; 77/360] START colsample_bytree=0.2, max_depth=1, n_estimators=500......\n",
      "[CV 5/5; 77/360] END colsample_bytree=0.2, max_depth=1, n_estimators=500;, score=0.930 total time=   0.3s\n",
      "[CV 1/5; 78/360] START colsample_bytree=0.2, max_depth=1, n_estimators=550......\n",
      "[CV 1/5; 78/360] END colsample_bytree=0.2, max_depth=1, n_estimators=550;, score=0.929 total time=   0.3s\n",
      "[CV 2/5; 78/360] START colsample_bytree=0.2, max_depth=1, n_estimators=550......\n",
      "[CV 2/5; 78/360] END colsample_bytree=0.2, max_depth=1, n_estimators=550;, score=0.928 total time=   0.3s\n",
      "[CV 3/5; 78/360] START colsample_bytree=0.2, max_depth=1, n_estimators=550......\n",
      "[CV 3/5; 78/360] END colsample_bytree=0.2, max_depth=1, n_estimators=550;, score=0.931 total time=   0.3s\n",
      "[CV 4/5; 78/360] START colsample_bytree=0.2, max_depth=1, n_estimators=550......\n",
      "[CV 4/5; 78/360] END colsample_bytree=0.2, max_depth=1, n_estimators=550;, score=0.932 total time=   0.2s\n",
      "[CV 5/5; 78/360] START colsample_bytree=0.2, max_depth=1, n_estimators=550......\n",
      "[CV 5/5; 78/360] END colsample_bytree=0.2, max_depth=1, n_estimators=550;, score=0.930 total time=   0.3s\n",
      "[CV 1/5; 79/360] START colsample_bytree=0.2, max_depth=2, n_estimators=300......\n",
      "[CV 1/5; 79/360] END colsample_bytree=0.2, max_depth=2, n_estimators=300;, score=0.948 total time=   0.1s\n",
      "[CV 2/5; 79/360] START colsample_bytree=0.2, max_depth=2, n_estimators=300......\n",
      "[CV 2/5; 79/360] END colsample_bytree=0.2, max_depth=2, n_estimators=300;, score=0.949 total time=   0.1s\n",
      "[CV 3/5; 79/360] START colsample_bytree=0.2, max_depth=2, n_estimators=300......\n",
      "[CV 3/5; 79/360] END colsample_bytree=0.2, max_depth=2, n_estimators=300;, score=0.948 total time=   0.2s\n",
      "[CV 4/5; 79/360] START colsample_bytree=0.2, max_depth=2, n_estimators=300......\n",
      "[CV 4/5; 79/360] END colsample_bytree=0.2, max_depth=2, n_estimators=300;, score=0.952 total time=   0.1s\n",
      "[CV 5/5; 79/360] START colsample_bytree=0.2, max_depth=2, n_estimators=300......\n",
      "[CV 5/5; 79/360] END colsample_bytree=0.2, max_depth=2, n_estimators=300;, score=0.950 total time=   0.1s\n",
      "[CV 1/5; 80/360] START colsample_bytree=0.2, max_depth=2, n_estimators=350......\n",
      "[CV 1/5; 80/360] END colsample_bytree=0.2, max_depth=2, n_estimators=350;, score=0.949 total time=   0.2s\n",
      "[CV 2/5; 80/360] START colsample_bytree=0.2, max_depth=2, n_estimators=350......\n",
      "[CV 2/5; 80/360] END colsample_bytree=0.2, max_depth=2, n_estimators=350;, score=0.949 total time=   0.2s\n",
      "[CV 3/5; 80/360] START colsample_bytree=0.2, max_depth=2, n_estimators=350......\n",
      "[CV 3/5; 80/360] END colsample_bytree=0.2, max_depth=2, n_estimators=350;, score=0.948 total time=   0.2s\n",
      "[CV 4/5; 80/360] START colsample_bytree=0.2, max_depth=2, n_estimators=350......\n",
      "[CV 4/5; 80/360] END colsample_bytree=0.2, max_depth=2, n_estimators=350;, score=0.954 total time=   0.2s\n",
      "[CV 5/5; 80/360] START colsample_bytree=0.2, max_depth=2, n_estimators=350......\n",
      "[CV 5/5; 80/360] END colsample_bytree=0.2, max_depth=2, n_estimators=350;, score=0.951 total time=   0.1s\n",
      "[CV 1/5; 81/360] START colsample_bytree=0.2, max_depth=2, n_estimators=400......\n",
      "[CV 1/5; 81/360] END colsample_bytree=0.2, max_depth=2, n_estimators=400;, score=0.949 total time=   0.2s\n",
      "[CV 2/5; 81/360] START colsample_bytree=0.2, max_depth=2, n_estimators=400......\n",
      "[CV 2/5; 81/360] END colsample_bytree=0.2, max_depth=2, n_estimators=400;, score=0.949 total time=   0.2s\n",
      "[CV 3/5; 81/360] START colsample_bytree=0.2, max_depth=2, n_estimators=400......\n",
      "[CV 3/5; 81/360] END colsample_bytree=0.2, max_depth=2, n_estimators=400;, score=0.949 total time=   0.2s\n",
      "[CV 4/5; 81/360] START colsample_bytree=0.2, max_depth=2, n_estimators=400......\n",
      "[CV 4/5; 81/360] END colsample_bytree=0.2, max_depth=2, n_estimators=400;, score=0.955 total time=   0.3s\n",
      "[CV 5/5; 81/360] START colsample_bytree=0.2, max_depth=2, n_estimators=400......\n",
      "[CV 5/5; 81/360] END colsample_bytree=0.2, max_depth=2, n_estimators=400;, score=0.951 total time=   0.3s\n",
      "[CV 1/5; 82/360] START colsample_bytree=0.2, max_depth=2, n_estimators=450......\n",
      "[CV 1/5; 82/360] END colsample_bytree=0.2, max_depth=2, n_estimators=450;, score=0.949 total time=   0.2s\n",
      "[CV 2/5; 82/360] START colsample_bytree=0.2, max_depth=2, n_estimators=450......\n",
      "[CV 2/5; 82/360] END colsample_bytree=0.2, max_depth=2, n_estimators=450;, score=0.950 total time=   0.2s\n",
      "[CV 3/5; 82/360] START colsample_bytree=0.2, max_depth=2, n_estimators=450......\n",
      "[CV 3/5; 82/360] END colsample_bytree=0.2, max_depth=2, n_estimators=450;, score=0.949 total time=   0.3s\n",
      "[CV 4/5; 82/360] START colsample_bytree=0.2, max_depth=2, n_estimators=450......\n",
      "[CV 4/5; 82/360] END colsample_bytree=0.2, max_depth=2, n_estimators=450;, score=0.954 total time=   0.3s\n",
      "[CV 5/5; 82/360] START colsample_bytree=0.2, max_depth=2, n_estimators=450......\n",
      "[CV 5/5; 82/360] END colsample_bytree=0.2, max_depth=2, n_estimators=450;, score=0.951 total time=   0.2s\n",
      "[CV 1/5; 83/360] START colsample_bytree=0.2, max_depth=2, n_estimators=500......\n",
      "[CV 1/5; 83/360] END colsample_bytree=0.2, max_depth=2, n_estimators=500;, score=0.949 total time=   0.3s\n",
      "[CV 2/5; 83/360] START colsample_bytree=0.2, max_depth=2, n_estimators=500......\n",
      "[CV 2/5; 83/360] END colsample_bytree=0.2, max_depth=2, n_estimators=500;, score=0.950 total time=   0.3s\n",
      "[CV 3/5; 83/360] START colsample_bytree=0.2, max_depth=2, n_estimators=500......\n",
      "[CV 3/5; 83/360] END colsample_bytree=0.2, max_depth=2, n_estimators=500;, score=0.949 total time=   0.3s\n",
      "[CV 4/5; 83/360] START colsample_bytree=0.2, max_depth=2, n_estimators=500......\n",
      "[CV 4/5; 83/360] END colsample_bytree=0.2, max_depth=2, n_estimators=500;, score=0.954 total time=   0.3s\n",
      "[CV 5/5; 83/360] START colsample_bytree=0.2, max_depth=2, n_estimators=500......\n",
      "[CV 5/5; 83/360] END colsample_bytree=0.2, max_depth=2, n_estimators=500;, score=0.951 total time=   0.3s\n",
      "[CV 1/5; 84/360] START colsample_bytree=0.2, max_depth=2, n_estimators=550......\n",
      "[CV 1/5; 84/360] END colsample_bytree=0.2, max_depth=2, n_estimators=550;, score=0.949 total time=   0.3s\n",
      "[CV 2/5; 84/360] START colsample_bytree=0.2, max_depth=2, n_estimators=550......\n",
      "[CV 2/5; 84/360] END colsample_bytree=0.2, max_depth=2, n_estimators=550;, score=0.950 total time=   0.3s\n",
      "[CV 3/5; 84/360] START colsample_bytree=0.2, max_depth=2, n_estimators=550......\n",
      "[CV 3/5; 84/360] END colsample_bytree=0.2, max_depth=2, n_estimators=550;, score=0.950 total time=   0.3s\n",
      "[CV 4/5; 84/360] START colsample_bytree=0.2, max_depth=2, n_estimators=550......\n",
      "[CV 4/5; 84/360] END colsample_bytree=0.2, max_depth=2, n_estimators=550;, score=0.954 total time=   0.3s\n",
      "[CV 5/5; 84/360] START colsample_bytree=0.2, max_depth=2, n_estimators=550......\n",
      "[CV 5/5; 84/360] END colsample_bytree=0.2, max_depth=2, n_estimators=550;, score=0.951 total time=   0.3s\n",
      "[CV 1/5; 85/360] START colsample_bytree=0.2, max_depth=3, n_estimators=300......\n",
      "[CV 1/5; 85/360] END colsample_bytree=0.2, max_depth=3, n_estimators=300;, score=0.949 total time=   0.2s\n",
      "[CV 2/5; 85/360] START colsample_bytree=0.2, max_depth=3, n_estimators=300......\n",
      "[CV 2/5; 85/360] END colsample_bytree=0.2, max_depth=3, n_estimators=300;, score=0.952 total time=   0.2s\n",
      "[CV 3/5; 85/360] START colsample_bytree=0.2, max_depth=3, n_estimators=300......\n",
      "[CV 3/5; 85/360] END colsample_bytree=0.2, max_depth=3, n_estimators=300;, score=0.951 total time=   0.2s\n",
      "[CV 4/5; 85/360] START colsample_bytree=0.2, max_depth=3, n_estimators=300......\n",
      "[CV 4/5; 85/360] END colsample_bytree=0.2, max_depth=3, n_estimators=300;, score=0.954 total time=   0.2s\n",
      "[CV 5/5; 85/360] START colsample_bytree=0.2, max_depth=3, n_estimators=300......\n",
      "[CV 5/5; 85/360] END colsample_bytree=0.2, max_depth=3, n_estimators=300;, score=0.952 total time=   0.2s\n",
      "[CV 1/5; 86/360] START colsample_bytree=0.2, max_depth=3, n_estimators=350......\n",
      "[CV 1/5; 86/360] END colsample_bytree=0.2, max_depth=3, n_estimators=350;, score=0.949 total time=   0.2s\n",
      "[CV 2/5; 86/360] START colsample_bytree=0.2, max_depth=3, n_estimators=350......\n",
      "[CV 2/5; 86/360] END colsample_bytree=0.2, max_depth=3, n_estimators=350;, score=0.952 total time=   0.2s\n",
      "[CV 3/5; 86/360] START colsample_bytree=0.2, max_depth=3, n_estimators=350......\n",
      "[CV 3/5; 86/360] END colsample_bytree=0.2, max_depth=3, n_estimators=350;, score=0.951 total time=   0.2s\n",
      "[CV 4/5; 86/360] START colsample_bytree=0.2, max_depth=3, n_estimators=350......\n",
      "[CV 4/5; 86/360] END colsample_bytree=0.2, max_depth=3, n_estimators=350;, score=0.954 total time=   0.3s\n",
      "[CV 5/5; 86/360] START colsample_bytree=0.2, max_depth=3, n_estimators=350......\n",
      "[CV 5/5; 86/360] END colsample_bytree=0.2, max_depth=3, n_estimators=350;, score=0.952 total time=   0.3s\n",
      "[CV 1/5; 87/360] START colsample_bytree=0.2, max_depth=3, n_estimators=400......\n",
      "[CV 1/5; 87/360] END colsample_bytree=0.2, max_depth=3, n_estimators=400;, score=0.948 total time=   0.4s\n",
      "[CV 2/5; 87/360] START colsample_bytree=0.2, max_depth=3, n_estimators=400......\n",
      "[CV 2/5; 87/360] END colsample_bytree=0.2, max_depth=3, n_estimators=400;, score=0.951 total time=   0.4s\n",
      "[CV 3/5; 87/360] START colsample_bytree=0.2, max_depth=3, n_estimators=400......\n",
      "[CV 3/5; 87/360] END colsample_bytree=0.2, max_depth=3, n_estimators=400;, score=0.951 total time=   0.4s\n",
      "[CV 4/5; 87/360] START colsample_bytree=0.2, max_depth=3, n_estimators=400......\n",
      "[CV 4/5; 87/360] END colsample_bytree=0.2, max_depth=3, n_estimators=400;, score=0.954 total time=   0.4s\n",
      "[CV 5/5; 87/360] START colsample_bytree=0.2, max_depth=3, n_estimators=400......\n",
      "[CV 5/5; 87/360] END colsample_bytree=0.2, max_depth=3, n_estimators=400;, score=0.952 total time=   0.4s\n",
      "[CV 1/5; 88/360] START colsample_bytree=0.2, max_depth=3, n_estimators=450......\n",
      "[CV 1/5; 88/360] END colsample_bytree=0.2, max_depth=3, n_estimators=450;, score=0.948 total time=   0.4s\n",
      "[CV 2/5; 88/360] START colsample_bytree=0.2, max_depth=3, n_estimators=450......\n",
      "[CV 2/5; 88/360] END colsample_bytree=0.2, max_depth=3, n_estimators=450;, score=0.952 total time=   0.4s\n",
      "[CV 3/5; 88/360] START colsample_bytree=0.2, max_depth=3, n_estimators=450......\n",
      "[CV 3/5; 88/360] END colsample_bytree=0.2, max_depth=3, n_estimators=450;, score=0.950 total time=   0.3s\n",
      "[CV 4/5; 88/360] START colsample_bytree=0.2, max_depth=3, n_estimators=450......\n",
      "[CV 4/5; 88/360] END colsample_bytree=0.2, max_depth=3, n_estimators=450;, score=0.955 total time=   0.4s\n",
      "[CV 5/5; 88/360] START colsample_bytree=0.2, max_depth=3, n_estimators=450......\n",
      "[CV 5/5; 88/360] END colsample_bytree=0.2, max_depth=3, n_estimators=450;, score=0.952 total time=   0.3s\n",
      "[CV 1/5; 89/360] START colsample_bytree=0.2, max_depth=3, n_estimators=500......\n",
      "[CV 1/5; 89/360] END colsample_bytree=0.2, max_depth=3, n_estimators=500;, score=0.948 total time=   0.4s\n",
      "[CV 2/5; 89/360] START colsample_bytree=0.2, max_depth=3, n_estimators=500......\n",
      "[CV 2/5; 89/360] END colsample_bytree=0.2, max_depth=3, n_estimators=500;, score=0.952 total time=   0.4s\n",
      "[CV 3/5; 89/360] START colsample_bytree=0.2, max_depth=3, n_estimators=500......\n",
      "[CV 3/5; 89/360] END colsample_bytree=0.2, max_depth=3, n_estimators=500;, score=0.950 total time=   0.4s\n",
      "[CV 4/5; 89/360] START colsample_bytree=0.2, max_depth=3, n_estimators=500......\n",
      "[CV 4/5; 89/360] END colsample_bytree=0.2, max_depth=3, n_estimators=500;, score=0.954 total time=   0.3s\n",
      "[CV 5/5; 89/360] START colsample_bytree=0.2, max_depth=3, n_estimators=500......\n",
      "[CV 5/5; 89/360] END colsample_bytree=0.2, max_depth=3, n_estimators=500;, score=0.952 total time=   0.4s\n",
      "[CV 1/5; 90/360] START colsample_bytree=0.2, max_depth=3, n_estimators=550......\n",
      "[CV 1/5; 90/360] END colsample_bytree=0.2, max_depth=3, n_estimators=550;, score=0.948 total time=   0.4s\n",
      "[CV 2/5; 90/360] START colsample_bytree=0.2, max_depth=3, n_estimators=550......\n",
      "[CV 2/5; 90/360] END colsample_bytree=0.2, max_depth=3, n_estimators=550;, score=0.951 total time=   0.4s\n",
      "[CV 3/5; 90/360] START colsample_bytree=0.2, max_depth=3, n_estimators=550......\n",
      "[CV 3/5; 90/360] END colsample_bytree=0.2, max_depth=3, n_estimators=550;, score=0.950 total time=   0.4s\n",
      "[CV 4/5; 90/360] START colsample_bytree=0.2, max_depth=3, n_estimators=550......\n",
      "[CV 4/5; 90/360] END colsample_bytree=0.2, max_depth=3, n_estimators=550;, score=0.955 total time=   0.4s\n",
      "[CV 5/5; 90/360] START colsample_bytree=0.2, max_depth=3, n_estimators=550......\n",
      "[CV 5/5; 90/360] END colsample_bytree=0.2, max_depth=3, n_estimators=550;, score=0.952 total time=   0.4s\n",
      "[CV 1/5; 91/360] START colsample_bytree=0.2, max_depth=4, n_estimators=300......\n",
      "[CV 1/5; 91/360] END colsample_bytree=0.2, max_depth=4, n_estimators=300;, score=0.949 total time=   0.2s\n",
      "[CV 2/5; 91/360] START colsample_bytree=0.2, max_depth=4, n_estimators=300......\n",
      "[CV 2/5; 91/360] END colsample_bytree=0.2, max_depth=4, n_estimators=300;, score=0.952 total time=   0.3s\n",
      "[CV 3/5; 91/360] START colsample_bytree=0.2, max_depth=4, n_estimators=300......\n",
      "[CV 3/5; 91/360] END colsample_bytree=0.2, max_depth=4, n_estimators=300;, score=0.951 total time=   0.2s\n",
      "[CV 4/5; 91/360] START colsample_bytree=0.2, max_depth=4, n_estimators=300......\n",
      "[CV 4/5; 91/360] END colsample_bytree=0.2, max_depth=4, n_estimators=300;, score=0.954 total time=   0.3s\n",
      "[CV 5/5; 91/360] START colsample_bytree=0.2, max_depth=4, n_estimators=300......\n",
      "[CV 5/5; 91/360] END colsample_bytree=0.2, max_depth=4, n_estimators=300;, score=0.951 total time=   0.3s\n",
      "[CV 1/5; 92/360] START colsample_bytree=0.2, max_depth=4, n_estimators=350......\n",
      "[CV 1/5; 92/360] END colsample_bytree=0.2, max_depth=4, n_estimators=350;, score=0.949 total time=   0.3s\n",
      "[CV 2/5; 92/360] START colsample_bytree=0.2, max_depth=4, n_estimators=350......\n",
      "[CV 2/5; 92/360] END colsample_bytree=0.2, max_depth=4, n_estimators=350;, score=0.951 total time=   0.3s\n",
      "[CV 3/5; 92/360] START colsample_bytree=0.2, max_depth=4, n_estimators=350......\n",
      "[CV 3/5; 92/360] END colsample_bytree=0.2, max_depth=4, n_estimators=350;, score=0.950 total time=   0.3s\n",
      "[CV 4/5; 92/360] START colsample_bytree=0.2, max_depth=4, n_estimators=350......\n",
      "[CV 4/5; 92/360] END colsample_bytree=0.2, max_depth=4, n_estimators=350;, score=0.955 total time=   0.3s\n",
      "[CV 5/5; 92/360] START colsample_bytree=0.2, max_depth=4, n_estimators=350......\n",
      "[CV 5/5; 92/360] END colsample_bytree=0.2, max_depth=4, n_estimators=350;, score=0.951 total time=   0.4s\n",
      "[CV 1/5; 93/360] START colsample_bytree=0.2, max_depth=4, n_estimators=400......\n",
      "[CV 1/5; 93/360] END colsample_bytree=0.2, max_depth=4, n_estimators=400;, score=0.949 total time=   0.3s\n",
      "[CV 2/5; 93/360] START colsample_bytree=0.2, max_depth=4, n_estimators=400......\n",
      "[CV 2/5; 93/360] END colsample_bytree=0.2, max_depth=4, n_estimators=400;, score=0.951 total time=   0.4s\n",
      "[CV 3/5; 93/360] START colsample_bytree=0.2, max_depth=4, n_estimators=400......\n",
      "[CV 3/5; 93/360] END colsample_bytree=0.2, max_depth=4, n_estimators=400;, score=0.950 total time=   0.4s\n",
      "[CV 4/5; 93/360] START colsample_bytree=0.2, max_depth=4, n_estimators=400......\n",
      "[CV 4/5; 93/360] END colsample_bytree=0.2, max_depth=4, n_estimators=400;, score=0.954 total time=   0.4s\n",
      "[CV 5/5; 93/360] START colsample_bytree=0.2, max_depth=4, n_estimators=400......\n",
      "[CV 5/5; 93/360] END colsample_bytree=0.2, max_depth=4, n_estimators=400;, score=0.951 total time=   0.4s\n",
      "[CV 1/5; 94/360] START colsample_bytree=0.2, max_depth=4, n_estimators=450......\n",
      "[CV 1/5; 94/360] END colsample_bytree=0.2, max_depth=4, n_estimators=450;, score=0.949 total time=   0.5s\n",
      "[CV 2/5; 94/360] START colsample_bytree=0.2, max_depth=4, n_estimators=450......\n",
      "[CV 2/5; 94/360] END colsample_bytree=0.2, max_depth=4, n_estimators=450;, score=0.951 total time=   0.5s\n",
      "[CV 3/5; 94/360] START colsample_bytree=0.2, max_depth=4, n_estimators=450......\n",
      "[CV 3/5; 94/360] END colsample_bytree=0.2, max_depth=4, n_estimators=450;, score=0.950 total time=   0.5s\n",
      "[CV 4/5; 94/360] START colsample_bytree=0.2, max_depth=4, n_estimators=450......\n",
      "[CV 4/5; 94/360] END colsample_bytree=0.2, max_depth=4, n_estimators=450;, score=0.953 total time=   0.4s\n",
      "[CV 5/5; 94/360] START colsample_bytree=0.2, max_depth=4, n_estimators=450......\n",
      "[CV 5/5; 94/360] END colsample_bytree=0.2, max_depth=4, n_estimators=450;, score=0.951 total time=   0.4s\n",
      "[CV 1/5; 95/360] START colsample_bytree=0.2, max_depth=4, n_estimators=500......\n",
      "[CV 1/5; 95/360] END colsample_bytree=0.2, max_depth=4, n_estimators=500;, score=0.948 total time=   0.4s\n",
      "[CV 2/5; 95/360] START colsample_bytree=0.2, max_depth=4, n_estimators=500......\n",
      "[CV 2/5; 95/360] END colsample_bytree=0.2, max_depth=4, n_estimators=500;, score=0.951 total time=   0.4s\n",
      "[CV 3/5; 95/360] START colsample_bytree=0.2, max_depth=4, n_estimators=500......\n",
      "[CV 3/5; 95/360] END colsample_bytree=0.2, max_depth=4, n_estimators=500;, score=0.950 total time=   0.4s\n",
      "[CV 4/5; 95/360] START colsample_bytree=0.2, max_depth=4, n_estimators=500......\n",
      "[CV 4/5; 95/360] END colsample_bytree=0.2, max_depth=4, n_estimators=500;, score=0.953 total time=   0.4s\n",
      "[CV 5/5; 95/360] START colsample_bytree=0.2, max_depth=4, n_estimators=500......\n",
      "[CV 5/5; 95/360] END colsample_bytree=0.2, max_depth=4, n_estimators=500;, score=0.951 total time=   0.4s\n",
      "[CV 1/5; 96/360] START colsample_bytree=0.2, max_depth=4, n_estimators=550......\n",
      "[CV 1/5; 96/360] END colsample_bytree=0.2, max_depth=4, n_estimators=550;, score=0.948 total time=   0.4s\n",
      "[CV 2/5; 96/360] START colsample_bytree=0.2, max_depth=4, n_estimators=550......\n",
      "[CV 2/5; 96/360] END colsample_bytree=0.2, max_depth=4, n_estimators=550;, score=0.951 total time=   0.5s\n",
      "[CV 3/5; 96/360] START colsample_bytree=0.2, max_depth=4, n_estimators=550......\n",
      "[CV 3/5; 96/360] END colsample_bytree=0.2, max_depth=4, n_estimators=550;, score=0.950 total time=   0.5s\n",
      "[CV 4/5; 96/360] START colsample_bytree=0.2, max_depth=4, n_estimators=550......\n",
      "[CV 4/5; 96/360] END colsample_bytree=0.2, max_depth=4, n_estimators=550;, score=0.953 total time=   0.5s\n",
      "[CV 5/5; 96/360] START colsample_bytree=0.2, max_depth=4, n_estimators=550......\n",
      "[CV 5/5; 96/360] END colsample_bytree=0.2, max_depth=4, n_estimators=550;, score=0.951 total time=   0.6s\n",
      "[CV 1/5; 97/360] START colsample_bytree=0.2, max_depth=5, n_estimators=300......\n",
      "[CV 1/5; 97/360] END colsample_bytree=0.2, max_depth=5, n_estimators=300;, score=0.949 total time=   0.3s\n",
      "[CV 2/5; 97/360] START colsample_bytree=0.2, max_depth=5, n_estimators=300......\n",
      "[CV 2/5; 97/360] END colsample_bytree=0.2, max_depth=5, n_estimators=300;, score=0.950 total time=   0.3s\n",
      "[CV 3/5; 97/360] START colsample_bytree=0.2, max_depth=5, n_estimators=300......\n",
      "[CV 3/5; 97/360] END colsample_bytree=0.2, max_depth=5, n_estimators=300;, score=0.950 total time=   0.3s\n",
      "[CV 4/5; 97/360] START colsample_bytree=0.2, max_depth=5, n_estimators=300......\n",
      "[CV 4/5; 97/360] END colsample_bytree=0.2, max_depth=5, n_estimators=300;, score=0.954 total time=   0.3s\n",
      "[CV 5/5; 97/360] START colsample_bytree=0.2, max_depth=5, n_estimators=300......\n",
      "[CV 5/5; 97/360] END colsample_bytree=0.2, max_depth=5, n_estimators=300;, score=0.951 total time=   0.3s\n",
      "[CV 1/5; 98/360] START colsample_bytree=0.2, max_depth=5, n_estimators=350......\n",
      "[CV 1/5; 98/360] END colsample_bytree=0.2, max_depth=5, n_estimators=350;, score=0.949 total time=   0.3s\n",
      "[CV 2/5; 98/360] START colsample_bytree=0.2, max_depth=5, n_estimators=350......\n",
      "[CV 2/5; 98/360] END colsample_bytree=0.2, max_depth=5, n_estimators=350;, score=0.950 total time=   0.3s\n",
      "[CV 3/5; 98/360] START colsample_bytree=0.2, max_depth=5, n_estimators=350......\n",
      "[CV 3/5; 98/360] END colsample_bytree=0.2, max_depth=5, n_estimators=350;, score=0.949 total time=   0.4s\n",
      "[CV 4/5; 98/360] START colsample_bytree=0.2, max_depth=5, n_estimators=350......\n",
      "[CV 4/5; 98/360] END colsample_bytree=0.2, max_depth=5, n_estimators=350;, score=0.954 total time=   0.4s\n",
      "[CV 5/5; 98/360] START colsample_bytree=0.2, max_depth=5, n_estimators=350......\n",
      "[CV 5/5; 98/360] END colsample_bytree=0.2, max_depth=5, n_estimators=350;, score=0.951 total time=   0.4s\n",
      "[CV 1/5; 99/360] START colsample_bytree=0.2, max_depth=5, n_estimators=400......\n",
      "[CV 1/5; 99/360] END colsample_bytree=0.2, max_depth=5, n_estimators=400;, score=0.949 total time=   0.4s\n",
      "[CV 2/5; 99/360] START colsample_bytree=0.2, max_depth=5, n_estimators=400......\n",
      "[CV 2/5; 99/360] END colsample_bytree=0.2, max_depth=5, n_estimators=400;, score=0.950 total time=   0.4s\n",
      "[CV 3/5; 99/360] START colsample_bytree=0.2, max_depth=5, n_estimators=400......\n",
      "[CV 3/5; 99/360] END colsample_bytree=0.2, max_depth=5, n_estimators=400;, score=0.949 total time=   0.5s\n",
      "[CV 4/5; 99/360] START colsample_bytree=0.2, max_depth=5, n_estimators=400......\n",
      "[CV 4/5; 99/360] END colsample_bytree=0.2, max_depth=5, n_estimators=400;, score=0.954 total time=   0.4s\n",
      "[CV 5/5; 99/360] START colsample_bytree=0.2, max_depth=5, n_estimators=400......\n",
      "[CV 5/5; 99/360] END colsample_bytree=0.2, max_depth=5, n_estimators=400;, score=0.952 total time=   0.5s\n",
      "[CV 1/5; 100/360] START colsample_bytree=0.2, max_depth=5, n_estimators=450.....\n",
      "[CV 1/5; 100/360] END colsample_bytree=0.2, max_depth=5, n_estimators=450;, score=0.949 total time=   0.6s\n",
      "[CV 2/5; 100/360] START colsample_bytree=0.2, max_depth=5, n_estimators=450.....\n",
      "[CV 2/5; 100/360] END colsample_bytree=0.2, max_depth=5, n_estimators=450;, score=0.950 total time=   0.6s\n",
      "[CV 3/5; 100/360] START colsample_bytree=0.2, max_depth=5, n_estimators=450.....\n",
      "[CV 3/5; 100/360] END colsample_bytree=0.2, max_depth=5, n_estimators=450;, score=0.949 total time=   0.6s\n",
      "[CV 4/5; 100/360] START colsample_bytree=0.2, max_depth=5, n_estimators=450.....\n",
      "[CV 4/5; 100/360] END colsample_bytree=0.2, max_depth=5, n_estimators=450;, score=0.954 total time=   0.5s\n",
      "[CV 5/5; 100/360] START colsample_bytree=0.2, max_depth=5, n_estimators=450.....\n",
      "[CV 5/5; 100/360] END colsample_bytree=0.2, max_depth=5, n_estimators=450;, score=0.951 total time=   0.4s\n",
      "[CV 1/5; 101/360] START colsample_bytree=0.2, max_depth=5, n_estimators=500.....\n",
      "[CV 1/5; 101/360] END colsample_bytree=0.2, max_depth=5, n_estimators=500;, score=0.948 total time=   0.5s\n",
      "[CV 2/5; 101/360] START colsample_bytree=0.2, max_depth=5, n_estimators=500.....\n",
      "[CV 2/5; 101/360] END colsample_bytree=0.2, max_depth=5, n_estimators=500;, score=0.950 total time=   0.5s\n",
      "[CV 3/5; 101/360] START colsample_bytree=0.2, max_depth=5, n_estimators=500.....\n",
      "[CV 3/5; 101/360] END colsample_bytree=0.2, max_depth=5, n_estimators=500;, score=0.948 total time=   0.5s\n",
      "[CV 4/5; 101/360] START colsample_bytree=0.2, max_depth=5, n_estimators=500.....\n",
      "[CV 4/5; 101/360] END colsample_bytree=0.2, max_depth=5, n_estimators=500;, score=0.954 total time=   0.5s\n",
      "[CV 5/5; 101/360] START colsample_bytree=0.2, max_depth=5, n_estimators=500.....\n",
      "[CV 5/5; 101/360] END colsample_bytree=0.2, max_depth=5, n_estimators=500;, score=0.950 total time=   0.5s\n",
      "[CV 1/5; 102/360] START colsample_bytree=0.2, max_depth=5, n_estimators=550.....\n",
      "[CV 1/5; 102/360] END colsample_bytree=0.2, max_depth=5, n_estimators=550;, score=0.948 total time=   0.5s\n",
      "[CV 2/5; 102/360] START colsample_bytree=0.2, max_depth=5, n_estimators=550.....\n",
      "[CV 2/5; 102/360] END colsample_bytree=0.2, max_depth=5, n_estimators=550;, score=0.949 total time=   0.5s\n",
      "[CV 3/5; 102/360] START colsample_bytree=0.2, max_depth=5, n_estimators=550.....\n",
      "[CV 3/5; 102/360] END colsample_bytree=0.2, max_depth=5, n_estimators=550;, score=0.948 total time=   0.5s\n",
      "[CV 4/5; 102/360] START colsample_bytree=0.2, max_depth=5, n_estimators=550.....\n",
      "[CV 4/5; 102/360] END colsample_bytree=0.2, max_depth=5, n_estimators=550;, score=0.953 total time=   0.6s\n",
      "[CV 5/5; 102/360] START colsample_bytree=0.2, max_depth=5, n_estimators=550.....\n",
      "[CV 5/5; 102/360] END colsample_bytree=0.2, max_depth=5, n_estimators=550;, score=0.950 total time=   0.5s\n",
      "[CV 1/5; 103/360] START colsample_bytree=0.2, max_depth=6, n_estimators=300.....\n",
      "[CV 1/5; 103/360] END colsample_bytree=0.2, max_depth=6, n_estimators=300;, score=0.948 total time=   0.3s\n",
      "[CV 2/5; 103/360] START colsample_bytree=0.2, max_depth=6, n_estimators=300.....\n",
      "[CV 2/5; 103/360] END colsample_bytree=0.2, max_depth=6, n_estimators=300;, score=0.949 total time=   0.4s\n",
      "[CV 3/5; 103/360] START colsample_bytree=0.2, max_depth=6, n_estimators=300.....\n",
      "[CV 3/5; 103/360] END colsample_bytree=0.2, max_depth=6, n_estimators=300;, score=0.951 total time=   0.3s\n",
      "[CV 4/5; 103/360] START colsample_bytree=0.2, max_depth=6, n_estimators=300.....\n",
      "[CV 4/5; 103/360] END colsample_bytree=0.2, max_depth=6, n_estimators=300;, score=0.952 total time=   0.3s\n",
      "[CV 5/5; 103/360] START colsample_bytree=0.2, max_depth=6, n_estimators=300.....\n",
      "[CV 5/5; 103/360] END colsample_bytree=0.2, max_depth=6, n_estimators=300;, score=0.951 total time=   0.3s\n",
      "[CV 1/5; 104/360] START colsample_bytree=0.2, max_depth=6, n_estimators=350.....\n",
      "[CV 1/5; 104/360] END colsample_bytree=0.2, max_depth=6, n_estimators=350;, score=0.948 total time=   0.4s\n",
      "[CV 2/5; 104/360] START colsample_bytree=0.2, max_depth=6, n_estimators=350.....\n",
      "[CV 2/5; 104/360] END colsample_bytree=0.2, max_depth=6, n_estimators=350;, score=0.949 total time=   0.4s\n",
      "[CV 3/5; 104/360] START colsample_bytree=0.2, max_depth=6, n_estimators=350.....\n",
      "[CV 3/5; 104/360] END colsample_bytree=0.2, max_depth=6, n_estimators=350;, score=0.950 total time=   0.4s\n",
      "[CV 4/5; 104/360] START colsample_bytree=0.2, max_depth=6, n_estimators=350.....\n",
      "[CV 4/5; 104/360] END colsample_bytree=0.2, max_depth=6, n_estimators=350;, score=0.952 total time=   0.4s\n",
      "[CV 5/5; 104/360] START colsample_bytree=0.2, max_depth=6, n_estimators=350.....\n",
      "[CV 5/5; 104/360] END colsample_bytree=0.2, max_depth=6, n_estimators=350;, score=0.950 total time=   0.4s\n",
      "[CV 1/5; 105/360] START colsample_bytree=0.2, max_depth=6, n_estimators=400.....\n",
      "[CV 1/5; 105/360] END colsample_bytree=0.2, max_depth=6, n_estimators=400;, score=0.948 total time=   0.5s\n",
      "[CV 2/5; 105/360] START colsample_bytree=0.2, max_depth=6, n_estimators=400.....\n",
      "[CV 2/5; 105/360] END colsample_bytree=0.2, max_depth=6, n_estimators=400;, score=0.949 total time=   0.5s\n",
      "[CV 3/5; 105/360] START colsample_bytree=0.2, max_depth=6, n_estimators=400.....\n",
      "[CV 3/5; 105/360] END colsample_bytree=0.2, max_depth=6, n_estimators=400;, score=0.949 total time=   0.5s\n",
      "[CV 4/5; 105/360] START colsample_bytree=0.2, max_depth=6, n_estimators=400.....\n",
      "[CV 4/5; 105/360] END colsample_bytree=0.2, max_depth=6, n_estimators=400;, score=0.952 total time=   0.6s\n",
      "[CV 5/5; 105/360] START colsample_bytree=0.2, max_depth=6, n_estimators=400.....\n",
      "[CV 5/5; 105/360] END colsample_bytree=0.2, max_depth=6, n_estimators=400;, score=0.950 total time=   0.6s\n",
      "[CV 1/5; 106/360] START colsample_bytree=0.2, max_depth=6, n_estimators=450.....\n",
      "[CV 1/5; 106/360] END colsample_bytree=0.2, max_depth=6, n_estimators=450;, score=0.947 total time=   0.7s\n",
      "[CV 2/5; 106/360] START colsample_bytree=0.2, max_depth=6, n_estimators=450.....\n",
      "[CV 2/5; 106/360] END colsample_bytree=0.2, max_depth=6, n_estimators=450;, score=0.949 total time=   0.7s\n",
      "[CV 3/5; 106/360] START colsample_bytree=0.2, max_depth=6, n_estimators=450.....\n",
      "[CV 3/5; 106/360] END colsample_bytree=0.2, max_depth=6, n_estimators=450;, score=0.948 total time=   0.5s\n",
      "[CV 4/5; 106/360] START colsample_bytree=0.2, max_depth=6, n_estimators=450.....\n",
      "[CV 4/5; 106/360] END colsample_bytree=0.2, max_depth=6, n_estimators=450;, score=0.952 total time=   0.5s\n",
      "[CV 5/5; 106/360] START colsample_bytree=0.2, max_depth=6, n_estimators=450.....\n",
      "[CV 5/5; 106/360] END colsample_bytree=0.2, max_depth=6, n_estimators=450;, score=0.949 total time=   0.5s\n",
      "[CV 1/5; 107/360] START colsample_bytree=0.2, max_depth=6, n_estimators=500.....\n",
      "[CV 1/5; 107/360] END colsample_bytree=0.2, max_depth=6, n_estimators=500;, score=0.947 total time=   0.6s\n",
      "[CV 2/5; 107/360] START colsample_bytree=0.2, max_depth=6, n_estimators=500.....\n",
      "[CV 2/5; 107/360] END colsample_bytree=0.2, max_depth=6, n_estimators=500;, score=0.949 total time=   0.6s\n",
      "[CV 3/5; 107/360] START colsample_bytree=0.2, max_depth=6, n_estimators=500.....\n",
      "[CV 3/5; 107/360] END colsample_bytree=0.2, max_depth=6, n_estimators=500;, score=0.948 total time=   0.6s\n",
      "[CV 4/5; 107/360] START colsample_bytree=0.2, max_depth=6, n_estimators=500.....\n",
      "[CV 4/5; 107/360] END colsample_bytree=0.2, max_depth=6, n_estimators=500;, score=0.952 total time=   0.6s\n",
      "[CV 5/5; 107/360] START colsample_bytree=0.2, max_depth=6, n_estimators=500.....\n",
      "[CV 5/5; 107/360] END colsample_bytree=0.2, max_depth=6, n_estimators=500;, score=0.949 total time=   0.6s\n",
      "[CV 1/5; 108/360] START colsample_bytree=0.2, max_depth=6, n_estimators=550.....\n",
      "[CV 1/5; 108/360] END colsample_bytree=0.2, max_depth=6, n_estimators=550;, score=0.946 total time=   0.7s\n",
      "[CV 2/5; 108/360] START colsample_bytree=0.2, max_depth=6, n_estimators=550.....\n",
      "[CV 2/5; 108/360] END colsample_bytree=0.2, max_depth=6, n_estimators=550;, score=0.948 total time=   0.7s\n",
      "[CV 3/5; 108/360] START colsample_bytree=0.2, max_depth=6, n_estimators=550.....\n",
      "[CV 3/5; 108/360] END colsample_bytree=0.2, max_depth=6, n_estimators=550;, score=0.948 total time=   0.7s\n",
      "[CV 4/5; 108/360] START colsample_bytree=0.2, max_depth=6, n_estimators=550.....\n",
      "[CV 4/5; 108/360] END colsample_bytree=0.2, max_depth=6, n_estimators=550;, score=0.951 total time=   0.7s\n",
      "[CV 5/5; 108/360] START colsample_bytree=0.2, max_depth=6, n_estimators=550.....\n",
      "[CV 5/5; 108/360] END colsample_bytree=0.2, max_depth=6, n_estimators=550;, score=0.948 total time=   0.7s\n",
      "[CV 1/5; 109/360] START colsample_bytree=0.3, max_depth=1, n_estimators=300.....\n",
      "[CV 1/5; 109/360] END colsample_bytree=0.3, max_depth=1, n_estimators=300;, score=0.928 total time=   0.1s\n",
      "[CV 2/5; 109/360] START colsample_bytree=0.3, max_depth=1, n_estimators=300.....\n",
      "[CV 2/5; 109/360] END colsample_bytree=0.3, max_depth=1, n_estimators=300;, score=0.928 total time=   0.1s\n",
      "[CV 3/5; 109/360] START colsample_bytree=0.3, max_depth=1, n_estimators=300.....\n",
      "[CV 3/5; 109/360] END colsample_bytree=0.3, max_depth=1, n_estimators=300;, score=0.931 total time=   0.2s\n",
      "[CV 4/5; 109/360] START colsample_bytree=0.3, max_depth=1, n_estimators=300.....\n",
      "[CV 4/5; 109/360] END colsample_bytree=0.3, max_depth=1, n_estimators=300;, score=0.933 total time=   0.2s\n",
      "[CV 5/5; 109/360] START colsample_bytree=0.3, max_depth=1, n_estimators=300.....\n",
      "[CV 5/5; 109/360] END colsample_bytree=0.3, max_depth=1, n_estimators=300;, score=0.929 total time=   0.2s\n",
      "[CV 1/5; 110/360] START colsample_bytree=0.3, max_depth=1, n_estimators=350.....\n",
      "[CV 1/5; 110/360] END colsample_bytree=0.3, max_depth=1, n_estimators=350;, score=0.928 total time=   0.2s\n",
      "[CV 2/5; 110/360] START colsample_bytree=0.3, max_depth=1, n_estimators=350.....\n",
      "[CV 2/5; 110/360] END colsample_bytree=0.3, max_depth=1, n_estimators=350;, score=0.928 total time=   0.2s\n",
      "[CV 3/5; 110/360] START colsample_bytree=0.3, max_depth=1, n_estimators=350.....\n",
      "[CV 3/5; 110/360] END colsample_bytree=0.3, max_depth=1, n_estimators=350;, score=0.931 total time=   0.2s\n",
      "[CV 4/5; 110/360] START colsample_bytree=0.3, max_depth=1, n_estimators=350.....\n",
      "[CV 4/5; 110/360] END colsample_bytree=0.3, max_depth=1, n_estimators=350;, score=0.932 total time=   0.3s\n",
      "[CV 5/5; 110/360] START colsample_bytree=0.3, max_depth=1, n_estimators=350.....\n",
      "[CV 5/5; 110/360] END colsample_bytree=0.3, max_depth=1, n_estimators=350;, score=0.929 total time=   0.2s\n",
      "[CV 1/5; 111/360] START colsample_bytree=0.3, max_depth=1, n_estimators=400.....\n",
      "[CV 1/5; 111/360] END colsample_bytree=0.3, max_depth=1, n_estimators=400;, score=0.928 total time=   0.2s\n",
      "[CV 2/5; 111/360] START colsample_bytree=0.3, max_depth=1, n_estimators=400.....\n",
      "[CV 2/5; 111/360] END colsample_bytree=0.3, max_depth=1, n_estimators=400;, score=0.928 total time=   0.3s\n",
      "[CV 3/5; 111/360] START colsample_bytree=0.3, max_depth=1, n_estimators=400.....\n",
      "[CV 3/5; 111/360] END colsample_bytree=0.3, max_depth=1, n_estimators=400;, score=0.932 total time=   0.3s\n",
      "[CV 4/5; 111/360] START colsample_bytree=0.3, max_depth=1, n_estimators=400.....\n",
      "[CV 4/5; 111/360] END colsample_bytree=0.3, max_depth=1, n_estimators=400;, score=0.932 total time=   0.3s\n",
      "[CV 5/5; 111/360] START colsample_bytree=0.3, max_depth=1, n_estimators=400.....\n",
      "[CV 5/5; 111/360] END colsample_bytree=0.3, max_depth=1, n_estimators=400;, score=0.929 total time=   0.3s\n",
      "[CV 1/5; 112/360] START colsample_bytree=0.3, max_depth=1, n_estimators=450.....\n",
      "[CV 1/5; 112/360] END colsample_bytree=0.3, max_depth=1, n_estimators=450;, score=0.928 total time=   0.4s\n",
      "[CV 2/5; 112/360] START colsample_bytree=0.3, max_depth=1, n_estimators=450.....\n",
      "[CV 2/5; 112/360] END colsample_bytree=0.3, max_depth=1, n_estimators=450;, score=0.928 total time=   0.4s\n",
      "[CV 3/5; 112/360] START colsample_bytree=0.3, max_depth=1, n_estimators=450.....\n",
      "[CV 3/5; 112/360] END colsample_bytree=0.3, max_depth=1, n_estimators=450;, score=0.931 total time=   0.4s\n",
      "[CV 4/5; 112/360] START colsample_bytree=0.3, max_depth=1, n_estimators=450.....\n",
      "[CV 4/5; 112/360] END colsample_bytree=0.3, max_depth=1, n_estimators=450;, score=0.932 total time=   0.3s\n",
      "[CV 5/5; 112/360] START colsample_bytree=0.3, max_depth=1, n_estimators=450.....\n",
      "[CV 5/5; 112/360] END colsample_bytree=0.3, max_depth=1, n_estimators=450;, score=0.930 total time=   0.3s\n",
      "[CV 1/5; 113/360] START colsample_bytree=0.3, max_depth=1, n_estimators=500.....\n",
      "[CV 1/5; 113/360] END colsample_bytree=0.3, max_depth=1, n_estimators=500;, score=0.928 total time=   0.3s\n",
      "[CV 2/5; 113/360] START colsample_bytree=0.3, max_depth=1, n_estimators=500.....\n",
      "[CV 2/5; 113/360] END colsample_bytree=0.3, max_depth=1, n_estimators=500;, score=0.928 total time=   0.4s\n",
      "[CV 3/5; 113/360] START colsample_bytree=0.3, max_depth=1, n_estimators=500.....\n",
      "[CV 3/5; 113/360] END colsample_bytree=0.3, max_depth=1, n_estimators=500;, score=0.931 total time=   0.4s\n",
      "[CV 4/5; 113/360] START colsample_bytree=0.3, max_depth=1, n_estimators=500.....\n",
      "[CV 4/5; 113/360] END colsample_bytree=0.3, max_depth=1, n_estimators=500;, score=0.932 total time=   0.3s\n",
      "[CV 5/5; 113/360] START colsample_bytree=0.3, max_depth=1, n_estimators=500.....\n",
      "[CV 5/5; 113/360] END colsample_bytree=0.3, max_depth=1, n_estimators=500;, score=0.930 total time=   0.3s\n",
      "[CV 1/5; 114/360] START colsample_bytree=0.3, max_depth=1, n_estimators=550.....\n",
      "[CV 1/5; 114/360] END colsample_bytree=0.3, max_depth=1, n_estimators=550;, score=0.928 total time=   0.4s\n",
      "[CV 2/5; 114/360] START colsample_bytree=0.3, max_depth=1, n_estimators=550.....\n",
      "[CV 2/5; 114/360] END colsample_bytree=0.3, max_depth=1, n_estimators=550;, score=0.929 total time=   0.4s\n",
      "[CV 3/5; 114/360] START colsample_bytree=0.3, max_depth=1, n_estimators=550.....\n",
      "[CV 3/5; 114/360] END colsample_bytree=0.3, max_depth=1, n_estimators=550;, score=0.931 total time=   0.4s\n",
      "[CV 4/5; 114/360] START colsample_bytree=0.3, max_depth=1, n_estimators=550.....\n",
      "[CV 4/5; 114/360] END colsample_bytree=0.3, max_depth=1, n_estimators=550;, score=0.932 total time=   0.4s\n",
      "[CV 5/5; 114/360] START colsample_bytree=0.3, max_depth=1, n_estimators=550.....\n",
      "[CV 5/5; 114/360] END colsample_bytree=0.3, max_depth=1, n_estimators=550;, score=0.930 total time=   0.4s\n",
      "[CV 1/5; 115/360] START colsample_bytree=0.3, max_depth=2, n_estimators=300.....\n",
      "[CV 1/5; 115/360] END colsample_bytree=0.3, max_depth=2, n_estimators=300;, score=0.949 total time=   0.2s\n",
      "[CV 2/5; 115/360] START colsample_bytree=0.3, max_depth=2, n_estimators=300.....\n",
      "[CV 2/5; 115/360] END colsample_bytree=0.3, max_depth=2, n_estimators=300;, score=0.949 total time=   0.2s\n",
      "[CV 3/5; 115/360] START colsample_bytree=0.3, max_depth=2, n_estimators=300.....\n",
      "[CV 3/5; 115/360] END colsample_bytree=0.3, max_depth=2, n_estimators=300;, score=0.951 total time=   0.2s\n",
      "[CV 4/5; 115/360] START colsample_bytree=0.3, max_depth=2, n_estimators=300.....\n",
      "[CV 4/5; 115/360] END colsample_bytree=0.3, max_depth=2, n_estimators=300;, score=0.954 total time=   0.3s\n",
      "[CV 5/5; 115/360] START colsample_bytree=0.3, max_depth=2, n_estimators=300.....\n",
      "[CV 5/5; 115/360] END colsample_bytree=0.3, max_depth=2, n_estimators=300;, score=0.951 total time=   0.4s\n",
      "[CV 1/5; 116/360] START colsample_bytree=0.3, max_depth=2, n_estimators=350.....\n",
      "[CV 1/5; 116/360] END colsample_bytree=0.3, max_depth=2, n_estimators=350;, score=0.948 total time=   0.4s\n",
      "[CV 2/5; 116/360] START colsample_bytree=0.3, max_depth=2, n_estimators=350.....\n",
      "[CV 2/5; 116/360] END colsample_bytree=0.3, max_depth=2, n_estimators=350;, score=0.950 total time=   0.3s\n",
      "[CV 3/5; 116/360] START colsample_bytree=0.3, max_depth=2, n_estimators=350.....\n",
      "[CV 3/5; 116/360] END colsample_bytree=0.3, max_depth=2, n_estimators=350;, score=0.951 total time=   0.3s\n",
      "[CV 4/5; 116/360] START colsample_bytree=0.3, max_depth=2, n_estimators=350.....\n",
      "[CV 4/5; 116/360] END colsample_bytree=0.3, max_depth=2, n_estimators=350;, score=0.955 total time=   0.3s\n",
      "[CV 5/5; 116/360] START colsample_bytree=0.3, max_depth=2, n_estimators=350.....\n",
      "[CV 5/5; 116/360] END colsample_bytree=0.3, max_depth=2, n_estimators=350;, score=0.952 total time=   0.3s\n",
      "[CV 1/5; 117/360] START colsample_bytree=0.3, max_depth=2, n_estimators=400.....\n",
      "[CV 1/5; 117/360] END colsample_bytree=0.3, max_depth=2, n_estimators=400;, score=0.949 total time=   0.3s\n",
      "[CV 2/5; 117/360] START colsample_bytree=0.3, max_depth=2, n_estimators=400.....\n",
      "[CV 2/5; 117/360] END colsample_bytree=0.3, max_depth=2, n_estimators=400;, score=0.950 total time=   0.3s\n",
      "[CV 3/5; 117/360] START colsample_bytree=0.3, max_depth=2, n_estimators=400.....\n",
      "[CV 3/5; 117/360] END colsample_bytree=0.3, max_depth=2, n_estimators=400;, score=0.951 total time=   0.3s\n",
      "[CV 4/5; 117/360] START colsample_bytree=0.3, max_depth=2, n_estimators=400.....\n",
      "[CV 4/5; 117/360] END colsample_bytree=0.3, max_depth=2, n_estimators=400;, score=0.955 total time=   0.3s\n",
      "[CV 5/5; 117/360] START colsample_bytree=0.3, max_depth=2, n_estimators=400.....\n",
      "[CV 5/5; 117/360] END colsample_bytree=0.3, max_depth=2, n_estimators=400;, score=0.951 total time=   0.4s\n",
      "[CV 1/5; 118/360] START colsample_bytree=0.3, max_depth=2, n_estimators=450.....\n",
      "[CV 1/5; 118/360] END colsample_bytree=0.3, max_depth=2, n_estimators=450;, score=0.949 total time=   0.4s\n",
      "[CV 2/5; 118/360] START colsample_bytree=0.3, max_depth=2, n_estimators=450.....\n",
      "[CV 2/5; 118/360] END colsample_bytree=0.3, max_depth=2, n_estimators=450;, score=0.950 total time=   0.4s\n",
      "[CV 3/5; 118/360] START colsample_bytree=0.3, max_depth=2, n_estimators=450.....\n",
      "[CV 3/5; 118/360] END colsample_bytree=0.3, max_depth=2, n_estimators=450;, score=0.951 total time=   0.4s\n",
      "[CV 4/5; 118/360] START colsample_bytree=0.3, max_depth=2, n_estimators=450.....\n",
      "[CV 4/5; 118/360] END colsample_bytree=0.3, max_depth=2, n_estimators=450;, score=0.954 total time=   0.4s\n",
      "[CV 5/5; 118/360] START colsample_bytree=0.3, max_depth=2, n_estimators=450.....\n",
      "[CV 5/5; 118/360] END colsample_bytree=0.3, max_depth=2, n_estimators=450;, score=0.952 total time=   0.5s\n",
      "[CV 1/5; 119/360] START colsample_bytree=0.3, max_depth=2, n_estimators=500.....\n",
      "[CV 1/5; 119/360] END colsample_bytree=0.3, max_depth=2, n_estimators=500;, score=0.949 total time=   0.5s\n",
      "[CV 2/5; 119/360] START colsample_bytree=0.3, max_depth=2, n_estimators=500.....\n",
      "[CV 2/5; 119/360] END colsample_bytree=0.3, max_depth=2, n_estimators=500;, score=0.950 total time=   0.5s\n",
      "[CV 3/5; 119/360] START colsample_bytree=0.3, max_depth=2, n_estimators=500.....\n",
      "[CV 3/5; 119/360] END colsample_bytree=0.3, max_depth=2, n_estimators=500;, score=0.951 total time=   0.5s\n",
      "[CV 4/5; 119/360] START colsample_bytree=0.3, max_depth=2, n_estimators=500.....\n",
      "[CV 4/5; 119/360] END colsample_bytree=0.3, max_depth=2, n_estimators=500;, score=0.954 total time=   0.5s\n",
      "[CV 5/5; 119/360] START colsample_bytree=0.3, max_depth=2, n_estimators=500.....\n",
      "[CV 5/5; 119/360] END colsample_bytree=0.3, max_depth=2, n_estimators=500;, score=0.951 total time=   0.4s\n",
      "[CV 1/5; 120/360] START colsample_bytree=0.3, max_depth=2, n_estimators=550.....\n",
      "[CV 1/5; 120/360] END colsample_bytree=0.3, max_depth=2, n_estimators=550;, score=0.949 total time=   0.5s\n",
      "[CV 2/5; 120/360] START colsample_bytree=0.3, max_depth=2, n_estimators=550.....\n",
      "[CV 2/5; 120/360] END colsample_bytree=0.3, max_depth=2, n_estimators=550;, score=0.950 total time=   0.5s\n",
      "[CV 3/5; 120/360] START colsample_bytree=0.3, max_depth=2, n_estimators=550.....\n",
      "[CV 3/5; 120/360] END colsample_bytree=0.3, max_depth=2, n_estimators=550;, score=0.951 total time=   0.5s\n",
      "[CV 4/5; 120/360] START colsample_bytree=0.3, max_depth=2, n_estimators=550.....\n",
      "[CV 4/5; 120/360] END colsample_bytree=0.3, max_depth=2, n_estimators=550;, score=0.955 total time=   0.6s\n",
      "[CV 5/5; 120/360] START colsample_bytree=0.3, max_depth=2, n_estimators=550.....\n",
      "[CV 5/5; 120/360] END colsample_bytree=0.3, max_depth=2, n_estimators=550;, score=0.952 total time=   0.5s\n",
      "[CV 1/5; 121/360] START colsample_bytree=0.3, max_depth=3, n_estimators=300.....\n",
      "[CV 1/5; 121/360] END colsample_bytree=0.3, max_depth=3, n_estimators=300;, score=0.949 total time=   0.3s\n",
      "[CV 2/5; 121/360] START colsample_bytree=0.3, max_depth=3, n_estimators=300.....\n",
      "[CV 2/5; 121/360] END colsample_bytree=0.3, max_depth=3, n_estimators=300;, score=0.952 total time=   0.3s\n",
      "[CV 3/5; 121/360] START colsample_bytree=0.3, max_depth=3, n_estimators=300.....\n",
      "[CV 3/5; 121/360] END colsample_bytree=0.3, max_depth=3, n_estimators=300;, score=0.951 total time=   0.3s\n",
      "[CV 4/5; 121/360] START colsample_bytree=0.3, max_depth=3, n_estimators=300.....\n",
      "[CV 4/5; 121/360] END colsample_bytree=0.3, max_depth=3, n_estimators=300;, score=0.954 total time=   0.3s\n",
      "[CV 5/5; 121/360] START colsample_bytree=0.3, max_depth=3, n_estimators=300.....\n",
      "[CV 5/5; 121/360] END colsample_bytree=0.3, max_depth=3, n_estimators=300;, score=0.952 total time=   0.3s\n",
      "[CV 1/5; 122/360] START colsample_bytree=0.3, max_depth=3, n_estimators=350.....\n",
      "[CV 1/5; 122/360] END colsample_bytree=0.3, max_depth=3, n_estimators=350;, score=0.949 total time=   0.4s\n",
      "[CV 2/5; 122/360] START colsample_bytree=0.3, max_depth=3, n_estimators=350.....\n",
      "[CV 2/5; 122/360] END colsample_bytree=0.3, max_depth=3, n_estimators=350;, score=0.952 total time=   0.4s\n",
      "[CV 3/5; 122/360] START colsample_bytree=0.3, max_depth=3, n_estimators=350.....\n",
      "[CV 3/5; 122/360] END colsample_bytree=0.3, max_depth=3, n_estimators=350;, score=0.951 total time=   0.4s\n",
      "[CV 4/5; 122/360] START colsample_bytree=0.3, max_depth=3, n_estimators=350.....\n",
      "[CV 4/5; 122/360] END colsample_bytree=0.3, max_depth=3, n_estimators=350;, score=0.955 total time=   0.4s\n",
      "[CV 5/5; 122/360] START colsample_bytree=0.3, max_depth=3, n_estimators=350.....\n",
      "[CV 5/5; 122/360] END colsample_bytree=0.3, max_depth=3, n_estimators=350;, score=0.952 total time=   0.4s\n",
      "[CV 1/5; 123/360] START colsample_bytree=0.3, max_depth=3, n_estimators=400.....\n",
      "[CV 1/5; 123/360] END colsample_bytree=0.3, max_depth=3, n_estimators=400;, score=0.949 total time=   0.5s\n",
      "[CV 2/5; 123/360] START colsample_bytree=0.3, max_depth=3, n_estimators=400.....\n",
      "[CV 2/5; 123/360] END colsample_bytree=0.3, max_depth=3, n_estimators=400;, score=0.952 total time=   0.4s\n",
      "[CV 3/5; 123/360] START colsample_bytree=0.3, max_depth=3, n_estimators=400.....\n",
      "[CV 3/5; 123/360] END colsample_bytree=0.3, max_depth=3, n_estimators=400;, score=0.951 total time=   0.4s\n",
      "[CV 4/5; 123/360] START colsample_bytree=0.3, max_depth=3, n_estimators=400.....\n",
      "[CV 4/5; 123/360] END colsample_bytree=0.3, max_depth=3, n_estimators=400;, score=0.954 total time=   0.5s\n",
      "[CV 5/5; 123/360] START colsample_bytree=0.3, max_depth=3, n_estimators=400.....\n",
      "[CV 5/5; 123/360] END colsample_bytree=0.3, max_depth=3, n_estimators=400;, score=0.952 total time=   0.5s\n",
      "[CV 1/5; 124/360] START colsample_bytree=0.3, max_depth=3, n_estimators=450.....\n",
      "[CV 1/5; 124/360] END colsample_bytree=0.3, max_depth=3, n_estimators=450;, score=0.949 total time=   0.5s\n",
      "[CV 2/5; 124/360] START colsample_bytree=0.3, max_depth=3, n_estimators=450.....\n",
      "[CV 2/5; 124/360] END colsample_bytree=0.3, max_depth=3, n_estimators=450;, score=0.952 total time=   0.5s\n",
      "[CV 3/5; 124/360] START colsample_bytree=0.3, max_depth=3, n_estimators=450.....\n",
      "[CV 3/5; 124/360] END colsample_bytree=0.3, max_depth=3, n_estimators=450;, score=0.951 total time=   0.5s\n",
      "[CV 4/5; 124/360] START colsample_bytree=0.3, max_depth=3, n_estimators=450.....\n",
      "[CV 4/5; 124/360] END colsample_bytree=0.3, max_depth=3, n_estimators=450;, score=0.954 total time=   0.6s\n",
      "[CV 5/5; 124/360] START colsample_bytree=0.3, max_depth=3, n_estimators=450.....\n",
      "[CV 5/5; 124/360] END colsample_bytree=0.3, max_depth=3, n_estimators=450;, score=0.952 total time=   0.6s\n",
      "[CV 1/5; 125/360] START colsample_bytree=0.3, max_depth=3, n_estimators=500.....\n",
      "[CV 1/5; 125/360] END colsample_bytree=0.3, max_depth=3, n_estimators=500;, score=0.949 total time=   0.7s\n",
      "[CV 2/5; 125/360] START colsample_bytree=0.3, max_depth=3, n_estimators=500.....\n",
      "[CV 2/5; 125/360] END colsample_bytree=0.3, max_depth=3, n_estimators=500;, score=0.952 total time=   0.7s\n",
      "[CV 3/5; 125/360] START colsample_bytree=0.3, max_depth=3, n_estimators=500.....\n",
      "[CV 3/5; 125/360] END colsample_bytree=0.3, max_depth=3, n_estimators=500;, score=0.951 total time=   0.7s\n",
      "[CV 4/5; 125/360] START colsample_bytree=0.3, max_depth=3, n_estimators=500.....\n",
      "[CV 4/5; 125/360] END colsample_bytree=0.3, max_depth=3, n_estimators=500;, score=0.954 total time=   0.6s\n",
      "[CV 5/5; 125/360] START colsample_bytree=0.3, max_depth=3, n_estimators=500.....\n",
      "[CV 5/5; 125/360] END colsample_bytree=0.3, max_depth=3, n_estimators=500;, score=0.952 total time=   0.6s\n",
      "[CV 1/5; 126/360] START colsample_bytree=0.3, max_depth=3, n_estimators=550.....\n",
      "[CV 1/5; 126/360] END colsample_bytree=0.3, max_depth=3, n_estimators=550;, score=0.949 total time=   0.8s\n",
      "[CV 2/5; 126/360] START colsample_bytree=0.3, max_depth=3, n_estimators=550.....\n",
      "[CV 2/5; 126/360] END colsample_bytree=0.3, max_depth=3, n_estimators=550;, score=0.951 total time=   0.8s\n",
      "[CV 3/5; 126/360] START colsample_bytree=0.3, max_depth=3, n_estimators=550.....\n",
      "[CV 3/5; 126/360] END colsample_bytree=0.3, max_depth=3, n_estimators=550;, score=0.951 total time=   0.8s\n",
      "[CV 4/5; 126/360] START colsample_bytree=0.3, max_depth=3, n_estimators=550.....\n",
      "[CV 4/5; 126/360] END colsample_bytree=0.3, max_depth=3, n_estimators=550;, score=0.954 total time=   0.8s\n",
      "[CV 5/5; 126/360] START colsample_bytree=0.3, max_depth=3, n_estimators=550.....\n",
      "[CV 5/5; 126/360] END colsample_bytree=0.3, max_depth=3, n_estimators=550;, score=0.951 total time=   0.8s\n",
      "[CV 1/5; 127/360] START colsample_bytree=0.3, max_depth=4, n_estimators=300.....\n",
      "[CV 1/5; 127/360] END colsample_bytree=0.3, max_depth=4, n_estimators=300;, score=0.948 total time=   0.5s\n",
      "[CV 2/5; 127/360] START colsample_bytree=0.3, max_depth=4, n_estimators=300.....\n",
      "[CV 2/5; 127/360] END colsample_bytree=0.3, max_depth=4, n_estimators=300;, score=0.952 total time=   0.5s\n",
      "[CV 3/5; 127/360] START colsample_bytree=0.3, max_depth=4, n_estimators=300.....\n",
      "[CV 3/5; 127/360] END colsample_bytree=0.3, max_depth=4, n_estimators=300;, score=0.951 total time=   0.4s\n",
      "[CV 4/5; 127/360] START colsample_bytree=0.3, max_depth=4, n_estimators=300.....\n",
      "[CV 4/5; 127/360] END colsample_bytree=0.3, max_depth=4, n_estimators=300;, score=0.955 total time=   0.4s\n",
      "[CV 5/5; 127/360] START colsample_bytree=0.3, max_depth=4, n_estimators=300.....\n",
      "[CV 5/5; 127/360] END colsample_bytree=0.3, max_depth=4, n_estimators=300;, score=0.952 total time=   0.4s\n",
      "[CV 1/5; 128/360] START colsample_bytree=0.3, max_depth=4, n_estimators=350.....\n",
      "[CV 1/5; 128/360] END colsample_bytree=0.3, max_depth=4, n_estimators=350;, score=0.948 total time=   0.5s\n",
      "[CV 2/5; 128/360] START colsample_bytree=0.3, max_depth=4, n_estimators=350.....\n",
      "[CV 2/5; 128/360] END colsample_bytree=0.3, max_depth=4, n_estimators=350;, score=0.952 total time=   0.5s\n",
      "[CV 3/5; 128/360] START colsample_bytree=0.3, max_depth=4, n_estimators=350.....\n",
      "[CV 3/5; 128/360] END colsample_bytree=0.3, max_depth=4, n_estimators=350;, score=0.951 total time=   0.5s\n",
      "[CV 4/5; 128/360] START colsample_bytree=0.3, max_depth=4, n_estimators=350.....\n",
      "[CV 4/5; 128/360] END colsample_bytree=0.3, max_depth=4, n_estimators=350;, score=0.955 total time=   0.5s\n",
      "[CV 5/5; 128/360] START colsample_bytree=0.3, max_depth=4, n_estimators=350.....\n",
      "[CV 5/5; 128/360] END colsample_bytree=0.3, max_depth=4, n_estimators=350;, score=0.952 total time=   0.5s\n",
      "[CV 1/5; 129/360] START colsample_bytree=0.3, max_depth=4, n_estimators=400.....\n",
      "[CV 1/5; 129/360] END colsample_bytree=0.3, max_depth=4, n_estimators=400;, score=0.949 total time=   0.6s\n",
      "[CV 2/5; 129/360] START colsample_bytree=0.3, max_depth=4, n_estimators=400.....\n",
      "[CV 2/5; 129/360] END colsample_bytree=0.3, max_depth=4, n_estimators=400;, score=0.951 total time=   0.6s\n",
      "[CV 3/5; 129/360] START colsample_bytree=0.3, max_depth=4, n_estimators=400.....\n",
      "[CV 3/5; 129/360] END colsample_bytree=0.3, max_depth=4, n_estimators=400;, score=0.951 total time=   0.6s\n",
      "[CV 4/5; 129/360] START colsample_bytree=0.3, max_depth=4, n_estimators=400.....\n",
      "[CV 4/5; 129/360] END colsample_bytree=0.3, max_depth=4, n_estimators=400;, score=0.954 total time=   0.7s\n",
      "[CV 5/5; 129/360] START colsample_bytree=0.3, max_depth=4, n_estimators=400.....\n",
      "[CV 5/5; 129/360] END colsample_bytree=0.3, max_depth=4, n_estimators=400;, score=0.951 total time=   0.7s\n",
      "[CV 1/5; 130/360] START colsample_bytree=0.3, max_depth=4, n_estimators=450.....\n",
      "[CV 1/5; 130/360] END colsample_bytree=0.3, max_depth=4, n_estimators=450;, score=0.949 total time=   0.7s\n",
      "[CV 2/5; 130/360] START colsample_bytree=0.3, max_depth=4, n_estimators=450.....\n",
      "[CV 2/5; 130/360] END colsample_bytree=0.3, max_depth=4, n_estimators=450;, score=0.951 total time=   0.6s\n",
      "[CV 3/5; 130/360] START colsample_bytree=0.3, max_depth=4, n_estimators=450.....\n",
      "[CV 3/5; 130/360] END colsample_bytree=0.3, max_depth=4, n_estimators=450;, score=0.950 total time=   0.7s\n",
      "[CV 4/5; 130/360] START colsample_bytree=0.3, max_depth=4, n_estimators=450.....\n",
      "[CV 4/5; 130/360] END colsample_bytree=0.3, max_depth=4, n_estimators=450;, score=0.954 total time=   0.7s\n",
      "[CV 5/5; 130/360] START colsample_bytree=0.3, max_depth=4, n_estimators=450.....\n",
      "[CV 5/5; 130/360] END colsample_bytree=0.3, max_depth=4, n_estimators=450;, score=0.952 total time=   0.6s\n",
      "[CV 1/5; 131/360] START colsample_bytree=0.3, max_depth=4, n_estimators=500.....\n",
      "[CV 1/5; 131/360] END colsample_bytree=0.3, max_depth=4, n_estimators=500;, score=0.949 total time=   0.7s\n",
      "[CV 2/5; 131/360] START colsample_bytree=0.3, max_depth=4, n_estimators=500.....\n",
      "[CV 2/5; 131/360] END colsample_bytree=0.3, max_depth=4, n_estimators=500;, score=0.951 total time=   0.7s\n",
      "[CV 3/5; 131/360] START colsample_bytree=0.3, max_depth=4, n_estimators=500.....\n",
      "[CV 3/5; 131/360] END colsample_bytree=0.3, max_depth=4, n_estimators=500;, score=0.950 total time=   0.7s\n",
      "[CV 4/5; 131/360] START colsample_bytree=0.3, max_depth=4, n_estimators=500.....\n",
      "[CV 4/5; 131/360] END colsample_bytree=0.3, max_depth=4, n_estimators=500;, score=0.953 total time=   0.8s\n",
      "[CV 5/5; 131/360] START colsample_bytree=0.3, max_depth=4, n_estimators=500.....\n",
      "[CV 5/5; 131/360] END colsample_bytree=0.3, max_depth=4, n_estimators=500;, score=0.951 total time=   0.7s\n",
      "[CV 1/5; 132/360] START colsample_bytree=0.3, max_depth=4, n_estimators=550.....\n",
      "[CV 1/5; 132/360] END colsample_bytree=0.3, max_depth=4, n_estimators=550;, score=0.949 total time=   0.8s\n",
      "[CV 2/5; 132/360] START colsample_bytree=0.3, max_depth=4, n_estimators=550.....\n",
      "[CV 2/5; 132/360] END colsample_bytree=0.3, max_depth=4, n_estimators=550;, score=0.951 total time=   0.8s\n",
      "[CV 3/5; 132/360] START colsample_bytree=0.3, max_depth=4, n_estimators=550.....\n",
      "[CV 3/5; 132/360] END colsample_bytree=0.3, max_depth=4, n_estimators=550;, score=0.950 total time=   0.9s\n",
      "[CV 4/5; 132/360] START colsample_bytree=0.3, max_depth=4, n_estimators=550.....\n",
      "[CV 4/5; 132/360] END colsample_bytree=0.3, max_depth=4, n_estimators=550;, score=0.954 total time=   0.8s\n",
      "[CV 5/5; 132/360] START colsample_bytree=0.3, max_depth=4, n_estimators=550.....\n",
      "[CV 5/5; 132/360] END colsample_bytree=0.3, max_depth=4, n_estimators=550;, score=0.951 total time=   0.9s\n",
      "[CV 1/5; 133/360] START colsample_bytree=0.3, max_depth=5, n_estimators=300.....\n",
      "[CV 1/5; 133/360] END colsample_bytree=0.3, max_depth=5, n_estimators=300;, score=0.948 total time=   0.6s\n",
      "[CV 2/5; 133/360] START colsample_bytree=0.3, max_depth=5, n_estimators=300.....\n",
      "[CV 2/5; 133/360] END colsample_bytree=0.3, max_depth=5, n_estimators=300;, score=0.950 total time=   0.6s\n",
      "[CV 3/5; 133/360] START colsample_bytree=0.3, max_depth=5, n_estimators=300.....\n",
      "[CV 3/5; 133/360] END colsample_bytree=0.3, max_depth=5, n_estimators=300;, score=0.950 total time=   0.8s\n",
      "[CV 4/5; 133/360] START colsample_bytree=0.3, max_depth=5, n_estimators=300.....\n",
      "[CV 4/5; 133/360] END colsample_bytree=0.3, max_depth=5, n_estimators=300;, score=0.953 total time=   0.6s\n",
      "[CV 5/5; 133/360] START colsample_bytree=0.3, max_depth=5, n_estimators=300.....\n",
      "[CV 5/5; 133/360] END colsample_bytree=0.3, max_depth=5, n_estimators=300;, score=0.952 total time=   0.6s\n",
      "[CV 1/5; 134/360] START colsample_bytree=0.3, max_depth=5, n_estimators=350.....\n",
      "[CV 1/5; 134/360] END colsample_bytree=0.3, max_depth=5, n_estimators=350;, score=0.948 total time=   0.6s\n",
      "[CV 2/5; 134/360] START colsample_bytree=0.3, max_depth=5, n_estimators=350.....\n",
      "[CV 2/5; 134/360] END colsample_bytree=0.3, max_depth=5, n_estimators=350;, score=0.949 total time=   0.6s\n",
      "[CV 3/5; 134/360] START colsample_bytree=0.3, max_depth=5, n_estimators=350.....\n",
      "[CV 3/5; 134/360] END colsample_bytree=0.3, max_depth=5, n_estimators=350;, score=0.950 total time=   0.6s\n",
      "[CV 4/5; 134/360] START colsample_bytree=0.3, max_depth=5, n_estimators=350.....\n",
      "[CV 4/5; 134/360] END colsample_bytree=0.3, max_depth=5, n_estimators=350;, score=0.952 total time=   0.5s\n",
      "[CV 5/5; 134/360] START colsample_bytree=0.3, max_depth=5, n_estimators=350.....\n",
      "[CV 5/5; 134/360] END colsample_bytree=0.3, max_depth=5, n_estimators=350;, score=0.952 total time=   0.4s\n",
      "[CV 1/5; 135/360] START colsample_bytree=0.3, max_depth=5, n_estimators=400.....\n",
      "[CV 1/5; 135/360] END colsample_bytree=0.3, max_depth=5, n_estimators=400;, score=0.948 total time=   0.5s\n",
      "[CV 2/5; 135/360] START colsample_bytree=0.3, max_depth=5, n_estimators=400.....\n",
      "[CV 2/5; 135/360] END colsample_bytree=0.3, max_depth=5, n_estimators=400;, score=0.949 total time=   0.4s\n",
      "[CV 3/5; 135/360] START colsample_bytree=0.3, max_depth=5, n_estimators=400.....\n",
      "[CV 3/5; 135/360] END colsample_bytree=0.3, max_depth=5, n_estimators=400;, score=0.950 total time=   0.4s\n",
      "[CV 4/5; 135/360] START colsample_bytree=0.3, max_depth=5, n_estimators=400.....\n",
      "[CV 4/5; 135/360] END colsample_bytree=0.3, max_depth=5, n_estimators=400;, score=0.952 total time=   0.4s\n",
      "[CV 5/5; 135/360] START colsample_bytree=0.3, max_depth=5, n_estimators=400.....\n",
      "[CV 5/5; 135/360] END colsample_bytree=0.3, max_depth=5, n_estimators=400;, score=0.951 total time=   0.4s\n",
      "[CV 1/5; 136/360] START colsample_bytree=0.3, max_depth=5, n_estimators=450.....\n",
      "[CV 1/5; 136/360] END colsample_bytree=0.3, max_depth=5, n_estimators=450;, score=0.947 total time=   0.5s\n",
      "[CV 2/5; 136/360] START colsample_bytree=0.3, max_depth=5, n_estimators=450.....\n",
      "[CV 2/5; 136/360] END colsample_bytree=0.3, max_depth=5, n_estimators=450;, score=0.949 total time=   0.5s\n",
      "[CV 3/5; 136/360] START colsample_bytree=0.3, max_depth=5, n_estimators=450.....\n",
      "[CV 3/5; 136/360] END colsample_bytree=0.3, max_depth=5, n_estimators=450;, score=0.948 total time=   0.5s\n",
      "[CV 4/5; 136/360] START colsample_bytree=0.3, max_depth=5, n_estimators=450.....\n",
      "[CV 4/5; 136/360] END colsample_bytree=0.3, max_depth=5, n_estimators=450;, score=0.952 total time=   0.5s\n",
      "[CV 5/5; 136/360] START colsample_bytree=0.3, max_depth=5, n_estimators=450.....\n",
      "[CV 5/5; 136/360] END colsample_bytree=0.3, max_depth=5, n_estimators=450;, score=0.951 total time=   0.5s\n",
      "[CV 1/5; 137/360] START colsample_bytree=0.3, max_depth=5, n_estimators=500.....\n",
      "[CV 1/5; 137/360] END colsample_bytree=0.3, max_depth=5, n_estimators=500;, score=0.947 total time=   0.6s\n",
      "[CV 2/5; 137/360] START colsample_bytree=0.3, max_depth=5, n_estimators=500.....\n",
      "[CV 2/5; 137/360] END colsample_bytree=0.3, max_depth=5, n_estimators=500;, score=0.949 total time=   0.6s\n",
      "[CV 3/5; 137/360] START colsample_bytree=0.3, max_depth=5, n_estimators=500.....\n",
      "[CV 3/5; 137/360] END colsample_bytree=0.3, max_depth=5, n_estimators=500;, score=0.949 total time=   0.6s\n",
      "[CV 4/5; 137/360] START colsample_bytree=0.3, max_depth=5, n_estimators=500.....\n",
      "[CV 4/5; 137/360] END colsample_bytree=0.3, max_depth=5, n_estimators=500;, score=0.951 total time=   0.6s\n",
      "[CV 5/5; 137/360] START colsample_bytree=0.3, max_depth=5, n_estimators=500.....\n",
      "[CV 5/5; 137/360] END colsample_bytree=0.3, max_depth=5, n_estimators=500;, score=0.952 total time=   0.6s\n",
      "[CV 1/5; 138/360] START colsample_bytree=0.3, max_depth=5, n_estimators=550.....\n",
      "[CV 1/5; 138/360] END colsample_bytree=0.3, max_depth=5, n_estimators=550;, score=0.946 total time=   0.8s\n",
      "[CV 2/5; 138/360] START colsample_bytree=0.3, max_depth=5, n_estimators=550.....\n",
      "[CV 2/5; 138/360] END colsample_bytree=0.3, max_depth=5, n_estimators=550;, score=0.949 total time=   0.7s\n",
      "[CV 3/5; 138/360] START colsample_bytree=0.3, max_depth=5, n_estimators=550.....\n",
      "[CV 3/5; 138/360] END colsample_bytree=0.3, max_depth=5, n_estimators=550;, score=0.949 total time=   0.7s\n",
      "[CV 4/5; 138/360] START colsample_bytree=0.3, max_depth=5, n_estimators=550.....\n",
      "[CV 4/5; 138/360] END colsample_bytree=0.3, max_depth=5, n_estimators=550;, score=0.952 total time=   0.6s\n",
      "[CV 5/5; 138/360] START colsample_bytree=0.3, max_depth=5, n_estimators=550.....\n",
      "[CV 5/5; 138/360] END colsample_bytree=0.3, max_depth=5, n_estimators=550;, score=0.951 total time=   0.6s\n",
      "[CV 1/5; 139/360] START colsample_bytree=0.3, max_depth=6, n_estimators=300.....\n",
      "[CV 1/5; 139/360] END colsample_bytree=0.3, max_depth=6, n_estimators=300;, score=0.948 total time=   0.4s\n",
      "[CV 2/5; 139/360] START colsample_bytree=0.3, max_depth=6, n_estimators=300.....\n",
      "[CV 2/5; 139/360] END colsample_bytree=0.3, max_depth=6, n_estimators=300;, score=0.950 total time=   0.4s\n",
      "[CV 3/5; 139/360] START colsample_bytree=0.3, max_depth=6, n_estimators=300.....\n",
      "[CV 3/5; 139/360] END colsample_bytree=0.3, max_depth=6, n_estimators=300;, score=0.950 total time=   0.4s\n",
      "[CV 4/5; 139/360] START colsample_bytree=0.3, max_depth=6, n_estimators=300.....\n",
      "[CV 4/5; 139/360] END colsample_bytree=0.3, max_depth=6, n_estimators=300;, score=0.952 total time=   0.4s\n",
      "[CV 5/5; 139/360] START colsample_bytree=0.3, max_depth=6, n_estimators=300.....\n",
      "[CV 5/5; 139/360] END colsample_bytree=0.3, max_depth=6, n_estimators=300;, score=0.952 total time=   0.4s\n",
      "[CV 1/5; 140/360] START colsample_bytree=0.3, max_depth=6, n_estimators=350.....\n",
      "[CV 1/5; 140/360] END colsample_bytree=0.3, max_depth=6, n_estimators=350;, score=0.948 total time=   0.5s\n",
      "[CV 2/5; 140/360] START colsample_bytree=0.3, max_depth=6, n_estimators=350.....\n",
      "[CV 2/5; 140/360] END colsample_bytree=0.3, max_depth=6, n_estimators=350;, score=0.949 total time=   0.5s\n",
      "[CV 3/5; 140/360] START colsample_bytree=0.3, max_depth=6, n_estimators=350.....\n",
      "[CV 3/5; 140/360] END colsample_bytree=0.3, max_depth=6, n_estimators=350;, score=0.949 total time=   0.5s\n",
      "[CV 4/5; 140/360] START colsample_bytree=0.3, max_depth=6, n_estimators=350.....\n",
      "[CV 4/5; 140/360] END colsample_bytree=0.3, max_depth=6, n_estimators=350;, score=0.953 total time=   0.5s\n",
      "[CV 5/5; 140/360] START colsample_bytree=0.3, max_depth=6, n_estimators=350.....\n",
      "[CV 5/5; 140/360] END colsample_bytree=0.3, max_depth=6, n_estimators=350;, score=0.951 total time=   0.4s\n",
      "[CV 1/5; 141/360] START colsample_bytree=0.3, max_depth=6, n_estimators=400.....\n",
      "[CV 1/5; 141/360] END colsample_bytree=0.3, max_depth=6, n_estimators=400;, score=0.947 total time=   0.5s\n",
      "[CV 2/5; 141/360] START colsample_bytree=0.3, max_depth=6, n_estimators=400.....\n",
      "[CV 2/5; 141/360] END colsample_bytree=0.3, max_depth=6, n_estimators=400;, score=0.949 total time=   0.5s\n",
      "[CV 3/5; 141/360] START colsample_bytree=0.3, max_depth=6, n_estimators=400.....\n",
      "[CV 3/5; 141/360] END colsample_bytree=0.3, max_depth=6, n_estimators=400;, score=0.949 total time=   0.5s\n",
      "[CV 4/5; 141/360] START colsample_bytree=0.3, max_depth=6, n_estimators=400.....\n",
      "[CV 4/5; 141/360] END colsample_bytree=0.3, max_depth=6, n_estimators=400;, score=0.953 total time=   0.4s\n",
      "[CV 5/5; 141/360] START colsample_bytree=0.3, max_depth=6, n_estimators=400.....\n",
      "[CV 5/5; 141/360] END colsample_bytree=0.3, max_depth=6, n_estimators=400;, score=0.951 total time=   0.4s\n",
      "[CV 1/5; 142/360] START colsample_bytree=0.3, max_depth=6, n_estimators=450.....\n",
      "[CV 1/5; 142/360] END colsample_bytree=0.3, max_depth=6, n_estimators=450;, score=0.947 total time=   0.5s\n",
      "[CV 2/5; 142/360] START colsample_bytree=0.3, max_depth=6, n_estimators=450.....\n",
      "[CV 2/5; 142/360] END colsample_bytree=0.3, max_depth=6, n_estimators=450;, score=0.948 total time=   0.5s\n",
      "[CV 3/5; 142/360] START colsample_bytree=0.3, max_depth=6, n_estimators=450.....\n",
      "[CV 3/5; 142/360] END colsample_bytree=0.3, max_depth=6, n_estimators=450;, score=0.950 total time=   0.5s\n",
      "[CV 4/5; 142/360] START colsample_bytree=0.3, max_depth=6, n_estimators=450.....\n",
      "[CV 4/5; 142/360] END colsample_bytree=0.3, max_depth=6, n_estimators=450;, score=0.952 total time=   0.5s\n",
      "[CV 5/5; 142/360] START colsample_bytree=0.3, max_depth=6, n_estimators=450.....\n",
      "[CV 5/5; 142/360] END colsample_bytree=0.3, max_depth=6, n_estimators=450;, score=0.950 total time=   0.5s\n",
      "[CV 1/5; 143/360] START colsample_bytree=0.3, max_depth=6, n_estimators=500.....\n",
      "[CV 1/5; 143/360] END colsample_bytree=0.3, max_depth=6, n_estimators=500;, score=0.948 total time=   0.5s\n",
      "[CV 2/5; 143/360] START colsample_bytree=0.3, max_depth=6, n_estimators=500.....\n",
      "[CV 2/5; 143/360] END colsample_bytree=0.3, max_depth=6, n_estimators=500;, score=0.947 total time=   0.6s\n",
      "[CV 3/5; 143/360] START colsample_bytree=0.3, max_depth=6, n_estimators=500.....\n",
      "[CV 3/5; 143/360] END colsample_bytree=0.3, max_depth=6, n_estimators=500;, score=0.949 total time=   0.7s\n",
      "[CV 4/5; 143/360] START colsample_bytree=0.3, max_depth=6, n_estimators=500.....\n",
      "[CV 4/5; 143/360] END colsample_bytree=0.3, max_depth=6, n_estimators=500;, score=0.952 total time=   0.7s\n",
      "[CV 5/5; 143/360] START colsample_bytree=0.3, max_depth=6, n_estimators=500.....\n",
      "[CV 5/5; 143/360] END colsample_bytree=0.3, max_depth=6, n_estimators=500;, score=0.950 total time=   0.6s\n",
      "[CV 1/5; 144/360] START colsample_bytree=0.3, max_depth=6, n_estimators=550.....\n",
      "[CV 1/5; 144/360] END colsample_bytree=0.3, max_depth=6, n_estimators=550;, score=0.948 total time=   0.6s\n",
      "[CV 2/5; 144/360] START colsample_bytree=0.3, max_depth=6, n_estimators=550.....\n",
      "[CV 2/5; 144/360] END colsample_bytree=0.3, max_depth=6, n_estimators=550;, score=0.947 total time=   0.6s\n",
      "[CV 3/5; 144/360] START colsample_bytree=0.3, max_depth=6, n_estimators=550.....\n",
      "[CV 3/5; 144/360] END colsample_bytree=0.3, max_depth=6, n_estimators=550;, score=0.949 total time=   0.6s\n",
      "[CV 4/5; 144/360] START colsample_bytree=0.3, max_depth=6, n_estimators=550.....\n",
      "[CV 4/5; 144/360] END colsample_bytree=0.3, max_depth=6, n_estimators=550;, score=0.951 total time=   0.6s\n",
      "[CV 5/5; 144/360] START colsample_bytree=0.3, max_depth=6, n_estimators=550.....\n",
      "[CV 5/5; 144/360] END colsample_bytree=0.3, max_depth=6, n_estimators=550;, score=0.949 total time=   0.6s\n",
      "[CV 1/5; 145/360] START colsample_bytree=0.4, max_depth=1, n_estimators=300.....\n",
      "[CV 1/5; 145/360] END colsample_bytree=0.4, max_depth=1, n_estimators=300;, score=0.928 total time=   0.1s\n",
      "[CV 2/5; 145/360] START colsample_bytree=0.4, max_depth=1, n_estimators=300.....\n",
      "[CV 2/5; 145/360] END colsample_bytree=0.4, max_depth=1, n_estimators=300;, score=0.929 total time=   0.1s\n",
      "[CV 3/5; 145/360] START colsample_bytree=0.4, max_depth=1, n_estimators=300.....\n",
      "[CV 3/5; 145/360] END colsample_bytree=0.4, max_depth=1, n_estimators=300;, score=0.931 total time=   0.1s\n",
      "[CV 4/5; 145/360] START colsample_bytree=0.4, max_depth=1, n_estimators=300.....\n",
      "[CV 4/5; 145/360] END colsample_bytree=0.4, max_depth=1, n_estimators=300;, score=0.932 total time=   0.1s\n",
      "[CV 5/5; 145/360] START colsample_bytree=0.4, max_depth=1, n_estimators=300.....\n",
      "[CV 5/5; 145/360] END colsample_bytree=0.4, max_depth=1, n_estimators=300;, score=0.929 total time=   0.1s\n",
      "[CV 1/5; 146/360] START colsample_bytree=0.4, max_depth=1, n_estimators=350.....\n",
      "[CV 1/5; 146/360] END colsample_bytree=0.4, max_depth=1, n_estimators=350;, score=0.928 total time=   0.1s\n",
      "[CV 2/5; 146/360] START colsample_bytree=0.4, max_depth=1, n_estimators=350.....\n",
      "[CV 2/5; 146/360] END colsample_bytree=0.4, max_depth=1, n_estimators=350;, score=0.929 total time=   0.1s\n",
      "[CV 3/5; 146/360] START colsample_bytree=0.4, max_depth=1, n_estimators=350.....\n",
      "[CV 3/5; 146/360] END colsample_bytree=0.4, max_depth=1, n_estimators=350;, score=0.931 total time=   0.1s\n",
      "[CV 4/5; 146/360] START colsample_bytree=0.4, max_depth=1, n_estimators=350.....\n",
      "[CV 4/5; 146/360] END colsample_bytree=0.4, max_depth=1, n_estimators=350;, score=0.932 total time=   0.1s\n",
      "[CV 5/5; 146/360] START colsample_bytree=0.4, max_depth=1, n_estimators=350.....\n",
      "[CV 5/5; 146/360] END colsample_bytree=0.4, max_depth=1, n_estimators=350;, score=0.930 total time=   0.1s\n",
      "[CV 1/5; 147/360] START colsample_bytree=0.4, max_depth=1, n_estimators=400.....\n",
      "[CV 1/5; 147/360] END colsample_bytree=0.4, max_depth=1, n_estimators=400;, score=0.928 total time=   0.2s\n",
      "[CV 2/5; 147/360] START colsample_bytree=0.4, max_depth=1, n_estimators=400.....\n",
      "[CV 2/5; 147/360] END colsample_bytree=0.4, max_depth=1, n_estimators=400;, score=0.929 total time=   0.1s\n",
      "[CV 3/5; 147/360] START colsample_bytree=0.4, max_depth=1, n_estimators=400.....\n",
      "[CV 3/5; 147/360] END colsample_bytree=0.4, max_depth=1, n_estimators=400;, score=0.931 total time=   0.1s\n",
      "[CV 4/5; 147/360] START colsample_bytree=0.4, max_depth=1, n_estimators=400.....\n",
      "[CV 4/5; 147/360] END colsample_bytree=0.4, max_depth=1, n_estimators=400;, score=0.932 total time=   0.2s\n",
      "[CV 5/5; 147/360] START colsample_bytree=0.4, max_depth=1, n_estimators=400.....\n",
      "[CV 5/5; 147/360] END colsample_bytree=0.4, max_depth=1, n_estimators=400;, score=0.931 total time=   0.2s\n",
      "[CV 1/5; 148/360] START colsample_bytree=0.4, max_depth=1, n_estimators=450.....\n",
      "[CV 1/5; 148/360] END colsample_bytree=0.4, max_depth=1, n_estimators=450;, score=0.928 total time=   0.2s\n",
      "[CV 2/5; 148/360] START colsample_bytree=0.4, max_depth=1, n_estimators=450.....\n",
      "[CV 2/5; 148/360] END colsample_bytree=0.4, max_depth=1, n_estimators=450;, score=0.929 total time=   0.2s\n",
      "[CV 3/5; 148/360] START colsample_bytree=0.4, max_depth=1, n_estimators=450.....\n",
      "[CV 3/5; 148/360] END colsample_bytree=0.4, max_depth=1, n_estimators=450;, score=0.931 total time=   0.2s\n",
      "[CV 4/5; 148/360] START colsample_bytree=0.4, max_depth=1, n_estimators=450.....\n",
      "[CV 4/5; 148/360] END colsample_bytree=0.4, max_depth=1, n_estimators=450;, score=0.932 total time=   0.2s\n",
      "[CV 5/5; 148/360] START colsample_bytree=0.4, max_depth=1, n_estimators=450.....\n",
      "[CV 5/5; 148/360] END colsample_bytree=0.4, max_depth=1, n_estimators=450;, score=0.931 total time=   0.2s\n",
      "[CV 1/5; 149/360] START colsample_bytree=0.4, max_depth=1, n_estimators=500.....\n",
      "[CV 1/5; 149/360] END colsample_bytree=0.4, max_depth=1, n_estimators=500;, score=0.928 total time=   0.2s\n",
      "[CV 2/5; 149/360] START colsample_bytree=0.4, max_depth=1, n_estimators=500.....\n",
      "[CV 2/5; 149/360] END colsample_bytree=0.4, max_depth=1, n_estimators=500;, score=0.929 total time=   0.2s\n",
      "[CV 3/5; 149/360] START colsample_bytree=0.4, max_depth=1, n_estimators=500.....\n",
      "[CV 3/5; 149/360] END colsample_bytree=0.4, max_depth=1, n_estimators=500;, score=0.931 total time=   0.2s\n",
      "[CV 4/5; 149/360] START colsample_bytree=0.4, max_depth=1, n_estimators=500.....\n",
      "[CV 4/5; 149/360] END colsample_bytree=0.4, max_depth=1, n_estimators=500;, score=0.932 total time=   0.2s\n",
      "[CV 5/5; 149/360] START colsample_bytree=0.4, max_depth=1, n_estimators=500.....\n",
      "[CV 5/5; 149/360] END colsample_bytree=0.4, max_depth=1, n_estimators=500;, score=0.931 total time=   0.2s\n",
      "[CV 1/5; 150/360] START colsample_bytree=0.4, max_depth=1, n_estimators=550.....\n",
      "[CV 1/5; 150/360] END colsample_bytree=0.4, max_depth=1, n_estimators=550;, score=0.929 total time=   0.2s\n",
      "[CV 2/5; 150/360] START colsample_bytree=0.4, max_depth=1, n_estimators=550.....\n",
      "[CV 2/5; 150/360] END colsample_bytree=0.4, max_depth=1, n_estimators=550;, score=0.929 total time=   0.2s\n",
      "[CV 3/5; 150/360] START colsample_bytree=0.4, max_depth=1, n_estimators=550.....\n",
      "[CV 3/5; 150/360] END colsample_bytree=0.4, max_depth=1, n_estimators=550;, score=0.931 total time=   0.2s\n",
      "[CV 4/5; 150/360] START colsample_bytree=0.4, max_depth=1, n_estimators=550.....\n",
      "[CV 4/5; 150/360] END colsample_bytree=0.4, max_depth=1, n_estimators=550;, score=0.932 total time=   0.2s\n",
      "[CV 5/5; 150/360] START colsample_bytree=0.4, max_depth=1, n_estimators=550.....\n",
      "[CV 5/5; 150/360] END colsample_bytree=0.4, max_depth=1, n_estimators=550;, score=0.931 total time=   0.2s\n",
      "[CV 1/5; 151/360] START colsample_bytree=0.4, max_depth=2, n_estimators=300.....\n",
      "[CV 1/5; 151/360] END colsample_bytree=0.4, max_depth=2, n_estimators=300;, score=0.949 total time=   0.1s\n",
      "[CV 2/5; 151/360] START colsample_bytree=0.4, max_depth=2, n_estimators=300.....\n",
      "[CV 2/5; 151/360] END colsample_bytree=0.4, max_depth=2, n_estimators=300;, score=0.950 total time=   0.1s\n",
      "[CV 3/5; 151/360] START colsample_bytree=0.4, max_depth=2, n_estimators=300.....\n",
      "[CV 3/5; 151/360] END colsample_bytree=0.4, max_depth=2, n_estimators=300;, score=0.951 total time=   0.2s\n",
      "[CV 4/5; 151/360] START colsample_bytree=0.4, max_depth=2, n_estimators=300.....\n",
      "[CV 4/5; 151/360] END colsample_bytree=0.4, max_depth=2, n_estimators=300;, score=0.953 total time=   0.1s\n",
      "[CV 5/5; 151/360] START colsample_bytree=0.4, max_depth=2, n_estimators=300.....\n",
      "[CV 5/5; 151/360] END colsample_bytree=0.4, max_depth=2, n_estimators=300;, score=0.951 total time=   0.1s\n",
      "[CV 1/5; 152/360] START colsample_bytree=0.4, max_depth=2, n_estimators=350.....\n",
      "[CV 1/5; 152/360] END colsample_bytree=0.4, max_depth=2, n_estimators=350;, score=0.949 total time=   0.2s\n",
      "[CV 2/5; 152/360] START colsample_bytree=0.4, max_depth=2, n_estimators=350.....\n",
      "[CV 2/5; 152/360] END colsample_bytree=0.4, max_depth=2, n_estimators=350;, score=0.950 total time=   0.2s\n",
      "[CV 3/5; 152/360] START colsample_bytree=0.4, max_depth=2, n_estimators=350.....\n",
      "[CV 3/5; 152/360] END colsample_bytree=0.4, max_depth=2, n_estimators=350;, score=0.951 total time=   0.2s\n",
      "[CV 4/5; 152/360] START colsample_bytree=0.4, max_depth=2, n_estimators=350.....\n",
      "[CV 4/5; 152/360] END colsample_bytree=0.4, max_depth=2, n_estimators=350;, score=0.953 total time=   0.3s\n",
      "[CV 5/5; 152/360] START colsample_bytree=0.4, max_depth=2, n_estimators=350.....\n",
      "[CV 5/5; 152/360] END colsample_bytree=0.4, max_depth=2, n_estimators=350;, score=0.951 total time=   0.2s\n",
      "[CV 1/5; 153/360] START colsample_bytree=0.4, max_depth=2, n_estimators=400.....\n",
      "[CV 1/5; 153/360] END colsample_bytree=0.4, max_depth=2, n_estimators=400;, score=0.949 total time=   0.3s\n",
      "[CV 2/5; 153/360] START colsample_bytree=0.4, max_depth=2, n_estimators=400.....\n",
      "[CV 2/5; 153/360] END colsample_bytree=0.4, max_depth=2, n_estimators=400;, score=0.950 total time=   0.3s\n",
      "[CV 3/5; 153/360] START colsample_bytree=0.4, max_depth=2, n_estimators=400.....\n",
      "[CV 3/5; 153/360] END colsample_bytree=0.4, max_depth=2, n_estimators=400;, score=0.951 total time=   0.3s\n",
      "[CV 4/5; 153/360] START colsample_bytree=0.4, max_depth=2, n_estimators=400.....\n",
      "[CV 4/5; 153/360] END colsample_bytree=0.4, max_depth=2, n_estimators=400;, score=0.954 total time=   0.3s\n",
      "[CV 5/5; 153/360] START colsample_bytree=0.4, max_depth=2, n_estimators=400.....\n",
      "[CV 5/5; 153/360] END colsample_bytree=0.4, max_depth=2, n_estimators=400;, score=0.951 total time=   0.3s\n",
      "[CV 1/5; 154/360] START colsample_bytree=0.4, max_depth=2, n_estimators=450.....\n",
      "[CV 1/5; 154/360] END colsample_bytree=0.4, max_depth=2, n_estimators=450;, score=0.949 total time=   0.3s\n",
      "[CV 2/5; 154/360] START colsample_bytree=0.4, max_depth=2, n_estimators=450.....\n",
      "[CV 2/5; 154/360] END colsample_bytree=0.4, max_depth=2, n_estimators=450;, score=0.950 total time=   0.2s\n",
      "[CV 3/5; 154/360] START colsample_bytree=0.4, max_depth=2, n_estimators=450.....\n",
      "[CV 3/5; 154/360] END colsample_bytree=0.4, max_depth=2, n_estimators=450;, score=0.951 total time=   0.3s\n",
      "[CV 4/5; 154/360] START colsample_bytree=0.4, max_depth=2, n_estimators=450.....\n",
      "[CV 4/5; 154/360] END colsample_bytree=0.4, max_depth=2, n_estimators=450;, score=0.953 total time=   0.2s\n",
      "[CV 5/5; 154/360] START colsample_bytree=0.4, max_depth=2, n_estimators=450.....\n",
      "[CV 5/5; 154/360] END colsample_bytree=0.4, max_depth=2, n_estimators=450;, score=0.951 total time=   0.2s\n",
      "[CV 1/5; 155/360] START colsample_bytree=0.4, max_depth=2, n_estimators=500.....\n",
      "[CV 1/5; 155/360] END colsample_bytree=0.4, max_depth=2, n_estimators=500;, score=0.949 total time=   0.3s\n",
      "[CV 2/5; 155/360] START colsample_bytree=0.4, max_depth=2, n_estimators=500.....\n",
      "[CV 2/5; 155/360] END colsample_bytree=0.4, max_depth=2, n_estimators=500;, score=0.950 total time=   0.3s\n",
      "[CV 3/5; 155/360] START colsample_bytree=0.4, max_depth=2, n_estimators=500.....\n",
      "[CV 3/5; 155/360] END colsample_bytree=0.4, max_depth=2, n_estimators=500;, score=0.951 total time=   0.3s\n",
      "[CV 4/5; 155/360] START colsample_bytree=0.4, max_depth=2, n_estimators=500.....\n",
      "[CV 4/5; 155/360] END colsample_bytree=0.4, max_depth=2, n_estimators=500;, score=0.953 total time=   0.3s\n",
      "[CV 5/5; 155/360] START colsample_bytree=0.4, max_depth=2, n_estimators=500.....\n",
      "[CV 5/5; 155/360] END colsample_bytree=0.4, max_depth=2, n_estimators=500;, score=0.951 total time=   0.3s\n",
      "[CV 1/5; 156/360] START colsample_bytree=0.4, max_depth=2, n_estimators=550.....\n",
      "[CV 1/5; 156/360] END colsample_bytree=0.4, max_depth=2, n_estimators=550;, score=0.949 total time=   0.3s\n",
      "[CV 2/5; 156/360] START colsample_bytree=0.4, max_depth=2, n_estimators=550.....\n",
      "[CV 2/5; 156/360] END colsample_bytree=0.4, max_depth=2, n_estimators=550;, score=0.950 total time=   0.3s\n",
      "[CV 3/5; 156/360] START colsample_bytree=0.4, max_depth=2, n_estimators=550.....\n",
      "[CV 3/5; 156/360] END colsample_bytree=0.4, max_depth=2, n_estimators=550;, score=0.951 total time=   0.3s\n",
      "[CV 4/5; 156/360] START colsample_bytree=0.4, max_depth=2, n_estimators=550.....\n",
      "[CV 4/5; 156/360] END colsample_bytree=0.4, max_depth=2, n_estimators=550;, score=0.954 total time=   0.3s\n",
      "[CV 5/5; 156/360] START colsample_bytree=0.4, max_depth=2, n_estimators=550.....\n",
      "[CV 5/5; 156/360] END colsample_bytree=0.4, max_depth=2, n_estimators=550;, score=0.951 total time=   0.3s\n",
      "[CV 1/5; 157/360] START colsample_bytree=0.4, max_depth=3, n_estimators=300.....\n",
      "[CV 1/5; 157/360] END colsample_bytree=0.4, max_depth=3, n_estimators=300;, score=0.949 total time=   0.2s\n",
      "[CV 2/5; 157/360] START colsample_bytree=0.4, max_depth=3, n_estimators=300.....\n",
      "[CV 2/5; 157/360] END colsample_bytree=0.4, max_depth=3, n_estimators=300;, score=0.951 total time=   0.2s\n",
      "[CV 3/5; 157/360] START colsample_bytree=0.4, max_depth=3, n_estimators=300.....\n",
      "[CV 3/5; 157/360] END colsample_bytree=0.4, max_depth=3, n_estimators=300;, score=0.951 total time=   0.2s\n",
      "[CV 4/5; 157/360] START colsample_bytree=0.4, max_depth=3, n_estimators=300.....\n",
      "[CV 4/5; 157/360] END colsample_bytree=0.4, max_depth=3, n_estimators=300;, score=0.955 total time=   0.2s\n",
      "[CV 5/5; 157/360] START colsample_bytree=0.4, max_depth=3, n_estimators=300.....\n",
      "[CV 5/5; 157/360] END colsample_bytree=0.4, max_depth=3, n_estimators=300;, score=0.952 total time=   0.2s\n",
      "[CV 1/5; 158/360] START colsample_bytree=0.4, max_depth=3, n_estimators=350.....\n",
      "[CV 1/5; 158/360] END colsample_bytree=0.4, max_depth=3, n_estimators=350;, score=0.949 total time=   0.2s\n",
      "[CV 2/5; 158/360] START colsample_bytree=0.4, max_depth=3, n_estimators=350.....\n",
      "[CV 2/5; 158/360] END colsample_bytree=0.4, max_depth=3, n_estimators=350;, score=0.951 total time=   0.2s\n",
      "[CV 3/5; 158/360] START colsample_bytree=0.4, max_depth=3, n_estimators=350.....\n",
      "[CV 3/5; 158/360] END colsample_bytree=0.4, max_depth=3, n_estimators=350;, score=0.951 total time=   0.2s\n",
      "[CV 4/5; 158/360] START colsample_bytree=0.4, max_depth=3, n_estimators=350.....\n",
      "[CV 4/5; 158/360] END colsample_bytree=0.4, max_depth=3, n_estimators=350;, score=0.955 total time=   0.2s\n",
      "[CV 5/5; 158/360] START colsample_bytree=0.4, max_depth=3, n_estimators=350.....\n",
      "[CV 5/5; 158/360] END colsample_bytree=0.4, max_depth=3, n_estimators=350;, score=0.952 total time=   0.2s\n",
      "[CV 1/5; 159/360] START colsample_bytree=0.4, max_depth=3, n_estimators=400.....\n",
      "[CV 1/5; 159/360] END colsample_bytree=0.4, max_depth=3, n_estimators=400;, score=0.949 total time=   0.2s\n",
      "[CV 2/5; 159/360] START colsample_bytree=0.4, max_depth=3, n_estimators=400.....\n",
      "[CV 2/5; 159/360] END colsample_bytree=0.4, max_depth=3, n_estimators=400;, score=0.951 total time=   0.2s\n",
      "[CV 3/5; 159/360] START colsample_bytree=0.4, max_depth=3, n_estimators=400.....\n",
      "[CV 3/5; 159/360] END colsample_bytree=0.4, max_depth=3, n_estimators=400;, score=0.951 total time=   0.2s\n",
      "[CV 4/5; 159/360] START colsample_bytree=0.4, max_depth=3, n_estimators=400.....\n",
      "[CV 4/5; 159/360] END colsample_bytree=0.4, max_depth=3, n_estimators=400;, score=0.955 total time=   0.2s\n",
      "[CV 5/5; 159/360] START colsample_bytree=0.4, max_depth=3, n_estimators=400.....\n",
      "[CV 5/5; 159/360] END colsample_bytree=0.4, max_depth=3, n_estimators=400;, score=0.952 total time=   0.2s\n",
      "[CV 1/5; 160/360] START colsample_bytree=0.4, max_depth=3, n_estimators=450.....\n",
      "[CV 1/5; 160/360] END colsample_bytree=0.4, max_depth=3, n_estimators=450;, score=0.949 total time=   0.3s\n",
      "[CV 2/5; 160/360] START colsample_bytree=0.4, max_depth=3, n_estimators=450.....\n",
      "[CV 2/5; 160/360] END colsample_bytree=0.4, max_depth=3, n_estimators=450;, score=0.951 total time=   0.3s\n",
      "[CV 3/5; 160/360] START colsample_bytree=0.4, max_depth=3, n_estimators=450.....\n",
      "[CV 3/5; 160/360] END colsample_bytree=0.4, max_depth=3, n_estimators=450;, score=0.951 total time=   0.3s\n",
      "[CV 4/5; 160/360] START colsample_bytree=0.4, max_depth=3, n_estimators=450.....\n",
      "[CV 4/5; 160/360] END colsample_bytree=0.4, max_depth=3, n_estimators=450;, score=0.955 total time=   0.3s\n",
      "[CV 5/5; 160/360] START colsample_bytree=0.4, max_depth=3, n_estimators=450.....\n",
      "[CV 5/5; 160/360] END colsample_bytree=0.4, max_depth=3, n_estimators=450;, score=0.951 total time=   0.3s\n",
      "[CV 1/5; 161/360] START colsample_bytree=0.4, max_depth=3, n_estimators=500.....\n",
      "[CV 1/5; 161/360] END colsample_bytree=0.4, max_depth=3, n_estimators=500;, score=0.949 total time=   0.3s\n",
      "[CV 2/5; 161/360] START colsample_bytree=0.4, max_depth=3, n_estimators=500.....\n",
      "[CV 2/5; 161/360] END colsample_bytree=0.4, max_depth=3, n_estimators=500;, score=0.950 total time=   0.3s\n",
      "[CV 3/5; 161/360] START colsample_bytree=0.4, max_depth=3, n_estimators=500.....\n",
      "[CV 3/5; 161/360] END colsample_bytree=0.4, max_depth=3, n_estimators=500;, score=0.951 total time=   0.3s\n",
      "[CV 4/5; 161/360] START colsample_bytree=0.4, max_depth=3, n_estimators=500.....\n",
      "[CV 4/5; 161/360] END colsample_bytree=0.4, max_depth=3, n_estimators=500;, score=0.954 total time=   0.4s\n",
      "[CV 5/5; 161/360] START colsample_bytree=0.4, max_depth=3, n_estimators=500.....\n",
      "[CV 5/5; 161/360] END colsample_bytree=0.4, max_depth=3, n_estimators=500;, score=0.951 total time=   0.4s\n",
      "[CV 1/5; 162/360] START colsample_bytree=0.4, max_depth=3, n_estimators=550.....\n",
      "[CV 1/5; 162/360] END colsample_bytree=0.4, max_depth=3, n_estimators=550;, score=0.949 total time=   0.5s\n",
      "[CV 2/5; 162/360] START colsample_bytree=0.4, max_depth=3, n_estimators=550.....\n",
      "[CV 2/5; 162/360] END colsample_bytree=0.4, max_depth=3, n_estimators=550;, score=0.950 total time=   0.5s\n",
      "[CV 3/5; 162/360] START colsample_bytree=0.4, max_depth=3, n_estimators=550.....\n",
      "[CV 3/5; 162/360] END colsample_bytree=0.4, max_depth=3, n_estimators=550;, score=0.951 total time=   0.4s\n",
      "[CV 4/5; 162/360] START colsample_bytree=0.4, max_depth=3, n_estimators=550.....\n",
      "[CV 4/5; 162/360] END colsample_bytree=0.4, max_depth=3, n_estimators=550;, score=0.954 total time=   0.4s\n",
      "[CV 5/5; 162/360] START colsample_bytree=0.4, max_depth=3, n_estimators=550.....\n",
      "[CV 5/5; 162/360] END colsample_bytree=0.4, max_depth=3, n_estimators=550;, score=0.952 total time=   0.3s\n",
      "[CV 1/5; 163/360] START colsample_bytree=0.4, max_depth=4, n_estimators=300.....\n",
      "[CV 1/5; 163/360] END colsample_bytree=0.4, max_depth=4, n_estimators=300;, score=0.950 total time=   0.2s\n",
      "[CV 2/5; 163/360] START colsample_bytree=0.4, max_depth=4, n_estimators=300.....\n",
      "[CV 2/5; 163/360] END colsample_bytree=0.4, max_depth=4, n_estimators=300;, score=0.951 total time=   0.2s\n",
      "[CV 3/5; 163/360] START colsample_bytree=0.4, max_depth=4, n_estimators=300.....\n",
      "[CV 3/5; 163/360] END colsample_bytree=0.4, max_depth=4, n_estimators=300;, score=0.951 total time=   0.2s\n",
      "[CV 4/5; 163/360] START colsample_bytree=0.4, max_depth=4, n_estimators=300.....\n",
      "[CV 4/5; 163/360] END colsample_bytree=0.4, max_depth=4, n_estimators=300;, score=0.954 total time=   0.3s\n",
      "[CV 5/5; 163/360] START colsample_bytree=0.4, max_depth=4, n_estimators=300.....\n",
      "[CV 5/5; 163/360] END colsample_bytree=0.4, max_depth=4, n_estimators=300;, score=0.952 total time=   0.2s\n",
      "[CV 1/5; 164/360] START colsample_bytree=0.4, max_depth=4, n_estimators=350.....\n",
      "[CV 1/5; 164/360] END colsample_bytree=0.4, max_depth=4, n_estimators=350;, score=0.949 total time=   0.3s\n",
      "[CV 2/5; 164/360] START colsample_bytree=0.4, max_depth=4, n_estimators=350.....\n",
      "[CV 2/5; 164/360] END colsample_bytree=0.4, max_depth=4, n_estimators=350;, score=0.950 total time=   0.3s\n",
      "[CV 3/5; 164/360] START colsample_bytree=0.4, max_depth=4, n_estimators=350.....\n",
      "[CV 3/5; 164/360] END colsample_bytree=0.4, max_depth=4, n_estimators=350;, score=0.951 total time=   0.3s\n",
      "[CV 4/5; 164/360] START colsample_bytree=0.4, max_depth=4, n_estimators=350.....\n",
      "[CV 4/5; 164/360] END colsample_bytree=0.4, max_depth=4, n_estimators=350;, score=0.954 total time=   0.3s\n",
      "[CV 5/5; 164/360] START colsample_bytree=0.4, max_depth=4, n_estimators=350.....\n",
      "[CV 5/5; 164/360] END colsample_bytree=0.4, max_depth=4, n_estimators=350;, score=0.952 total time=   0.3s\n",
      "[CV 1/5; 165/360] START colsample_bytree=0.4, max_depth=4, n_estimators=400.....\n",
      "[CV 1/5; 165/360] END colsample_bytree=0.4, max_depth=4, n_estimators=400;, score=0.950 total time=   0.4s\n",
      "[CV 2/5; 165/360] START colsample_bytree=0.4, max_depth=4, n_estimators=400.....\n",
      "[CV 2/5; 165/360] END colsample_bytree=0.4, max_depth=4, n_estimators=400;, score=0.951 total time=   0.3s\n",
      "[CV 3/5; 165/360] START colsample_bytree=0.4, max_depth=4, n_estimators=400.....\n",
      "[CV 3/5; 165/360] END colsample_bytree=0.4, max_depth=4, n_estimators=400;, score=0.951 total time=   0.4s\n",
      "[CV 4/5; 165/360] START colsample_bytree=0.4, max_depth=4, n_estimators=400.....\n",
      "[CV 4/5; 165/360] END colsample_bytree=0.4, max_depth=4, n_estimators=400;, score=0.954 total time=   0.4s\n",
      "[CV 5/5; 165/360] START colsample_bytree=0.4, max_depth=4, n_estimators=400.....\n",
      "[CV 5/5; 165/360] END colsample_bytree=0.4, max_depth=4, n_estimators=400;, score=0.952 total time=   0.4s\n",
      "[CV 1/5; 166/360] START colsample_bytree=0.4, max_depth=4, n_estimators=450.....\n",
      "[CV 1/5; 166/360] END colsample_bytree=0.4, max_depth=4, n_estimators=450;, score=0.949 total time=   0.4s\n",
      "[CV 2/5; 166/360] START colsample_bytree=0.4, max_depth=4, n_estimators=450.....\n",
      "[CV 2/5; 166/360] END colsample_bytree=0.4, max_depth=4, n_estimators=450;, score=0.950 total time=   0.4s\n",
      "[CV 3/5; 166/360] START colsample_bytree=0.4, max_depth=4, n_estimators=450.....\n",
      "[CV 3/5; 166/360] END colsample_bytree=0.4, max_depth=4, n_estimators=450;, score=0.951 total time=   0.5s\n",
      "[CV 4/5; 166/360] START colsample_bytree=0.4, max_depth=4, n_estimators=450.....\n",
      "[CV 4/5; 166/360] END colsample_bytree=0.4, max_depth=4, n_estimators=450;, score=0.954 total time=   0.4s\n",
      "[CV 5/5; 166/360] START colsample_bytree=0.4, max_depth=4, n_estimators=450.....\n",
      "[CV 5/5; 166/360] END colsample_bytree=0.4, max_depth=4, n_estimators=450;, score=0.952 total time=   0.4s\n",
      "[CV 1/5; 167/360] START colsample_bytree=0.4, max_depth=4, n_estimators=500.....\n",
      "[CV 1/5; 167/360] END colsample_bytree=0.4, max_depth=4, n_estimators=500;, score=0.949 total time=   0.4s\n",
      "[CV 2/5; 167/360] START colsample_bytree=0.4, max_depth=4, n_estimators=500.....\n",
      "[CV 2/5; 167/360] END colsample_bytree=0.4, max_depth=4, n_estimators=500;, score=0.950 total time=   0.5s\n",
      "[CV 3/5; 167/360] START colsample_bytree=0.4, max_depth=4, n_estimators=500.....\n",
      "[CV 3/5; 167/360] END colsample_bytree=0.4, max_depth=4, n_estimators=500;, score=0.950 total time=   0.4s\n",
      "[CV 4/5; 167/360] START colsample_bytree=0.4, max_depth=4, n_estimators=500.....\n",
      "[CV 4/5; 167/360] END colsample_bytree=0.4, max_depth=4, n_estimators=500;, score=0.954 total time=   0.4s\n",
      "[CV 5/5; 167/360] START colsample_bytree=0.4, max_depth=4, n_estimators=500.....\n",
      "[CV 5/5; 167/360] END colsample_bytree=0.4, max_depth=4, n_estimators=500;, score=0.951 total time=   0.4s\n",
      "[CV 1/5; 168/360] START colsample_bytree=0.4, max_depth=4, n_estimators=550.....\n",
      "[CV 1/5; 168/360] END colsample_bytree=0.4, max_depth=4, n_estimators=550;, score=0.949 total time=   0.5s\n",
      "[CV 2/5; 168/360] START colsample_bytree=0.4, max_depth=4, n_estimators=550.....\n",
      "[CV 2/5; 168/360] END colsample_bytree=0.4, max_depth=4, n_estimators=550;, score=0.948 total time=   0.5s\n",
      "[CV 3/5; 168/360] START colsample_bytree=0.4, max_depth=4, n_estimators=550.....\n",
      "[CV 3/5; 168/360] END colsample_bytree=0.4, max_depth=4, n_estimators=550;, score=0.950 total time=   0.6s\n",
      "[CV 4/5; 168/360] START colsample_bytree=0.4, max_depth=4, n_estimators=550.....\n",
      "[CV 4/5; 168/360] END colsample_bytree=0.4, max_depth=4, n_estimators=550;, score=0.953 total time=   0.6s\n",
      "[CV 5/5; 168/360] START colsample_bytree=0.4, max_depth=4, n_estimators=550.....\n",
      "[CV 5/5; 168/360] END colsample_bytree=0.4, max_depth=4, n_estimators=550;, score=0.952 total time=   0.6s\n",
      "[CV 1/5; 169/360] START colsample_bytree=0.4, max_depth=5, n_estimators=300.....\n",
      "[CV 1/5; 169/360] END colsample_bytree=0.4, max_depth=5, n_estimators=300;, score=0.949 total time=   0.4s\n",
      "[CV 2/5; 169/360] START colsample_bytree=0.4, max_depth=5, n_estimators=300.....\n",
      "[CV 2/5; 169/360] END colsample_bytree=0.4, max_depth=5, n_estimators=300;, score=0.950 total time=   0.3s\n",
      "[CV 3/5; 169/360] START colsample_bytree=0.4, max_depth=5, n_estimators=300.....\n",
      "[CV 3/5; 169/360] END colsample_bytree=0.4, max_depth=5, n_estimators=300;, score=0.951 total time=   0.3s\n",
      "[CV 4/5; 169/360] START colsample_bytree=0.4, max_depth=5, n_estimators=300.....\n",
      "[CV 4/5; 169/360] END colsample_bytree=0.4, max_depth=5, n_estimators=300;, score=0.955 total time=   0.4s\n",
      "[CV 5/5; 169/360] START colsample_bytree=0.4, max_depth=5, n_estimators=300.....\n",
      "[CV 5/5; 169/360] END colsample_bytree=0.4, max_depth=5, n_estimators=300;, score=0.952 total time=   0.3s\n",
      "[CV 1/5; 170/360] START colsample_bytree=0.4, max_depth=5, n_estimators=350.....\n",
      "[CV 1/5; 170/360] END colsample_bytree=0.4, max_depth=5, n_estimators=350;, score=0.949 total time=   0.3s\n",
      "[CV 2/5; 170/360] START colsample_bytree=0.4, max_depth=5, n_estimators=350.....\n",
      "[CV 2/5; 170/360] END colsample_bytree=0.4, max_depth=5, n_estimators=350;, score=0.950 total time=   0.4s\n",
      "[CV 3/5; 170/360] START colsample_bytree=0.4, max_depth=5, n_estimators=350.....\n",
      "[CV 3/5; 170/360] END colsample_bytree=0.4, max_depth=5, n_estimators=350;, score=0.950 total time=   0.3s\n",
      "[CV 4/5; 170/360] START colsample_bytree=0.4, max_depth=5, n_estimators=350.....\n",
      "[CV 4/5; 170/360] END colsample_bytree=0.4, max_depth=5, n_estimators=350;, score=0.955 total time=   0.3s\n",
      "[CV 5/5; 170/360] START colsample_bytree=0.4, max_depth=5, n_estimators=350.....\n",
      "[CV 5/5; 170/360] END colsample_bytree=0.4, max_depth=5, n_estimators=350;, score=0.953 total time=   0.3s\n",
      "[CV 1/5; 171/360] START colsample_bytree=0.4, max_depth=5, n_estimators=400.....\n",
      "[CV 1/5; 171/360] END colsample_bytree=0.4, max_depth=5, n_estimators=400;, score=0.948 total time=   0.4s\n",
      "[CV 2/5; 171/360] START colsample_bytree=0.4, max_depth=5, n_estimators=400.....\n",
      "[CV 2/5; 171/360] END colsample_bytree=0.4, max_depth=5, n_estimators=400;, score=0.950 total time=   0.4s\n",
      "[CV 3/5; 171/360] START colsample_bytree=0.4, max_depth=5, n_estimators=400.....\n",
      "[CV 3/5; 171/360] END colsample_bytree=0.4, max_depth=5, n_estimators=400;, score=0.951 total time=   0.4s\n",
      "[CV 4/5; 171/360] START colsample_bytree=0.4, max_depth=5, n_estimators=400.....\n",
      "[CV 4/5; 171/360] END colsample_bytree=0.4, max_depth=5, n_estimators=400;, score=0.954 total time=   0.4s\n",
      "[CV 5/5; 171/360] START colsample_bytree=0.4, max_depth=5, n_estimators=400.....\n",
      "[CV 5/5; 171/360] END colsample_bytree=0.4, max_depth=5, n_estimators=400;, score=0.952 total time=   0.4s\n",
      "[CV 1/5; 172/360] START colsample_bytree=0.4, max_depth=5, n_estimators=450.....\n",
      "[CV 1/5; 172/360] END colsample_bytree=0.4, max_depth=5, n_estimators=450;, score=0.947 total time=   0.4s\n",
      "[CV 2/5; 172/360] START colsample_bytree=0.4, max_depth=5, n_estimators=450.....\n",
      "[CV 2/5; 172/360] END colsample_bytree=0.4, max_depth=5, n_estimators=450;, score=0.950 total time=   0.5s\n",
      "[CV 3/5; 172/360] START colsample_bytree=0.4, max_depth=5, n_estimators=450.....\n",
      "[CV 3/5; 172/360] END colsample_bytree=0.4, max_depth=5, n_estimators=450;, score=0.951 total time=   0.5s\n",
      "[CV 4/5; 172/360] START colsample_bytree=0.4, max_depth=5, n_estimators=450.....\n",
      "[CV 4/5; 172/360] END colsample_bytree=0.4, max_depth=5, n_estimators=450;, score=0.954 total time=   0.5s\n",
      "[CV 5/5; 172/360] START colsample_bytree=0.4, max_depth=5, n_estimators=450.....\n",
      "[CV 5/5; 172/360] END colsample_bytree=0.4, max_depth=5, n_estimators=450;, score=0.952 total time=   0.4s\n",
      "[CV 1/5; 173/360] START colsample_bytree=0.4, max_depth=5, n_estimators=500.....\n",
      "[CV 1/5; 173/360] END colsample_bytree=0.4, max_depth=5, n_estimators=500;, score=0.946 total time=   0.5s\n",
      "[CV 2/5; 173/360] START colsample_bytree=0.4, max_depth=5, n_estimators=500.....\n",
      "[CV 2/5; 173/360] END colsample_bytree=0.4, max_depth=5, n_estimators=500;, score=0.949 total time=   0.5s\n",
      "[CV 3/5; 173/360] START colsample_bytree=0.4, max_depth=5, n_estimators=500.....\n",
      "[CV 3/5; 173/360] END colsample_bytree=0.4, max_depth=5, n_estimators=500;, score=0.950 total time=   0.5s\n",
      "[CV 4/5; 173/360] START colsample_bytree=0.4, max_depth=5, n_estimators=500.....\n",
      "[CV 4/5; 173/360] END colsample_bytree=0.4, max_depth=5, n_estimators=500;, score=0.953 total time=   0.5s\n",
      "[CV 5/5; 173/360] START colsample_bytree=0.4, max_depth=5, n_estimators=500.....\n",
      "[CV 5/5; 173/360] END colsample_bytree=0.4, max_depth=5, n_estimators=500;, score=0.953 total time=   0.5s\n",
      "[CV 1/5; 174/360] START colsample_bytree=0.4, max_depth=5, n_estimators=550.....\n",
      "[CV 1/5; 174/360] END colsample_bytree=0.4, max_depth=5, n_estimators=550;, score=0.946 total time=   0.7s\n",
      "[CV 2/5; 174/360] START colsample_bytree=0.4, max_depth=5, n_estimators=550.....\n",
      "[CV 2/5; 174/360] END colsample_bytree=0.4, max_depth=5, n_estimators=550;, score=0.949 total time=   0.8s\n",
      "[CV 3/5; 174/360] START colsample_bytree=0.4, max_depth=5, n_estimators=550.....\n",
      "[CV 3/5; 174/360] END colsample_bytree=0.4, max_depth=5, n_estimators=550;, score=0.949 total time=   0.8s\n",
      "[CV 4/5; 174/360] START colsample_bytree=0.4, max_depth=5, n_estimators=550.....\n",
      "[CV 4/5; 174/360] END colsample_bytree=0.4, max_depth=5, n_estimators=550;, score=0.953 total time=   0.9s\n",
      "[CV 5/5; 174/360] START colsample_bytree=0.4, max_depth=5, n_estimators=550.....\n",
      "[CV 5/5; 174/360] END colsample_bytree=0.4, max_depth=5, n_estimators=550;, score=0.952 total time=   0.8s\n",
      "[CV 1/5; 175/360] START colsample_bytree=0.4, max_depth=6, n_estimators=300.....\n",
      "[CV 1/5; 175/360] END colsample_bytree=0.4, max_depth=6, n_estimators=300;, score=0.946 total time=   0.4s\n",
      "[CV 2/5; 175/360] START colsample_bytree=0.4, max_depth=6, n_estimators=300.....\n",
      "[CV 2/5; 175/360] END colsample_bytree=0.4, max_depth=6, n_estimators=300;, score=0.950 total time=   0.4s\n",
      "[CV 3/5; 175/360] START colsample_bytree=0.4, max_depth=6, n_estimators=300.....\n",
      "[CV 3/5; 175/360] END colsample_bytree=0.4, max_depth=6, n_estimators=300;, score=0.950 total time=   0.4s\n",
      "[CV 4/5; 175/360] START colsample_bytree=0.4, max_depth=6, n_estimators=300.....\n",
      "[CV 4/5; 175/360] END colsample_bytree=0.4, max_depth=6, n_estimators=300;, score=0.952 total time=   0.4s\n",
      "[CV 5/5; 175/360] START colsample_bytree=0.4, max_depth=6, n_estimators=300.....\n",
      "[CV 5/5; 175/360] END colsample_bytree=0.4, max_depth=6, n_estimators=300;, score=0.950 total time=   0.4s\n",
      "[CV 1/5; 176/360] START colsample_bytree=0.4, max_depth=6, n_estimators=350.....\n",
      "[CV 1/5; 176/360] END colsample_bytree=0.4, max_depth=6, n_estimators=350;, score=0.945 total time=   0.5s\n",
      "[CV 2/5; 176/360] START colsample_bytree=0.4, max_depth=6, n_estimators=350.....\n",
      "[CV 2/5; 176/360] END colsample_bytree=0.4, max_depth=6, n_estimators=350;, score=0.949 total time=   0.5s\n",
      "[CV 3/5; 176/360] START colsample_bytree=0.4, max_depth=6, n_estimators=350.....\n",
      "[CV 3/5; 176/360] END colsample_bytree=0.4, max_depth=6, n_estimators=350;, score=0.950 total time=   0.5s\n",
      "[CV 4/5; 176/360] START colsample_bytree=0.4, max_depth=6, n_estimators=350.....\n",
      "[CV 4/5; 176/360] END colsample_bytree=0.4, max_depth=6, n_estimators=350;, score=0.952 total time=   0.5s\n",
      "[CV 5/5; 176/360] START colsample_bytree=0.4, max_depth=6, n_estimators=350.....\n",
      "[CV 5/5; 176/360] END colsample_bytree=0.4, max_depth=6, n_estimators=350;, score=0.950 total time=   0.5s\n",
      "[CV 1/5; 177/360] START colsample_bytree=0.4, max_depth=6, n_estimators=400.....\n",
      "[CV 1/5; 177/360] END colsample_bytree=0.4, max_depth=6, n_estimators=400;, score=0.945 total time=   0.5s\n",
      "[CV 2/5; 177/360] START colsample_bytree=0.4, max_depth=6, n_estimators=400.....\n",
      "[CV 2/5; 177/360] END colsample_bytree=0.4, max_depth=6, n_estimators=400;, score=0.949 total time=   0.5s\n",
      "[CV 3/5; 177/360] START colsample_bytree=0.4, max_depth=6, n_estimators=400.....\n",
      "[CV 3/5; 177/360] END colsample_bytree=0.4, max_depth=6, n_estimators=400;, score=0.948 total time=   0.6s\n",
      "[CV 4/5; 177/360] START colsample_bytree=0.4, max_depth=6, n_estimators=400.....\n",
      "[CV 4/5; 177/360] END colsample_bytree=0.4, max_depth=6, n_estimators=400;, score=0.952 total time=   0.5s\n",
      "[CV 5/5; 177/360] START colsample_bytree=0.4, max_depth=6, n_estimators=400.....\n",
      "[CV 5/5; 177/360] END colsample_bytree=0.4, max_depth=6, n_estimators=400;, score=0.949 total time=   0.5s\n",
      "[CV 1/5; 178/360] START colsample_bytree=0.4, max_depth=6, n_estimators=450.....\n",
      "[CV 1/5; 178/360] END colsample_bytree=0.4, max_depth=6, n_estimators=450;, score=0.944 total time=   0.6s\n",
      "[CV 2/5; 178/360] START colsample_bytree=0.4, max_depth=6, n_estimators=450.....\n",
      "[CV 2/5; 178/360] END colsample_bytree=0.4, max_depth=6, n_estimators=450;, score=0.948 total time=   0.7s\n",
      "[CV 3/5; 178/360] START colsample_bytree=0.4, max_depth=6, n_estimators=450.....\n",
      "[CV 3/5; 178/360] END colsample_bytree=0.4, max_depth=6, n_estimators=450;, score=0.949 total time=   0.6s\n",
      "[CV 4/5; 178/360] START colsample_bytree=0.4, max_depth=6, n_estimators=450.....\n",
      "[CV 4/5; 178/360] END colsample_bytree=0.4, max_depth=6, n_estimators=450;, score=0.953 total time=   0.5s\n",
      "[CV 5/5; 178/360] START colsample_bytree=0.4, max_depth=6, n_estimators=450.....\n",
      "[CV 5/5; 178/360] END colsample_bytree=0.4, max_depth=6, n_estimators=450;, score=0.951 total time=   0.6s\n",
      "[CV 1/5; 179/360] START colsample_bytree=0.4, max_depth=6, n_estimators=500.....\n",
      "[CV 1/5; 179/360] END colsample_bytree=0.4, max_depth=6, n_estimators=500;, score=0.944 total time=   0.7s\n",
      "[CV 2/5; 179/360] START colsample_bytree=0.4, max_depth=6, n_estimators=500.....\n",
      "[CV 2/5; 179/360] END colsample_bytree=0.4, max_depth=6, n_estimators=500;, score=0.949 total time=   0.8s\n",
      "[CV 3/5; 179/360] START colsample_bytree=0.4, max_depth=6, n_estimators=500.....\n",
      "[CV 3/5; 179/360] END colsample_bytree=0.4, max_depth=6, n_estimators=500;, score=0.949 total time=   0.8s\n",
      "[CV 4/5; 179/360] START colsample_bytree=0.4, max_depth=6, n_estimators=500.....\n",
      "[CV 4/5; 179/360] END colsample_bytree=0.4, max_depth=6, n_estimators=500;, score=0.951 total time=   0.8s\n",
      "[CV 5/5; 179/360] START colsample_bytree=0.4, max_depth=6, n_estimators=500.....\n",
      "[CV 5/5; 179/360] END colsample_bytree=0.4, max_depth=6, n_estimators=500;, score=0.950 total time=   0.8s\n",
      "[CV 1/5; 180/360] START colsample_bytree=0.4, max_depth=6, n_estimators=550.....\n",
      "[CV 1/5; 180/360] END colsample_bytree=0.4, max_depth=6, n_estimators=550;, score=0.943 total time=   0.6s\n",
      "[CV 2/5; 180/360] START colsample_bytree=0.4, max_depth=6, n_estimators=550.....\n",
      "[CV 2/5; 180/360] END colsample_bytree=0.4, max_depth=6, n_estimators=550;, score=0.948 total time=   0.7s\n",
      "[CV 3/5; 180/360] START colsample_bytree=0.4, max_depth=6, n_estimators=550.....\n",
      "[CV 3/5; 180/360] END colsample_bytree=0.4, max_depth=6, n_estimators=550;, score=0.949 total time=   0.7s\n",
      "[CV 4/5; 180/360] START colsample_bytree=0.4, max_depth=6, n_estimators=550.....\n",
      "[CV 4/5; 180/360] END colsample_bytree=0.4, max_depth=6, n_estimators=550;, score=0.951 total time=   0.8s\n",
      "[CV 5/5; 180/360] START colsample_bytree=0.4, max_depth=6, n_estimators=550.....\n",
      "[CV 5/5; 180/360] END colsample_bytree=0.4, max_depth=6, n_estimators=550;, score=0.949 total time=   0.7s\n",
      "[CV 1/5; 181/360] START colsample_bytree=0.5, max_depth=1, n_estimators=300.....\n",
      "[CV 1/5; 181/360] END colsample_bytree=0.5, max_depth=1, n_estimators=300;, score=0.929 total time=   0.1s\n",
      "[CV 2/5; 181/360] START colsample_bytree=0.5, max_depth=1, n_estimators=300.....\n",
      "[CV 2/5; 181/360] END colsample_bytree=0.5, max_depth=1, n_estimators=300;, score=0.929 total time=   0.1s\n",
      "[CV 3/5; 181/360] START colsample_bytree=0.5, max_depth=1, n_estimators=300.....\n",
      "[CV 3/5; 181/360] END colsample_bytree=0.5, max_depth=1, n_estimators=300;, score=0.932 total time=   0.2s\n",
      "[CV 4/5; 181/360] START colsample_bytree=0.5, max_depth=1, n_estimators=300.....\n",
      "[CV 4/5; 181/360] END colsample_bytree=0.5, max_depth=1, n_estimators=300;, score=0.933 total time=   0.1s\n",
      "[CV 5/5; 181/360] START colsample_bytree=0.5, max_depth=1, n_estimators=300.....\n",
      "[CV 5/5; 181/360] END colsample_bytree=0.5, max_depth=1, n_estimators=300;, score=0.930 total time=   0.1s\n",
      "[CV 1/5; 182/360] START colsample_bytree=0.5, max_depth=1, n_estimators=350.....\n",
      "[CV 1/5; 182/360] END colsample_bytree=0.5, max_depth=1, n_estimators=350;, score=0.929 total time=   0.2s\n",
      "[CV 2/5; 182/360] START colsample_bytree=0.5, max_depth=1, n_estimators=350.....\n",
      "[CV 2/5; 182/360] END colsample_bytree=0.5, max_depth=1, n_estimators=350;, score=0.929 total time=   0.2s\n",
      "[CV 3/5; 182/360] START colsample_bytree=0.5, max_depth=1, n_estimators=350.....\n",
      "[CV 3/5; 182/360] END colsample_bytree=0.5, max_depth=1, n_estimators=350;, score=0.932 total time=   0.2s\n",
      "[CV 4/5; 182/360] START colsample_bytree=0.5, max_depth=1, n_estimators=350.....\n",
      "[CV 4/5; 182/360] END colsample_bytree=0.5, max_depth=1, n_estimators=350;, score=0.933 total time=   0.2s\n",
      "[CV 5/5; 182/360] START colsample_bytree=0.5, max_depth=1, n_estimators=350.....\n",
      "[CV 5/5; 182/360] END colsample_bytree=0.5, max_depth=1, n_estimators=350;, score=0.930 total time=   0.1s\n",
      "[CV 1/5; 183/360] START colsample_bytree=0.5, max_depth=1, n_estimators=400.....\n",
      "[CV 1/5; 183/360] END colsample_bytree=0.5, max_depth=1, n_estimators=400;, score=0.929 total time=   0.2s\n",
      "[CV 2/5; 183/360] START colsample_bytree=0.5, max_depth=1, n_estimators=400.....\n",
      "[CV 2/5; 183/360] END colsample_bytree=0.5, max_depth=1, n_estimators=400;, score=0.929 total time=   0.2s\n",
      "[CV 3/5; 183/360] START colsample_bytree=0.5, max_depth=1, n_estimators=400.....\n",
      "[CV 3/5; 183/360] END colsample_bytree=0.5, max_depth=1, n_estimators=400;, score=0.932 total time=   0.2s\n",
      "[CV 4/5; 183/360] START colsample_bytree=0.5, max_depth=1, n_estimators=400.....\n",
      "[CV 4/5; 183/360] END colsample_bytree=0.5, max_depth=1, n_estimators=400;, score=0.932 total time=   0.3s\n",
      "[CV 5/5; 183/360] START colsample_bytree=0.5, max_depth=1, n_estimators=400.....\n",
      "[CV 5/5; 183/360] END colsample_bytree=0.5, max_depth=1, n_estimators=400;, score=0.930 total time=   0.2s\n",
      "[CV 1/5; 184/360] START colsample_bytree=0.5, max_depth=1, n_estimators=450.....\n",
      "[CV 1/5; 184/360] END colsample_bytree=0.5, max_depth=1, n_estimators=450;, score=0.929 total time=   0.2s\n",
      "[CV 2/5; 184/360] START colsample_bytree=0.5, max_depth=1, n_estimators=450.....\n",
      "[CV 2/5; 184/360] END colsample_bytree=0.5, max_depth=1, n_estimators=450;, score=0.929 total time=   0.2s\n",
      "[CV 3/5; 184/360] START colsample_bytree=0.5, max_depth=1, n_estimators=450.....\n",
      "[CV 3/5; 184/360] END colsample_bytree=0.5, max_depth=1, n_estimators=450;, score=0.932 total time=   0.2s\n",
      "[CV 4/5; 184/360] START colsample_bytree=0.5, max_depth=1, n_estimators=450.....\n",
      "[CV 4/5; 184/360] END colsample_bytree=0.5, max_depth=1, n_estimators=450;, score=0.932 total time=   0.3s\n",
      "[CV 5/5; 184/360] START colsample_bytree=0.5, max_depth=1, n_estimators=450.....\n",
      "[CV 5/5; 184/360] END colsample_bytree=0.5, max_depth=1, n_estimators=450;, score=0.931 total time=   0.3s\n",
      "[CV 1/5; 185/360] START colsample_bytree=0.5, max_depth=1, n_estimators=500.....\n",
      "[CV 1/5; 185/360] END colsample_bytree=0.5, max_depth=1, n_estimators=500;, score=0.929 total time=   0.3s\n",
      "[CV 2/5; 185/360] START colsample_bytree=0.5, max_depth=1, n_estimators=500.....\n",
      "[CV 2/5; 185/360] END colsample_bytree=0.5, max_depth=1, n_estimators=500;, score=0.929 total time=   0.2s\n",
      "[CV 3/5; 185/360] START colsample_bytree=0.5, max_depth=1, n_estimators=500.....\n",
      "[CV 3/5; 185/360] END colsample_bytree=0.5, max_depth=1, n_estimators=500;, score=0.932 total time=   0.3s\n",
      "[CV 4/5; 185/360] START colsample_bytree=0.5, max_depth=1, n_estimators=500.....\n",
      "[CV 4/5; 185/360] END colsample_bytree=0.5, max_depth=1, n_estimators=500;, score=0.932 total time=   0.3s\n",
      "[CV 5/5; 185/360] START colsample_bytree=0.5, max_depth=1, n_estimators=500.....\n",
      "[CV 5/5; 185/360] END colsample_bytree=0.5, max_depth=1, n_estimators=500;, score=0.931 total time=   0.3s\n",
      "[CV 1/5; 186/360] START colsample_bytree=0.5, max_depth=1, n_estimators=550.....\n",
      "[CV 1/5; 186/360] END colsample_bytree=0.5, max_depth=1, n_estimators=550;, score=0.929 total time=   0.3s\n",
      "[CV 2/5; 186/360] START colsample_bytree=0.5, max_depth=1, n_estimators=550.....\n",
      "[CV 2/5; 186/360] END colsample_bytree=0.5, max_depth=1, n_estimators=550;, score=0.929 total time=   0.4s\n",
      "[CV 3/5; 186/360] START colsample_bytree=0.5, max_depth=1, n_estimators=550.....\n",
      "[CV 3/5; 186/360] END colsample_bytree=0.5, max_depth=1, n_estimators=550;, score=0.931 total time=   0.4s\n",
      "[CV 4/5; 186/360] START colsample_bytree=0.5, max_depth=1, n_estimators=550.....\n",
      "[CV 4/5; 186/360] END colsample_bytree=0.5, max_depth=1, n_estimators=550;, score=0.932 total time=   0.4s\n",
      "[CV 5/5; 186/360] START colsample_bytree=0.5, max_depth=1, n_estimators=550.....\n",
      "[CV 5/5; 186/360] END colsample_bytree=0.5, max_depth=1, n_estimators=550;, score=0.932 total time=   0.4s\n",
      "[CV 1/5; 187/360] START colsample_bytree=0.5, max_depth=2, n_estimators=300.....\n",
      "[CV 1/5; 187/360] END colsample_bytree=0.5, max_depth=2, n_estimators=300;, score=0.948 total time=   0.3s\n",
      "[CV 2/5; 187/360] START colsample_bytree=0.5, max_depth=2, n_estimators=300.....\n",
      "[CV 2/5; 187/360] END colsample_bytree=0.5, max_depth=2, n_estimators=300;, score=0.950 total time=   0.3s\n",
      "[CV 3/5; 187/360] START colsample_bytree=0.5, max_depth=2, n_estimators=300.....\n",
      "[CV 3/5; 187/360] END colsample_bytree=0.5, max_depth=2, n_estimators=300;, score=0.950 total time=   0.3s\n",
      "[CV 4/5; 187/360] START colsample_bytree=0.5, max_depth=2, n_estimators=300.....\n",
      "[CV 4/5; 187/360] END colsample_bytree=0.5, max_depth=2, n_estimators=300;, score=0.954 total time=   0.3s\n",
      "[CV 5/5; 187/360] START colsample_bytree=0.5, max_depth=2, n_estimators=300.....\n",
      "[CV 5/5; 187/360] END colsample_bytree=0.5, max_depth=2, n_estimators=300;, score=0.951 total time=   0.2s\n",
      "[CV 1/5; 188/360] START colsample_bytree=0.5, max_depth=2, n_estimators=350.....\n",
      "[CV 1/5; 188/360] END colsample_bytree=0.5, max_depth=2, n_estimators=350;, score=0.948 total time=   0.2s\n",
      "[CV 2/5; 188/360] START colsample_bytree=0.5, max_depth=2, n_estimators=350.....\n",
      "[CV 2/5; 188/360] END colsample_bytree=0.5, max_depth=2, n_estimators=350;, score=0.950 total time=   0.3s\n",
      "[CV 3/5; 188/360] START colsample_bytree=0.5, max_depth=2, n_estimators=350.....\n",
      "[CV 3/5; 188/360] END colsample_bytree=0.5, max_depth=2, n_estimators=350;, score=0.951 total time=   0.2s\n",
      "[CV 4/5; 188/360] START colsample_bytree=0.5, max_depth=2, n_estimators=350.....\n",
      "[CV 4/5; 188/360] END colsample_bytree=0.5, max_depth=2, n_estimators=350;, score=0.954 total time=   0.2s\n",
      "[CV 5/5; 188/360] START colsample_bytree=0.5, max_depth=2, n_estimators=350.....\n",
      "[CV 5/5; 188/360] END colsample_bytree=0.5, max_depth=2, n_estimators=350;, score=0.951 total time=   0.2s\n",
      "[CV 1/5; 189/360] START colsample_bytree=0.5, max_depth=2, n_estimators=400.....\n",
      "[CV 1/5; 189/360] END colsample_bytree=0.5, max_depth=2, n_estimators=400;, score=0.949 total time=   0.3s\n",
      "[CV 2/5; 189/360] START colsample_bytree=0.5, max_depth=2, n_estimators=400.....\n",
      "[CV 2/5; 189/360] END colsample_bytree=0.5, max_depth=2, n_estimators=400;, score=0.950 total time=   0.2s\n",
      "[CV 3/5; 189/360] START colsample_bytree=0.5, max_depth=2, n_estimators=400.....\n",
      "[CV 3/5; 189/360] END colsample_bytree=0.5, max_depth=2, n_estimators=400;, score=0.951 total time=   0.2s\n",
      "[CV 4/5; 189/360] START colsample_bytree=0.5, max_depth=2, n_estimators=400.....\n",
      "[CV 4/5; 189/360] END colsample_bytree=0.5, max_depth=2, n_estimators=400;, score=0.954 total time=   0.2s\n",
      "[CV 5/5; 189/360] START colsample_bytree=0.5, max_depth=2, n_estimators=400.....\n",
      "[CV 5/5; 189/360] END colsample_bytree=0.5, max_depth=2, n_estimators=400;, score=0.951 total time=   0.3s\n",
      "[CV 1/5; 190/360] START colsample_bytree=0.5, max_depth=2, n_estimators=450.....\n",
      "[CV 1/5; 190/360] END colsample_bytree=0.5, max_depth=2, n_estimators=450;, score=0.949 total time=   0.3s\n",
      "[CV 2/5; 190/360] START colsample_bytree=0.5, max_depth=2, n_estimators=450.....\n",
      "[CV 2/5; 190/360] END colsample_bytree=0.5, max_depth=2, n_estimators=450;, score=0.950 total time=   0.3s\n",
      "[CV 3/5; 190/360] START colsample_bytree=0.5, max_depth=2, n_estimators=450.....\n",
      "[CV 3/5; 190/360] END colsample_bytree=0.5, max_depth=2, n_estimators=450;, score=0.951 total time=   0.3s\n",
      "[CV 4/5; 190/360] START colsample_bytree=0.5, max_depth=2, n_estimators=450.....\n",
      "[CV 4/5; 190/360] END colsample_bytree=0.5, max_depth=2, n_estimators=450;, score=0.954 total time=   0.4s\n",
      "[CV 5/5; 190/360] START colsample_bytree=0.5, max_depth=2, n_estimators=450.....\n",
      "[CV 5/5; 190/360] END colsample_bytree=0.5, max_depth=2, n_estimators=450;, score=0.952 total time=   0.3s\n",
      "[CV 1/5; 191/360] START colsample_bytree=0.5, max_depth=2, n_estimators=500.....\n",
      "[CV 1/5; 191/360] END colsample_bytree=0.5, max_depth=2, n_estimators=500;, score=0.949 total time=   0.6s\n",
      "[CV 2/5; 191/360] START colsample_bytree=0.5, max_depth=2, n_estimators=500.....\n",
      "[CV 2/5; 191/360] END colsample_bytree=0.5, max_depth=2, n_estimators=500;, score=0.950 total time=   0.5s\n",
      "[CV 3/5; 191/360] START colsample_bytree=0.5, max_depth=2, n_estimators=500.....\n",
      "[CV 3/5; 191/360] END colsample_bytree=0.5, max_depth=2, n_estimators=500;, score=0.951 total time=   0.6s\n",
      "[CV 4/5; 191/360] START colsample_bytree=0.5, max_depth=2, n_estimators=500.....\n",
      "[CV 4/5; 191/360] END colsample_bytree=0.5, max_depth=2, n_estimators=500;, score=0.954 total time=   0.6s\n",
      "[CV 5/5; 191/360] START colsample_bytree=0.5, max_depth=2, n_estimators=500.....\n",
      "[CV 5/5; 191/360] END colsample_bytree=0.5, max_depth=2, n_estimators=500;, score=0.952 total time=   0.5s\n",
      "[CV 1/5; 192/360] START colsample_bytree=0.5, max_depth=2, n_estimators=550.....\n",
      "[CV 1/5; 192/360] END colsample_bytree=0.5, max_depth=2, n_estimators=550;, score=0.948 total time=   0.6s\n",
      "[CV 2/5; 192/360] START colsample_bytree=0.5, max_depth=2, n_estimators=550.....\n",
      "[CV 2/5; 192/360] END colsample_bytree=0.5, max_depth=2, n_estimators=550;, score=0.950 total time=   0.6s\n",
      "[CV 3/5; 192/360] START colsample_bytree=0.5, max_depth=2, n_estimators=550.....\n",
      "[CV 3/5; 192/360] END colsample_bytree=0.5, max_depth=2, n_estimators=550;, score=0.951 total time=   0.7s\n",
      "[CV 4/5; 192/360] START colsample_bytree=0.5, max_depth=2, n_estimators=550.....\n",
      "[CV 4/5; 192/360] END colsample_bytree=0.5, max_depth=2, n_estimators=550;, score=0.954 total time=   0.6s\n",
      "[CV 5/5; 192/360] START colsample_bytree=0.5, max_depth=2, n_estimators=550.....\n",
      "[CV 5/5; 192/360] END colsample_bytree=0.5, max_depth=2, n_estimators=550;, score=0.952 total time=   0.7s\n",
      "[CV 1/5; 193/360] START colsample_bytree=0.5, max_depth=3, n_estimators=300.....\n",
      "[CV 1/5; 193/360] END colsample_bytree=0.5, max_depth=3, n_estimators=300;, score=0.950 total time=   0.5s\n",
      "[CV 2/5; 193/360] START colsample_bytree=0.5, max_depth=3, n_estimators=300.....\n",
      "[CV 2/5; 193/360] END colsample_bytree=0.5, max_depth=3, n_estimators=300;, score=0.951 total time=   0.5s\n",
      "[CV 3/5; 193/360] START colsample_bytree=0.5, max_depth=3, n_estimators=300.....\n",
      "[CV 3/5; 193/360] END colsample_bytree=0.5, max_depth=3, n_estimators=300;, score=0.951 total time=   0.5s\n",
      "[CV 4/5; 193/360] START colsample_bytree=0.5, max_depth=3, n_estimators=300.....\n",
      "[CV 4/5; 193/360] END colsample_bytree=0.5, max_depth=3, n_estimators=300;, score=0.955 total time=   0.5s\n",
      "[CV 5/5; 193/360] START colsample_bytree=0.5, max_depth=3, n_estimators=300.....\n",
      "[CV 5/5; 193/360] END colsample_bytree=0.5, max_depth=3, n_estimators=300;, score=0.952 total time=   0.4s\n",
      "[CV 1/5; 194/360] START colsample_bytree=0.5, max_depth=3, n_estimators=350.....\n",
      "[CV 1/5; 194/360] END colsample_bytree=0.5, max_depth=3, n_estimators=350;, score=0.950 total time=   0.4s\n",
      "[CV 2/5; 194/360] START colsample_bytree=0.5, max_depth=3, n_estimators=350.....\n",
      "[CV 2/5; 194/360] END colsample_bytree=0.5, max_depth=3, n_estimators=350;, score=0.951 total time=   0.4s\n",
      "[CV 3/5; 194/360] START colsample_bytree=0.5, max_depth=3, n_estimators=350.....\n",
      "[CV 3/5; 194/360] END colsample_bytree=0.5, max_depth=3, n_estimators=350;, score=0.951 total time=   0.4s\n",
      "[CV 4/5; 194/360] START colsample_bytree=0.5, max_depth=3, n_estimators=350.....\n",
      "[CV 4/5; 194/360] END colsample_bytree=0.5, max_depth=3, n_estimators=350;, score=0.955 total time=   0.3s\n",
      "[CV 5/5; 194/360] START colsample_bytree=0.5, max_depth=3, n_estimators=350.....\n",
      "[CV 5/5; 194/360] END colsample_bytree=0.5, max_depth=3, n_estimators=350;, score=0.953 total time=   0.3s\n",
      "[CV 1/5; 195/360] START colsample_bytree=0.5, max_depth=3, n_estimators=400.....\n",
      "[CV 1/5; 195/360] END colsample_bytree=0.5, max_depth=3, n_estimators=400;, score=0.950 total time=   0.3s\n",
      "[CV 2/5; 195/360] START colsample_bytree=0.5, max_depth=3, n_estimators=400.....\n",
      "[CV 2/5; 195/360] END colsample_bytree=0.5, max_depth=3, n_estimators=400;, score=0.951 total time=   0.4s\n",
      "[CV 3/5; 195/360] START colsample_bytree=0.5, max_depth=3, n_estimators=400.....\n",
      "[CV 3/5; 195/360] END colsample_bytree=0.5, max_depth=3, n_estimators=400;, score=0.950 total time=   0.3s\n",
      "[CV 4/5; 195/360] START colsample_bytree=0.5, max_depth=3, n_estimators=400.....\n",
      "[CV 4/5; 195/360] END colsample_bytree=0.5, max_depth=3, n_estimators=400;, score=0.955 total time=   0.4s\n",
      "[CV 5/5; 195/360] START colsample_bytree=0.5, max_depth=3, n_estimators=400.....\n",
      "[CV 5/5; 195/360] END colsample_bytree=0.5, max_depth=3, n_estimators=400;, score=0.952 total time=   0.4s\n",
      "[CV 1/5; 196/360] START colsample_bytree=0.5, max_depth=3, n_estimators=450.....\n",
      "[CV 1/5; 196/360] END colsample_bytree=0.5, max_depth=3, n_estimators=450;, score=0.949 total time=   0.3s\n",
      "[CV 2/5; 196/360] START colsample_bytree=0.5, max_depth=3, n_estimators=450.....\n",
      "[CV 2/5; 196/360] END colsample_bytree=0.5, max_depth=3, n_estimators=450;, score=0.952 total time=   0.4s\n",
      "[CV 3/5; 196/360] START colsample_bytree=0.5, max_depth=3, n_estimators=450.....\n",
      "[CV 3/5; 196/360] END colsample_bytree=0.5, max_depth=3, n_estimators=450;, score=0.950 total time=   0.4s\n",
      "[CV 4/5; 196/360] START colsample_bytree=0.5, max_depth=3, n_estimators=450.....\n",
      "[CV 4/5; 196/360] END colsample_bytree=0.5, max_depth=3, n_estimators=450;, score=0.955 total time=   0.3s\n",
      "[CV 5/5; 196/360] START colsample_bytree=0.5, max_depth=3, n_estimators=450.....\n",
      "[CV 5/5; 196/360] END colsample_bytree=0.5, max_depth=3, n_estimators=450;, score=0.953 total time=   0.3s\n",
      "[CV 1/5; 197/360] START colsample_bytree=0.5, max_depth=3, n_estimators=500.....\n",
      "[CV 1/5; 197/360] END colsample_bytree=0.5, max_depth=3, n_estimators=500;, score=0.950 total time=   0.5s\n",
      "[CV 2/5; 197/360] START colsample_bytree=0.5, max_depth=3, n_estimators=500.....\n",
      "[CV 2/5; 197/360] END colsample_bytree=0.5, max_depth=3, n_estimators=500;, score=0.951 total time=   0.6s\n",
      "[CV 3/5; 197/360] START colsample_bytree=0.5, max_depth=3, n_estimators=500.....\n",
      "[CV 3/5; 197/360] END colsample_bytree=0.5, max_depth=3, n_estimators=500;, score=0.950 total time=   0.4s\n",
      "[CV 4/5; 197/360] START colsample_bytree=0.5, max_depth=3, n_estimators=500.....\n",
      "[CV 4/5; 197/360] END colsample_bytree=0.5, max_depth=3, n_estimators=500;, score=0.954 total time=   0.4s\n",
      "[CV 5/5; 197/360] START colsample_bytree=0.5, max_depth=3, n_estimators=500.....\n",
      "[CV 5/5; 197/360] END colsample_bytree=0.5, max_depth=3, n_estimators=500;, score=0.953 total time=   0.4s\n",
      "[CV 1/5; 198/360] START colsample_bytree=0.5, max_depth=3, n_estimators=550.....\n",
      "[CV 1/5; 198/360] END colsample_bytree=0.5, max_depth=3, n_estimators=550;, score=0.949 total time=   0.5s\n",
      "[CV 2/5; 198/360] START colsample_bytree=0.5, max_depth=3, n_estimators=550.....\n",
      "[CV 2/5; 198/360] END colsample_bytree=0.5, max_depth=3, n_estimators=550;, score=0.951 total time=   0.5s\n",
      "[CV 3/5; 198/360] START colsample_bytree=0.5, max_depth=3, n_estimators=550.....\n",
      "[CV 3/5; 198/360] END colsample_bytree=0.5, max_depth=3, n_estimators=550;, score=0.950 total time=   0.4s\n",
      "[CV 4/5; 198/360] START colsample_bytree=0.5, max_depth=3, n_estimators=550.....\n",
      "[CV 4/5; 198/360] END colsample_bytree=0.5, max_depth=3, n_estimators=550;, score=0.954 total time=   0.4s\n",
      "[CV 5/5; 198/360] START colsample_bytree=0.5, max_depth=3, n_estimators=550.....\n",
      "[CV 5/5; 198/360] END colsample_bytree=0.5, max_depth=3, n_estimators=550;, score=0.952 total time=   0.5s\n",
      "[CV 1/5; 199/360] START colsample_bytree=0.5, max_depth=4, n_estimators=300.....\n",
      "[CV 1/5; 199/360] END colsample_bytree=0.5, max_depth=4, n_estimators=300;, score=0.950 total time=   0.3s\n",
      "[CV 2/5; 199/360] START colsample_bytree=0.5, max_depth=4, n_estimators=300.....\n",
      "[CV 2/5; 199/360] END colsample_bytree=0.5, max_depth=4, n_estimators=300;, score=0.950 total time=   0.3s\n",
      "[CV 3/5; 199/360] START colsample_bytree=0.5, max_depth=4, n_estimators=300.....\n",
      "[CV 3/5; 199/360] END colsample_bytree=0.5, max_depth=4, n_estimators=300;, score=0.951 total time=   0.3s\n",
      "[CV 4/5; 199/360] START colsample_bytree=0.5, max_depth=4, n_estimators=300.....\n",
      "[CV 4/5; 199/360] END colsample_bytree=0.5, max_depth=4, n_estimators=300;, score=0.955 total time=   0.4s\n",
      "[CV 5/5; 199/360] START colsample_bytree=0.5, max_depth=4, n_estimators=300.....\n",
      "[CV 5/5; 199/360] END colsample_bytree=0.5, max_depth=4, n_estimators=300;, score=0.953 total time=   0.4s\n",
      "[CV 1/5; 200/360] START colsample_bytree=0.5, max_depth=4, n_estimators=350.....\n",
      "[CV 1/5; 200/360] END colsample_bytree=0.5, max_depth=4, n_estimators=350;, score=0.949 total time=   0.4s\n",
      "[CV 2/5; 200/360] START colsample_bytree=0.5, max_depth=4, n_estimators=350.....\n",
      "[CV 2/5; 200/360] END colsample_bytree=0.5, max_depth=4, n_estimators=350;, score=0.949 total time=   0.4s\n",
      "[CV 3/5; 200/360] START colsample_bytree=0.5, max_depth=4, n_estimators=350.....\n",
      "[CV 3/5; 200/360] END colsample_bytree=0.5, max_depth=4, n_estimators=350;, score=0.951 total time=   0.4s\n",
      "[CV 4/5; 200/360] START colsample_bytree=0.5, max_depth=4, n_estimators=350.....\n",
      "[CV 4/5; 200/360] END colsample_bytree=0.5, max_depth=4, n_estimators=350;, score=0.955 total time=   0.4s\n",
      "[CV 5/5; 200/360] START colsample_bytree=0.5, max_depth=4, n_estimators=350.....\n",
      "[CV 5/5; 200/360] END colsample_bytree=0.5, max_depth=4, n_estimators=350;, score=0.953 total time=   0.3s\n",
      "[CV 1/5; 201/360] START colsample_bytree=0.5, max_depth=4, n_estimators=400.....\n",
      "[CV 1/5; 201/360] END colsample_bytree=0.5, max_depth=4, n_estimators=400;, score=0.950 total time=   0.4s\n",
      "[CV 2/5; 201/360] START colsample_bytree=0.5, max_depth=4, n_estimators=400.....\n",
      "[CV 2/5; 201/360] END colsample_bytree=0.5, max_depth=4, n_estimators=400;, score=0.949 total time=   0.4s\n",
      "[CV 3/5; 201/360] START colsample_bytree=0.5, max_depth=4, n_estimators=400.....\n",
      "[CV 3/5; 201/360] END colsample_bytree=0.5, max_depth=4, n_estimators=400;, score=0.951 total time=   0.4s\n",
      "[CV 4/5; 201/360] START colsample_bytree=0.5, max_depth=4, n_estimators=400.....\n",
      "[CV 4/5; 201/360] END colsample_bytree=0.5, max_depth=4, n_estimators=400;, score=0.954 total time=   0.4s\n",
      "[CV 5/5; 201/360] START colsample_bytree=0.5, max_depth=4, n_estimators=400.....\n",
      "[CV 5/5; 201/360] END colsample_bytree=0.5, max_depth=4, n_estimators=400;, score=0.954 total time=   0.4s\n",
      "[CV 1/5; 202/360] START colsample_bytree=0.5, max_depth=4, n_estimators=450.....\n",
      "[CV 1/5; 202/360] END colsample_bytree=0.5, max_depth=4, n_estimators=450;, score=0.949 total time=   0.5s\n",
      "[CV 2/5; 202/360] START colsample_bytree=0.5, max_depth=4, n_estimators=450.....\n",
      "[CV 2/5; 202/360] END colsample_bytree=0.5, max_depth=4, n_estimators=450;, score=0.949 total time=   0.5s\n",
      "[CV 3/5; 202/360] START colsample_bytree=0.5, max_depth=4, n_estimators=450.....\n",
      "[CV 3/5; 202/360] END colsample_bytree=0.5, max_depth=4, n_estimators=450;, score=0.951 total time=   0.4s\n",
      "[CV 4/5; 202/360] START colsample_bytree=0.5, max_depth=4, n_estimators=450.....\n",
      "[CV 4/5; 202/360] END colsample_bytree=0.5, max_depth=4, n_estimators=450;, score=0.954 total time=   0.5s\n",
      "[CV 5/5; 202/360] START colsample_bytree=0.5, max_depth=4, n_estimators=450.....\n",
      "[CV 5/5; 202/360] END colsample_bytree=0.5, max_depth=4, n_estimators=450;, score=0.953 total time=   0.4s\n",
      "[CV 1/5; 203/360] START colsample_bytree=0.5, max_depth=4, n_estimators=500.....\n",
      "[CV 1/5; 203/360] END colsample_bytree=0.5, max_depth=4, n_estimators=500;, score=0.949 total time=   0.5s\n",
      "[CV 2/5; 203/360] START colsample_bytree=0.5, max_depth=4, n_estimators=500.....\n",
      "[CV 2/5; 203/360] END colsample_bytree=0.5, max_depth=4, n_estimators=500;, score=0.949 total time=   0.5s\n",
      "[CV 3/5; 203/360] START colsample_bytree=0.5, max_depth=4, n_estimators=500.....\n",
      "[CV 3/5; 203/360] END colsample_bytree=0.5, max_depth=4, n_estimators=500;, score=0.950 total time=   0.5s\n",
      "[CV 4/5; 203/360] START colsample_bytree=0.5, max_depth=4, n_estimators=500.....\n",
      "[CV 4/5; 203/360] END colsample_bytree=0.5, max_depth=4, n_estimators=500;, score=0.954 total time=   0.5s\n",
      "[CV 5/5; 203/360] START colsample_bytree=0.5, max_depth=4, n_estimators=500.....\n",
      "[CV 5/5; 203/360] END colsample_bytree=0.5, max_depth=4, n_estimators=500;, score=0.952 total time=   0.5s\n",
      "[CV 1/5; 204/360] START colsample_bytree=0.5, max_depth=4, n_estimators=550.....\n",
      "[CV 1/5; 204/360] END colsample_bytree=0.5, max_depth=4, n_estimators=550;, score=0.948 total time=   0.6s\n",
      "[CV 2/5; 204/360] START colsample_bytree=0.5, max_depth=4, n_estimators=550.....\n",
      "[CV 2/5; 204/360] END colsample_bytree=0.5, max_depth=4, n_estimators=550;, score=0.949 total time=   0.6s\n",
      "[CV 3/5; 204/360] START colsample_bytree=0.5, max_depth=4, n_estimators=550.....\n",
      "[CV 3/5; 204/360] END colsample_bytree=0.5, max_depth=4, n_estimators=550;, score=0.950 total time=   0.6s\n",
      "[CV 4/5; 204/360] START colsample_bytree=0.5, max_depth=4, n_estimators=550.....\n",
      "[CV 4/5; 204/360] END colsample_bytree=0.5, max_depth=4, n_estimators=550;, score=0.954 total time=   0.5s\n",
      "[CV 5/5; 204/360] START colsample_bytree=0.5, max_depth=4, n_estimators=550.....\n",
      "[CV 5/5; 204/360] END colsample_bytree=0.5, max_depth=4, n_estimators=550;, score=0.952 total time=   0.5s\n",
      "[CV 1/5; 205/360] START colsample_bytree=0.5, max_depth=5, n_estimators=300.....\n",
      "[CV 1/5; 205/360] END colsample_bytree=0.5, max_depth=5, n_estimators=300;, score=0.949 total time=   0.3s\n",
      "[CV 2/5; 205/360] START colsample_bytree=0.5, max_depth=5, n_estimators=300.....\n",
      "[CV 2/5; 205/360] END colsample_bytree=0.5, max_depth=5, n_estimators=300;, score=0.950 total time=   0.3s\n",
      "[CV 3/5; 205/360] START colsample_bytree=0.5, max_depth=5, n_estimators=300.....\n",
      "[CV 3/5; 205/360] END colsample_bytree=0.5, max_depth=5, n_estimators=300;, score=0.952 total time=   0.5s\n",
      "[CV 4/5; 205/360] START colsample_bytree=0.5, max_depth=5, n_estimators=300.....\n",
      "[CV 4/5; 205/360] END colsample_bytree=0.5, max_depth=5, n_estimators=300;, score=0.954 total time=   0.5s\n",
      "[CV 5/5; 205/360] START colsample_bytree=0.5, max_depth=5, n_estimators=300.....\n",
      "[CV 5/5; 205/360] END colsample_bytree=0.5, max_depth=5, n_estimators=300;, score=0.952 total time=   0.5s\n",
      "[CV 1/5; 206/360] START colsample_bytree=0.5, max_depth=5, n_estimators=350.....\n",
      "[CV 1/5; 206/360] END colsample_bytree=0.5, max_depth=5, n_estimators=350;, score=0.949 total time=   0.6s\n",
      "[CV 2/5; 206/360] START colsample_bytree=0.5, max_depth=5, n_estimators=350.....\n",
      "[CV 2/5; 206/360] END colsample_bytree=0.5, max_depth=5, n_estimators=350;, score=0.949 total time=   0.5s\n",
      "[CV 3/5; 206/360] START colsample_bytree=0.5, max_depth=5, n_estimators=350.....\n",
      "[CV 3/5; 206/360] END colsample_bytree=0.5, max_depth=5, n_estimators=350;, score=0.951 total time=   0.5s\n",
      "[CV 4/5; 206/360] START colsample_bytree=0.5, max_depth=5, n_estimators=350.....\n",
      "[CV 4/5; 206/360] END colsample_bytree=0.5, max_depth=5, n_estimators=350;, score=0.954 total time=   0.4s\n",
      "[CV 5/5; 206/360] START colsample_bytree=0.5, max_depth=5, n_estimators=350.....\n",
      "[CV 5/5; 206/360] END colsample_bytree=0.5, max_depth=5, n_estimators=350;, score=0.951 total time=   0.5s\n",
      "[CV 1/5; 207/360] START colsample_bytree=0.5, max_depth=5, n_estimators=400.....\n",
      "[CV 1/5; 207/360] END colsample_bytree=0.5, max_depth=5, n_estimators=400;, score=0.947 total time=   0.5s\n",
      "[CV 2/5; 207/360] START colsample_bytree=0.5, max_depth=5, n_estimators=400.....\n",
      "[CV 2/5; 207/360] END colsample_bytree=0.5, max_depth=5, n_estimators=400;, score=0.949 total time=   0.4s\n",
      "[CV 3/5; 207/360] START colsample_bytree=0.5, max_depth=5, n_estimators=400.....\n",
      "[CV 3/5; 207/360] END colsample_bytree=0.5, max_depth=5, n_estimators=400;, score=0.951 total time=   0.5s\n",
      "[CV 4/5; 207/360] START colsample_bytree=0.5, max_depth=5, n_estimators=400.....\n",
      "[CV 4/5; 207/360] END colsample_bytree=0.5, max_depth=5, n_estimators=400;, score=0.953 total time=   0.5s\n",
      "[CV 5/5; 207/360] START colsample_bytree=0.5, max_depth=5, n_estimators=400.....\n",
      "[CV 5/5; 207/360] END colsample_bytree=0.5, max_depth=5, n_estimators=400;, score=0.950 total time=   0.5s\n",
      "[CV 1/5; 208/360] START colsample_bytree=0.5, max_depth=5, n_estimators=450.....\n",
      "[CV 1/5; 208/360] END colsample_bytree=0.5, max_depth=5, n_estimators=450;, score=0.947 total time=   0.6s\n",
      "[CV 2/5; 208/360] START colsample_bytree=0.5, max_depth=5, n_estimators=450.....\n",
      "[CV 2/5; 208/360] END colsample_bytree=0.5, max_depth=5, n_estimators=450;, score=0.949 total time=   0.5s\n",
      "[CV 3/5; 208/360] START colsample_bytree=0.5, max_depth=5, n_estimators=450.....\n",
      "[CV 3/5; 208/360] END colsample_bytree=0.5, max_depth=5, n_estimators=450;, score=0.950 total time=   0.6s\n",
      "[CV 4/5; 208/360] START colsample_bytree=0.5, max_depth=5, n_estimators=450.....\n",
      "[CV 4/5; 208/360] END colsample_bytree=0.5, max_depth=5, n_estimators=450;, score=0.953 total time=   0.5s\n",
      "[CV 5/5; 208/360] START colsample_bytree=0.5, max_depth=5, n_estimators=450.....\n",
      "[CV 5/5; 208/360] END colsample_bytree=0.5, max_depth=5, n_estimators=450;, score=0.950 total time=   0.5s\n",
      "[CV 1/5; 209/360] START colsample_bytree=0.5, max_depth=5, n_estimators=500.....\n",
      "[CV 1/5; 209/360] END colsample_bytree=0.5, max_depth=5, n_estimators=500;, score=0.947 total time=   0.6s\n",
      "[CV 2/5; 209/360] START colsample_bytree=0.5, max_depth=5, n_estimators=500.....\n",
      "[CV 2/5; 209/360] END colsample_bytree=0.5, max_depth=5, n_estimators=500;, score=0.949 total time=   0.6s\n",
      "[CV 3/5; 209/360] START colsample_bytree=0.5, max_depth=5, n_estimators=500.....\n",
      "[CV 3/5; 209/360] END colsample_bytree=0.5, max_depth=5, n_estimators=500;, score=0.951 total time=   0.6s\n",
      "[CV 4/5; 209/360] START colsample_bytree=0.5, max_depth=5, n_estimators=500.....\n",
      "[CV 4/5; 209/360] END colsample_bytree=0.5, max_depth=5, n_estimators=500;, score=0.953 total time=   0.6s\n",
      "[CV 5/5; 209/360] START colsample_bytree=0.5, max_depth=5, n_estimators=500.....\n",
      "[CV 5/5; 209/360] END colsample_bytree=0.5, max_depth=5, n_estimators=500;, score=0.950 total time=   0.6s\n",
      "[CV 1/5; 210/360] START colsample_bytree=0.5, max_depth=5, n_estimators=550.....\n",
      "[CV 1/5; 210/360] END colsample_bytree=0.5, max_depth=5, n_estimators=550;, score=0.947 total time=   0.7s\n",
      "[CV 2/5; 210/360] START colsample_bytree=0.5, max_depth=5, n_estimators=550.....\n",
      "[CV 2/5; 210/360] END colsample_bytree=0.5, max_depth=5, n_estimators=550;, score=0.949 total time=   0.7s\n",
      "[CV 3/5; 210/360] START colsample_bytree=0.5, max_depth=5, n_estimators=550.....\n",
      "[CV 3/5; 210/360] END colsample_bytree=0.5, max_depth=5, n_estimators=550;, score=0.950 total time=   0.8s\n",
      "[CV 4/5; 210/360] START colsample_bytree=0.5, max_depth=5, n_estimators=550.....\n",
      "[CV 4/5; 210/360] END colsample_bytree=0.5, max_depth=5, n_estimators=550;, score=0.953 total time=   0.8s\n",
      "[CV 5/5; 210/360] START colsample_bytree=0.5, max_depth=5, n_estimators=550.....\n",
      "[CV 5/5; 210/360] END colsample_bytree=0.5, max_depth=5, n_estimators=550;, score=0.950 total time=   0.8s\n",
      "[CV 1/5; 211/360] START colsample_bytree=0.5, max_depth=6, n_estimators=300.....\n",
      "[CV 1/5; 211/360] END colsample_bytree=0.5, max_depth=6, n_estimators=300;, score=0.945 total time=   0.5s\n",
      "[CV 2/5; 211/360] START colsample_bytree=0.5, max_depth=6, n_estimators=300.....\n",
      "[CV 2/5; 211/360] END colsample_bytree=0.5, max_depth=6, n_estimators=300;, score=0.949 total time=   0.4s\n",
      "[CV 3/5; 211/360] START colsample_bytree=0.5, max_depth=6, n_estimators=300.....\n",
      "[CV 3/5; 211/360] END colsample_bytree=0.5, max_depth=6, n_estimators=300;, score=0.949 total time=   0.4s\n",
      "[CV 4/5; 211/360] START colsample_bytree=0.5, max_depth=6, n_estimators=300.....\n",
      "[CV 4/5; 211/360] END colsample_bytree=0.5, max_depth=6, n_estimators=300;, score=0.953 total time=   0.4s\n",
      "[CV 5/5; 211/360] START colsample_bytree=0.5, max_depth=6, n_estimators=300.....\n",
      "[CV 5/5; 211/360] END colsample_bytree=0.5, max_depth=6, n_estimators=300;, score=0.949 total time=   0.4s\n",
      "[CV 1/5; 212/360] START colsample_bytree=0.5, max_depth=6, n_estimators=350.....\n",
      "[CV 1/5; 212/360] END colsample_bytree=0.5, max_depth=6, n_estimators=350;, score=0.945 total time=   0.6s\n",
      "[CV 2/5; 212/360] START colsample_bytree=0.5, max_depth=6, n_estimators=350.....\n",
      "[CV 2/5; 212/360] END colsample_bytree=0.5, max_depth=6, n_estimators=350;, score=0.948 total time=   0.5s\n",
      "[CV 3/5; 212/360] START colsample_bytree=0.5, max_depth=6, n_estimators=350.....\n",
      "[CV 3/5; 212/360] END colsample_bytree=0.5, max_depth=6, n_estimators=350;, score=0.949 total time=   0.5s\n",
      "[CV 4/5; 212/360] START colsample_bytree=0.5, max_depth=6, n_estimators=350.....\n",
      "[CV 4/5; 212/360] END colsample_bytree=0.5, max_depth=6, n_estimators=350;, score=0.953 total time=   0.5s\n",
      "[CV 5/5; 212/360] START colsample_bytree=0.5, max_depth=6, n_estimators=350.....\n",
      "[CV 5/5; 212/360] END colsample_bytree=0.5, max_depth=6, n_estimators=350;, score=0.949 total time=   0.5s\n",
      "[CV 1/5; 213/360] START colsample_bytree=0.5, max_depth=6, n_estimators=400.....\n",
      "[CV 1/5; 213/360] END colsample_bytree=0.5, max_depth=6, n_estimators=400;, score=0.945 total time=   0.5s\n",
      "[CV 2/5; 213/360] START colsample_bytree=0.5, max_depth=6, n_estimators=400.....\n",
      "[CV 2/5; 213/360] END colsample_bytree=0.5, max_depth=6, n_estimators=400;, score=0.948 total time=   0.6s\n",
      "[CV 3/5; 213/360] START colsample_bytree=0.5, max_depth=6, n_estimators=400.....\n",
      "[CV 3/5; 213/360] END colsample_bytree=0.5, max_depth=6, n_estimators=400;, score=0.949 total time=   0.5s\n",
      "[CV 4/5; 213/360] START colsample_bytree=0.5, max_depth=6, n_estimators=400.....\n",
      "[CV 4/5; 213/360] END colsample_bytree=0.5, max_depth=6, n_estimators=400;, score=0.953 total time=   0.5s\n",
      "[CV 5/5; 213/360] START colsample_bytree=0.5, max_depth=6, n_estimators=400.....\n",
      "[CV 5/5; 213/360] END colsample_bytree=0.5, max_depth=6, n_estimators=400;, score=0.949 total time=   0.6s\n",
      "[CV 1/5; 214/360] START colsample_bytree=0.5, max_depth=6, n_estimators=450.....\n",
      "[CV 1/5; 214/360] END colsample_bytree=0.5, max_depth=6, n_estimators=450;, score=0.945 total time=   0.6s\n",
      "[CV 2/5; 214/360] START colsample_bytree=0.5, max_depth=6, n_estimators=450.....\n",
      "[CV 2/5; 214/360] END colsample_bytree=0.5, max_depth=6, n_estimators=450;, score=0.947 total time=   0.6s\n",
      "[CV 3/5; 214/360] START colsample_bytree=0.5, max_depth=6, n_estimators=450.....\n",
      "[CV 3/5; 214/360] END colsample_bytree=0.5, max_depth=6, n_estimators=450;, score=0.948 total time=   0.8s\n",
      "[CV 4/5; 214/360] START colsample_bytree=0.5, max_depth=6, n_estimators=450.....\n",
      "[CV 4/5; 214/360] END colsample_bytree=0.5, max_depth=6, n_estimators=450;, score=0.952 total time=   0.8s\n",
      "[CV 5/5; 214/360] START colsample_bytree=0.5, max_depth=6, n_estimators=450.....\n",
      "[CV 5/5; 214/360] END colsample_bytree=0.5, max_depth=6, n_estimators=450;, score=0.949 total time=   0.8s\n",
      "[CV 1/5; 215/360] START colsample_bytree=0.5, max_depth=6, n_estimators=500.....\n",
      "[CV 1/5; 215/360] END colsample_bytree=0.5, max_depth=6, n_estimators=500;, score=0.944 total time=   1.1s\n",
      "[CV 2/5; 215/360] START colsample_bytree=0.5, max_depth=6, n_estimators=500.....\n",
      "[CV 2/5; 215/360] END colsample_bytree=0.5, max_depth=6, n_estimators=500;, score=0.947 total time=   1.0s\n",
      "[CV 3/5; 215/360] START colsample_bytree=0.5, max_depth=6, n_estimators=500.....\n",
      "[CV 3/5; 215/360] END colsample_bytree=0.5, max_depth=6, n_estimators=500;, score=0.948 total time=   0.9s\n",
      "[CV 4/5; 215/360] START colsample_bytree=0.5, max_depth=6, n_estimators=500.....\n",
      "[CV 4/5; 215/360] END colsample_bytree=0.5, max_depth=6, n_estimators=500;, score=0.952 total time=   0.9s\n",
      "[CV 5/5; 215/360] START colsample_bytree=0.5, max_depth=6, n_estimators=500.....\n",
      "[CV 5/5; 215/360] END colsample_bytree=0.5, max_depth=6, n_estimators=500;, score=0.949 total time=   0.9s\n",
      "[CV 1/5; 216/360] START colsample_bytree=0.5, max_depth=6, n_estimators=550.....\n",
      "[CV 1/5; 216/360] END colsample_bytree=0.5, max_depth=6, n_estimators=550;, score=0.945 total time=   0.8s\n",
      "[CV 2/5; 216/360] START colsample_bytree=0.5, max_depth=6, n_estimators=550.....\n",
      "[CV 2/5; 216/360] END colsample_bytree=0.5, max_depth=6, n_estimators=550;, score=0.947 total time=   0.8s\n",
      "[CV 3/5; 216/360] START colsample_bytree=0.5, max_depth=6, n_estimators=550.....\n",
      "[CV 3/5; 216/360] END colsample_bytree=0.5, max_depth=6, n_estimators=550;, score=0.948 total time=   0.8s\n",
      "[CV 4/5; 216/360] START colsample_bytree=0.5, max_depth=6, n_estimators=550.....\n",
      "[CV 4/5; 216/360] END colsample_bytree=0.5, max_depth=6, n_estimators=550;, score=0.952 total time=   0.9s\n",
      "[CV 5/5; 216/360] START colsample_bytree=0.5, max_depth=6, n_estimators=550.....\n",
      "[CV 5/5; 216/360] END colsample_bytree=0.5, max_depth=6, n_estimators=550;, score=0.948 total time=   0.8s\n",
      "[CV 1/5; 217/360] START colsample_bytree=0.6, max_depth=1, n_estimators=300.....\n",
      "[CV 1/5; 217/360] END colsample_bytree=0.6, max_depth=1, n_estimators=300;, score=0.929 total time=   0.1s\n",
      "[CV 2/5; 217/360] START colsample_bytree=0.6, max_depth=1, n_estimators=300.....\n",
      "[CV 2/5; 217/360] END colsample_bytree=0.6, max_depth=1, n_estimators=300;, score=0.929 total time=   0.2s\n",
      "[CV 3/5; 217/360] START colsample_bytree=0.6, max_depth=1, n_estimators=300.....\n",
      "[CV 3/5; 217/360] END colsample_bytree=0.6, max_depth=1, n_estimators=300;, score=0.931 total time=   0.2s\n",
      "[CV 4/5; 217/360] START colsample_bytree=0.6, max_depth=1, n_estimators=300.....\n",
      "[CV 4/5; 217/360] END colsample_bytree=0.6, max_depth=1, n_estimators=300;, score=0.932 total time=   0.2s\n",
      "[CV 5/5; 217/360] START colsample_bytree=0.6, max_depth=1, n_estimators=300.....\n",
      "[CV 5/5; 217/360] END colsample_bytree=0.6, max_depth=1, n_estimators=300;, score=0.931 total time=   0.2s\n",
      "[CV 1/5; 218/360] START colsample_bytree=0.6, max_depth=1, n_estimators=350.....\n",
      "[CV 1/5; 218/360] END colsample_bytree=0.6, max_depth=1, n_estimators=350;, score=0.928 total time=   0.2s\n",
      "[CV 2/5; 218/360] START colsample_bytree=0.6, max_depth=1, n_estimators=350.....\n",
      "[CV 2/5; 218/360] END colsample_bytree=0.6, max_depth=1, n_estimators=350;, score=0.929 total time=   0.2s\n",
      "[CV 3/5; 218/360] START colsample_bytree=0.6, max_depth=1, n_estimators=350.....\n",
      "[CV 3/5; 218/360] END colsample_bytree=0.6, max_depth=1, n_estimators=350;, score=0.932 total time=   0.3s\n",
      "[CV 4/5; 218/360] START colsample_bytree=0.6, max_depth=1, n_estimators=350.....\n",
      "[CV 4/5; 218/360] END colsample_bytree=0.6, max_depth=1, n_estimators=350;, score=0.932 total time=   0.2s\n",
      "[CV 5/5; 218/360] START colsample_bytree=0.6, max_depth=1, n_estimators=350.....\n",
      "[CV 5/5; 218/360] END colsample_bytree=0.6, max_depth=1, n_estimators=350;, score=0.931 total time=   0.2s\n",
      "[CV 1/5; 219/360] START colsample_bytree=0.6, max_depth=1, n_estimators=400.....\n",
      "[CV 1/5; 219/360] END colsample_bytree=0.6, max_depth=1, n_estimators=400;, score=0.929 total time=   0.3s\n",
      "[CV 2/5; 219/360] START colsample_bytree=0.6, max_depth=1, n_estimators=400.....\n",
      "[CV 2/5; 219/360] END colsample_bytree=0.6, max_depth=1, n_estimators=400;, score=0.930 total time=   0.3s\n",
      "[CV 3/5; 219/360] START colsample_bytree=0.6, max_depth=1, n_estimators=400.....\n",
      "[CV 3/5; 219/360] END colsample_bytree=0.6, max_depth=1, n_estimators=400;, score=0.932 total time=   0.2s\n",
      "[CV 4/5; 219/360] START colsample_bytree=0.6, max_depth=1, n_estimators=400.....\n",
      "[CV 4/5; 219/360] END colsample_bytree=0.6, max_depth=1, n_estimators=400;, score=0.932 total time=   0.2s\n",
      "[CV 5/5; 219/360] START colsample_bytree=0.6, max_depth=1, n_estimators=400.....\n",
      "[CV 5/5; 219/360] END colsample_bytree=0.6, max_depth=1, n_estimators=400;, score=0.931 total time=   0.3s\n",
      "[CV 1/5; 220/360] START colsample_bytree=0.6, max_depth=1, n_estimators=450.....\n",
      "[CV 1/5; 220/360] END colsample_bytree=0.6, max_depth=1, n_estimators=450;, score=0.928 total time=   0.3s\n",
      "[CV 2/5; 220/360] START colsample_bytree=0.6, max_depth=1, n_estimators=450.....\n",
      "[CV 2/5; 220/360] END colsample_bytree=0.6, max_depth=1, n_estimators=450;, score=0.930 total time=   0.3s\n",
      "[CV 3/5; 220/360] START colsample_bytree=0.6, max_depth=1, n_estimators=450.....\n",
      "[CV 3/5; 220/360] END colsample_bytree=0.6, max_depth=1, n_estimators=450;, score=0.931 total time=   0.3s\n",
      "[CV 4/5; 220/360] START colsample_bytree=0.6, max_depth=1, n_estimators=450.....\n",
      "[CV 4/5; 220/360] END colsample_bytree=0.6, max_depth=1, n_estimators=450;, score=0.932 total time=   0.3s\n",
      "[CV 5/5; 220/360] START colsample_bytree=0.6, max_depth=1, n_estimators=450.....\n",
      "[CV 5/5; 220/360] END colsample_bytree=0.6, max_depth=1, n_estimators=450;, score=0.932 total time=   0.4s\n",
      "[CV 1/5; 221/360] START colsample_bytree=0.6, max_depth=1, n_estimators=500.....\n",
      "[CV 1/5; 221/360] END colsample_bytree=0.6, max_depth=1, n_estimators=500;, score=0.929 total time=   0.4s\n",
      "[CV 2/5; 221/360] START colsample_bytree=0.6, max_depth=1, n_estimators=500.....\n",
      "[CV 2/5; 221/360] END colsample_bytree=0.6, max_depth=1, n_estimators=500;, score=0.929 total time=   0.4s\n",
      "[CV 3/5; 221/360] START colsample_bytree=0.6, max_depth=1, n_estimators=500.....\n",
      "[CV 3/5; 221/360] END colsample_bytree=0.6, max_depth=1, n_estimators=500;, score=0.932 total time=   0.4s\n",
      "[CV 4/5; 221/360] START colsample_bytree=0.6, max_depth=1, n_estimators=500.....\n",
      "[CV 4/5; 221/360] END colsample_bytree=0.6, max_depth=1, n_estimators=500;, score=0.933 total time=   0.4s\n",
      "[CV 5/5; 221/360] START colsample_bytree=0.6, max_depth=1, n_estimators=500.....\n",
      "[CV 5/5; 221/360] END colsample_bytree=0.6, max_depth=1, n_estimators=500;, score=0.932 total time=   0.4s\n",
      "[CV 1/5; 222/360] START colsample_bytree=0.6, max_depth=1, n_estimators=550.....\n",
      "[CV 1/5; 222/360] END colsample_bytree=0.6, max_depth=1, n_estimators=550;, score=0.929 total time=   0.4s\n",
      "[CV 2/5; 222/360] START colsample_bytree=0.6, max_depth=1, n_estimators=550.....\n",
      "[CV 2/5; 222/360] END colsample_bytree=0.6, max_depth=1, n_estimators=550;, score=0.929 total time=   0.4s\n",
      "[CV 3/5; 222/360] START colsample_bytree=0.6, max_depth=1, n_estimators=550.....\n",
      "[CV 3/5; 222/360] END colsample_bytree=0.6, max_depth=1, n_estimators=550;, score=0.932 total time=   0.4s\n",
      "[CV 4/5; 222/360] START colsample_bytree=0.6, max_depth=1, n_estimators=550.....\n",
      "[CV 4/5; 222/360] END colsample_bytree=0.6, max_depth=1, n_estimators=550;, score=0.932 total time=   0.4s\n",
      "[CV 5/5; 222/360] START colsample_bytree=0.6, max_depth=1, n_estimators=550.....\n",
      "[CV 5/5; 222/360] END colsample_bytree=0.6, max_depth=1, n_estimators=550;, score=0.932 total time=   0.4s\n",
      "[CV 1/5; 223/360] START colsample_bytree=0.6, max_depth=2, n_estimators=300.....\n",
      "[CV 1/5; 223/360] END colsample_bytree=0.6, max_depth=2, n_estimators=300;, score=0.948 total time=   0.2s\n",
      "[CV 2/5; 223/360] START colsample_bytree=0.6, max_depth=2, n_estimators=300.....\n",
      "[CV 2/5; 223/360] END colsample_bytree=0.6, max_depth=2, n_estimators=300;, score=0.950 total time=   0.2s\n",
      "[CV 3/5; 223/360] START colsample_bytree=0.6, max_depth=2, n_estimators=300.....\n",
      "[CV 3/5; 223/360] END colsample_bytree=0.6, max_depth=2, n_estimators=300;, score=0.951 total time=   0.2s\n",
      "[CV 4/5; 223/360] START colsample_bytree=0.6, max_depth=2, n_estimators=300.....\n",
      "[CV 4/5; 223/360] END colsample_bytree=0.6, max_depth=2, n_estimators=300;, score=0.955 total time=   0.2s\n",
      "[CV 5/5; 223/360] START colsample_bytree=0.6, max_depth=2, n_estimators=300.....\n",
      "[CV 5/5; 223/360] END colsample_bytree=0.6, max_depth=2, n_estimators=300;, score=0.951 total time=   0.2s\n",
      "[CV 1/5; 224/360] START colsample_bytree=0.6, max_depth=2, n_estimators=350.....\n",
      "[CV 1/5; 224/360] END colsample_bytree=0.6, max_depth=2, n_estimators=350;, score=0.948 total time=   0.3s\n",
      "[CV 2/5; 224/360] START colsample_bytree=0.6, max_depth=2, n_estimators=350.....\n",
      "[CV 2/5; 224/360] END colsample_bytree=0.6, max_depth=2, n_estimators=350;, score=0.951 total time=   0.3s\n",
      "[CV 3/5; 224/360] START colsample_bytree=0.6, max_depth=2, n_estimators=350.....\n",
      "[CV 3/5; 224/360] END colsample_bytree=0.6, max_depth=2, n_estimators=350;, score=0.952 total time=   0.3s\n",
      "[CV 4/5; 224/360] START colsample_bytree=0.6, max_depth=2, n_estimators=350.....\n",
      "[CV 4/5; 224/360] END colsample_bytree=0.6, max_depth=2, n_estimators=350;, score=0.954 total time=   0.3s\n",
      "[CV 5/5; 224/360] START colsample_bytree=0.6, max_depth=2, n_estimators=350.....\n",
      "[CV 5/5; 224/360] END colsample_bytree=0.6, max_depth=2, n_estimators=350;, score=0.951 total time=   0.3s\n",
      "[CV 1/5; 225/360] START colsample_bytree=0.6, max_depth=2, n_estimators=400.....\n",
      "[CV 1/5; 225/360] END colsample_bytree=0.6, max_depth=2, n_estimators=400;, score=0.948 total time=   0.4s\n",
      "[CV 2/5; 225/360] START colsample_bytree=0.6, max_depth=2, n_estimators=400.....\n",
      "[CV 2/5; 225/360] END colsample_bytree=0.6, max_depth=2, n_estimators=400;, score=0.950 total time=   0.3s\n",
      "[CV 3/5; 225/360] START colsample_bytree=0.6, max_depth=2, n_estimators=400.....\n",
      "[CV 3/5; 225/360] END colsample_bytree=0.6, max_depth=2, n_estimators=400;, score=0.952 total time=   0.3s\n",
      "[CV 4/5; 225/360] START colsample_bytree=0.6, max_depth=2, n_estimators=400.....\n",
      "[CV 4/5; 225/360] END colsample_bytree=0.6, max_depth=2, n_estimators=400;, score=0.954 total time=   0.3s\n",
      "[CV 5/5; 225/360] START colsample_bytree=0.6, max_depth=2, n_estimators=400.....\n",
      "[CV 5/5; 225/360] END colsample_bytree=0.6, max_depth=2, n_estimators=400;, score=0.951 total time=   0.3s\n",
      "[CV 1/5; 226/360] START colsample_bytree=0.6, max_depth=2, n_estimators=450.....\n",
      "[CV 1/5; 226/360] END colsample_bytree=0.6, max_depth=2, n_estimators=450;, score=0.948 total time=   0.4s\n",
      "[CV 2/5; 226/360] START colsample_bytree=0.6, max_depth=2, n_estimators=450.....\n",
      "[CV 2/5; 226/360] END colsample_bytree=0.6, max_depth=2, n_estimators=450;, score=0.950 total time=   0.4s\n",
      "[CV 3/5; 226/360] START colsample_bytree=0.6, max_depth=2, n_estimators=450.....\n",
      "[CV 3/5; 226/360] END colsample_bytree=0.6, max_depth=2, n_estimators=450;, score=0.952 total time=   0.4s\n",
      "[CV 4/5; 226/360] START colsample_bytree=0.6, max_depth=2, n_estimators=450.....\n",
      "[CV 4/5; 226/360] END colsample_bytree=0.6, max_depth=2, n_estimators=450;, score=0.954 total time=   0.4s\n",
      "[CV 5/5; 226/360] START colsample_bytree=0.6, max_depth=2, n_estimators=450.....\n",
      "[CV 5/5; 226/360] END colsample_bytree=0.6, max_depth=2, n_estimators=450;, score=0.951 total time=   0.4s\n",
      "[CV 1/5; 227/360] START colsample_bytree=0.6, max_depth=2, n_estimators=500.....\n",
      "[CV 1/5; 227/360] END colsample_bytree=0.6, max_depth=2, n_estimators=500;, score=0.948 total time=   0.4s\n",
      "[CV 2/5; 227/360] START colsample_bytree=0.6, max_depth=2, n_estimators=500.....\n",
      "[CV 2/5; 227/360] END colsample_bytree=0.6, max_depth=2, n_estimators=500;, score=0.949 total time=   0.5s\n",
      "[CV 3/5; 227/360] START colsample_bytree=0.6, max_depth=2, n_estimators=500.....\n",
      "[CV 3/5; 227/360] END colsample_bytree=0.6, max_depth=2, n_estimators=500;, score=0.951 total time=   0.5s\n",
      "[CV 4/5; 227/360] START colsample_bytree=0.6, max_depth=2, n_estimators=500.....\n",
      "[CV 4/5; 227/360] END colsample_bytree=0.6, max_depth=2, n_estimators=500;, score=0.954 total time=   0.4s\n",
      "[CV 5/5; 227/360] START colsample_bytree=0.6, max_depth=2, n_estimators=500.....\n",
      "[CV 5/5; 227/360] END colsample_bytree=0.6, max_depth=2, n_estimators=500;, score=0.951 total time=   0.6s\n",
      "[CV 1/5; 228/360] START colsample_bytree=0.6, max_depth=2, n_estimators=550.....\n",
      "[CV 1/5; 228/360] END colsample_bytree=0.6, max_depth=2, n_estimators=550;, score=0.948 total time=   0.6s\n",
      "[CV 2/5; 228/360] START colsample_bytree=0.6, max_depth=2, n_estimators=550.....\n",
      "[CV 2/5; 228/360] END colsample_bytree=0.6, max_depth=2, n_estimators=550;, score=0.949 total time=   0.6s\n",
      "[CV 3/5; 228/360] START colsample_bytree=0.6, max_depth=2, n_estimators=550.....\n",
      "[CV 3/5; 228/360] END colsample_bytree=0.6, max_depth=2, n_estimators=550;, score=0.951 total time=   0.6s\n",
      "[CV 4/5; 228/360] START colsample_bytree=0.6, max_depth=2, n_estimators=550.....\n",
      "[CV 4/5; 228/360] END colsample_bytree=0.6, max_depth=2, n_estimators=550;, score=0.954 total time=   0.6s\n",
      "[CV 5/5; 228/360] START colsample_bytree=0.6, max_depth=2, n_estimators=550.....\n",
      "[CV 5/5; 228/360] END colsample_bytree=0.6, max_depth=2, n_estimators=550;, score=0.951 total time=   0.5s\n",
      "[CV 1/5; 229/360] START colsample_bytree=0.6, max_depth=3, n_estimators=300.....\n",
      "[CV 1/5; 229/360] END colsample_bytree=0.6, max_depth=3, n_estimators=300;, score=0.950 total time=   0.4s\n",
      "[CV 2/5; 229/360] START colsample_bytree=0.6, max_depth=3, n_estimators=300.....\n",
      "[CV 2/5; 229/360] END colsample_bytree=0.6, max_depth=3, n_estimators=300;, score=0.952 total time=   0.3s\n",
      "[CV 3/5; 229/360] START colsample_bytree=0.6, max_depth=3, n_estimators=300.....\n",
      "[CV 3/5; 229/360] END colsample_bytree=0.6, max_depth=3, n_estimators=300;, score=0.951 total time=   0.4s\n",
      "[CV 4/5; 229/360] START colsample_bytree=0.6, max_depth=3, n_estimators=300.....\n",
      "[CV 4/5; 229/360] END colsample_bytree=0.6, max_depth=3, n_estimators=300;, score=0.954 total time=   0.3s\n",
      "[CV 5/5; 229/360] START colsample_bytree=0.6, max_depth=3, n_estimators=300.....\n",
      "[CV 5/5; 229/360] END colsample_bytree=0.6, max_depth=3, n_estimators=300;, score=0.953 total time=   0.3s\n",
      "[CV 1/5; 230/360] START colsample_bytree=0.6, max_depth=3, n_estimators=350.....\n",
      "[CV 1/5; 230/360] END colsample_bytree=0.6, max_depth=3, n_estimators=350;, score=0.949 total time=   0.3s\n",
      "[CV 2/5; 230/360] START colsample_bytree=0.6, max_depth=3, n_estimators=350.....\n",
      "[CV 2/5; 230/360] END colsample_bytree=0.6, max_depth=3, n_estimators=350;, score=0.951 total time=   0.4s\n",
      "[CV 3/5; 230/360] START colsample_bytree=0.6, max_depth=3, n_estimators=350.....\n",
      "[CV 3/5; 230/360] END colsample_bytree=0.6, max_depth=3, n_estimators=350;, score=0.951 total time=   0.3s\n",
      "[CV 4/5; 230/360] START colsample_bytree=0.6, max_depth=3, n_estimators=350.....\n",
      "[CV 4/5; 230/360] END colsample_bytree=0.6, max_depth=3, n_estimators=350;, score=0.954 total time=   0.3s\n",
      "[CV 5/5; 230/360] START colsample_bytree=0.6, max_depth=3, n_estimators=350.....\n",
      "[CV 5/5; 230/360] END colsample_bytree=0.6, max_depth=3, n_estimators=350;, score=0.953 total time=   0.4s\n",
      "[CV 1/5; 231/360] START colsample_bytree=0.6, max_depth=3, n_estimators=400.....\n",
      "[CV 1/5; 231/360] END colsample_bytree=0.6, max_depth=3, n_estimators=400;, score=0.949 total time=   0.4s\n",
      "[CV 2/5; 231/360] START colsample_bytree=0.6, max_depth=3, n_estimators=400.....\n",
      "[CV 2/5; 231/360] END colsample_bytree=0.6, max_depth=3, n_estimators=400;, score=0.951 total time=   0.4s\n",
      "[CV 3/5; 231/360] START colsample_bytree=0.6, max_depth=3, n_estimators=400.....\n",
      "[CV 3/5; 231/360] END colsample_bytree=0.6, max_depth=3, n_estimators=400;, score=0.951 total time=   0.4s\n",
      "[CV 4/5; 231/360] START colsample_bytree=0.6, max_depth=3, n_estimators=400.....\n",
      "[CV 4/5; 231/360] END colsample_bytree=0.6, max_depth=3, n_estimators=400;, score=0.954 total time=   0.5s\n",
      "[CV 5/5; 231/360] START colsample_bytree=0.6, max_depth=3, n_estimators=400.....\n",
      "[CV 5/5; 231/360] END colsample_bytree=0.6, max_depth=3, n_estimators=400;, score=0.954 total time=   0.4s\n",
      "[CV 1/5; 232/360] START colsample_bytree=0.6, max_depth=3, n_estimators=450.....\n",
      "[CV 1/5; 232/360] END colsample_bytree=0.6, max_depth=3, n_estimators=450;, score=0.949 total time=   0.5s\n",
      "[CV 2/5; 232/360] START colsample_bytree=0.6, max_depth=3, n_estimators=450.....\n",
      "[CV 2/5; 232/360] END colsample_bytree=0.6, max_depth=3, n_estimators=450;, score=0.951 total time=   0.5s\n",
      "[CV 3/5; 232/360] START colsample_bytree=0.6, max_depth=3, n_estimators=450.....\n",
      "[CV 3/5; 232/360] END colsample_bytree=0.6, max_depth=3, n_estimators=450;, score=0.951 total time=   0.4s\n",
      "[CV 4/5; 232/360] START colsample_bytree=0.6, max_depth=3, n_estimators=450.....\n",
      "[CV 4/5; 232/360] END colsample_bytree=0.6, max_depth=3, n_estimators=450;, score=0.955 total time=   0.5s\n",
      "[CV 5/5; 232/360] START colsample_bytree=0.6, max_depth=3, n_estimators=450.....\n",
      "[CV 5/5; 232/360] END colsample_bytree=0.6, max_depth=3, n_estimators=450;, score=0.953 total time=   0.5s\n",
      "[CV 1/5; 233/360] START colsample_bytree=0.6, max_depth=3, n_estimators=500.....\n",
      "[CV 1/5; 233/360] END colsample_bytree=0.6, max_depth=3, n_estimators=500;, score=0.949 total time=   0.5s\n",
      "[CV 2/5; 233/360] START colsample_bytree=0.6, max_depth=3, n_estimators=500.....\n",
      "[CV 2/5; 233/360] END colsample_bytree=0.6, max_depth=3, n_estimators=500;, score=0.952 total time=   0.5s\n",
      "[CV 3/5; 233/360] START colsample_bytree=0.6, max_depth=3, n_estimators=500.....\n",
      "[CV 3/5; 233/360] END colsample_bytree=0.6, max_depth=3, n_estimators=500;, score=0.951 total time=   0.5s\n",
      "[CV 4/5; 233/360] START colsample_bytree=0.6, max_depth=3, n_estimators=500.....\n",
      "[CV 4/5; 233/360] END colsample_bytree=0.6, max_depth=3, n_estimators=500;, score=0.954 total time=   0.6s\n",
      "[CV 5/5; 233/360] START colsample_bytree=0.6, max_depth=3, n_estimators=500.....\n",
      "[CV 5/5; 233/360] END colsample_bytree=0.6, max_depth=3, n_estimators=500;, score=0.953 total time=   0.7s\n",
      "[CV 1/5; 234/360] START colsample_bytree=0.6, max_depth=3, n_estimators=550.....\n",
      "[CV 1/5; 234/360] END colsample_bytree=0.6, max_depth=3, n_estimators=550;, score=0.949 total time=   0.8s\n",
      "[CV 2/5; 234/360] START colsample_bytree=0.6, max_depth=3, n_estimators=550.....\n",
      "[CV 2/5; 234/360] END colsample_bytree=0.6, max_depth=3, n_estimators=550;, score=0.951 total time=   0.8s\n",
      "[CV 3/5; 234/360] START colsample_bytree=0.6, max_depth=3, n_estimators=550.....\n",
      "[CV 3/5; 234/360] END colsample_bytree=0.6, max_depth=3, n_estimators=550;, score=0.952 total time=   0.7s\n",
      "[CV 4/5; 234/360] START colsample_bytree=0.6, max_depth=3, n_estimators=550.....\n",
      "[CV 4/5; 234/360] END colsample_bytree=0.6, max_depth=3, n_estimators=550;, score=0.953 total time=   0.6s\n",
      "[CV 5/5; 234/360] START colsample_bytree=0.6, max_depth=3, n_estimators=550.....\n",
      "[CV 5/5; 234/360] END colsample_bytree=0.6, max_depth=3, n_estimators=550;, score=0.953 total time=   0.6s\n",
      "[CV 1/5; 235/360] START colsample_bytree=0.6, max_depth=4, n_estimators=300.....\n",
      "[CV 1/5; 235/360] END colsample_bytree=0.6, max_depth=4, n_estimators=300;, score=0.949 total time=   0.4s\n",
      "[CV 2/5; 235/360] START colsample_bytree=0.6, max_depth=4, n_estimators=300.....\n",
      "[CV 2/5; 235/360] END colsample_bytree=0.6, max_depth=4, n_estimators=300;, score=0.951 total time=   0.4s\n",
      "[CV 3/5; 235/360] START colsample_bytree=0.6, max_depth=4, n_estimators=300.....\n",
      "[CV 3/5; 235/360] END colsample_bytree=0.6, max_depth=4, n_estimators=300;, score=0.951 total time=   0.4s\n",
      "[CV 4/5; 235/360] START colsample_bytree=0.6, max_depth=4, n_estimators=300.....\n",
      "[CV 4/5; 235/360] END colsample_bytree=0.6, max_depth=4, n_estimators=300;, score=0.954 total time=   0.4s\n",
      "[CV 5/5; 235/360] START colsample_bytree=0.6, max_depth=4, n_estimators=300.....\n",
      "[CV 5/5; 235/360] END colsample_bytree=0.6, max_depth=4, n_estimators=300;, score=0.954 total time=   0.5s\n",
      "[CV 1/5; 236/360] START colsample_bytree=0.6, max_depth=4, n_estimators=350.....\n",
      "[CV 1/5; 236/360] END colsample_bytree=0.6, max_depth=4, n_estimators=350;, score=0.949 total time=   0.7s\n",
      "[CV 2/5; 236/360] START colsample_bytree=0.6, max_depth=4, n_estimators=350.....\n",
      "[CV 2/5; 236/360] END colsample_bytree=0.6, max_depth=4, n_estimators=350;, score=0.951 total time=   0.6s\n",
      "[CV 3/5; 236/360] START colsample_bytree=0.6, max_depth=4, n_estimators=350.....\n",
      "[CV 3/5; 236/360] END colsample_bytree=0.6, max_depth=4, n_estimators=350;, score=0.951 total time=   0.5s\n",
      "[CV 4/5; 236/360] START colsample_bytree=0.6, max_depth=4, n_estimators=350.....\n",
      "[CV 4/5; 236/360] END colsample_bytree=0.6, max_depth=4, n_estimators=350;, score=0.953 total time=   0.5s\n",
      "[CV 5/5; 236/360] START colsample_bytree=0.6, max_depth=4, n_estimators=350.....\n",
      "[CV 5/5; 236/360] END colsample_bytree=0.6, max_depth=4, n_estimators=350;, score=0.954 total time=   0.5s\n",
      "[CV 1/5; 237/360] START colsample_bytree=0.6, max_depth=4, n_estimators=400.....\n",
      "[CV 1/5; 237/360] END colsample_bytree=0.6, max_depth=4, n_estimators=400;, score=0.949 total time=   0.6s\n",
      "[CV 2/5; 237/360] START colsample_bytree=0.6, max_depth=4, n_estimators=400.....\n",
      "[CV 2/5; 237/360] END colsample_bytree=0.6, max_depth=4, n_estimators=400;, score=0.950 total time=   0.5s\n",
      "[CV 3/5; 237/360] START colsample_bytree=0.6, max_depth=4, n_estimators=400.....\n",
      "[CV 3/5; 237/360] END colsample_bytree=0.6, max_depth=4, n_estimators=400;, score=0.951 total time=   0.5s\n",
      "[CV 4/5; 237/360] START colsample_bytree=0.6, max_depth=4, n_estimators=400.....\n",
      "[CV 4/5; 237/360] END colsample_bytree=0.6, max_depth=4, n_estimators=400;, score=0.953 total time=   0.5s\n",
      "[CV 5/5; 237/360] START colsample_bytree=0.6, max_depth=4, n_estimators=400.....\n",
      "[CV 5/5; 237/360] END colsample_bytree=0.6, max_depth=4, n_estimators=400;, score=0.954 total time=   0.5s\n",
      "[CV 1/5; 238/360] START colsample_bytree=0.6, max_depth=4, n_estimators=450.....\n",
      "[CV 1/5; 238/360] END colsample_bytree=0.6, max_depth=4, n_estimators=450;, score=0.949 total time=   0.7s\n",
      "[CV 2/5; 238/360] START colsample_bytree=0.6, max_depth=4, n_estimators=450.....\n",
      "[CV 2/5; 238/360] END colsample_bytree=0.6, max_depth=4, n_estimators=450;, score=0.950 total time=   0.6s\n",
      "[CV 3/5; 238/360] START colsample_bytree=0.6, max_depth=4, n_estimators=450.....\n",
      "[CV 3/5; 238/360] END colsample_bytree=0.6, max_depth=4, n_estimators=450;, score=0.950 total time=   0.7s\n",
      "[CV 4/5; 238/360] START colsample_bytree=0.6, max_depth=4, n_estimators=450.....\n",
      "[CV 4/5; 238/360] END colsample_bytree=0.6, max_depth=4, n_estimators=450;, score=0.953 total time=   0.7s\n",
      "[CV 5/5; 238/360] START colsample_bytree=0.6, max_depth=4, n_estimators=450.....\n",
      "[CV 5/5; 238/360] END colsample_bytree=0.6, max_depth=4, n_estimators=450;, score=0.953 total time=   0.8s\n",
      "[CV 1/5; 239/360] START colsample_bytree=0.6, max_depth=4, n_estimators=500.....\n",
      "[CV 1/5; 239/360] END colsample_bytree=0.6, max_depth=4, n_estimators=500;, score=0.948 total time=   0.9s\n",
      "[CV 2/5; 239/360] START colsample_bytree=0.6, max_depth=4, n_estimators=500.....\n",
      "[CV 2/5; 239/360] END colsample_bytree=0.6, max_depth=4, n_estimators=500;, score=0.950 total time=   0.8s\n",
      "[CV 3/5; 239/360] START colsample_bytree=0.6, max_depth=4, n_estimators=500.....\n",
      "[CV 3/5; 239/360] END colsample_bytree=0.6, max_depth=4, n_estimators=500;, score=0.951 total time=   0.6s\n",
      "[CV 4/5; 239/360] START colsample_bytree=0.6, max_depth=4, n_estimators=500.....\n",
      "[CV 4/5; 239/360] END colsample_bytree=0.6, max_depth=4, n_estimators=500;, score=0.953 total time=   0.7s\n",
      "[CV 5/5; 239/360] START colsample_bytree=0.6, max_depth=4, n_estimators=500.....\n",
      "[CV 5/5; 239/360] END colsample_bytree=0.6, max_depth=4, n_estimators=500;, score=0.953 total time=   0.7s\n",
      "[CV 1/5; 240/360] START colsample_bytree=0.6, max_depth=4, n_estimators=550.....\n",
      "[CV 1/5; 240/360] END colsample_bytree=0.6, max_depth=4, n_estimators=550;, score=0.948 total time=   0.8s\n",
      "[CV 2/5; 240/360] START colsample_bytree=0.6, max_depth=4, n_estimators=550.....\n",
      "[CV 2/5; 240/360] END colsample_bytree=0.6, max_depth=4, n_estimators=550;, score=0.949 total time=   0.8s\n",
      "[CV 3/5; 240/360] START colsample_bytree=0.6, max_depth=4, n_estimators=550.....\n",
      "[CV 3/5; 240/360] END colsample_bytree=0.6, max_depth=4, n_estimators=550;, score=0.950 total time=   0.8s\n",
      "[CV 4/5; 240/360] START colsample_bytree=0.6, max_depth=4, n_estimators=550.....\n",
      "[CV 4/5; 240/360] END colsample_bytree=0.6, max_depth=4, n_estimators=550;, score=0.953 total time=   0.7s\n",
      "[CV 5/5; 240/360] START colsample_bytree=0.6, max_depth=4, n_estimators=550.....\n",
      "[CV 5/5; 240/360] END colsample_bytree=0.6, max_depth=4, n_estimators=550;, score=0.953 total time=   0.7s\n",
      "[CV 1/5; 241/360] START colsample_bytree=0.6, max_depth=5, n_estimators=300.....\n",
      "[CV 1/5; 241/360] END colsample_bytree=0.6, max_depth=5, n_estimators=300;, score=0.949 total time=   0.4s\n",
      "[CV 2/5; 241/360] START colsample_bytree=0.6, max_depth=5, n_estimators=300.....\n",
      "[CV 2/5; 241/360] END colsample_bytree=0.6, max_depth=5, n_estimators=300;, score=0.950 total time=   0.5s\n",
      "[CV 3/5; 241/360] START colsample_bytree=0.6, max_depth=5, n_estimators=300.....\n",
      "[CV 3/5; 241/360] END colsample_bytree=0.6, max_depth=5, n_estimators=300;, score=0.950 total time=   0.5s\n",
      "[CV 4/5; 241/360] START colsample_bytree=0.6, max_depth=5, n_estimators=300.....\n",
      "[CV 4/5; 241/360] END colsample_bytree=0.6, max_depth=5, n_estimators=300;, score=0.955 total time=   0.5s\n",
      "[CV 5/5; 241/360] START colsample_bytree=0.6, max_depth=5, n_estimators=300.....\n",
      "[CV 5/5; 241/360] END colsample_bytree=0.6, max_depth=5, n_estimators=300;, score=0.950 total time=   0.5s\n",
      "[CV 1/5; 242/360] START colsample_bytree=0.6, max_depth=5, n_estimators=350.....\n",
      "[CV 1/5; 242/360] END colsample_bytree=0.6, max_depth=5, n_estimators=350;, score=0.948 total time=   0.5s\n",
      "[CV 2/5; 242/360] START colsample_bytree=0.6, max_depth=5, n_estimators=350.....\n",
      "[CV 2/5; 242/360] END colsample_bytree=0.6, max_depth=5, n_estimators=350;, score=0.950 total time=   0.5s\n",
      "[CV 3/5; 242/360] START colsample_bytree=0.6, max_depth=5, n_estimators=350.....\n",
      "[CV 3/5; 242/360] END colsample_bytree=0.6, max_depth=5, n_estimators=350;, score=0.950 total time=   0.6s\n",
      "[CV 4/5; 242/360] START colsample_bytree=0.6, max_depth=5, n_estimators=350.....\n",
      "[CV 4/5; 242/360] END colsample_bytree=0.6, max_depth=5, n_estimators=350;, score=0.955 total time=   0.6s\n",
      "[CV 5/5; 242/360] START colsample_bytree=0.6, max_depth=5, n_estimators=350.....\n",
      "[CV 5/5; 242/360] END colsample_bytree=0.6, max_depth=5, n_estimators=350;, score=0.949 total time=   0.7s\n",
      "[CV 1/5; 243/360] START colsample_bytree=0.6, max_depth=5, n_estimators=400.....\n",
      "[CV 1/5; 243/360] END colsample_bytree=0.6, max_depth=5, n_estimators=400;, score=0.947 total time=   0.8s\n",
      "[CV 2/5; 243/360] START colsample_bytree=0.6, max_depth=5, n_estimators=400.....\n",
      "[CV 2/5; 243/360] END colsample_bytree=0.6, max_depth=5, n_estimators=400;, score=0.949 total time=   0.8s\n",
      "[CV 3/5; 243/360] START colsample_bytree=0.6, max_depth=5, n_estimators=400.....\n",
      "[CV 3/5; 243/360] END colsample_bytree=0.6, max_depth=5, n_estimators=400;, score=0.950 total time=   0.8s\n",
      "[CV 4/5; 243/360] START colsample_bytree=0.6, max_depth=5, n_estimators=400.....\n",
      "[CV 4/5; 243/360] END colsample_bytree=0.6, max_depth=5, n_estimators=400;, score=0.955 total time=   0.7s\n",
      "[CV 5/5; 243/360] START colsample_bytree=0.6, max_depth=5, n_estimators=400.....\n",
      "[CV 5/5; 243/360] END colsample_bytree=0.6, max_depth=5, n_estimators=400;, score=0.949 total time=   0.6s\n",
      "[CV 1/5; 244/360] START colsample_bytree=0.6, max_depth=5, n_estimators=450.....\n",
      "[CV 1/5; 244/360] END colsample_bytree=0.6, max_depth=5, n_estimators=450;, score=0.947 total time=   0.7s\n",
      "[CV 2/5; 244/360] START colsample_bytree=0.6, max_depth=5, n_estimators=450.....\n",
      "[CV 2/5; 244/360] END colsample_bytree=0.6, max_depth=5, n_estimators=450;, score=0.948 total time=   0.7s\n",
      "[CV 3/5; 244/360] START colsample_bytree=0.6, max_depth=5, n_estimators=450.....\n",
      "[CV 3/5; 244/360] END colsample_bytree=0.6, max_depth=5, n_estimators=450;, score=0.949 total time=   0.7s\n",
      "[CV 4/5; 244/360] START colsample_bytree=0.6, max_depth=5, n_estimators=450.....\n",
      "[CV 4/5; 244/360] END colsample_bytree=0.6, max_depth=5, n_estimators=450;, score=0.954 total time=   0.7s\n",
      "[CV 5/5; 244/360] START colsample_bytree=0.6, max_depth=5, n_estimators=450.....\n",
      "[CV 5/5; 244/360] END colsample_bytree=0.6, max_depth=5, n_estimators=450;, score=0.949 total time=   0.8s\n",
      "[CV 1/5; 245/360] START colsample_bytree=0.6, max_depth=5, n_estimators=500.....\n",
      "[CV 1/5; 245/360] END colsample_bytree=0.6, max_depth=5, n_estimators=500;, score=0.946 total time=   0.7s\n",
      "[CV 2/5; 245/360] START colsample_bytree=0.6, max_depth=5, n_estimators=500.....\n",
      "[CV 2/5; 245/360] END colsample_bytree=0.6, max_depth=5, n_estimators=500;, score=0.948 total time=   0.8s\n",
      "[CV 3/5; 245/360] START colsample_bytree=0.6, max_depth=5, n_estimators=500.....\n",
      "[CV 3/5; 245/360] END colsample_bytree=0.6, max_depth=5, n_estimators=500;, score=0.949 total time=   0.8s\n",
      "[CV 4/5; 245/360] START colsample_bytree=0.6, max_depth=5, n_estimators=500.....\n",
      "[CV 4/5; 245/360] END colsample_bytree=0.6, max_depth=5, n_estimators=500;, score=0.953 total time=   0.7s\n",
      "[CV 5/5; 245/360] START colsample_bytree=0.6, max_depth=5, n_estimators=500.....\n",
      "[CV 5/5; 245/360] END colsample_bytree=0.6, max_depth=5, n_estimators=500;, score=0.949 total time=   0.7s\n",
      "[CV 1/5; 246/360] START colsample_bytree=0.6, max_depth=5, n_estimators=550.....\n",
      "[CV 1/5; 246/360] END colsample_bytree=0.6, max_depth=5, n_estimators=550;, score=0.945 total time=   0.8s\n",
      "[CV 2/5; 246/360] START colsample_bytree=0.6, max_depth=5, n_estimators=550.....\n",
      "[CV 2/5; 246/360] END colsample_bytree=0.6, max_depth=5, n_estimators=550;, score=0.948 total time=   0.9s\n",
      "[CV 3/5; 246/360] START colsample_bytree=0.6, max_depth=5, n_estimators=550.....\n",
      "[CV 3/5; 246/360] END colsample_bytree=0.6, max_depth=5, n_estimators=550;, score=0.949 total time=   1.0s\n",
      "[CV 4/5; 246/360] START colsample_bytree=0.6, max_depth=5, n_estimators=550.....\n",
      "[CV 4/5; 246/360] END colsample_bytree=0.6, max_depth=5, n_estimators=550;, score=0.953 total time=   1.2s\n",
      "[CV 5/5; 246/360] START colsample_bytree=0.6, max_depth=5, n_estimators=550.....\n",
      "[CV 5/5; 246/360] END colsample_bytree=0.6, max_depth=5, n_estimators=550;, score=0.948 total time=   1.1s\n",
      "[CV 1/5; 247/360] START colsample_bytree=0.6, max_depth=6, n_estimators=300.....\n",
      "[CV 1/5; 247/360] END colsample_bytree=0.6, max_depth=6, n_estimators=300;, score=0.946 total time=   0.6s\n",
      "[CV 2/5; 247/360] START colsample_bytree=0.6, max_depth=6, n_estimators=300.....\n",
      "[CV 2/5; 247/360] END colsample_bytree=0.6, max_depth=6, n_estimators=300;, score=0.949 total time=   0.6s\n",
      "[CV 3/5; 247/360] START colsample_bytree=0.6, max_depth=6, n_estimators=300.....\n",
      "[CV 3/5; 247/360] END colsample_bytree=0.6, max_depth=6, n_estimators=300;, score=0.951 total time=   0.5s\n",
      "[CV 4/5; 247/360] START colsample_bytree=0.6, max_depth=6, n_estimators=300.....\n",
      "[CV 4/5; 247/360] END colsample_bytree=0.6, max_depth=6, n_estimators=300;, score=0.954 total time=   0.5s\n",
      "[CV 5/5; 247/360] START colsample_bytree=0.6, max_depth=6, n_estimators=300.....\n",
      "[CV 5/5; 247/360] END colsample_bytree=0.6, max_depth=6, n_estimators=300;, score=0.949 total time=   0.5s\n",
      "[CV 1/5; 248/360] START colsample_bytree=0.6, max_depth=6, n_estimators=350.....\n",
      "[CV 1/5; 248/360] END colsample_bytree=0.6, max_depth=6, n_estimators=350;, score=0.946 total time=   0.6s\n",
      "[CV 2/5; 248/360] START colsample_bytree=0.6, max_depth=6, n_estimators=350.....\n",
      "[CV 2/5; 248/360] END colsample_bytree=0.6, max_depth=6, n_estimators=350;, score=0.949 total time=   0.6s\n",
      "[CV 3/5; 248/360] START colsample_bytree=0.6, max_depth=6, n_estimators=350.....\n",
      "[CV 3/5; 248/360] END colsample_bytree=0.6, max_depth=6, n_estimators=350;, score=0.949 total time=   0.7s\n",
      "[CV 4/5; 248/360] START colsample_bytree=0.6, max_depth=6, n_estimators=350.....\n",
      "[CV 4/5; 248/360] END colsample_bytree=0.6, max_depth=6, n_estimators=350;, score=0.954 total time=   0.7s\n",
      "[CV 5/5; 248/360] START colsample_bytree=0.6, max_depth=6, n_estimators=350.....\n",
      "[CV 5/5; 248/360] END colsample_bytree=0.6, max_depth=6, n_estimators=350;, score=0.949 total time=   0.6s\n",
      "[CV 1/5; 249/360] START colsample_bytree=0.6, max_depth=6, n_estimators=400.....\n",
      "[CV 1/5; 249/360] END colsample_bytree=0.6, max_depth=6, n_estimators=400;, score=0.946 total time=   0.7s\n",
      "[CV 2/5; 249/360] START colsample_bytree=0.6, max_depth=6, n_estimators=400.....\n",
      "[CV 2/5; 249/360] END colsample_bytree=0.6, max_depth=6, n_estimators=400;, score=0.948 total time=   0.7s\n",
      "[CV 3/5; 249/360] START colsample_bytree=0.6, max_depth=6, n_estimators=400.....\n",
      "[CV 3/5; 249/360] END colsample_bytree=0.6, max_depth=6, n_estimators=400;, score=0.950 total time=   0.7s\n",
      "[CV 4/5; 249/360] START colsample_bytree=0.6, max_depth=6, n_estimators=400.....\n",
      "[CV 4/5; 249/360] END colsample_bytree=0.6, max_depth=6, n_estimators=400;, score=0.954 total time=   0.7s\n",
      "[CV 5/5; 249/360] START colsample_bytree=0.6, max_depth=6, n_estimators=400.....\n",
      "[CV 5/5; 249/360] END colsample_bytree=0.6, max_depth=6, n_estimators=400;, score=0.948 total time=   0.7s\n",
      "[CV 1/5; 250/360] START colsample_bytree=0.6, max_depth=6, n_estimators=450.....\n",
      "[CV 1/5; 250/360] END colsample_bytree=0.6, max_depth=6, n_estimators=450;, score=0.945 total time=   0.7s\n",
      "[CV 2/5; 250/360] START colsample_bytree=0.6, max_depth=6, n_estimators=450.....\n",
      "[CV 2/5; 250/360] END colsample_bytree=0.6, max_depth=6, n_estimators=450;, score=0.949 total time=   0.7s\n",
      "[CV 3/5; 250/360] START colsample_bytree=0.6, max_depth=6, n_estimators=450.....\n",
      "[CV 3/5; 250/360] END colsample_bytree=0.6, max_depth=6, n_estimators=450;, score=0.949 total time=   0.8s\n",
      "[CV 4/5; 250/360] START colsample_bytree=0.6, max_depth=6, n_estimators=450.....\n",
      "[CV 4/5; 250/360] END colsample_bytree=0.6, max_depth=6, n_estimators=450;, score=0.953 total time=   1.0s\n",
      "[CV 5/5; 250/360] START colsample_bytree=0.6, max_depth=6, n_estimators=450.....\n",
      "[CV 5/5; 250/360] END colsample_bytree=0.6, max_depth=6, n_estimators=450;, score=0.948 total time=   1.0s\n",
      "[CV 1/5; 251/360] START colsample_bytree=0.6, max_depth=6, n_estimators=500.....\n",
      "[CV 1/5; 251/360] END colsample_bytree=0.6, max_depth=6, n_estimators=500;, score=0.945 total time=   1.0s\n",
      "[CV 2/5; 251/360] START colsample_bytree=0.6, max_depth=6, n_estimators=500.....\n",
      "[CV 2/5; 251/360] END colsample_bytree=0.6, max_depth=6, n_estimators=500;, score=0.948 total time=   0.9s\n",
      "[CV 3/5; 251/360] START colsample_bytree=0.6, max_depth=6, n_estimators=500.....\n",
      "[CV 3/5; 251/360] END colsample_bytree=0.6, max_depth=6, n_estimators=500;, score=0.950 total time=   0.8s\n",
      "[CV 4/5; 251/360] START colsample_bytree=0.6, max_depth=6, n_estimators=500.....\n",
      "[CV 4/5; 251/360] END colsample_bytree=0.6, max_depth=6, n_estimators=500;, score=0.953 total time=   0.9s\n",
      "[CV 5/5; 251/360] START colsample_bytree=0.6, max_depth=6, n_estimators=500.....\n",
      "[CV 5/5; 251/360] END colsample_bytree=0.6, max_depth=6, n_estimators=500;, score=0.948 total time=   0.9s\n",
      "[CV 1/5; 252/360] START colsample_bytree=0.6, max_depth=6, n_estimators=550.....\n",
      "[CV 1/5; 252/360] END colsample_bytree=0.6, max_depth=6, n_estimators=550;, score=0.945 total time=   0.9s\n",
      "[CV 2/5; 252/360] START colsample_bytree=0.6, max_depth=6, n_estimators=550.....\n",
      "[CV 2/5; 252/360] END colsample_bytree=0.6, max_depth=6, n_estimators=550;, score=0.946 total time=   0.9s\n",
      "[CV 3/5; 252/360] START colsample_bytree=0.6, max_depth=6, n_estimators=550.....\n",
      "[CV 3/5; 252/360] END colsample_bytree=0.6, max_depth=6, n_estimators=550;, score=0.950 total time=   0.9s\n",
      "[CV 4/5; 252/360] START colsample_bytree=0.6, max_depth=6, n_estimators=550.....\n",
      "[CV 4/5; 252/360] END colsample_bytree=0.6, max_depth=6, n_estimators=550;, score=0.952 total time=   1.0s\n",
      "[CV 5/5; 252/360] START colsample_bytree=0.6, max_depth=6, n_estimators=550.....\n",
      "[CV 5/5; 252/360] END colsample_bytree=0.6, max_depth=6, n_estimators=550;, score=0.947 total time=   1.0s\n",
      "[CV 1/5; 253/360] START colsample_bytree=0.7, max_depth=1, n_estimators=300.....\n",
      "[CV 1/5; 253/360] END colsample_bytree=0.7, max_depth=1, n_estimators=300;, score=0.929 total time=   0.2s\n",
      "[CV 2/5; 253/360] START colsample_bytree=0.7, max_depth=1, n_estimators=300.....\n",
      "[CV 2/5; 253/360] END colsample_bytree=0.7, max_depth=1, n_estimators=300;, score=0.929 total time=   0.2s\n",
      "[CV 3/5; 253/360] START colsample_bytree=0.7, max_depth=1, n_estimators=300.....\n",
      "[CV 3/5; 253/360] END colsample_bytree=0.7, max_depth=1, n_estimators=300;, score=0.931 total time=   0.2s\n",
      "[CV 4/5; 253/360] START colsample_bytree=0.7, max_depth=1, n_estimators=300.....\n",
      "[CV 4/5; 253/360] END colsample_bytree=0.7, max_depth=1, n_estimators=300;, score=0.933 total time=   0.2s\n",
      "[CV 5/5; 253/360] START colsample_bytree=0.7, max_depth=1, n_estimators=300.....\n",
      "[CV 5/5; 253/360] END colsample_bytree=0.7, max_depth=1, n_estimators=300;, score=0.931 total time=   0.2s\n",
      "[CV 1/5; 254/360] START colsample_bytree=0.7, max_depth=1, n_estimators=350.....\n",
      "[CV 1/5; 254/360] END colsample_bytree=0.7, max_depth=1, n_estimators=350;, score=0.929 total time=   0.3s\n",
      "[CV 2/5; 254/360] START colsample_bytree=0.7, max_depth=1, n_estimators=350.....\n",
      "[CV 2/5; 254/360] END colsample_bytree=0.7, max_depth=1, n_estimators=350;, score=0.930 total time=   0.3s\n",
      "[CV 3/5; 254/360] START colsample_bytree=0.7, max_depth=1, n_estimators=350.....\n",
      "[CV 3/5; 254/360] END colsample_bytree=0.7, max_depth=1, n_estimators=350;, score=0.931 total time=   0.3s\n",
      "[CV 4/5; 254/360] START colsample_bytree=0.7, max_depth=1, n_estimators=350.....\n",
      "[CV 4/5; 254/360] END colsample_bytree=0.7, max_depth=1, n_estimators=350;, score=0.932 total time=   0.4s\n",
      "[CV 5/5; 254/360] START colsample_bytree=0.7, max_depth=1, n_estimators=350.....\n",
      "[CV 5/5; 254/360] END colsample_bytree=0.7, max_depth=1, n_estimators=350;, score=0.931 total time=   0.4s\n",
      "[CV 1/5; 255/360] START colsample_bytree=0.7, max_depth=1, n_estimators=400.....\n",
      "[CV 1/5; 255/360] END colsample_bytree=0.7, max_depth=1, n_estimators=400;, score=0.929 total time=   0.4s\n",
      "[CV 2/5; 255/360] START colsample_bytree=0.7, max_depth=1, n_estimators=400.....\n",
      "[CV 2/5; 255/360] END colsample_bytree=0.7, max_depth=1, n_estimators=400;, score=0.929 total time=   0.4s\n",
      "[CV 3/5; 255/360] START colsample_bytree=0.7, max_depth=1, n_estimators=400.....\n",
      "[CV 3/5; 255/360] END colsample_bytree=0.7, max_depth=1, n_estimators=400;, score=0.931 total time=   0.4s\n",
      "[CV 4/5; 255/360] START colsample_bytree=0.7, max_depth=1, n_estimators=400.....\n",
      "[CV 4/5; 255/360] END colsample_bytree=0.7, max_depth=1, n_estimators=400;, score=0.933 total time=   0.4s\n",
      "[CV 5/5; 255/360] START colsample_bytree=0.7, max_depth=1, n_estimators=400.....\n",
      "[CV 5/5; 255/360] END colsample_bytree=0.7, max_depth=1, n_estimators=400;, score=0.931 total time=   0.4s\n",
      "[CV 1/5; 256/360] START colsample_bytree=0.7, max_depth=1, n_estimators=450.....\n",
      "[CV 1/5; 256/360] END colsample_bytree=0.7, max_depth=1, n_estimators=450;, score=0.929 total time=   0.5s\n",
      "[CV 2/5; 256/360] START colsample_bytree=0.7, max_depth=1, n_estimators=450.....\n",
      "[CV 2/5; 256/360] END colsample_bytree=0.7, max_depth=1, n_estimators=450;, score=0.929 total time=   0.4s\n",
      "[CV 3/5; 256/360] START colsample_bytree=0.7, max_depth=1, n_estimators=450.....\n",
      "[CV 3/5; 256/360] END colsample_bytree=0.7, max_depth=1, n_estimators=450;, score=0.931 total time=   0.4s\n",
      "[CV 4/5; 256/360] START colsample_bytree=0.7, max_depth=1, n_estimators=450.....\n",
      "[CV 4/5; 256/360] END colsample_bytree=0.7, max_depth=1, n_estimators=450;, score=0.932 total time=   0.4s\n",
      "[CV 5/5; 256/360] START colsample_bytree=0.7, max_depth=1, n_estimators=450.....\n",
      "[CV 5/5; 256/360] END colsample_bytree=0.7, max_depth=1, n_estimators=450;, score=0.932 total time=   0.4s\n",
      "[CV 1/5; 257/360] START colsample_bytree=0.7, max_depth=1, n_estimators=500.....\n",
      "[CV 1/5; 257/360] END colsample_bytree=0.7, max_depth=1, n_estimators=500;, score=0.929 total time=   0.4s\n",
      "[CV 2/5; 257/360] START colsample_bytree=0.7, max_depth=1, n_estimators=500.....\n",
      "[CV 2/5; 257/360] END colsample_bytree=0.7, max_depth=1, n_estimators=500;, score=0.930 total time=   0.4s\n",
      "[CV 3/5; 257/360] START colsample_bytree=0.7, max_depth=1, n_estimators=500.....\n",
      "[CV 3/5; 257/360] END colsample_bytree=0.7, max_depth=1, n_estimators=500;, score=0.932 total time=   0.4s\n",
      "[CV 4/5; 257/360] START colsample_bytree=0.7, max_depth=1, n_estimators=500.....\n",
      "[CV 4/5; 257/360] END colsample_bytree=0.7, max_depth=1, n_estimators=500;, score=0.932 total time=   0.4s\n",
      "[CV 5/5; 257/360] START colsample_bytree=0.7, max_depth=1, n_estimators=500.....\n",
      "[CV 5/5; 257/360] END colsample_bytree=0.7, max_depth=1, n_estimators=500;, score=0.932 total time=   0.4s\n",
      "[CV 1/5; 258/360] START colsample_bytree=0.7, max_depth=1, n_estimators=550.....\n",
      "[CV 1/5; 258/360] END colsample_bytree=0.7, max_depth=1, n_estimators=550;, score=0.929 total time=   0.4s\n",
      "[CV 2/5; 258/360] START colsample_bytree=0.7, max_depth=1, n_estimators=550.....\n",
      "[CV 2/5; 258/360] END colsample_bytree=0.7, max_depth=1, n_estimators=550;, score=0.930 total time=   0.5s\n",
      "[CV 3/5; 258/360] START colsample_bytree=0.7, max_depth=1, n_estimators=550.....\n",
      "[CV 3/5; 258/360] END colsample_bytree=0.7, max_depth=1, n_estimators=550;, score=0.932 total time=   0.4s\n",
      "[CV 4/5; 258/360] START colsample_bytree=0.7, max_depth=1, n_estimators=550.....\n",
      "[CV 4/5; 258/360] END colsample_bytree=0.7, max_depth=1, n_estimators=550;, score=0.932 total time=   0.5s\n",
      "[CV 5/5; 258/360] START colsample_bytree=0.7, max_depth=1, n_estimators=550.....\n",
      "[CV 5/5; 258/360] END colsample_bytree=0.7, max_depth=1, n_estimators=550;, score=0.932 total time=   0.4s\n",
      "[CV 1/5; 259/360] START colsample_bytree=0.7, max_depth=2, n_estimators=300.....\n",
      "[CV 1/5; 259/360] END colsample_bytree=0.7, max_depth=2, n_estimators=300;, score=0.949 total time=   0.3s\n",
      "[CV 2/5; 259/360] START colsample_bytree=0.7, max_depth=2, n_estimators=300.....\n",
      "[CV 2/5; 259/360] END colsample_bytree=0.7, max_depth=2, n_estimators=300;, score=0.950 total time=   0.3s\n",
      "[CV 3/5; 259/360] START colsample_bytree=0.7, max_depth=2, n_estimators=300.....\n",
      "[CV 3/5; 259/360] END colsample_bytree=0.7, max_depth=2, n_estimators=300;, score=0.951 total time=   0.3s\n",
      "[CV 4/5; 259/360] START colsample_bytree=0.7, max_depth=2, n_estimators=300.....\n",
      "[CV 4/5; 259/360] END colsample_bytree=0.7, max_depth=2, n_estimators=300;, score=0.955 total time=   0.3s\n",
      "[CV 5/5; 259/360] START colsample_bytree=0.7, max_depth=2, n_estimators=300.....\n",
      "[CV 5/5; 259/360] END colsample_bytree=0.7, max_depth=2, n_estimators=300;, score=0.950 total time=   0.3s\n",
      "[CV 1/5; 260/360] START colsample_bytree=0.7, max_depth=2, n_estimators=350.....\n",
      "[CV 1/5; 260/360] END colsample_bytree=0.7, max_depth=2, n_estimators=350;, score=0.948 total time=   0.3s\n",
      "[CV 2/5; 260/360] START colsample_bytree=0.7, max_depth=2, n_estimators=350.....\n",
      "[CV 2/5; 260/360] END colsample_bytree=0.7, max_depth=2, n_estimators=350;, score=0.950 total time=   0.4s\n",
      "[CV 3/5; 260/360] START colsample_bytree=0.7, max_depth=2, n_estimators=350.....\n",
      "[CV 3/5; 260/360] END colsample_bytree=0.7, max_depth=2, n_estimators=350;, score=0.951 total time=   0.3s\n",
      "[CV 4/5; 260/360] START colsample_bytree=0.7, max_depth=2, n_estimators=350.....\n",
      "[CV 4/5; 260/360] END colsample_bytree=0.7, max_depth=2, n_estimators=350;, score=0.954 total time=   0.4s\n",
      "[CV 5/5; 260/360] START colsample_bytree=0.7, max_depth=2, n_estimators=350.....\n",
      "[CV 5/5; 260/360] END colsample_bytree=0.7, max_depth=2, n_estimators=350;, score=0.950 total time=   0.4s\n",
      "[CV 1/5; 261/360] START colsample_bytree=0.7, max_depth=2, n_estimators=400.....\n",
      "[CV 1/5; 261/360] END colsample_bytree=0.7, max_depth=2, n_estimators=400;, score=0.948 total time=   0.4s\n",
      "[CV 2/5; 261/360] START colsample_bytree=0.7, max_depth=2, n_estimators=400.....\n",
      "[CV 2/5; 261/360] END colsample_bytree=0.7, max_depth=2, n_estimators=400;, score=0.951 total time=   0.6s\n",
      "[CV 3/5; 261/360] START colsample_bytree=0.7, max_depth=2, n_estimators=400.....\n",
      "[CV 3/5; 261/360] END colsample_bytree=0.7, max_depth=2, n_estimators=400;, score=0.951 total time=   0.5s\n",
      "[CV 4/5; 261/360] START colsample_bytree=0.7, max_depth=2, n_estimators=400.....\n",
      "[CV 4/5; 261/360] END colsample_bytree=0.7, max_depth=2, n_estimators=400;, score=0.955 total time=   0.5s\n",
      "[CV 5/5; 261/360] START colsample_bytree=0.7, max_depth=2, n_estimators=400.....\n",
      "[CV 5/5; 261/360] END colsample_bytree=0.7, max_depth=2, n_estimators=400;, score=0.950 total time=   0.5s\n",
      "[CV 1/5; 262/360] START colsample_bytree=0.7, max_depth=2, n_estimators=450.....\n",
      "[CV 1/5; 262/360] END colsample_bytree=0.7, max_depth=2, n_estimators=450;, score=0.948 total time=   0.6s\n",
      "[CV 2/5; 262/360] START colsample_bytree=0.7, max_depth=2, n_estimators=450.....\n",
      "[CV 2/5; 262/360] END colsample_bytree=0.7, max_depth=2, n_estimators=450;, score=0.950 total time=   0.5s\n",
      "[CV 3/5; 262/360] START colsample_bytree=0.7, max_depth=2, n_estimators=450.....\n",
      "[CV 3/5; 262/360] END colsample_bytree=0.7, max_depth=2, n_estimators=450;, score=0.951 total time=   0.4s\n",
      "[CV 4/5; 262/360] START colsample_bytree=0.7, max_depth=2, n_estimators=450.....\n",
      "[CV 4/5; 262/360] END colsample_bytree=0.7, max_depth=2, n_estimators=450;, score=0.954 total time=   0.5s\n",
      "[CV 5/5; 262/360] START colsample_bytree=0.7, max_depth=2, n_estimators=450.....\n",
      "[CV 5/5; 262/360] END colsample_bytree=0.7, max_depth=2, n_estimators=450;, score=0.951 total time=   0.5s\n",
      "[CV 1/5; 263/360] START colsample_bytree=0.7, max_depth=2, n_estimators=500.....\n",
      "[CV 1/5; 263/360] END colsample_bytree=0.7, max_depth=2, n_estimators=500;, score=0.948 total time=   0.5s\n",
      "[CV 2/5; 263/360] START colsample_bytree=0.7, max_depth=2, n_estimators=500.....\n",
      "[CV 2/5; 263/360] END colsample_bytree=0.7, max_depth=2, n_estimators=500;, score=0.950 total time=   0.5s\n",
      "[CV 3/5; 263/360] START colsample_bytree=0.7, max_depth=2, n_estimators=500.....\n",
      "[CV 3/5; 263/360] END colsample_bytree=0.7, max_depth=2, n_estimators=500;, score=0.951 total time=   0.5s\n",
      "[CV 4/5; 263/360] START colsample_bytree=0.7, max_depth=2, n_estimators=500.....\n",
      "[CV 4/5; 263/360] END colsample_bytree=0.7, max_depth=2, n_estimators=500;, score=0.954 total time=   0.5s\n",
      "[CV 5/5; 263/360] START colsample_bytree=0.7, max_depth=2, n_estimators=500.....\n",
      "[CV 5/5; 263/360] END colsample_bytree=0.7, max_depth=2, n_estimators=500;, score=0.950 total time=   0.5s\n",
      "[CV 1/5; 264/360] START colsample_bytree=0.7, max_depth=2, n_estimators=550.....\n",
      "[CV 1/5; 264/360] END colsample_bytree=0.7, max_depth=2, n_estimators=550;, score=0.948 total time=   0.5s\n",
      "[CV 2/5; 264/360] START colsample_bytree=0.7, max_depth=2, n_estimators=550.....\n",
      "[CV 2/5; 264/360] END colsample_bytree=0.7, max_depth=2, n_estimators=550;, score=0.951 total time=   0.5s\n",
      "[CV 3/5; 264/360] START colsample_bytree=0.7, max_depth=2, n_estimators=550.....\n",
      "[CV 3/5; 264/360] END colsample_bytree=0.7, max_depth=2, n_estimators=550;, score=0.951 total time=   0.5s\n",
      "[CV 4/5; 264/360] START colsample_bytree=0.7, max_depth=2, n_estimators=550.....\n",
      "[CV 4/5; 264/360] END colsample_bytree=0.7, max_depth=2, n_estimators=550;, score=0.954 total time=   0.7s\n",
      "[CV 5/5; 264/360] START colsample_bytree=0.7, max_depth=2, n_estimators=550.....\n",
      "[CV 5/5; 264/360] END colsample_bytree=0.7, max_depth=2, n_estimators=550;, score=0.950 total time=   0.6s\n",
      "[CV 1/5; 265/360] START colsample_bytree=0.7, max_depth=3, n_estimators=300.....\n",
      "[CV 1/5; 265/360] END colsample_bytree=0.7, max_depth=3, n_estimators=300;, score=0.949 total time=   0.3s\n",
      "[CV 2/5; 265/360] START colsample_bytree=0.7, max_depth=3, n_estimators=300.....\n",
      "[CV 2/5; 265/360] END colsample_bytree=0.7, max_depth=3, n_estimators=300;, score=0.952 total time=   0.3s\n",
      "[CV 3/5; 265/360] START colsample_bytree=0.7, max_depth=3, n_estimators=300.....\n",
      "[CV 3/5; 265/360] END colsample_bytree=0.7, max_depth=3, n_estimators=300;, score=0.951 total time=   0.3s\n",
      "[CV 4/5; 265/360] START colsample_bytree=0.7, max_depth=3, n_estimators=300.....\n",
      "[CV 4/5; 265/360] END colsample_bytree=0.7, max_depth=3, n_estimators=300;, score=0.955 total time=   0.3s\n",
      "[CV 5/5; 265/360] START colsample_bytree=0.7, max_depth=3, n_estimators=300.....\n",
      "[CV 5/5; 265/360] END colsample_bytree=0.7, max_depth=3, n_estimators=300;, score=0.952 total time=   0.3s\n",
      "[CV 1/5; 266/360] START colsample_bytree=0.7, max_depth=3, n_estimators=350.....\n",
      "[CV 1/5; 266/360] END colsample_bytree=0.7, max_depth=3, n_estimators=350;, score=0.949 total time=   0.4s\n",
      "[CV 2/5; 266/360] START colsample_bytree=0.7, max_depth=3, n_estimators=350.....\n",
      "[CV 2/5; 266/360] END colsample_bytree=0.7, max_depth=3, n_estimators=350;, score=0.952 total time=   0.4s\n",
      "[CV 3/5; 266/360] START colsample_bytree=0.7, max_depth=3, n_estimators=350.....\n",
      "[CV 3/5; 266/360] END colsample_bytree=0.7, max_depth=3, n_estimators=350;, score=0.951 total time=   0.4s\n",
      "[CV 4/5; 266/360] START colsample_bytree=0.7, max_depth=3, n_estimators=350.....\n",
      "[CV 4/5; 266/360] END colsample_bytree=0.7, max_depth=3, n_estimators=350;, score=0.955 total time=   0.6s\n",
      "[CV 5/5; 266/360] START colsample_bytree=0.7, max_depth=3, n_estimators=350.....\n",
      "[CV 5/5; 266/360] END colsample_bytree=0.7, max_depth=3, n_estimators=350;, score=0.952 total time=   0.5s\n",
      "[CV 1/5; 267/360] START colsample_bytree=0.7, max_depth=3, n_estimators=400.....\n",
      "[CV 1/5; 267/360] END colsample_bytree=0.7, max_depth=3, n_estimators=400;, score=0.948 total time=   0.6s\n",
      "[CV 2/5; 267/360] START colsample_bytree=0.7, max_depth=3, n_estimators=400.....\n",
      "[CV 2/5; 267/360] END colsample_bytree=0.7, max_depth=3, n_estimators=400;, score=0.951 total time=   0.6s\n",
      "[CV 3/5; 267/360] START colsample_bytree=0.7, max_depth=3, n_estimators=400.....\n",
      "[CV 3/5; 267/360] END colsample_bytree=0.7, max_depth=3, n_estimators=400;, score=0.951 total time=   0.6s\n",
      "[CV 4/5; 267/360] START colsample_bytree=0.7, max_depth=3, n_estimators=400.....\n",
      "[CV 4/5; 267/360] END colsample_bytree=0.7, max_depth=3, n_estimators=400;, score=0.955 total time=   0.6s\n",
      "[CV 5/5; 267/360] START colsample_bytree=0.7, max_depth=3, n_estimators=400.....\n",
      "[CV 5/5; 267/360] END colsample_bytree=0.7, max_depth=3, n_estimators=400;, score=0.952 total time=   0.5s\n",
      "[CV 1/5; 268/360] START colsample_bytree=0.7, max_depth=3, n_estimators=450.....\n",
      "[CV 1/5; 268/360] END colsample_bytree=0.7, max_depth=3, n_estimators=450;, score=0.949 total time=   0.5s\n",
      "[CV 2/5; 268/360] START colsample_bytree=0.7, max_depth=3, n_estimators=450.....\n",
      "[CV 2/5; 268/360] END colsample_bytree=0.7, max_depth=3, n_estimators=450;, score=0.951 total time=   0.5s\n",
      "[CV 3/5; 268/360] START colsample_bytree=0.7, max_depth=3, n_estimators=450.....\n",
      "[CV 3/5; 268/360] END colsample_bytree=0.7, max_depth=3, n_estimators=450;, score=0.951 total time=   0.5s\n",
      "[CV 4/5; 268/360] START colsample_bytree=0.7, max_depth=3, n_estimators=450.....\n",
      "[CV 4/5; 268/360] END colsample_bytree=0.7, max_depth=3, n_estimators=450;, score=0.955 total time=   0.6s\n",
      "[CV 5/5; 268/360] START colsample_bytree=0.7, max_depth=3, n_estimators=450.....\n",
      "[CV 5/5; 268/360] END colsample_bytree=0.7, max_depth=3, n_estimators=450;, score=0.952 total time=   0.5s\n",
      "[CV 1/5; 269/360] START colsample_bytree=0.7, max_depth=3, n_estimators=500.....\n",
      "[CV 1/5; 269/360] END colsample_bytree=0.7, max_depth=3, n_estimators=500;, score=0.949 total time=   0.6s\n",
      "[CV 2/5; 269/360] START colsample_bytree=0.7, max_depth=3, n_estimators=500.....\n",
      "[CV 2/5; 269/360] END colsample_bytree=0.7, max_depth=3, n_estimators=500;, score=0.951 total time=   0.6s\n",
      "[CV 3/5; 269/360] START colsample_bytree=0.7, max_depth=3, n_estimators=500.....\n",
      "[CV 3/5; 269/360] END colsample_bytree=0.7, max_depth=3, n_estimators=500;, score=0.951 total time=   0.6s\n",
      "[CV 4/5; 269/360] START colsample_bytree=0.7, max_depth=3, n_estimators=500.....\n",
      "[CV 4/5; 269/360] END colsample_bytree=0.7, max_depth=3, n_estimators=500;, score=0.955 total time=   0.6s\n",
      "[CV 5/5; 269/360] START colsample_bytree=0.7, max_depth=3, n_estimators=500.....\n",
      "[CV 5/5; 269/360] END colsample_bytree=0.7, max_depth=3, n_estimators=500;, score=0.952 total time=   0.6s\n",
      "[CV 1/5; 270/360] START colsample_bytree=0.7, max_depth=3, n_estimators=550.....\n",
      "[CV 1/5; 270/360] END colsample_bytree=0.7, max_depth=3, n_estimators=550;, score=0.949 total time=   0.7s\n",
      "[CV 2/5; 270/360] START colsample_bytree=0.7, max_depth=3, n_estimators=550.....\n",
      "[CV 2/5; 270/360] END colsample_bytree=0.7, max_depth=3, n_estimators=550;, score=0.950 total time=   0.6s\n",
      "[CV 3/5; 270/360] START colsample_bytree=0.7, max_depth=3, n_estimators=550.....\n",
      "[CV 3/5; 270/360] END colsample_bytree=0.7, max_depth=3, n_estimators=550;, score=0.952 total time=   0.7s\n",
      "[CV 4/5; 270/360] START colsample_bytree=0.7, max_depth=3, n_estimators=550.....\n",
      "[CV 4/5; 270/360] END colsample_bytree=0.7, max_depth=3, n_estimators=550;, score=0.954 total time=   0.7s\n",
      "[CV 5/5; 270/360] START colsample_bytree=0.7, max_depth=3, n_estimators=550.....\n",
      "[CV 5/5; 270/360] END colsample_bytree=0.7, max_depth=3, n_estimators=550;, score=0.952 total time=   0.6s\n",
      "[CV 1/5; 271/360] START colsample_bytree=0.7, max_depth=4, n_estimators=300.....\n",
      "[CV 1/5; 271/360] END colsample_bytree=0.7, max_depth=4, n_estimators=300;, score=0.948 total time=   0.4s\n",
      "[CV 2/5; 271/360] START colsample_bytree=0.7, max_depth=4, n_estimators=300.....\n",
      "[CV 2/5; 271/360] END colsample_bytree=0.7, max_depth=4, n_estimators=300;, score=0.951 total time=   0.4s\n",
      "[CV 3/5; 271/360] START colsample_bytree=0.7, max_depth=4, n_estimators=300.....\n",
      "[CV 3/5; 271/360] END colsample_bytree=0.7, max_depth=4, n_estimators=300;, score=0.951 total time=   0.5s\n",
      "[CV 4/5; 271/360] START colsample_bytree=0.7, max_depth=4, n_estimators=300.....\n",
      "[CV 4/5; 271/360] END colsample_bytree=0.7, max_depth=4, n_estimators=300;, score=0.955 total time=   0.5s\n",
      "[CV 5/5; 271/360] START colsample_bytree=0.7, max_depth=4, n_estimators=300.....\n",
      "[CV 5/5; 271/360] END colsample_bytree=0.7, max_depth=4, n_estimators=300;, score=0.952 total time=   0.5s\n",
      "[CV 1/5; 272/360] START colsample_bytree=0.7, max_depth=4, n_estimators=350.....\n",
      "[CV 1/5; 272/360] END colsample_bytree=0.7, max_depth=4, n_estimators=350;, score=0.948 total time=   0.6s\n",
      "[CV 2/5; 272/360] START colsample_bytree=0.7, max_depth=4, n_estimators=350.....\n",
      "[CV 2/5; 272/360] END colsample_bytree=0.7, max_depth=4, n_estimators=350;, score=0.950 total time=   0.6s\n",
      "[CV 3/5; 272/360] START colsample_bytree=0.7, max_depth=4, n_estimators=350.....\n",
      "[CV 3/5; 272/360] END colsample_bytree=0.7, max_depth=4, n_estimators=350;, score=0.951 total time=   0.6s\n",
      "[CV 4/5; 272/360] START colsample_bytree=0.7, max_depth=4, n_estimators=350.....\n",
      "[CV 4/5; 272/360] END colsample_bytree=0.7, max_depth=4, n_estimators=350;, score=0.955 total time=   0.5s\n",
      "[CV 5/5; 272/360] START colsample_bytree=0.7, max_depth=4, n_estimators=350.....\n",
      "[CV 5/5; 272/360] END colsample_bytree=0.7, max_depth=4, n_estimators=350;, score=0.952 total time=   0.5s\n",
      "[CV 1/5; 273/360] START colsample_bytree=0.7, max_depth=4, n_estimators=400.....\n",
      "[CV 1/5; 273/360] END colsample_bytree=0.7, max_depth=4, n_estimators=400;, score=0.947 total time=   0.5s\n",
      "[CV 2/5; 273/360] START colsample_bytree=0.7, max_depth=4, n_estimators=400.....\n",
      "[CV 2/5; 273/360] END colsample_bytree=0.7, max_depth=4, n_estimators=400;, score=0.950 total time=   0.5s\n",
      "[CV 3/5; 273/360] START colsample_bytree=0.7, max_depth=4, n_estimators=400.....\n",
      "[CV 3/5; 273/360] END colsample_bytree=0.7, max_depth=4, n_estimators=400;, score=0.950 total time=   0.5s\n",
      "[CV 4/5; 273/360] START colsample_bytree=0.7, max_depth=4, n_estimators=400.....\n",
      "[CV 4/5; 273/360] END colsample_bytree=0.7, max_depth=4, n_estimators=400;, score=0.955 total time=   0.5s\n",
      "[CV 5/5; 273/360] START colsample_bytree=0.7, max_depth=4, n_estimators=400.....\n",
      "[CV 5/5; 273/360] END colsample_bytree=0.7, max_depth=4, n_estimators=400;, score=0.953 total time=   0.6s\n",
      "[CV 1/5; 274/360] START colsample_bytree=0.7, max_depth=4, n_estimators=450.....\n",
      "[CV 1/5; 274/360] END colsample_bytree=0.7, max_depth=4, n_estimators=450;, score=0.947 total time=   0.7s\n",
      "[CV 2/5; 274/360] START colsample_bytree=0.7, max_depth=4, n_estimators=450.....\n",
      "[CV 2/5; 274/360] END colsample_bytree=0.7, max_depth=4, n_estimators=450;, score=0.949 total time=   0.6s\n",
      "[CV 3/5; 274/360] START colsample_bytree=0.7, max_depth=4, n_estimators=450.....\n",
      "[CV 3/5; 274/360] END colsample_bytree=0.7, max_depth=4, n_estimators=450;, score=0.950 total time=   0.6s\n",
      "[CV 4/5; 274/360] START colsample_bytree=0.7, max_depth=4, n_estimators=450.....\n",
      "[CV 4/5; 274/360] END colsample_bytree=0.7, max_depth=4, n_estimators=450;, score=0.955 total time=   0.7s\n",
      "[CV 5/5; 274/360] START colsample_bytree=0.7, max_depth=4, n_estimators=450.....\n",
      "[CV 5/5; 274/360] END colsample_bytree=0.7, max_depth=4, n_estimators=450;, score=0.951 total time=   0.7s\n",
      "[CV 1/5; 275/360] START colsample_bytree=0.7, max_depth=4, n_estimators=500.....\n",
      "[CV 1/5; 275/360] END colsample_bytree=0.7, max_depth=4, n_estimators=500;, score=0.947 total time=   0.7s\n",
      "[CV 2/5; 275/360] START colsample_bytree=0.7, max_depth=4, n_estimators=500.....\n",
      "[CV 2/5; 275/360] END colsample_bytree=0.7, max_depth=4, n_estimators=500;, score=0.949 total time=   0.7s\n",
      "[CV 3/5; 275/360] START colsample_bytree=0.7, max_depth=4, n_estimators=500.....\n",
      "[CV 3/5; 275/360] END colsample_bytree=0.7, max_depth=4, n_estimators=500;, score=0.950 total time=   0.7s\n",
      "[CV 4/5; 275/360] START colsample_bytree=0.7, max_depth=4, n_estimators=500.....\n",
      "[CV 4/5; 275/360] END colsample_bytree=0.7, max_depth=4, n_estimators=500;, score=0.954 total time=   0.7s\n",
      "[CV 5/5; 275/360] START colsample_bytree=0.7, max_depth=4, n_estimators=500.....\n",
      "[CV 5/5; 275/360] END colsample_bytree=0.7, max_depth=4, n_estimators=500;, score=0.951 total time=   0.8s\n",
      "[CV 1/5; 276/360] START colsample_bytree=0.7, max_depth=4, n_estimators=550.....\n",
      "[CV 1/5; 276/360] END colsample_bytree=0.7, max_depth=4, n_estimators=550;, score=0.947 total time=   1.0s\n",
      "[CV 2/5; 276/360] START colsample_bytree=0.7, max_depth=4, n_estimators=550.....\n",
      "[CV 2/5; 276/360] END colsample_bytree=0.7, max_depth=4, n_estimators=550;, score=0.948 total time=   1.1s\n",
      "[CV 3/5; 276/360] START colsample_bytree=0.7, max_depth=4, n_estimators=550.....\n",
      "[CV 3/5; 276/360] END colsample_bytree=0.7, max_depth=4, n_estimators=550;, score=0.950 total time=   1.1s\n",
      "[CV 4/5; 276/360] START colsample_bytree=0.7, max_depth=4, n_estimators=550.....\n",
      "[CV 4/5; 276/360] END colsample_bytree=0.7, max_depth=4, n_estimators=550;, score=0.954 total time=   1.0s\n",
      "[CV 5/5; 276/360] START colsample_bytree=0.7, max_depth=4, n_estimators=550.....\n",
      "[CV 5/5; 276/360] END colsample_bytree=0.7, max_depth=4, n_estimators=550;, score=0.951 total time=   0.9s\n",
      "[CV 1/5; 277/360] START colsample_bytree=0.7, max_depth=5, n_estimators=300.....\n",
      "[CV 1/5; 277/360] END colsample_bytree=0.7, max_depth=5, n_estimators=300;, score=0.949 total time=   0.5s\n",
      "[CV 2/5; 277/360] START colsample_bytree=0.7, max_depth=5, n_estimators=300.....\n",
      "[CV 2/5; 277/360] END colsample_bytree=0.7, max_depth=5, n_estimators=300;, score=0.950 total time=   0.5s\n",
      "[CV 3/5; 277/360] START colsample_bytree=0.7, max_depth=5, n_estimators=300.....\n",
      "[CV 3/5; 277/360] END colsample_bytree=0.7, max_depth=5, n_estimators=300;, score=0.951 total time=   0.6s\n",
      "[CV 4/5; 277/360] START colsample_bytree=0.7, max_depth=5, n_estimators=300.....\n",
      "[CV 4/5; 277/360] END colsample_bytree=0.7, max_depth=5, n_estimators=300;, score=0.956 total time=   0.5s\n",
      "[CV 5/5; 277/360] START colsample_bytree=0.7, max_depth=5, n_estimators=300.....\n",
      "[CV 5/5; 277/360] END colsample_bytree=0.7, max_depth=5, n_estimators=300;, score=0.952 total time=   0.5s\n",
      "[CV 1/5; 278/360] START colsample_bytree=0.7, max_depth=5, n_estimators=350.....\n",
      "[CV 1/5; 278/360] END colsample_bytree=0.7, max_depth=5, n_estimators=350;, score=0.948 total time=   0.5s\n",
      "[CV 2/5; 278/360] START colsample_bytree=0.7, max_depth=5, n_estimators=350.....\n",
      "[CV 2/5; 278/360] END colsample_bytree=0.7, max_depth=5, n_estimators=350;, score=0.949 total time=   0.6s\n",
      "[CV 3/5; 278/360] START colsample_bytree=0.7, max_depth=5, n_estimators=350.....\n",
      "[CV 3/5; 278/360] END colsample_bytree=0.7, max_depth=5, n_estimators=350;, score=0.950 total time=   0.5s\n",
      "[CV 4/5; 278/360] START colsample_bytree=0.7, max_depth=5, n_estimators=350.....\n",
      "[CV 4/5; 278/360] END colsample_bytree=0.7, max_depth=5, n_estimators=350;, score=0.955 total time=   0.7s\n",
      "[CV 5/5; 278/360] START colsample_bytree=0.7, max_depth=5, n_estimators=350.....\n",
      "[CV 5/5; 278/360] END colsample_bytree=0.7, max_depth=5, n_estimators=350;, score=0.951 total time=   0.6s\n",
      "[CV 1/5; 279/360] START colsample_bytree=0.7, max_depth=5, n_estimators=400.....\n",
      "[CV 1/5; 279/360] END colsample_bytree=0.7, max_depth=5, n_estimators=400;, score=0.948 total time=   0.6s\n",
      "[CV 2/5; 279/360] START colsample_bytree=0.7, max_depth=5, n_estimators=400.....\n",
      "[CV 2/5; 279/360] END colsample_bytree=0.7, max_depth=5, n_estimators=400;, score=0.949 total time=   0.6s\n",
      "[CV 3/5; 279/360] START colsample_bytree=0.7, max_depth=5, n_estimators=400.....\n",
      "[CV 3/5; 279/360] END colsample_bytree=0.7, max_depth=5, n_estimators=400;, score=0.950 total time=   0.7s\n",
      "[CV 4/5; 279/360] START colsample_bytree=0.7, max_depth=5, n_estimators=400.....\n",
      "[CV 4/5; 279/360] END colsample_bytree=0.7, max_depth=5, n_estimators=400;, score=0.953 total time=   0.7s\n",
      "[CV 5/5; 279/360] START colsample_bytree=0.7, max_depth=5, n_estimators=400.....\n",
      "[CV 5/5; 279/360] END colsample_bytree=0.7, max_depth=5, n_estimators=400;, score=0.951 total time=   0.6s\n",
      "[CV 1/5; 280/360] START colsample_bytree=0.7, max_depth=5, n_estimators=450.....\n",
      "[CV 1/5; 280/360] END colsample_bytree=0.7, max_depth=5, n_estimators=450;, score=0.948 total time=   0.9s\n",
      "[CV 2/5; 280/360] START colsample_bytree=0.7, max_depth=5, n_estimators=450.....\n",
      "[CV 2/5; 280/360] END colsample_bytree=0.7, max_depth=5, n_estimators=450;, score=0.948 total time=   0.9s\n",
      "[CV 3/5; 280/360] START colsample_bytree=0.7, max_depth=5, n_estimators=450.....\n",
      "[CV 3/5; 280/360] END colsample_bytree=0.7, max_depth=5, n_estimators=450;, score=0.949 total time=   0.9s\n",
      "[CV 4/5; 280/360] START colsample_bytree=0.7, max_depth=5, n_estimators=450.....\n",
      "[CV 4/5; 280/360] END colsample_bytree=0.7, max_depth=5, n_estimators=450;, score=0.953 total time=   0.9s\n",
      "[CV 5/5; 280/360] START colsample_bytree=0.7, max_depth=5, n_estimators=450.....\n",
      "[CV 5/5; 280/360] END colsample_bytree=0.7, max_depth=5, n_estimators=450;, score=0.949 total time=   0.7s\n",
      "[CV 1/5; 281/360] START colsample_bytree=0.7, max_depth=5, n_estimators=500.....\n",
      "[CV 1/5; 281/360] END colsample_bytree=0.7, max_depth=5, n_estimators=500;, score=0.948 total time=   0.8s\n",
      "[CV 2/5; 281/360] START colsample_bytree=0.7, max_depth=5, n_estimators=500.....\n",
      "[CV 2/5; 281/360] END colsample_bytree=0.7, max_depth=5, n_estimators=500;, score=0.948 total time=   0.9s\n",
      "[CV 3/5; 281/360] START colsample_bytree=0.7, max_depth=5, n_estimators=500.....\n",
      "[CV 3/5; 281/360] END colsample_bytree=0.7, max_depth=5, n_estimators=500;, score=0.950 total time=   0.8s\n",
      "[CV 4/5; 281/360] START colsample_bytree=0.7, max_depth=5, n_estimators=500.....\n",
      "[CV 4/5; 281/360] END colsample_bytree=0.7, max_depth=5, n_estimators=500;, score=0.953 total time=   0.8s\n",
      "[CV 5/5; 281/360] START colsample_bytree=0.7, max_depth=5, n_estimators=500.....\n",
      "[CV 5/5; 281/360] END colsample_bytree=0.7, max_depth=5, n_estimators=500;, score=0.950 total time=   0.8s\n",
      "[CV 1/5; 282/360] START colsample_bytree=0.7, max_depth=5, n_estimators=550.....\n",
      "[CV 1/5; 282/360] END colsample_bytree=0.7, max_depth=5, n_estimators=550;, score=0.948 total time=   0.8s\n",
      "[CV 2/5; 282/360] START colsample_bytree=0.7, max_depth=5, n_estimators=550.....\n",
      "[CV 2/5; 282/360] END colsample_bytree=0.7, max_depth=5, n_estimators=550;, score=0.949 total time=   0.8s\n",
      "[CV 3/5; 282/360] START colsample_bytree=0.7, max_depth=5, n_estimators=550.....\n",
      "[CV 3/5; 282/360] END colsample_bytree=0.7, max_depth=5, n_estimators=550;, score=0.950 total time=   0.9s\n",
      "[CV 4/5; 282/360] START colsample_bytree=0.7, max_depth=5, n_estimators=550.....\n",
      "[CV 4/5; 282/360] END colsample_bytree=0.7, max_depth=5, n_estimators=550;, score=0.953 total time=   0.8s\n",
      "[CV 5/5; 282/360] START colsample_bytree=0.7, max_depth=5, n_estimators=550.....\n",
      "[CV 5/5; 282/360] END colsample_bytree=0.7, max_depth=5, n_estimators=550;, score=0.949 total time=   0.8s\n",
      "[CV 1/5; 283/360] START colsample_bytree=0.7, max_depth=6, n_estimators=300.....\n",
      "[CV 1/5; 283/360] END colsample_bytree=0.7, max_depth=6, n_estimators=300;, score=0.947 total time=   0.6s\n",
      "[CV 2/5; 283/360] START colsample_bytree=0.7, max_depth=6, n_estimators=300.....\n",
      "[CV 2/5; 283/360] END colsample_bytree=0.7, max_depth=6, n_estimators=300;, score=0.950 total time=   0.5s\n",
      "[CV 3/5; 283/360] START colsample_bytree=0.7, max_depth=6, n_estimators=300.....\n",
      "[CV 3/5; 283/360] END colsample_bytree=0.7, max_depth=6, n_estimators=300;, score=0.950 total time=   0.5s\n",
      "[CV 4/5; 283/360] START colsample_bytree=0.7, max_depth=6, n_estimators=300.....\n",
      "[CV 4/5; 283/360] END colsample_bytree=0.7, max_depth=6, n_estimators=300;, score=0.952 total time=   0.7s\n",
      "[CV 5/5; 283/360] START colsample_bytree=0.7, max_depth=6, n_estimators=300.....\n",
      "[CV 5/5; 283/360] END colsample_bytree=0.7, max_depth=6, n_estimators=300;, score=0.950 total time=   0.7s\n",
      "[CV 1/5; 284/360] START colsample_bytree=0.7, max_depth=6, n_estimators=350.....\n",
      "[CV 1/5; 284/360] END colsample_bytree=0.7, max_depth=6, n_estimators=350;, score=0.946 total time=   0.8s\n",
      "[CV 2/5; 284/360] START colsample_bytree=0.7, max_depth=6, n_estimators=350.....\n",
      "[CV 2/5; 284/360] END colsample_bytree=0.7, max_depth=6, n_estimators=350;, score=0.949 total time=   0.8s\n",
      "[CV 3/5; 284/360] START colsample_bytree=0.7, max_depth=6, n_estimators=350.....\n",
      "[CV 3/5; 284/360] END colsample_bytree=0.7, max_depth=6, n_estimators=350;, score=0.950 total time=   0.7s\n",
      "[CV 4/5; 284/360] START colsample_bytree=0.7, max_depth=6, n_estimators=350.....\n",
      "[CV 4/5; 284/360] END colsample_bytree=0.7, max_depth=6, n_estimators=350;, score=0.952 total time=   0.6s\n",
      "[CV 5/5; 284/360] START colsample_bytree=0.7, max_depth=6, n_estimators=350.....\n",
      "[CV 5/5; 284/360] END colsample_bytree=0.7, max_depth=6, n_estimators=350;, score=0.949 total time=   0.7s\n",
      "[CV 1/5; 285/360] START colsample_bytree=0.7, max_depth=6, n_estimators=400.....\n",
      "[CV 1/5; 285/360] END colsample_bytree=0.7, max_depth=6, n_estimators=400;, score=0.946 total time=   0.7s\n",
      "[CV 2/5; 285/360] START colsample_bytree=0.7, max_depth=6, n_estimators=400.....\n",
      "[CV 2/5; 285/360] END colsample_bytree=0.7, max_depth=6, n_estimators=400;, score=0.948 total time=   0.7s\n",
      "[CV 3/5; 285/360] START colsample_bytree=0.7, max_depth=6, n_estimators=400.....\n",
      "[CV 3/5; 285/360] END colsample_bytree=0.7, max_depth=6, n_estimators=400;, score=0.950 total time=   0.7s\n",
      "[CV 4/5; 285/360] START colsample_bytree=0.7, max_depth=6, n_estimators=400.....\n",
      "[CV 4/5; 285/360] END colsample_bytree=0.7, max_depth=6, n_estimators=400;, score=0.952 total time=   0.7s\n",
      "[CV 5/5; 285/360] START colsample_bytree=0.7, max_depth=6, n_estimators=400.....\n",
      "[CV 5/5; 285/360] END colsample_bytree=0.7, max_depth=6, n_estimators=400;, score=0.950 total time=   0.7s\n",
      "[CV 1/5; 286/360] START colsample_bytree=0.7, max_depth=6, n_estimators=450.....\n",
      "[CV 1/5; 286/360] END colsample_bytree=0.7, max_depth=6, n_estimators=450;, score=0.946 total time=   0.8s\n",
      "[CV 2/5; 286/360] START colsample_bytree=0.7, max_depth=6, n_estimators=450.....\n",
      "[CV 2/5; 286/360] END colsample_bytree=0.7, max_depth=6, n_estimators=450;, score=0.948 total time=   0.8s\n",
      "[CV 3/5; 286/360] START colsample_bytree=0.7, max_depth=6, n_estimators=450.....\n",
      "[CV 3/5; 286/360] END colsample_bytree=0.7, max_depth=6, n_estimators=450;, score=0.950 total time=   0.8s\n",
      "[CV 4/5; 286/360] START colsample_bytree=0.7, max_depth=6, n_estimators=450.....\n",
      "[CV 4/5; 286/360] END colsample_bytree=0.7, max_depth=6, n_estimators=450;, score=0.952 total time=   0.8s\n",
      "[CV 5/5; 286/360] START colsample_bytree=0.7, max_depth=6, n_estimators=450.....\n",
      "[CV 5/5; 286/360] END colsample_bytree=0.7, max_depth=6, n_estimators=450;, score=0.949 total time=   0.8s\n",
      "[CV 1/5; 287/360] START colsample_bytree=0.7, max_depth=6, n_estimators=500.....\n",
      "[CV 1/5; 287/360] END colsample_bytree=0.7, max_depth=6, n_estimators=500;, score=0.946 total time=   0.9s\n",
      "[CV 2/5; 287/360] START colsample_bytree=0.7, max_depth=6, n_estimators=500.....\n",
      "[CV 2/5; 287/360] END colsample_bytree=0.7, max_depth=6, n_estimators=500;, score=0.948 total time=   1.0s\n",
      "[CV 3/5; 287/360] START colsample_bytree=0.7, max_depth=6, n_estimators=500.....\n",
      "[CV 3/5; 287/360] END colsample_bytree=0.7, max_depth=6, n_estimators=500;, score=0.949 total time=   1.1s\n",
      "[CV 4/5; 287/360] START colsample_bytree=0.7, max_depth=6, n_estimators=500.....\n",
      "[CV 4/5; 287/360] END colsample_bytree=0.7, max_depth=6, n_estimators=500;, score=0.952 total time=   1.2s\n",
      "[CV 5/5; 287/360] START colsample_bytree=0.7, max_depth=6, n_estimators=500.....\n",
      "[CV 5/5; 287/360] END colsample_bytree=0.7, max_depth=6, n_estimators=500;, score=0.949 total time=   1.0s\n",
      "[CV 1/5; 288/360] START colsample_bytree=0.7, max_depth=6, n_estimators=550.....\n",
      "[CV 1/5; 288/360] END colsample_bytree=0.7, max_depth=6, n_estimators=550;, score=0.946 total time=   1.0s\n",
      "[CV 2/5; 288/360] START colsample_bytree=0.7, max_depth=6, n_estimators=550.....\n",
      "[CV 2/5; 288/360] END colsample_bytree=0.7, max_depth=6, n_estimators=550;, score=0.948 total time=   1.1s\n",
      "[CV 3/5; 288/360] START colsample_bytree=0.7, max_depth=6, n_estimators=550.....\n",
      "[CV 3/5; 288/360] END colsample_bytree=0.7, max_depth=6, n_estimators=550;, score=0.949 total time=   1.1s\n",
      "[CV 4/5; 288/360] START colsample_bytree=0.7, max_depth=6, n_estimators=550.....\n",
      "[CV 4/5; 288/360] END colsample_bytree=0.7, max_depth=6, n_estimators=550;, score=0.951 total time=   1.0s\n",
      "[CV 5/5; 288/360] START colsample_bytree=0.7, max_depth=6, n_estimators=550.....\n",
      "[CV 5/5; 288/360] END colsample_bytree=0.7, max_depth=6, n_estimators=550;, score=0.949 total time=   1.0s\n",
      "[CV 1/5; 289/360] START colsample_bytree=0.8, max_depth=1, n_estimators=300.....\n",
      "[CV 1/5; 289/360] END colsample_bytree=0.8, max_depth=1, n_estimators=300;, score=0.929 total time=   0.2s\n",
      "[CV 2/5; 289/360] START colsample_bytree=0.8, max_depth=1, n_estimators=300.....\n",
      "[CV 2/5; 289/360] END colsample_bytree=0.8, max_depth=1, n_estimators=300;, score=0.929 total time=   0.2s\n",
      "[CV 3/5; 289/360] START colsample_bytree=0.8, max_depth=1, n_estimators=300.....\n",
      "[CV 3/5; 289/360] END colsample_bytree=0.8, max_depth=1, n_estimators=300;, score=0.931 total time=   0.2s\n",
      "[CV 4/5; 289/360] START colsample_bytree=0.8, max_depth=1, n_estimators=300.....\n",
      "[CV 4/5; 289/360] END colsample_bytree=0.8, max_depth=1, n_estimators=300;, score=0.932 total time=   0.2s\n",
      "[CV 5/5; 289/360] START colsample_bytree=0.8, max_depth=1, n_estimators=300.....\n",
      "[CV 5/5; 289/360] END colsample_bytree=0.8, max_depth=1, n_estimators=300;, score=0.930 total time=   0.2s\n",
      "[CV 1/5; 290/360] START colsample_bytree=0.8, max_depth=1, n_estimators=350.....\n",
      "[CV 1/5; 290/360] END colsample_bytree=0.8, max_depth=1, n_estimators=350;, score=0.929 total time=   0.3s\n",
      "[CV 2/5; 290/360] START colsample_bytree=0.8, max_depth=1, n_estimators=350.....\n",
      "[CV 2/5; 290/360] END colsample_bytree=0.8, max_depth=1, n_estimators=350;, score=0.929 total time=   0.3s\n",
      "[CV 3/5; 290/360] START colsample_bytree=0.8, max_depth=1, n_estimators=350.....\n",
      "[CV 3/5; 290/360] END colsample_bytree=0.8, max_depth=1, n_estimators=350;, score=0.931 total time=   0.3s\n",
      "[CV 4/5; 290/360] START colsample_bytree=0.8, max_depth=1, n_estimators=350.....\n",
      "[CV 4/5; 290/360] END colsample_bytree=0.8, max_depth=1, n_estimators=350;, score=0.932 total time=   0.3s\n",
      "[CV 5/5; 290/360] START colsample_bytree=0.8, max_depth=1, n_estimators=350.....\n",
      "[CV 5/5; 290/360] END colsample_bytree=0.8, max_depth=1, n_estimators=350;, score=0.931 total time=   0.3s\n",
      "[CV 1/5; 291/360] START colsample_bytree=0.8, max_depth=1, n_estimators=400.....\n",
      "[CV 1/5; 291/360] END colsample_bytree=0.8, max_depth=1, n_estimators=400;, score=0.929 total time=   0.3s\n",
      "[CV 2/5; 291/360] START colsample_bytree=0.8, max_depth=1, n_estimators=400.....\n",
      "[CV 2/5; 291/360] END colsample_bytree=0.8, max_depth=1, n_estimators=400;, score=0.929 total time=   0.3s\n",
      "[CV 3/5; 291/360] START colsample_bytree=0.8, max_depth=1, n_estimators=400.....\n",
      "[CV 3/5; 291/360] END colsample_bytree=0.8, max_depth=1, n_estimators=400;, score=0.931 total time=   0.3s\n",
      "[CV 4/5; 291/360] START colsample_bytree=0.8, max_depth=1, n_estimators=400.....\n",
      "[CV 4/5; 291/360] END colsample_bytree=0.8, max_depth=1, n_estimators=400;, score=0.932 total time=   0.3s\n",
      "[CV 5/5; 291/360] START colsample_bytree=0.8, max_depth=1, n_estimators=400.....\n",
      "[CV 5/5; 291/360] END colsample_bytree=0.8, max_depth=1, n_estimators=400;, score=0.931 total time=   0.4s\n",
      "[CV 1/5; 292/360] START colsample_bytree=0.8, max_depth=1, n_estimators=450.....\n",
      "[CV 1/5; 292/360] END colsample_bytree=0.8, max_depth=1, n_estimators=450;, score=0.929 total time=   0.5s\n",
      "[CV 2/5; 292/360] START colsample_bytree=0.8, max_depth=1, n_estimators=450.....\n",
      "[CV 2/5; 292/360] END colsample_bytree=0.8, max_depth=1, n_estimators=450;, score=0.929 total time=   0.5s\n",
      "[CV 3/5; 292/360] START colsample_bytree=0.8, max_depth=1, n_estimators=450.....\n",
      "[CV 3/5; 292/360] END colsample_bytree=0.8, max_depth=1, n_estimators=450;, score=0.931 total time=   0.5s\n",
      "[CV 4/5; 292/360] START colsample_bytree=0.8, max_depth=1, n_estimators=450.....\n",
      "[CV 4/5; 292/360] END colsample_bytree=0.8, max_depth=1, n_estimators=450;, score=0.932 total time=   0.5s\n",
      "[CV 5/5; 292/360] START colsample_bytree=0.8, max_depth=1, n_estimators=450.....\n",
      "[CV 5/5; 292/360] END colsample_bytree=0.8, max_depth=1, n_estimators=450;, score=0.931 total time=   0.5s\n",
      "[CV 1/5; 293/360] START colsample_bytree=0.8, max_depth=1, n_estimators=500.....\n",
      "[CV 1/5; 293/360] END colsample_bytree=0.8, max_depth=1, n_estimators=500;, score=0.930 total time=   0.5s\n",
      "[CV 2/5; 293/360] START colsample_bytree=0.8, max_depth=1, n_estimators=500.....\n",
      "[CV 2/5; 293/360] END colsample_bytree=0.8, max_depth=1, n_estimators=500;, score=0.929 total time=   0.5s\n",
      "[CV 3/5; 293/360] START colsample_bytree=0.8, max_depth=1, n_estimators=500.....\n",
      "[CV 3/5; 293/360] END colsample_bytree=0.8, max_depth=1, n_estimators=500;, score=0.931 total time=   0.4s\n",
      "[CV 4/5; 293/360] START colsample_bytree=0.8, max_depth=1, n_estimators=500.....\n",
      "[CV 4/5; 293/360] END colsample_bytree=0.8, max_depth=1, n_estimators=500;, score=0.932 total time=   0.4s\n",
      "[CV 5/5; 293/360] START colsample_bytree=0.8, max_depth=1, n_estimators=500.....\n",
      "[CV 5/5; 293/360] END colsample_bytree=0.8, max_depth=1, n_estimators=500;, score=0.931 total time=   0.5s\n",
      "[CV 1/5; 294/360] START colsample_bytree=0.8, max_depth=1, n_estimators=550.....\n",
      "[CV 1/5; 294/360] END colsample_bytree=0.8, max_depth=1, n_estimators=550;, score=0.929 total time=   0.5s\n",
      "[CV 2/5; 294/360] START colsample_bytree=0.8, max_depth=1, n_estimators=550.....\n",
      "[CV 2/5; 294/360] END colsample_bytree=0.8, max_depth=1, n_estimators=550;, score=0.929 total time=   0.5s\n",
      "[CV 3/5; 294/360] START colsample_bytree=0.8, max_depth=1, n_estimators=550.....\n",
      "[CV 3/5; 294/360] END colsample_bytree=0.8, max_depth=1, n_estimators=550;, score=0.931 total time=   0.5s\n",
      "[CV 4/5; 294/360] START colsample_bytree=0.8, max_depth=1, n_estimators=550.....\n",
      "[CV 4/5; 294/360] END colsample_bytree=0.8, max_depth=1, n_estimators=550;, score=0.932 total time=   0.5s\n",
      "[CV 5/5; 294/360] START colsample_bytree=0.8, max_depth=1, n_estimators=550.....\n",
      "[CV 5/5; 294/360] END colsample_bytree=0.8, max_depth=1, n_estimators=550;, score=0.932 total time=   0.5s\n",
      "[CV 1/5; 295/360] START colsample_bytree=0.8, max_depth=2, n_estimators=300.....\n",
      "[CV 1/5; 295/360] END colsample_bytree=0.8, max_depth=2, n_estimators=300;, score=0.948 total time=   0.3s\n",
      "[CV 2/5; 295/360] START colsample_bytree=0.8, max_depth=2, n_estimators=300.....\n",
      "[CV 2/5; 295/360] END colsample_bytree=0.8, max_depth=2, n_estimators=300;, score=0.951 total time=   0.3s\n",
      "[CV 3/5; 295/360] START colsample_bytree=0.8, max_depth=2, n_estimators=300.....\n",
      "[CV 3/5; 295/360] END colsample_bytree=0.8, max_depth=2, n_estimators=300;, score=0.951 total time=   0.3s\n",
      "[CV 4/5; 295/360] START colsample_bytree=0.8, max_depth=2, n_estimators=300.....\n",
      "[CV 4/5; 295/360] END colsample_bytree=0.8, max_depth=2, n_estimators=300;, score=0.955 total time=   0.3s\n",
      "[CV 5/5; 295/360] START colsample_bytree=0.8, max_depth=2, n_estimators=300.....\n",
      "[CV 5/5; 295/360] END colsample_bytree=0.8, max_depth=2, n_estimators=300;, score=0.951 total time=   0.3s\n",
      "[CV 1/5; 296/360] START colsample_bytree=0.8, max_depth=2, n_estimators=350.....\n",
      "[CV 1/5; 296/360] END colsample_bytree=0.8, max_depth=2, n_estimators=350;, score=0.949 total time=   0.3s\n",
      "[CV 2/5; 296/360] START colsample_bytree=0.8, max_depth=2, n_estimators=350.....\n",
      "[CV 2/5; 296/360] END colsample_bytree=0.8, max_depth=2, n_estimators=350;, score=0.951 total time=   0.4s\n",
      "[CV 3/5; 296/360] START colsample_bytree=0.8, max_depth=2, n_estimators=350.....\n",
      "[CV 3/5; 296/360] END colsample_bytree=0.8, max_depth=2, n_estimators=350;, score=0.952 total time=   0.3s\n",
      "[CV 4/5; 296/360] START colsample_bytree=0.8, max_depth=2, n_estimators=350.....\n",
      "[CV 4/5; 296/360] END colsample_bytree=0.8, max_depth=2, n_estimators=350;, score=0.955 total time=   0.4s\n",
      "[CV 5/5; 296/360] START colsample_bytree=0.8, max_depth=2, n_estimators=350.....\n",
      "[CV 5/5; 296/360] END colsample_bytree=0.8, max_depth=2, n_estimators=350;, score=0.951 total time=   0.3s\n",
      "[CV 1/5; 297/360] START colsample_bytree=0.8, max_depth=2, n_estimators=400.....\n",
      "[CV 1/5; 297/360] END colsample_bytree=0.8, max_depth=2, n_estimators=400;, score=0.949 total time=   0.4s\n",
      "[CV 2/5; 297/360] START colsample_bytree=0.8, max_depth=2, n_estimators=400.....\n",
      "[CV 2/5; 297/360] END colsample_bytree=0.8, max_depth=2, n_estimators=400;, score=0.950 total time=   0.4s\n",
      "[CV 3/5; 297/360] START colsample_bytree=0.8, max_depth=2, n_estimators=400.....\n",
      "[CV 3/5; 297/360] END colsample_bytree=0.8, max_depth=2, n_estimators=400;, score=0.951 total time=   0.5s\n",
      "[CV 4/5; 297/360] START colsample_bytree=0.8, max_depth=2, n_estimators=400.....\n",
      "[CV 4/5; 297/360] END colsample_bytree=0.8, max_depth=2, n_estimators=400;, score=0.955 total time=   0.4s\n",
      "[CV 5/5; 297/360] START colsample_bytree=0.8, max_depth=2, n_estimators=400.....\n",
      "[CV 5/5; 297/360] END colsample_bytree=0.8, max_depth=2, n_estimators=400;, score=0.951 total time=   0.4s\n",
      "[CV 1/5; 298/360] START colsample_bytree=0.8, max_depth=2, n_estimators=450.....\n",
      "[CV 1/5; 298/360] END colsample_bytree=0.8, max_depth=2, n_estimators=450;, score=0.949 total time=   0.4s\n",
      "[CV 2/5; 298/360] START colsample_bytree=0.8, max_depth=2, n_estimators=450.....\n",
      "[CV 2/5; 298/360] END colsample_bytree=0.8, max_depth=2, n_estimators=450;, score=0.950 total time=   0.5s\n",
      "[CV 3/5; 298/360] START colsample_bytree=0.8, max_depth=2, n_estimators=450.....\n",
      "[CV 3/5; 298/360] END colsample_bytree=0.8, max_depth=2, n_estimators=450;, score=0.952 total time=   0.6s\n",
      "[CV 4/5; 298/360] START colsample_bytree=0.8, max_depth=2, n_estimators=450.....\n",
      "[CV 4/5; 298/360] END colsample_bytree=0.8, max_depth=2, n_estimators=450;, score=0.954 total time=   0.6s\n",
      "[CV 5/5; 298/360] START colsample_bytree=0.8, max_depth=2, n_estimators=450.....\n",
      "[CV 5/5; 298/360] END colsample_bytree=0.8, max_depth=2, n_estimators=450;, score=0.951 total time=   0.6s\n",
      "[CV 1/5; 299/360] START colsample_bytree=0.8, max_depth=2, n_estimators=500.....\n",
      "[CV 1/5; 299/360] END colsample_bytree=0.8, max_depth=2, n_estimators=500;, score=0.949 total time=   0.6s\n",
      "[CV 2/5; 299/360] START colsample_bytree=0.8, max_depth=2, n_estimators=500.....\n",
      "[CV 2/5; 299/360] END colsample_bytree=0.8, max_depth=2, n_estimators=500;, score=0.950 total time=   0.7s\n",
      "[CV 3/5; 299/360] START colsample_bytree=0.8, max_depth=2, n_estimators=500.....\n",
      "[CV 3/5; 299/360] END colsample_bytree=0.8, max_depth=2, n_estimators=500;, score=0.951 total time=   0.5s\n",
      "[CV 4/5; 299/360] START colsample_bytree=0.8, max_depth=2, n_estimators=500.....\n",
      "[CV 4/5; 299/360] END colsample_bytree=0.8, max_depth=2, n_estimators=500;, score=0.955 total time=   0.5s\n",
      "[CV 5/5; 299/360] START colsample_bytree=0.8, max_depth=2, n_estimators=500.....\n",
      "[CV 5/5; 299/360] END colsample_bytree=0.8, max_depth=2, n_estimators=500;, score=0.951 total time=   0.5s\n",
      "[CV 1/5; 300/360] START colsample_bytree=0.8, max_depth=2, n_estimators=550.....\n",
      "[CV 1/5; 300/360] END colsample_bytree=0.8, max_depth=2, n_estimators=550;, score=0.948 total time=   0.5s\n",
      "[CV 2/5; 300/360] START colsample_bytree=0.8, max_depth=2, n_estimators=550.....\n",
      "[CV 2/5; 300/360] END colsample_bytree=0.8, max_depth=2, n_estimators=550;, score=0.950 total time=   0.7s\n",
      "[CV 3/5; 300/360] START colsample_bytree=0.8, max_depth=2, n_estimators=550.....\n",
      "[CV 3/5; 300/360] END colsample_bytree=0.8, max_depth=2, n_estimators=550;, score=0.951 total time=   0.5s\n",
      "[CV 4/5; 300/360] START colsample_bytree=0.8, max_depth=2, n_estimators=550.....\n",
      "[CV 4/5; 300/360] END colsample_bytree=0.8, max_depth=2, n_estimators=550;, score=0.954 total time=   0.5s\n",
      "[CV 5/5; 300/360] START colsample_bytree=0.8, max_depth=2, n_estimators=550.....\n",
      "[CV 5/5; 300/360] END colsample_bytree=0.8, max_depth=2, n_estimators=550;, score=0.951 total time=   0.6s\n",
      "[CV 1/5; 301/360] START colsample_bytree=0.8, max_depth=3, n_estimators=300.....\n",
      "[CV 1/5; 301/360] END colsample_bytree=0.8, max_depth=3, n_estimators=300;, score=0.949 total time=   0.3s\n",
      "[CV 2/5; 301/360] START colsample_bytree=0.8, max_depth=3, n_estimators=300.....\n",
      "[CV 2/5; 301/360] END colsample_bytree=0.8, max_depth=3, n_estimators=300;, score=0.951 total time=   0.3s\n",
      "[CV 3/5; 301/360] START colsample_bytree=0.8, max_depth=3, n_estimators=300.....\n",
      "[CV 3/5; 301/360] END colsample_bytree=0.8, max_depth=3, n_estimators=300;, score=0.951 total time=   0.4s\n",
      "[CV 4/5; 301/360] START colsample_bytree=0.8, max_depth=3, n_estimators=300.....\n",
      "[CV 4/5; 301/360] END colsample_bytree=0.8, max_depth=3, n_estimators=300;, score=0.955 total time=   0.3s\n",
      "[CV 5/5; 301/360] START colsample_bytree=0.8, max_depth=3, n_estimators=300.....\n",
      "[CV 5/5; 301/360] END colsample_bytree=0.8, max_depth=3, n_estimators=300;, score=0.953 total time=   0.3s\n",
      "[CV 1/5; 302/360] START colsample_bytree=0.8, max_depth=3, n_estimators=350.....\n",
      "[CV 1/5; 302/360] END colsample_bytree=0.8, max_depth=3, n_estimators=350;, score=0.950 total time=   0.4s\n",
      "[CV 2/5; 302/360] START colsample_bytree=0.8, max_depth=3, n_estimators=350.....\n",
      "[CV 2/5; 302/360] END colsample_bytree=0.8, max_depth=3, n_estimators=350;, score=0.951 total time=   0.4s\n",
      "[CV 3/5; 302/360] START colsample_bytree=0.8, max_depth=3, n_estimators=350.....\n",
      "[CV 3/5; 302/360] END colsample_bytree=0.8, max_depth=3, n_estimators=350;, score=0.952 total time=   0.5s\n",
      "[CV 4/5; 302/360] START colsample_bytree=0.8, max_depth=3, n_estimators=350.....\n",
      "[CV 4/5; 302/360] END colsample_bytree=0.8, max_depth=3, n_estimators=350;, score=0.955 total time=   0.4s\n",
      "[CV 5/5; 302/360] START colsample_bytree=0.8, max_depth=3, n_estimators=350.....\n",
      "[CV 5/5; 302/360] END colsample_bytree=0.8, max_depth=3, n_estimators=350;, score=0.953 total time=   0.4s\n",
      "[CV 1/5; 303/360] START colsample_bytree=0.8, max_depth=3, n_estimators=400.....\n",
      "[CV 1/5; 303/360] END colsample_bytree=0.8, max_depth=3, n_estimators=400;, score=0.949 total time=   0.5s\n",
      "[CV 2/5; 303/360] START colsample_bytree=0.8, max_depth=3, n_estimators=400.....\n",
      "[CV 2/5; 303/360] END colsample_bytree=0.8, max_depth=3, n_estimators=400;, score=0.951 total time=   0.5s\n",
      "[CV 3/5; 303/360] START colsample_bytree=0.8, max_depth=3, n_estimators=400.....\n",
      "[CV 3/5; 303/360] END colsample_bytree=0.8, max_depth=3, n_estimators=400;, score=0.952 total time=   0.5s\n",
      "[CV 4/5; 303/360] START colsample_bytree=0.8, max_depth=3, n_estimators=400.....\n",
      "[CV 4/5; 303/360] END colsample_bytree=0.8, max_depth=3, n_estimators=400;, score=0.954 total time=   0.5s\n",
      "[CV 5/5; 303/360] START colsample_bytree=0.8, max_depth=3, n_estimators=400.....\n",
      "[CV 5/5; 303/360] END colsample_bytree=0.8, max_depth=3, n_estimators=400;, score=0.953 total time=   0.6s\n",
      "[CV 1/5; 304/360] START colsample_bytree=0.8, max_depth=3, n_estimators=450.....\n",
      "[CV 1/5; 304/360] END colsample_bytree=0.8, max_depth=3, n_estimators=450;, score=0.949 total time=   0.7s\n",
      "[CV 2/5; 304/360] START colsample_bytree=0.8, max_depth=3, n_estimators=450.....\n",
      "[CV 2/5; 304/360] END colsample_bytree=0.8, max_depth=3, n_estimators=450;, score=0.951 total time=   0.7s\n",
      "[CV 3/5; 304/360] START colsample_bytree=0.8, max_depth=3, n_estimators=450.....\n",
      "[CV 3/5; 304/360] END colsample_bytree=0.8, max_depth=3, n_estimators=450;, score=0.952 total time=   0.7s\n",
      "[CV 4/5; 304/360] START colsample_bytree=0.8, max_depth=3, n_estimators=450.....\n",
      "[CV 4/5; 304/360] END colsample_bytree=0.8, max_depth=3, n_estimators=450;, score=0.954 total time=   0.6s\n",
      "[CV 5/5; 304/360] START colsample_bytree=0.8, max_depth=3, n_estimators=450.....\n",
      "[CV 5/5; 304/360] END colsample_bytree=0.8, max_depth=3, n_estimators=450;, score=0.953 total time=   0.5s\n",
      "[CV 1/5; 305/360] START colsample_bytree=0.8, max_depth=3, n_estimators=500.....\n",
      "[CV 1/5; 305/360] END colsample_bytree=0.8, max_depth=3, n_estimators=500;, score=0.949 total time=   0.6s\n",
      "[CV 2/5; 305/360] START colsample_bytree=0.8, max_depth=3, n_estimators=500.....\n",
      "[CV 2/5; 305/360] END colsample_bytree=0.8, max_depth=3, n_estimators=500;, score=0.951 total time=   0.6s\n",
      "[CV 3/5; 305/360] START colsample_bytree=0.8, max_depth=3, n_estimators=500.....\n",
      "[CV 3/5; 305/360] END colsample_bytree=0.8, max_depth=3, n_estimators=500;, score=0.952 total time=   0.6s\n",
      "[CV 4/5; 305/360] START colsample_bytree=0.8, max_depth=3, n_estimators=500.....\n",
      "[CV 4/5; 305/360] END colsample_bytree=0.8, max_depth=3, n_estimators=500;, score=0.954 total time=   0.6s\n",
      "[CV 5/5; 305/360] START colsample_bytree=0.8, max_depth=3, n_estimators=500.....\n",
      "[CV 5/5; 305/360] END colsample_bytree=0.8, max_depth=3, n_estimators=500;, score=0.952 total time=   0.6s\n",
      "[CV 1/5; 306/360] START colsample_bytree=0.8, max_depth=3, n_estimators=550.....\n",
      "[CV 1/5; 306/360] END colsample_bytree=0.8, max_depth=3, n_estimators=550;, score=0.949 total time=   0.7s\n",
      "[CV 2/5; 306/360] START colsample_bytree=0.8, max_depth=3, n_estimators=550.....\n",
      "[CV 2/5; 306/360] END colsample_bytree=0.8, max_depth=3, n_estimators=550;, score=0.951 total time=   0.7s\n",
      "[CV 3/5; 306/360] START colsample_bytree=0.8, max_depth=3, n_estimators=550.....\n",
      "[CV 3/5; 306/360] END colsample_bytree=0.8, max_depth=3, n_estimators=550;, score=0.951 total time=   0.6s\n",
      "[CV 4/5; 306/360] START colsample_bytree=0.8, max_depth=3, n_estimators=550.....\n",
      "[CV 4/5; 306/360] END colsample_bytree=0.8, max_depth=3, n_estimators=550;, score=0.954 total time=   0.8s\n",
      "[CV 5/5; 306/360] START colsample_bytree=0.8, max_depth=3, n_estimators=550.....\n",
      "[CV 5/5; 306/360] END colsample_bytree=0.8, max_depth=3, n_estimators=550;, score=0.953 total time=   0.7s\n",
      "[CV 1/5; 307/360] START colsample_bytree=0.8, max_depth=4, n_estimators=300.....\n",
      "[CV 1/5; 307/360] END colsample_bytree=0.8, max_depth=4, n_estimators=300;, score=0.947 total time=   0.4s\n",
      "[CV 2/5; 307/360] START colsample_bytree=0.8, max_depth=4, n_estimators=300.....\n",
      "[CV 2/5; 307/360] END colsample_bytree=0.8, max_depth=4, n_estimators=300;, score=0.950 total time=   0.5s\n",
      "[CV 3/5; 307/360] START colsample_bytree=0.8, max_depth=4, n_estimators=300.....\n",
      "[CV 3/5; 307/360] END colsample_bytree=0.8, max_depth=4, n_estimators=300;, score=0.951 total time=   0.4s\n",
      "[CV 4/5; 307/360] START colsample_bytree=0.8, max_depth=4, n_estimators=300.....\n",
      "[CV 4/5; 307/360] END colsample_bytree=0.8, max_depth=4, n_estimators=300;, score=0.955 total time=   0.4s\n",
      "[CV 5/5; 307/360] START colsample_bytree=0.8, max_depth=4, n_estimators=300.....\n",
      "[CV 5/5; 307/360] END colsample_bytree=0.8, max_depth=4, n_estimators=300;, score=0.952 total time=   0.4s\n",
      "[CV 1/5; 308/360] START colsample_bytree=0.8, max_depth=4, n_estimators=350.....\n",
      "[CV 1/5; 308/360] END colsample_bytree=0.8, max_depth=4, n_estimators=350;, score=0.948 total time=   0.5s\n",
      "[CV 2/5; 308/360] START colsample_bytree=0.8, max_depth=4, n_estimators=350.....\n",
      "[CV 2/5; 308/360] END colsample_bytree=0.8, max_depth=4, n_estimators=350;, score=0.950 total time=   0.5s\n",
      "[CV 3/5; 308/360] START colsample_bytree=0.8, max_depth=4, n_estimators=350.....\n",
      "[CV 3/5; 308/360] END colsample_bytree=0.8, max_depth=4, n_estimators=350;, score=0.951 total time=   0.6s\n",
      "[CV 4/5; 308/360] START colsample_bytree=0.8, max_depth=4, n_estimators=350.....\n",
      "[CV 4/5; 308/360] END colsample_bytree=0.8, max_depth=4, n_estimators=350;, score=0.954 total time=   0.6s\n",
      "[CV 5/5; 308/360] START colsample_bytree=0.8, max_depth=4, n_estimators=350.....\n",
      "[CV 5/5; 308/360] END colsample_bytree=0.8, max_depth=4, n_estimators=350;, score=0.952 total time=   0.7s\n",
      "[CV 1/5; 309/360] START colsample_bytree=0.8, max_depth=4, n_estimators=400.....\n",
      "[CV 1/5; 309/360] END colsample_bytree=0.8, max_depth=4, n_estimators=400;, score=0.948 total time=   0.7s\n",
      "[CV 2/5; 309/360] START colsample_bytree=0.8, max_depth=4, n_estimators=400.....\n",
      "[CV 2/5; 309/360] END colsample_bytree=0.8, max_depth=4, n_estimators=400;, score=0.950 total time=   0.7s\n",
      "[CV 3/5; 309/360] START colsample_bytree=0.8, max_depth=4, n_estimators=400.....\n",
      "[CV 3/5; 309/360] END colsample_bytree=0.8, max_depth=4, n_estimators=400;, score=0.952 total time=   0.6s\n",
      "[CV 4/5; 309/360] START colsample_bytree=0.8, max_depth=4, n_estimators=400.....\n",
      "[CV 4/5; 309/360] END colsample_bytree=0.8, max_depth=4, n_estimators=400;, score=0.954 total time=   0.5s\n",
      "[CV 5/5; 309/360] START colsample_bytree=0.8, max_depth=4, n_estimators=400.....\n",
      "[CV 5/5; 309/360] END colsample_bytree=0.8, max_depth=4, n_estimators=400;, score=0.951 total time=   0.6s\n",
      "[CV 1/5; 310/360] START colsample_bytree=0.8, max_depth=4, n_estimators=450.....\n",
      "[CV 1/5; 310/360] END colsample_bytree=0.8, max_depth=4, n_estimators=450;, score=0.948 total time=   0.6s\n",
      "[CV 2/5; 310/360] START colsample_bytree=0.8, max_depth=4, n_estimators=450.....\n",
      "[CV 2/5; 310/360] END colsample_bytree=0.8, max_depth=4, n_estimators=450;, score=0.950 total time=   0.6s\n",
      "[CV 3/5; 310/360] START colsample_bytree=0.8, max_depth=4, n_estimators=450.....\n",
      "[CV 3/5; 310/360] END colsample_bytree=0.8, max_depth=4, n_estimators=450;, score=0.951 total time=   0.7s\n",
      "[CV 4/5; 310/360] START colsample_bytree=0.8, max_depth=4, n_estimators=450.....\n",
      "[CV 4/5; 310/360] END colsample_bytree=0.8, max_depth=4, n_estimators=450;, score=0.954 total time=   0.6s\n",
      "[CV 5/5; 310/360] START colsample_bytree=0.8, max_depth=4, n_estimators=450.....\n",
      "[CV 5/5; 310/360] END colsample_bytree=0.8, max_depth=4, n_estimators=450;, score=0.952 total time=   0.6s\n",
      "[CV 1/5; 311/360] START colsample_bytree=0.8, max_depth=4, n_estimators=500.....\n",
      "[CV 1/5; 311/360] END colsample_bytree=0.8, max_depth=4, n_estimators=500;, score=0.948 total time=   0.7s\n",
      "[CV 2/5; 311/360] START colsample_bytree=0.8, max_depth=4, n_estimators=500.....\n",
      "[CV 2/5; 311/360] END colsample_bytree=0.8, max_depth=4, n_estimators=500;, score=0.950 total time=   0.7s\n",
      "[CV 3/5; 311/360] START colsample_bytree=0.8, max_depth=4, n_estimators=500.....\n",
      "[CV 3/5; 311/360] END colsample_bytree=0.8, max_depth=4, n_estimators=500;, score=0.951 total time=   0.7s\n",
      "[CV 4/5; 311/360] START colsample_bytree=0.8, max_depth=4, n_estimators=500.....\n",
      "[CV 4/5; 311/360] END colsample_bytree=0.8, max_depth=4, n_estimators=500;, score=0.954 total time=   0.7s\n",
      "[CV 5/5; 311/360] START colsample_bytree=0.8, max_depth=4, n_estimators=500.....\n",
      "[CV 5/5; 311/360] END colsample_bytree=0.8, max_depth=4, n_estimators=500;, score=0.952 total time=   0.7s\n",
      "[CV 1/5; 312/360] START colsample_bytree=0.8, max_depth=4, n_estimators=550.....\n",
      "[CV 1/5; 312/360] END colsample_bytree=0.8, max_depth=4, n_estimators=550;, score=0.948 total time=   0.8s\n",
      "[CV 2/5; 312/360] START colsample_bytree=0.8, max_depth=4, n_estimators=550.....\n",
      "[CV 2/5; 312/360] END colsample_bytree=0.8, max_depth=4, n_estimators=550;, score=0.950 total time=   0.9s\n",
      "[CV 3/5; 312/360] START colsample_bytree=0.8, max_depth=4, n_estimators=550.....\n",
      "[CV 3/5; 312/360] END colsample_bytree=0.8, max_depth=4, n_estimators=550;, score=0.951 total time=   1.1s\n",
      "[CV 4/5; 312/360] START colsample_bytree=0.8, max_depth=4, n_estimators=550.....\n",
      "[CV 4/5; 312/360] END colsample_bytree=0.8, max_depth=4, n_estimators=550;, score=0.953 total time=   1.1s\n",
      "[CV 5/5; 312/360] START colsample_bytree=0.8, max_depth=4, n_estimators=550.....\n",
      "[CV 5/5; 312/360] END colsample_bytree=0.8, max_depth=4, n_estimators=550;, score=0.952 total time=   1.0s\n",
      "[CV 1/5; 313/360] START colsample_bytree=0.8, max_depth=5, n_estimators=300.....\n",
      "[CV 1/5; 313/360] END colsample_bytree=0.8, max_depth=5, n_estimators=300;, score=0.948 total time=   0.6s\n",
      "[CV 2/5; 313/360] START colsample_bytree=0.8, max_depth=5, n_estimators=300.....\n",
      "[CV 2/5; 313/360] END colsample_bytree=0.8, max_depth=5, n_estimators=300;, score=0.950 total time=   0.6s\n",
      "[CV 3/5; 313/360] START colsample_bytree=0.8, max_depth=5, n_estimators=300.....\n",
      "[CV 3/5; 313/360] END colsample_bytree=0.8, max_depth=5, n_estimators=300;, score=0.951 total time=   0.5s\n",
      "[CV 4/5; 313/360] START colsample_bytree=0.8, max_depth=5, n_estimators=300.....\n",
      "[CV 4/5; 313/360] END colsample_bytree=0.8, max_depth=5, n_estimators=300;, score=0.954 total time=   0.5s\n",
      "[CV 5/5; 313/360] START colsample_bytree=0.8, max_depth=5, n_estimators=300.....\n",
      "[CV 5/5; 313/360] END colsample_bytree=0.8, max_depth=5, n_estimators=300;, score=0.951 total time=   0.5s\n",
      "[CV 1/5; 314/360] START colsample_bytree=0.8, max_depth=5, n_estimators=350.....\n",
      "[CV 1/5; 314/360] END colsample_bytree=0.8, max_depth=5, n_estimators=350;, score=0.947 total time=   0.6s\n",
      "[CV 2/5; 314/360] START colsample_bytree=0.8, max_depth=5, n_estimators=350.....\n",
      "[CV 2/5; 314/360] END colsample_bytree=0.8, max_depth=5, n_estimators=350;, score=0.951 total time=   0.6s\n",
      "[CV 3/5; 314/360] START colsample_bytree=0.8, max_depth=5, n_estimators=350.....\n",
      "[CV 3/5; 314/360] END colsample_bytree=0.8, max_depth=5, n_estimators=350;, score=0.949 total time=   0.6s\n",
      "[CV 4/5; 314/360] START colsample_bytree=0.8, max_depth=5, n_estimators=350.....\n",
      "[CV 4/5; 314/360] END colsample_bytree=0.8, max_depth=5, n_estimators=350;, score=0.952 total time=   0.6s\n",
      "[CV 5/5; 314/360] START colsample_bytree=0.8, max_depth=5, n_estimators=350.....\n",
      "[CV 5/5; 314/360] END colsample_bytree=0.8, max_depth=5, n_estimators=350;, score=0.951 total time=   0.5s\n",
      "[CV 1/5; 315/360] START colsample_bytree=0.8, max_depth=5, n_estimators=400.....\n",
      "[CV 1/5; 315/360] END colsample_bytree=0.8, max_depth=5, n_estimators=400;, score=0.947 total time=   0.7s\n",
      "[CV 2/5; 315/360] START colsample_bytree=0.8, max_depth=5, n_estimators=400.....\n",
      "[CV 2/5; 315/360] END colsample_bytree=0.8, max_depth=5, n_estimators=400;, score=0.951 total time=   0.7s\n",
      "[CV 3/5; 315/360] START colsample_bytree=0.8, max_depth=5, n_estimators=400.....\n",
      "[CV 3/5; 315/360] END colsample_bytree=0.8, max_depth=5, n_estimators=400;, score=0.949 total time=   0.6s\n",
      "[CV 4/5; 315/360] START colsample_bytree=0.8, max_depth=5, n_estimators=400.....\n",
      "[CV 4/5; 315/360] END colsample_bytree=0.8, max_depth=5, n_estimators=400;, score=0.953 total time=   0.6s\n",
      "[CV 5/5; 315/360] START colsample_bytree=0.8, max_depth=5, n_estimators=400.....\n",
      "[CV 5/5; 315/360] END colsample_bytree=0.8, max_depth=5, n_estimators=400;, score=0.951 total time=   0.7s\n",
      "[CV 1/5; 316/360] START colsample_bytree=0.8, max_depth=5, n_estimators=450.....\n",
      "[CV 1/5; 316/360] END colsample_bytree=0.8, max_depth=5, n_estimators=450;, score=0.946 total time=   0.7s\n",
      "[CV 2/5; 316/360] START colsample_bytree=0.8, max_depth=5, n_estimators=450.....\n",
      "[CV 2/5; 316/360] END colsample_bytree=0.8, max_depth=5, n_estimators=450;, score=0.950 total time=   0.7s\n",
      "[CV 3/5; 316/360] START colsample_bytree=0.8, max_depth=5, n_estimators=450.....\n",
      "[CV 3/5; 316/360] END colsample_bytree=0.8, max_depth=5, n_estimators=450;, score=0.949 total time=   0.7s\n",
      "[CV 4/5; 316/360] START colsample_bytree=0.8, max_depth=5, n_estimators=450.....\n",
      "[CV 4/5; 316/360] END colsample_bytree=0.8, max_depth=5, n_estimators=450;, score=0.951 total time=   0.8s\n",
      "[CV 5/5; 316/360] START colsample_bytree=0.8, max_depth=5, n_estimators=450.....\n",
      "[CV 5/5; 316/360] END colsample_bytree=0.8, max_depth=5, n_estimators=450;, score=0.951 total time=   0.9s\n",
      "[CV 1/5; 317/360] START colsample_bytree=0.8, max_depth=5, n_estimators=500.....\n",
      "[CV 1/5; 317/360] END colsample_bytree=0.8, max_depth=5, n_estimators=500;, score=0.946 total time=   1.1s\n",
      "[CV 2/5; 317/360] START colsample_bytree=0.8, max_depth=5, n_estimators=500.....\n",
      "[CV 2/5; 317/360] END colsample_bytree=0.8, max_depth=5, n_estimators=500;, score=0.949 total time=   1.0s\n",
      "[CV 3/5; 317/360] START colsample_bytree=0.8, max_depth=5, n_estimators=500.....\n",
      "[CV 3/5; 317/360] END colsample_bytree=0.8, max_depth=5, n_estimators=500;, score=0.949 total time=   0.8s\n",
      "[CV 4/5; 317/360] START colsample_bytree=0.8, max_depth=5, n_estimators=500.....\n",
      "[CV 4/5; 317/360] END colsample_bytree=0.8, max_depth=5, n_estimators=500;, score=0.951 total time=   0.8s\n",
      "[CV 5/5; 317/360] START colsample_bytree=0.8, max_depth=5, n_estimators=500.....\n",
      "[CV 5/5; 317/360] END colsample_bytree=0.8, max_depth=5, n_estimators=500;, score=0.950 total time=   0.8s\n",
      "[CV 1/5; 318/360] START colsample_bytree=0.8, max_depth=5, n_estimators=550.....\n",
      "[CV 1/5; 318/360] END colsample_bytree=0.8, max_depth=5, n_estimators=550;, score=0.946 total time=   0.8s\n",
      "[CV 2/5; 318/360] START colsample_bytree=0.8, max_depth=5, n_estimators=550.....\n",
      "[CV 2/5; 318/360] END colsample_bytree=0.8, max_depth=5, n_estimators=550;, score=0.949 total time=   0.8s\n",
      "[CV 3/5; 318/360] START colsample_bytree=0.8, max_depth=5, n_estimators=550.....\n",
      "[CV 3/5; 318/360] END colsample_bytree=0.8, max_depth=5, n_estimators=550;, score=0.949 total time=   0.9s\n",
      "[CV 4/5; 318/360] START colsample_bytree=0.8, max_depth=5, n_estimators=550.....\n",
      "[CV 4/5; 318/360] END colsample_bytree=0.8, max_depth=5, n_estimators=550;, score=0.951 total time=   0.8s\n",
      "[CV 5/5; 318/360] START colsample_bytree=0.8, max_depth=5, n_estimators=550.....\n",
      "[CV 5/5; 318/360] END colsample_bytree=0.8, max_depth=5, n_estimators=550;, score=0.949 total time=   0.8s\n",
      "[CV 1/5; 319/360] START colsample_bytree=0.8, max_depth=6, n_estimators=300.....\n",
      "[CV 1/5; 319/360] END colsample_bytree=0.8, max_depth=6, n_estimators=300;, score=0.947 total time=   0.5s\n",
      "[CV 2/5; 319/360] START colsample_bytree=0.8, max_depth=6, n_estimators=300.....\n",
      "[CV 2/5; 319/360] END colsample_bytree=0.8, max_depth=6, n_estimators=300;, score=0.948 total time=   0.5s\n",
      "[CV 3/5; 319/360] START colsample_bytree=0.8, max_depth=6, n_estimators=300.....\n",
      "[CV 3/5; 319/360] END colsample_bytree=0.8, max_depth=6, n_estimators=300;, score=0.949 total time=   0.5s\n",
      "[CV 4/5; 319/360] START colsample_bytree=0.8, max_depth=6, n_estimators=300.....\n",
      "[CV 4/5; 319/360] END colsample_bytree=0.8, max_depth=6, n_estimators=300;, score=0.954 total time=   0.5s\n",
      "[CV 5/5; 319/360] START colsample_bytree=0.8, max_depth=6, n_estimators=300.....\n",
      "[CV 5/5; 319/360] END colsample_bytree=0.8, max_depth=6, n_estimators=300;, score=0.950 total time=   0.6s\n",
      "[CV 1/5; 320/360] START colsample_bytree=0.8, max_depth=6, n_estimators=350.....\n",
      "[CV 1/5; 320/360] END colsample_bytree=0.8, max_depth=6, n_estimators=350;, score=0.946 total time=   0.7s\n",
      "[CV 2/5; 320/360] START colsample_bytree=0.8, max_depth=6, n_estimators=350.....\n",
      "[CV 2/5; 320/360] END colsample_bytree=0.8, max_depth=6, n_estimators=350;, score=0.948 total time=   0.6s\n",
      "[CV 3/5; 320/360] START colsample_bytree=0.8, max_depth=6, n_estimators=350.....\n",
      "[CV 3/5; 320/360] END colsample_bytree=0.8, max_depth=6, n_estimators=350;, score=0.950 total time=   0.8s\n",
      "[CV 4/5; 320/360] START colsample_bytree=0.8, max_depth=6, n_estimators=350.....\n",
      "[CV 4/5; 320/360] END colsample_bytree=0.8, max_depth=6, n_estimators=350;, score=0.954 total time=   0.8s\n",
      "[CV 5/5; 320/360] START colsample_bytree=0.8, max_depth=6, n_estimators=350.....\n",
      "[CV 5/5; 320/360] END colsample_bytree=0.8, max_depth=6, n_estimators=350;, score=0.950 total time=   0.8s\n",
      "[CV 1/5; 321/360] START colsample_bytree=0.8, max_depth=6, n_estimators=400.....\n",
      "[CV 1/5; 321/360] END colsample_bytree=0.8, max_depth=6, n_estimators=400;, score=0.946 total time=   0.9s\n",
      "[CV 2/5; 321/360] START colsample_bytree=0.8, max_depth=6, n_estimators=400.....\n",
      "[CV 2/5; 321/360] END colsample_bytree=0.8, max_depth=6, n_estimators=400;, score=0.948 total time=   0.8s\n",
      "[CV 3/5; 321/360] START colsample_bytree=0.8, max_depth=6, n_estimators=400.....\n",
      "[CV 3/5; 321/360] END colsample_bytree=0.8, max_depth=6, n_estimators=400;, score=0.950 total time=   0.7s\n",
      "[CV 4/5; 321/360] START colsample_bytree=0.8, max_depth=6, n_estimators=400.....\n",
      "[CV 4/5; 321/360] END colsample_bytree=0.8, max_depth=6, n_estimators=400;, score=0.953 total time=   0.8s\n",
      "[CV 5/5; 321/360] START colsample_bytree=0.8, max_depth=6, n_estimators=400.....\n",
      "[CV 5/5; 321/360] END colsample_bytree=0.8, max_depth=6, n_estimators=400;, score=0.949 total time=   0.7s\n",
      "[CV 1/5; 322/360] START colsample_bytree=0.8, max_depth=6, n_estimators=450.....\n",
      "[CV 1/5; 322/360] END colsample_bytree=0.8, max_depth=6, n_estimators=450;, score=0.945 total time=   0.8s\n",
      "[CV 2/5; 322/360] START colsample_bytree=0.8, max_depth=6, n_estimators=450.....\n",
      "[CV 2/5; 322/360] END colsample_bytree=0.8, max_depth=6, n_estimators=450;, score=0.947 total time=   0.9s\n",
      "[CV 3/5; 322/360] START colsample_bytree=0.8, max_depth=6, n_estimators=450.....\n",
      "[CV 3/5; 322/360] END colsample_bytree=0.8, max_depth=6, n_estimators=450;, score=0.950 total time=   0.8s\n",
      "[CV 4/5; 322/360] START colsample_bytree=0.8, max_depth=6, n_estimators=450.....\n",
      "[CV 4/5; 322/360] END colsample_bytree=0.8, max_depth=6, n_estimators=450;, score=0.954 total time=   0.8s\n",
      "[CV 5/5; 322/360] START colsample_bytree=0.8, max_depth=6, n_estimators=450.....\n",
      "[CV 5/5; 322/360] END colsample_bytree=0.8, max_depth=6, n_estimators=450;, score=0.949 total time=   0.8s\n",
      "[CV 1/5; 323/360] START colsample_bytree=0.8, max_depth=6, n_estimators=500.....\n",
      "[CV 1/5; 323/360] END colsample_bytree=0.8, max_depth=6, n_estimators=500;, score=0.945 total time=   0.9s\n",
      "[CV 2/5; 323/360] START colsample_bytree=0.8, max_depth=6, n_estimators=500.....\n",
      "[CV 2/5; 323/360] END colsample_bytree=0.8, max_depth=6, n_estimators=500;, score=0.947 total time=   0.9s\n",
      "[CV 3/5; 323/360] START colsample_bytree=0.8, max_depth=6, n_estimators=500.....\n",
      "[CV 3/5; 323/360] END colsample_bytree=0.8, max_depth=6, n_estimators=500;, score=0.950 total time=   0.9s\n",
      "[CV 4/5; 323/360] START colsample_bytree=0.8, max_depth=6, n_estimators=500.....\n",
      "[CV 4/5; 323/360] END colsample_bytree=0.8, max_depth=6, n_estimators=500;, score=0.953 total time=   0.9s\n",
      "[CV 5/5; 323/360] START colsample_bytree=0.8, max_depth=6, n_estimators=500.....\n",
      "[CV 5/5; 323/360] END colsample_bytree=0.8, max_depth=6, n_estimators=500;, score=0.948 total time=   1.1s\n",
      "[CV 1/5; 324/360] START colsample_bytree=0.8, max_depth=6, n_estimators=550.....\n",
      "[CV 1/5; 324/360] END colsample_bytree=0.8, max_depth=6, n_estimators=550;, score=0.945 total time=   1.3s\n",
      "[CV 2/5; 324/360] START colsample_bytree=0.8, max_depth=6, n_estimators=550.....\n",
      "[CV 2/5; 324/360] END colsample_bytree=0.8, max_depth=6, n_estimators=550;, score=0.947 total time=   1.3s\n",
      "[CV 3/5; 324/360] START colsample_bytree=0.8, max_depth=6, n_estimators=550.....\n",
      "[CV 3/5; 324/360] END colsample_bytree=0.8, max_depth=6, n_estimators=550;, score=0.949 total time=   1.1s\n",
      "[CV 4/5; 324/360] START colsample_bytree=0.8, max_depth=6, n_estimators=550.....\n",
      "[CV 4/5; 324/360] END colsample_bytree=0.8, max_depth=6, n_estimators=550;, score=0.953 total time=   1.0s\n",
      "[CV 5/5; 324/360] START colsample_bytree=0.8, max_depth=6, n_estimators=550.....\n",
      "[CV 5/5; 324/360] END colsample_bytree=0.8, max_depth=6, n_estimators=550;, score=0.948 total time=   1.1s\n",
      "[CV 1/5; 325/360] START colsample_bytree=0.9, max_depth=1, n_estimators=300.....\n",
      "[CV 1/5; 325/360] END colsample_bytree=0.9, max_depth=1, n_estimators=300;, score=0.929 total time=   0.2s\n",
      "[CV 2/5; 325/360] START colsample_bytree=0.9, max_depth=1, n_estimators=300.....\n",
      "[CV 2/5; 325/360] END colsample_bytree=0.9, max_depth=1, n_estimators=300;, score=0.929 total time=   0.2s\n",
      "[CV 3/5; 325/360] START colsample_bytree=0.9, max_depth=1, n_estimators=300.....\n",
      "[CV 3/5; 325/360] END colsample_bytree=0.9, max_depth=1, n_estimators=300;, score=0.931 total time=   0.3s\n",
      "[CV 4/5; 325/360] START colsample_bytree=0.9, max_depth=1, n_estimators=300.....\n",
      "[CV 4/5; 325/360] END colsample_bytree=0.9, max_depth=1, n_estimators=300;, score=0.932 total time=   0.2s\n",
      "[CV 5/5; 325/360] START colsample_bytree=0.9, max_depth=1, n_estimators=300.....\n",
      "[CV 5/5; 325/360] END colsample_bytree=0.9, max_depth=1, n_estimators=300;, score=0.931 total time=   0.2s\n",
      "[CV 1/5; 326/360] START colsample_bytree=0.9, max_depth=1, n_estimators=350.....\n",
      "[CV 1/5; 326/360] END colsample_bytree=0.9, max_depth=1, n_estimators=350;, score=0.929 total time=   0.3s\n",
      "[CV 2/5; 326/360] START colsample_bytree=0.9, max_depth=1, n_estimators=350.....\n",
      "[CV 2/5; 326/360] END colsample_bytree=0.9, max_depth=1, n_estimators=350;, score=0.929 total time=   0.3s\n",
      "[CV 3/5; 326/360] START colsample_bytree=0.9, max_depth=1, n_estimators=350.....\n",
      "[CV 3/5; 326/360] END colsample_bytree=0.9, max_depth=1, n_estimators=350;, score=0.931 total time=   0.3s\n",
      "[CV 4/5; 326/360] START colsample_bytree=0.9, max_depth=1, n_estimators=350.....\n",
      "[CV 4/5; 326/360] END colsample_bytree=0.9, max_depth=1, n_estimators=350;, score=0.932 total time=   0.3s\n",
      "[CV 5/5; 326/360] START colsample_bytree=0.9, max_depth=1, n_estimators=350.....\n",
      "[CV 5/5; 326/360] END colsample_bytree=0.9, max_depth=1, n_estimators=350;, score=0.932 total time=   0.4s\n",
      "[CV 1/5; 327/360] START colsample_bytree=0.9, max_depth=1, n_estimators=400.....\n",
      "[CV 1/5; 327/360] END colsample_bytree=0.9, max_depth=1, n_estimators=400;, score=0.929 total time=   0.3s\n",
      "[CV 2/5; 327/360] START colsample_bytree=0.9, max_depth=1, n_estimators=400.....\n",
      "[CV 2/5; 327/360] END colsample_bytree=0.9, max_depth=1, n_estimators=400;, score=0.929 total time=   0.3s\n",
      "[CV 3/5; 327/360] START colsample_bytree=0.9, max_depth=1, n_estimators=400.....\n",
      "[CV 3/5; 327/360] END colsample_bytree=0.9, max_depth=1, n_estimators=400;, score=0.932 total time=   0.3s\n",
      "[CV 4/5; 327/360] START colsample_bytree=0.9, max_depth=1, n_estimators=400.....\n",
      "[CV 4/5; 327/360] END colsample_bytree=0.9, max_depth=1, n_estimators=400;, score=0.932 total time=   0.3s\n",
      "[CV 5/5; 327/360] START colsample_bytree=0.9, max_depth=1, n_estimators=400.....\n",
      "[CV 5/5; 327/360] END colsample_bytree=0.9, max_depth=1, n_estimators=400;, score=0.932 total time=   0.3s\n",
      "[CV 1/5; 328/360] START colsample_bytree=0.9, max_depth=1, n_estimators=450.....\n",
      "[CV 1/5; 328/360] END colsample_bytree=0.9, max_depth=1, n_estimators=450;, score=0.929 total time=   0.4s\n",
      "[CV 2/5; 328/360] START colsample_bytree=0.9, max_depth=1, n_estimators=450.....\n",
      "[CV 2/5; 328/360] END colsample_bytree=0.9, max_depth=1, n_estimators=450;, score=0.929 total time=   0.4s\n",
      "[CV 3/5; 328/360] START colsample_bytree=0.9, max_depth=1, n_estimators=450.....\n",
      "[CV 3/5; 328/360] END colsample_bytree=0.9, max_depth=1, n_estimators=450;, score=0.932 total time=   0.4s\n",
      "[CV 4/5; 328/360] START colsample_bytree=0.9, max_depth=1, n_estimators=450.....\n",
      "[CV 4/5; 328/360] END colsample_bytree=0.9, max_depth=1, n_estimators=450;, score=0.932 total time=   0.4s\n",
      "[CV 5/5; 328/360] START colsample_bytree=0.9, max_depth=1, n_estimators=450.....\n",
      "[CV 5/5; 328/360] END colsample_bytree=0.9, max_depth=1, n_estimators=450;, score=0.932 total time=   0.4s\n",
      "[CV 1/5; 329/360] START colsample_bytree=0.9, max_depth=1, n_estimators=500.....\n",
      "[CV 1/5; 329/360] END colsample_bytree=0.9, max_depth=1, n_estimators=500;, score=0.929 total time=   0.4s\n",
      "[CV 2/5; 329/360] START colsample_bytree=0.9, max_depth=1, n_estimators=500.....\n",
      "[CV 2/5; 329/360] END colsample_bytree=0.9, max_depth=1, n_estimators=500;, score=0.930 total time=   0.6s\n",
      "[CV 3/5; 329/360] START colsample_bytree=0.9, max_depth=1, n_estimators=500.....\n",
      "[CV 3/5; 329/360] END colsample_bytree=0.9, max_depth=1, n_estimators=500;, score=0.931 total time=   0.5s\n",
      "[CV 4/5; 329/360] START colsample_bytree=0.9, max_depth=1, n_estimators=500.....\n",
      "[CV 4/5; 329/360] END colsample_bytree=0.9, max_depth=1, n_estimators=500;, score=0.932 total time=   0.6s\n",
      "[CV 5/5; 329/360] START colsample_bytree=0.9, max_depth=1, n_estimators=500.....\n",
      "[CV 5/5; 329/360] END colsample_bytree=0.9, max_depth=1, n_estimators=500;, score=0.932 total time=   0.6s\n",
      "[CV 1/5; 330/360] START colsample_bytree=0.9, max_depth=1, n_estimators=550.....\n",
      "[CV 1/5; 330/360] END colsample_bytree=0.9, max_depth=1, n_estimators=550;, score=0.929 total time=   0.6s\n",
      "[CV 2/5; 330/360] START colsample_bytree=0.9, max_depth=1, n_estimators=550.....\n",
      "[CV 2/5; 330/360] END colsample_bytree=0.9, max_depth=1, n_estimators=550;, score=0.930 total time=   0.7s\n",
      "[CV 3/5; 330/360] START colsample_bytree=0.9, max_depth=1, n_estimators=550.....\n",
      "[CV 3/5; 330/360] END colsample_bytree=0.9, max_depth=1, n_estimators=550;, score=0.932 total time=   0.5s\n",
      "[CV 4/5; 330/360] START colsample_bytree=0.9, max_depth=1, n_estimators=550.....\n",
      "[CV 4/5; 330/360] END colsample_bytree=0.9, max_depth=1, n_estimators=550;, score=0.932 total time=   0.5s\n",
      "[CV 5/5; 330/360] START colsample_bytree=0.9, max_depth=1, n_estimators=550.....\n",
      "[CV 5/5; 330/360] END colsample_bytree=0.9, max_depth=1, n_estimators=550;, score=0.932 total time=   0.5s\n",
      "[CV 1/5; 331/360] START colsample_bytree=0.9, max_depth=2, n_estimators=300.....\n",
      "[CV 1/5; 331/360] END colsample_bytree=0.9, max_depth=2, n_estimators=300;, score=0.948 total time=   0.4s\n",
      "[CV 2/5; 331/360] START colsample_bytree=0.9, max_depth=2, n_estimators=300.....\n",
      "[CV 2/5; 331/360] END colsample_bytree=0.9, max_depth=2, n_estimators=300;, score=0.950 total time=   0.4s\n",
      "[CV 3/5; 331/360] START colsample_bytree=0.9, max_depth=2, n_estimators=300.....\n",
      "[CV 3/5; 331/360] END colsample_bytree=0.9, max_depth=2, n_estimators=300;, score=0.951 total time=   0.4s\n",
      "[CV 4/5; 331/360] START colsample_bytree=0.9, max_depth=2, n_estimators=300.....\n",
      "[CV 4/5; 331/360] END colsample_bytree=0.9, max_depth=2, n_estimators=300;, score=0.955 total time=   0.3s\n",
      "[CV 5/5; 331/360] START colsample_bytree=0.9, max_depth=2, n_estimators=300.....\n",
      "[CV 5/5; 331/360] END colsample_bytree=0.9, max_depth=2, n_estimators=300;, score=0.951 total time=   0.3s\n",
      "[CV 1/5; 332/360] START colsample_bytree=0.9, max_depth=2, n_estimators=350.....\n",
      "[CV 1/5; 332/360] END colsample_bytree=0.9, max_depth=2, n_estimators=350;, score=0.948 total time=   0.4s\n",
      "[CV 2/5; 332/360] START colsample_bytree=0.9, max_depth=2, n_estimators=350.....\n",
      "[CV 2/5; 332/360] END colsample_bytree=0.9, max_depth=2, n_estimators=350;, score=0.950 total time=   0.4s\n",
      "[CV 3/5; 332/360] START colsample_bytree=0.9, max_depth=2, n_estimators=350.....\n",
      "[CV 3/5; 332/360] END colsample_bytree=0.9, max_depth=2, n_estimators=350;, score=0.951 total time=   0.4s\n",
      "[CV 4/5; 332/360] START colsample_bytree=0.9, max_depth=2, n_estimators=350.....\n",
      "[CV 4/5; 332/360] END colsample_bytree=0.9, max_depth=2, n_estimators=350;, score=0.955 total time=   0.5s\n",
      "[CV 5/5; 332/360] START colsample_bytree=0.9, max_depth=2, n_estimators=350.....\n",
      "[CV 5/5; 332/360] END colsample_bytree=0.9, max_depth=2, n_estimators=350;, score=0.951 total time=   0.4s\n",
      "[CV 1/5; 333/360] START colsample_bytree=0.9, max_depth=2, n_estimators=400.....\n",
      "[CV 1/5; 333/360] END colsample_bytree=0.9, max_depth=2, n_estimators=400;, score=0.948 total time=   0.4s\n",
      "[CV 2/5; 333/360] START colsample_bytree=0.9, max_depth=2, n_estimators=400.....\n",
      "[CV 2/5; 333/360] END colsample_bytree=0.9, max_depth=2, n_estimators=400;, score=0.950 total time=   0.4s\n",
      "[CV 3/5; 333/360] START colsample_bytree=0.9, max_depth=2, n_estimators=400.....\n",
      "[CV 3/5; 333/360] END colsample_bytree=0.9, max_depth=2, n_estimators=400;, score=0.951 total time=   0.4s\n",
      "[CV 4/5; 333/360] START colsample_bytree=0.9, max_depth=2, n_estimators=400.....\n",
      "[CV 4/5; 333/360] END colsample_bytree=0.9, max_depth=2, n_estimators=400;, score=0.955 total time=   0.4s\n",
      "[CV 5/5; 333/360] START colsample_bytree=0.9, max_depth=2, n_estimators=400.....\n",
      "[CV 5/5; 333/360] END colsample_bytree=0.9, max_depth=2, n_estimators=400;, score=0.951 total time=   0.4s\n",
      "[CV 1/5; 334/360] START colsample_bytree=0.9, max_depth=2, n_estimators=450.....\n",
      "[CV 1/5; 334/360] END colsample_bytree=0.9, max_depth=2, n_estimators=450;, score=0.948 total time=   0.5s\n",
      "[CV 2/5; 334/360] START colsample_bytree=0.9, max_depth=2, n_estimators=450.....\n",
      "[CV 2/5; 334/360] END colsample_bytree=0.9, max_depth=2, n_estimators=450;, score=0.950 total time=   0.5s\n",
      "[CV 3/5; 334/360] START colsample_bytree=0.9, max_depth=2, n_estimators=450.....\n",
      "[CV 3/5; 334/360] END colsample_bytree=0.9, max_depth=2, n_estimators=450;, score=0.951 total time=   0.5s\n",
      "[CV 4/5; 334/360] START colsample_bytree=0.9, max_depth=2, n_estimators=450.....\n",
      "[CV 4/5; 334/360] END colsample_bytree=0.9, max_depth=2, n_estimators=450;, score=0.955 total time=   0.4s\n",
      "[CV 5/5; 334/360] START colsample_bytree=0.9, max_depth=2, n_estimators=450.....\n",
      "[CV 5/5; 334/360] END colsample_bytree=0.9, max_depth=2, n_estimators=450;, score=0.951 total time=   0.5s\n",
      "[CV 1/5; 335/360] START colsample_bytree=0.9, max_depth=2, n_estimators=500.....\n",
      "[CV 1/5; 335/360] END colsample_bytree=0.9, max_depth=2, n_estimators=500;, score=0.948 total time=   0.7s\n",
      "[CV 2/5; 335/360] START colsample_bytree=0.9, max_depth=2, n_estimators=500.....\n",
      "[CV 2/5; 335/360] END colsample_bytree=0.9, max_depth=2, n_estimators=500;, score=0.950 total time=   0.6s\n",
      "[CV 3/5; 335/360] START colsample_bytree=0.9, max_depth=2, n_estimators=500.....\n",
      "[CV 3/5; 335/360] END colsample_bytree=0.9, max_depth=2, n_estimators=500;, score=0.951 total time=   0.7s\n",
      "[CV 4/5; 335/360] START colsample_bytree=0.9, max_depth=2, n_estimators=500.....\n",
      "[CV 4/5; 335/360] END colsample_bytree=0.9, max_depth=2, n_estimators=500;, score=0.955 total time=   0.7s\n",
      "[CV 5/5; 335/360] START colsample_bytree=0.9, max_depth=2, n_estimators=500.....\n",
      "[CV 5/5; 335/360] END colsample_bytree=0.9, max_depth=2, n_estimators=500;, score=0.951 total time=   0.6s\n",
      "[CV 1/5; 336/360] START colsample_bytree=0.9, max_depth=2, n_estimators=550.....\n",
      "[CV 1/5; 336/360] END colsample_bytree=0.9, max_depth=2, n_estimators=550;, score=0.948 total time=   0.5s\n",
      "[CV 2/5; 336/360] START colsample_bytree=0.9, max_depth=2, n_estimators=550.....\n",
      "[CV 2/5; 336/360] END colsample_bytree=0.9, max_depth=2, n_estimators=550;, score=0.950 total time=   0.6s\n",
      "[CV 3/5; 336/360] START colsample_bytree=0.9, max_depth=2, n_estimators=550.....\n",
      "[CV 3/5; 336/360] END colsample_bytree=0.9, max_depth=2, n_estimators=550;, score=0.951 total time=   0.5s\n",
      "[CV 4/5; 336/360] START colsample_bytree=0.9, max_depth=2, n_estimators=550.....\n",
      "[CV 4/5; 336/360] END colsample_bytree=0.9, max_depth=2, n_estimators=550;, score=0.955 total time=   0.5s\n",
      "[CV 5/5; 336/360] START colsample_bytree=0.9, max_depth=2, n_estimators=550.....\n",
      "[CV 5/5; 336/360] END colsample_bytree=0.9, max_depth=2, n_estimators=550;, score=0.951 total time=   0.6s\n",
      "[CV 1/5; 337/360] START colsample_bytree=0.9, max_depth=3, n_estimators=300.....\n",
      "[CV 1/5; 337/360] END colsample_bytree=0.9, max_depth=3, n_estimators=300;, score=0.950 total time=   0.4s\n",
      "[CV 2/5; 337/360] START colsample_bytree=0.9, max_depth=3, n_estimators=300.....\n",
      "[CV 2/5; 337/360] END colsample_bytree=0.9, max_depth=3, n_estimators=300;, score=0.951 total time=   0.4s\n",
      "[CV 3/5; 337/360] START colsample_bytree=0.9, max_depth=3, n_estimators=300.....\n",
      "[CV 3/5; 337/360] END colsample_bytree=0.9, max_depth=3, n_estimators=300;, score=0.952 total time=   0.3s\n",
      "[CV 4/5; 337/360] START colsample_bytree=0.9, max_depth=3, n_estimators=300.....\n",
      "[CV 4/5; 337/360] END colsample_bytree=0.9, max_depth=3, n_estimators=300;, score=0.956 total time=   0.4s\n",
      "[CV 5/5; 337/360] START colsample_bytree=0.9, max_depth=3, n_estimators=300.....\n",
      "[CV 5/5; 337/360] END colsample_bytree=0.9, max_depth=3, n_estimators=300;, score=0.953 total time=   0.3s\n",
      "[CV 1/5; 338/360] START colsample_bytree=0.9, max_depth=3, n_estimators=350.....\n",
      "[CV 1/5; 338/360] END colsample_bytree=0.9, max_depth=3, n_estimators=350;, score=0.949 total time=   0.4s\n",
      "[CV 2/5; 338/360] START colsample_bytree=0.9, max_depth=3, n_estimators=350.....\n",
      "[CV 2/5; 338/360] END colsample_bytree=0.9, max_depth=3, n_estimators=350;, score=0.951 total time=   0.4s\n",
      "[CV 3/5; 338/360] START colsample_bytree=0.9, max_depth=3, n_estimators=350.....\n",
      "[CV 3/5; 338/360] END colsample_bytree=0.9, max_depth=3, n_estimators=350;, score=0.951 total time=   0.4s\n",
      "[CV 4/5; 338/360] START colsample_bytree=0.9, max_depth=3, n_estimators=350.....\n",
      "[CV 4/5; 338/360] END colsample_bytree=0.9, max_depth=3, n_estimators=350;, score=0.955 total time=   0.4s\n",
      "[CV 5/5; 338/360] START colsample_bytree=0.9, max_depth=3, n_estimators=350.....\n",
      "[CV 5/5; 338/360] END colsample_bytree=0.9, max_depth=3, n_estimators=350;, score=0.953 total time=   0.5s\n",
      "[CV 1/5; 339/360] START colsample_bytree=0.9, max_depth=3, n_estimators=400.....\n",
      "[CV 1/5; 339/360] END colsample_bytree=0.9, max_depth=3, n_estimators=400;, score=0.949 total time=   0.5s\n",
      "[CV 2/5; 339/360] START colsample_bytree=0.9, max_depth=3, n_estimators=400.....\n",
      "[CV 2/5; 339/360] END colsample_bytree=0.9, max_depth=3, n_estimators=400;, score=0.950 total time=   0.5s\n",
      "[CV 3/5; 339/360] START colsample_bytree=0.9, max_depth=3, n_estimators=400.....\n",
      "[CV 3/5; 339/360] END colsample_bytree=0.9, max_depth=3, n_estimators=400;, score=0.952 total time=   0.5s\n",
      "[CV 4/5; 339/360] START colsample_bytree=0.9, max_depth=3, n_estimators=400.....\n",
      "[CV 4/5; 339/360] END colsample_bytree=0.9, max_depth=3, n_estimators=400;, score=0.957 total time=   0.5s\n",
      "[CV 5/5; 339/360] START colsample_bytree=0.9, max_depth=3, n_estimators=400.....\n",
      "[CV 5/5; 339/360] END colsample_bytree=0.9, max_depth=3, n_estimators=400;, score=0.953 total time=   0.5s\n",
      "[CV 1/5; 340/360] START colsample_bytree=0.9, max_depth=3, n_estimators=450.....\n",
      "[CV 1/5; 340/360] END colsample_bytree=0.9, max_depth=3, n_estimators=450;, score=0.949 total time=   0.6s\n",
      "[CV 2/5; 340/360] START colsample_bytree=0.9, max_depth=3, n_estimators=450.....\n",
      "[CV 2/5; 340/360] END colsample_bytree=0.9, max_depth=3, n_estimators=450;, score=0.950 total time=   0.7s\n",
      "[CV 3/5; 340/360] START colsample_bytree=0.9, max_depth=3, n_estimators=450.....\n",
      "[CV 3/5; 340/360] END colsample_bytree=0.9, max_depth=3, n_estimators=450;, score=0.951 total time=   0.8s\n",
      "[CV 4/5; 340/360] START colsample_bytree=0.9, max_depth=3, n_estimators=450.....\n",
      "[CV 4/5; 340/360] END colsample_bytree=0.9, max_depth=3, n_estimators=450;, score=0.955 total time=   0.7s\n",
      "[CV 5/5; 340/360] START colsample_bytree=0.9, max_depth=3, n_estimators=450.....\n",
      "[CV 5/5; 340/360] END colsample_bytree=0.9, max_depth=3, n_estimators=450;, score=0.954 total time=   0.7s\n",
      "[CV 1/5; 341/360] START colsample_bytree=0.9, max_depth=3, n_estimators=500.....\n",
      "[CV 1/5; 341/360] END colsample_bytree=0.9, max_depth=3, n_estimators=500;, score=0.948 total time=   0.8s\n",
      "[CV 2/5; 341/360] START colsample_bytree=0.9, max_depth=3, n_estimators=500.....\n",
      "[CV 2/5; 341/360] END colsample_bytree=0.9, max_depth=3, n_estimators=500;, score=0.950 total time=   0.6s\n",
      "[CV 3/5; 341/360] START colsample_bytree=0.9, max_depth=3, n_estimators=500.....\n",
      "[CV 3/5; 341/360] END colsample_bytree=0.9, max_depth=3, n_estimators=500;, score=0.951 total time=   0.6s\n",
      "[CV 4/5; 341/360] START colsample_bytree=0.9, max_depth=3, n_estimators=500.....\n",
      "[CV 4/5; 341/360] END colsample_bytree=0.9, max_depth=3, n_estimators=500;, score=0.955 total time=   0.6s\n",
      "[CV 5/5; 341/360] START colsample_bytree=0.9, max_depth=3, n_estimators=500.....\n",
      "[CV 5/5; 341/360] END colsample_bytree=0.9, max_depth=3, n_estimators=500;, score=0.953 total time=   0.6s\n",
      "[CV 1/5; 342/360] START colsample_bytree=0.9, max_depth=3, n_estimators=550.....\n",
      "[CV 1/5; 342/360] END colsample_bytree=0.9, max_depth=3, n_estimators=550;, score=0.949 total time=   0.6s\n",
      "[CV 2/5; 342/360] START colsample_bytree=0.9, max_depth=3, n_estimators=550.....\n",
      "[CV 2/5; 342/360] END colsample_bytree=0.9, max_depth=3, n_estimators=550;, score=0.950 total time=   0.6s\n",
      "[CV 3/5; 342/360] START colsample_bytree=0.9, max_depth=3, n_estimators=550.....\n",
      "[CV 3/5; 342/360] END colsample_bytree=0.9, max_depth=3, n_estimators=550;, score=0.951 total time=   0.7s\n",
      "[CV 4/5; 342/360] START colsample_bytree=0.9, max_depth=3, n_estimators=550.....\n",
      "[CV 4/5; 342/360] END colsample_bytree=0.9, max_depth=3, n_estimators=550;, score=0.955 total time=   0.6s\n",
      "[CV 5/5; 342/360] START colsample_bytree=0.9, max_depth=3, n_estimators=550.....\n",
      "[CV 5/5; 342/360] END colsample_bytree=0.9, max_depth=3, n_estimators=550;, score=0.953 total time=   0.7s\n",
      "[CV 1/5; 343/360] START colsample_bytree=0.9, max_depth=4, n_estimators=300.....\n",
      "[CV 1/5; 343/360] END colsample_bytree=0.9, max_depth=4, n_estimators=300;, score=0.949 total time=   0.4s\n",
      "[CV 2/5; 343/360] START colsample_bytree=0.9, max_depth=4, n_estimators=300.....\n",
      "[CV 2/5; 343/360] END colsample_bytree=0.9, max_depth=4, n_estimators=300;, score=0.950 total time=   0.5s\n",
      "[CV 3/5; 343/360] START colsample_bytree=0.9, max_depth=4, n_estimators=300.....\n",
      "[CV 3/5; 343/360] END colsample_bytree=0.9, max_depth=4, n_estimators=300;, score=0.951 total time=   0.4s\n",
      "[CV 4/5; 343/360] START colsample_bytree=0.9, max_depth=4, n_estimators=300.....\n",
      "[CV 4/5; 343/360] END colsample_bytree=0.9, max_depth=4, n_estimators=300;, score=0.955 total time=   0.4s\n",
      "[CV 5/5; 343/360] START colsample_bytree=0.9, max_depth=4, n_estimators=300.....\n",
      "[CV 5/5; 343/360] END colsample_bytree=0.9, max_depth=4, n_estimators=300;, score=0.953 total time=   0.4s\n",
      "[CV 1/5; 344/360] START colsample_bytree=0.9, max_depth=4, n_estimators=350.....\n",
      "[CV 1/5; 344/360] END colsample_bytree=0.9, max_depth=4, n_estimators=350;, score=0.948 total time=   0.5s\n",
      "[CV 2/5; 344/360] START colsample_bytree=0.9, max_depth=4, n_estimators=350.....\n",
      "[CV 2/5; 344/360] END colsample_bytree=0.9, max_depth=4, n_estimators=350;, score=0.949 total time=   0.5s\n",
      "[CV 3/5; 344/360] START colsample_bytree=0.9, max_depth=4, n_estimators=350.....\n",
      "[CV 3/5; 344/360] END colsample_bytree=0.9, max_depth=4, n_estimators=350;, score=0.951 total time=   0.5s\n",
      "[CV 4/5; 344/360] START colsample_bytree=0.9, max_depth=4, n_estimators=350.....\n",
      "[CV 4/5; 344/360] END colsample_bytree=0.9, max_depth=4, n_estimators=350;, score=0.955 total time=   0.6s\n",
      "[CV 5/5; 344/360] START colsample_bytree=0.9, max_depth=4, n_estimators=350.....\n",
      "[CV 5/5; 344/360] END colsample_bytree=0.9, max_depth=4, n_estimators=350;, score=0.953 total time=   0.5s\n",
      "[CV 1/5; 345/360] START colsample_bytree=0.9, max_depth=4, n_estimators=400.....\n",
      "[CV 1/5; 345/360] END colsample_bytree=0.9, max_depth=4, n_estimators=400;, score=0.948 total time=   0.7s\n",
      "[CV 2/5; 345/360] START colsample_bytree=0.9, max_depth=4, n_estimators=400.....\n",
      "[CV 2/5; 345/360] END colsample_bytree=0.9, max_depth=4, n_estimators=400;, score=0.950 total time=   0.7s\n",
      "[CV 3/5; 345/360] START colsample_bytree=0.9, max_depth=4, n_estimators=400.....\n",
      "[CV 3/5; 345/360] END colsample_bytree=0.9, max_depth=4, n_estimators=400;, score=0.951 total time=   0.7s\n",
      "[CV 4/5; 345/360] START colsample_bytree=0.9, max_depth=4, n_estimators=400.....\n",
      "[CV 4/5; 345/360] END colsample_bytree=0.9, max_depth=4, n_estimators=400;, score=0.954 total time=   0.7s\n",
      "[CV 5/5; 345/360] START colsample_bytree=0.9, max_depth=4, n_estimators=400.....\n",
      "[CV 5/5; 345/360] END colsample_bytree=0.9, max_depth=4, n_estimators=400;, score=0.952 total time=   0.6s\n",
      "[CV 1/5; 346/360] START colsample_bytree=0.9, max_depth=4, n_estimators=450.....\n",
      "[CV 1/5; 346/360] END colsample_bytree=0.9, max_depth=4, n_estimators=450;, score=0.948 total time=   0.6s\n",
      "[CV 2/5; 346/360] START colsample_bytree=0.9, max_depth=4, n_estimators=450.....\n",
      "[CV 2/5; 346/360] END colsample_bytree=0.9, max_depth=4, n_estimators=450;, score=0.950 total time=   0.7s\n",
      "[CV 3/5; 346/360] START colsample_bytree=0.9, max_depth=4, n_estimators=450.....\n",
      "[CV 3/5; 346/360] END colsample_bytree=0.9, max_depth=4, n_estimators=450;, score=0.950 total time=   0.6s\n",
      "[CV 4/5; 346/360] START colsample_bytree=0.9, max_depth=4, n_estimators=450.....\n",
      "[CV 4/5; 346/360] END colsample_bytree=0.9, max_depth=4, n_estimators=450;, score=0.954 total time=   0.6s\n",
      "[CV 5/5; 346/360] START colsample_bytree=0.9, max_depth=4, n_estimators=450.....\n",
      "[CV 5/5; 346/360] END colsample_bytree=0.9, max_depth=4, n_estimators=450;, score=0.952 total time=   0.6s\n",
      "[CV 1/5; 347/360] START colsample_bytree=0.9, max_depth=4, n_estimators=500.....\n",
      "[CV 1/5; 347/360] END colsample_bytree=0.9, max_depth=4, n_estimators=500;, score=0.947 total time=   0.7s\n",
      "[CV 2/5; 347/360] START colsample_bytree=0.9, max_depth=4, n_estimators=500.....\n",
      "[CV 2/5; 347/360] END colsample_bytree=0.9, max_depth=4, n_estimators=500;, score=0.948 total time=   0.7s\n",
      "[CV 3/5; 347/360] START colsample_bytree=0.9, max_depth=4, n_estimators=500.....\n",
      "[CV 3/5; 347/360] END colsample_bytree=0.9, max_depth=4, n_estimators=500;, score=0.950 total time=   0.7s\n",
      "[CV 4/5; 347/360] START colsample_bytree=0.9, max_depth=4, n_estimators=500.....\n",
      "[CV 4/5; 347/360] END colsample_bytree=0.9, max_depth=4, n_estimators=500;, score=0.954 total time=   0.7s\n",
      "[CV 5/5; 347/360] START colsample_bytree=0.9, max_depth=4, n_estimators=500.....\n",
      "[CV 5/5; 347/360] END colsample_bytree=0.9, max_depth=4, n_estimators=500;, score=0.951 total time=   0.7s\n",
      "[CV 1/5; 348/360] START colsample_bytree=0.9, max_depth=4, n_estimators=550.....\n",
      "[CV 1/5; 348/360] END colsample_bytree=0.9, max_depth=4, n_estimators=550;, score=0.947 total time=   0.8s\n",
      "[CV 2/5; 348/360] START colsample_bytree=0.9, max_depth=4, n_estimators=550.....\n",
      "[CV 2/5; 348/360] END colsample_bytree=0.9, max_depth=4, n_estimators=550;, score=0.949 total time=   0.8s\n",
      "[CV 3/5; 348/360] START colsample_bytree=0.9, max_depth=4, n_estimators=550.....\n",
      "[CV 3/5; 348/360] END colsample_bytree=0.9, max_depth=4, n_estimators=550;, score=0.950 total time=   0.7s\n",
      "[CV 4/5; 348/360] START colsample_bytree=0.9, max_depth=4, n_estimators=550.....\n",
      "[CV 4/5; 348/360] END colsample_bytree=0.9, max_depth=4, n_estimators=550;, score=0.953 total time=   0.8s\n",
      "[CV 5/5; 348/360] START colsample_bytree=0.9, max_depth=4, n_estimators=550.....\n",
      "[CV 5/5; 348/360] END colsample_bytree=0.9, max_depth=4, n_estimators=550;, score=0.951 total time=   0.8s\n",
      "[CV 1/5; 349/360] START colsample_bytree=0.9, max_depth=5, n_estimators=300.....\n",
      "[CV 1/5; 349/360] END colsample_bytree=0.9, max_depth=5, n_estimators=300;, score=0.948 total time=   0.7s\n",
      "[CV 2/5; 349/360] START colsample_bytree=0.9, max_depth=5, n_estimators=300.....\n",
      "[CV 2/5; 349/360] END colsample_bytree=0.9, max_depth=5, n_estimators=300;, score=0.950 total time=   0.6s\n",
      "[CV 3/5; 349/360] START colsample_bytree=0.9, max_depth=5, n_estimators=300.....\n",
      "[CV 3/5; 349/360] END colsample_bytree=0.9, max_depth=5, n_estimators=300;, score=0.951 total time=   0.6s\n",
      "[CV 4/5; 349/360] START colsample_bytree=0.9, max_depth=5, n_estimators=300.....\n",
      "[CV 4/5; 349/360] END colsample_bytree=0.9, max_depth=5, n_estimators=300;, score=0.954 total time=   0.6s\n",
      "[CV 5/5; 349/360] START colsample_bytree=0.9, max_depth=5, n_estimators=300.....\n",
      "[CV 5/5; 349/360] END colsample_bytree=0.9, max_depth=5, n_estimators=300;, score=0.951 total time=   0.6s\n",
      "[CV 1/5; 350/360] START colsample_bytree=0.9, max_depth=5, n_estimators=350.....\n",
      "[CV 1/5; 350/360] END colsample_bytree=0.9, max_depth=5, n_estimators=350;, score=0.947 total time=   0.6s\n",
      "[CV 2/5; 350/360] START colsample_bytree=0.9, max_depth=5, n_estimators=350.....\n",
      "[CV 2/5; 350/360] END colsample_bytree=0.9, max_depth=5, n_estimators=350;, score=0.950 total time=   0.6s\n",
      "[CV 3/5; 350/360] START colsample_bytree=0.9, max_depth=5, n_estimators=350.....\n",
      "[CV 3/5; 350/360] END colsample_bytree=0.9, max_depth=5, n_estimators=350;, score=0.951 total time=   0.6s\n",
      "[CV 4/5; 350/360] START colsample_bytree=0.9, max_depth=5, n_estimators=350.....\n",
      "[CV 4/5; 350/360] END colsample_bytree=0.9, max_depth=5, n_estimators=350;, score=0.954 total time=   0.6s\n",
      "[CV 5/5; 350/360] START colsample_bytree=0.9, max_depth=5, n_estimators=350.....\n",
      "[CV 5/5; 350/360] END colsample_bytree=0.9, max_depth=5, n_estimators=350;, score=0.950 total time=   0.6s\n",
      "[CV 1/5; 351/360] START colsample_bytree=0.9, max_depth=5, n_estimators=400.....\n",
      "[CV 1/5; 351/360] END colsample_bytree=0.9, max_depth=5, n_estimators=400;, score=0.947 total time=   0.6s\n",
      "[CV 2/5; 351/360] START colsample_bytree=0.9, max_depth=5, n_estimators=400.....\n",
      "[CV 2/5; 351/360] END colsample_bytree=0.9, max_depth=5, n_estimators=400;, score=0.949 total time=   0.6s\n",
      "[CV 3/5; 351/360] START colsample_bytree=0.9, max_depth=5, n_estimators=400.....\n",
      "[CV 3/5; 351/360] END colsample_bytree=0.9, max_depth=5, n_estimators=400;, score=0.951 total time=   0.6s\n",
      "[CV 4/5; 351/360] START colsample_bytree=0.9, max_depth=5, n_estimators=400.....\n",
      "[CV 4/5; 351/360] END colsample_bytree=0.9, max_depth=5, n_estimators=400;, score=0.954 total time=   0.6s\n",
      "[CV 5/5; 351/360] START colsample_bytree=0.9, max_depth=5, n_estimators=400.....\n",
      "[CV 5/5; 351/360] END colsample_bytree=0.9, max_depth=5, n_estimators=400;, score=0.950 total time=   0.7s\n",
      "[CV 1/5; 352/360] START colsample_bytree=0.9, max_depth=5, n_estimators=450.....\n",
      "[CV 1/5; 352/360] END colsample_bytree=0.9, max_depth=5, n_estimators=450;, score=0.946 total time=   0.7s\n",
      "[CV 2/5; 352/360] START colsample_bytree=0.9, max_depth=5, n_estimators=450.....\n",
      "[CV 2/5; 352/360] END colsample_bytree=0.9, max_depth=5, n_estimators=450;, score=0.948 total time=   0.7s\n",
      "[CV 3/5; 352/360] START colsample_bytree=0.9, max_depth=5, n_estimators=450.....\n",
      "[CV 3/5; 352/360] END colsample_bytree=0.9, max_depth=5, n_estimators=450;, score=0.950 total time=   0.7s\n",
      "[CV 4/5; 352/360] START colsample_bytree=0.9, max_depth=5, n_estimators=450.....\n",
      "[CV 4/5; 352/360] END colsample_bytree=0.9, max_depth=5, n_estimators=450;, score=0.954 total time=   0.7s\n",
      "[CV 5/5; 352/360] START colsample_bytree=0.9, max_depth=5, n_estimators=450.....\n",
      "[CV 5/5; 352/360] END colsample_bytree=0.9, max_depth=5, n_estimators=450;, score=0.949 total time=   0.7s\n",
      "[CV 1/5; 353/360] START colsample_bytree=0.9, max_depth=5, n_estimators=500.....\n",
      "[CV 1/5; 353/360] END colsample_bytree=0.9, max_depth=5, n_estimators=500;, score=0.946 total time=   0.8s\n",
      "[CV 2/5; 353/360] START colsample_bytree=0.9, max_depth=5, n_estimators=500.....\n",
      "[CV 2/5; 353/360] END colsample_bytree=0.9, max_depth=5, n_estimators=500;, score=0.948 total time=   1.0s\n",
      "[CV 3/5; 353/360] START colsample_bytree=0.9, max_depth=5, n_estimators=500.....\n",
      "[CV 3/5; 353/360] END colsample_bytree=0.9, max_depth=5, n_estimators=500;, score=0.950 total time=   1.0s\n",
      "[CV 4/5; 353/360] START colsample_bytree=0.9, max_depth=5, n_estimators=500.....\n",
      "[CV 4/5; 353/360] END colsample_bytree=0.9, max_depth=5, n_estimators=500;, score=0.953 total time=   1.0s\n",
      "[CV 5/5; 353/360] START colsample_bytree=0.9, max_depth=5, n_estimators=500.....\n",
      "[CV 5/5; 353/360] END colsample_bytree=0.9, max_depth=5, n_estimators=500;, score=0.949 total time=   1.0s\n",
      "[CV 1/5; 354/360] START colsample_bytree=0.9, max_depth=5, n_estimators=550.....\n",
      "[CV 1/5; 354/360] END colsample_bytree=0.9, max_depth=5, n_estimators=550;, score=0.946 total time=   1.0s\n",
      "[CV 2/5; 354/360] START colsample_bytree=0.9, max_depth=5, n_estimators=550.....\n",
      "[CV 2/5; 354/360] END colsample_bytree=0.9, max_depth=5, n_estimators=550;, score=0.948 total time=   0.9s\n",
      "[CV 3/5; 354/360] START colsample_bytree=0.9, max_depth=5, n_estimators=550.....\n",
      "[CV 3/5; 354/360] END colsample_bytree=0.9, max_depth=5, n_estimators=550;, score=0.950 total time=   0.9s\n",
      "[CV 4/5; 354/360] START colsample_bytree=0.9, max_depth=5, n_estimators=550.....\n",
      "[CV 4/5; 354/360] END colsample_bytree=0.9, max_depth=5, n_estimators=550;, score=0.953 total time=   0.9s\n",
      "[CV 5/5; 354/360] START colsample_bytree=0.9, max_depth=5, n_estimators=550.....\n",
      "[CV 5/5; 354/360] END colsample_bytree=0.9, max_depth=5, n_estimators=550;, score=0.949 total time=   0.9s\n",
      "[CV 1/5; 355/360] START colsample_bytree=0.9, max_depth=6, n_estimators=300.....\n",
      "[CV 1/5; 355/360] END colsample_bytree=0.9, max_depth=6, n_estimators=300;, score=0.948 total time=   0.5s\n",
      "[CV 2/5; 355/360] START colsample_bytree=0.9, max_depth=6, n_estimators=300.....\n",
      "[CV 2/5; 355/360] END colsample_bytree=0.9, max_depth=6, n_estimators=300;, score=0.949 total time=   0.5s\n",
      "[CV 3/5; 355/360] START colsample_bytree=0.9, max_depth=6, n_estimators=300.....\n",
      "[CV 3/5; 355/360] END colsample_bytree=0.9, max_depth=6, n_estimators=300;, score=0.950 total time=   0.5s\n",
      "[CV 4/5; 355/360] START colsample_bytree=0.9, max_depth=6, n_estimators=300.....\n",
      "[CV 4/5; 355/360] END colsample_bytree=0.9, max_depth=6, n_estimators=300;, score=0.954 total time=   0.5s\n",
      "[CV 5/5; 355/360] START colsample_bytree=0.9, max_depth=6, n_estimators=300.....\n",
      "[CV 5/5; 355/360] END colsample_bytree=0.9, max_depth=6, n_estimators=300;, score=0.950 total time=   0.5s\n",
      "[CV 1/5; 356/360] START colsample_bytree=0.9, max_depth=6, n_estimators=350.....\n",
      "[CV 1/5; 356/360] END colsample_bytree=0.9, max_depth=6, n_estimators=350;, score=0.947 total time=   0.7s\n",
      "[CV 2/5; 356/360] START colsample_bytree=0.9, max_depth=6, n_estimators=350.....\n",
      "[CV 2/5; 356/360] END colsample_bytree=0.9, max_depth=6, n_estimators=350;, score=0.949 total time=   0.6s\n",
      "[CV 3/5; 356/360] START colsample_bytree=0.9, max_depth=6, n_estimators=350.....\n",
      "[CV 3/5; 356/360] END colsample_bytree=0.9, max_depth=6, n_estimators=350;, score=0.949 total time=   0.9s\n",
      "[CV 4/5; 356/360] START colsample_bytree=0.9, max_depth=6, n_estimators=350.....\n",
      "[CV 4/5; 356/360] END colsample_bytree=0.9, max_depth=6, n_estimators=350;, score=0.953 total time=   0.6s\n",
      "[CV 5/5; 356/360] START colsample_bytree=0.9, max_depth=6, n_estimators=350.....\n",
      "[CV 5/5; 356/360] END colsample_bytree=0.9, max_depth=6, n_estimators=350;, score=0.950 total time=   0.8s\n",
      "[CV 1/5; 357/360] START colsample_bytree=0.9, max_depth=6, n_estimators=400.....\n",
      "[CV 1/5; 357/360] END colsample_bytree=0.9, max_depth=6, n_estimators=400;, score=0.946 total time=   0.9s\n",
      "[CV 2/5; 357/360] START colsample_bytree=0.9, max_depth=6, n_estimators=400.....\n",
      "[CV 2/5; 357/360] END colsample_bytree=0.9, max_depth=6, n_estimators=400;, score=0.948 total time=   0.9s\n",
      "[CV 3/5; 357/360] START colsample_bytree=0.9, max_depth=6, n_estimators=400.....\n",
      "[CV 3/5; 357/360] END colsample_bytree=0.9, max_depth=6, n_estimators=400;, score=0.949 total time=   0.9s\n",
      "[CV 4/5; 357/360] START colsample_bytree=0.9, max_depth=6, n_estimators=400.....\n",
      "[CV 4/5; 357/360] END colsample_bytree=0.9, max_depth=6, n_estimators=400;, score=0.953 total time=   0.7s\n",
      "[CV 5/5; 357/360] START colsample_bytree=0.9, max_depth=6, n_estimators=400.....\n",
      "[CV 5/5; 357/360] END colsample_bytree=0.9, max_depth=6, n_estimators=400;, score=0.949 total time=   0.8s\n",
      "[CV 1/5; 358/360] START colsample_bytree=0.9, max_depth=6, n_estimators=450.....\n",
      "[CV 1/5; 358/360] END colsample_bytree=0.9, max_depth=6, n_estimators=450;, score=0.947 total time=   1.0s\n",
      "[CV 2/5; 358/360] START colsample_bytree=0.9, max_depth=6, n_estimators=450.....\n",
      "[CV 2/5; 358/360] END colsample_bytree=0.9, max_depth=6, n_estimators=450;, score=0.948 total time=   1.0s\n",
      "[CV 3/5; 358/360] START colsample_bytree=0.9, max_depth=6, n_estimators=450.....\n",
      "[CV 3/5; 358/360] END colsample_bytree=0.9, max_depth=6, n_estimators=450;, score=0.949 total time=   0.9s\n",
      "[CV 4/5; 358/360] START colsample_bytree=0.9, max_depth=6, n_estimators=450.....\n",
      "[CV 4/5; 358/360] END colsample_bytree=0.9, max_depth=6, n_estimators=450;, score=0.953 total time=   0.8s\n",
      "[CV 5/5; 358/360] START colsample_bytree=0.9, max_depth=6, n_estimators=450.....\n",
      "[CV 5/5; 358/360] END colsample_bytree=0.9, max_depth=6, n_estimators=450;, score=0.948 total time=   0.9s\n",
      "[CV 1/5; 359/360] START colsample_bytree=0.9, max_depth=6, n_estimators=500.....\n",
      "[CV 1/5; 359/360] END colsample_bytree=0.9, max_depth=6, n_estimators=500;, score=0.945 total time=   1.1s\n",
      "[CV 2/5; 359/360] START colsample_bytree=0.9, max_depth=6, n_estimators=500.....\n",
      "[CV 2/5; 359/360] END colsample_bytree=0.9, max_depth=6, n_estimators=500;, score=0.948 total time=   1.0s\n",
      "[CV 3/5; 359/360] START colsample_bytree=0.9, max_depth=6, n_estimators=500.....\n",
      "[CV 3/5; 359/360] END colsample_bytree=0.9, max_depth=6, n_estimators=500;, score=0.949 total time=   0.9s\n",
      "[CV 4/5; 359/360] START colsample_bytree=0.9, max_depth=6, n_estimators=500.....\n",
      "[CV 4/5; 359/360] END colsample_bytree=0.9, max_depth=6, n_estimators=500;, score=0.953 total time=   0.9s\n",
      "[CV 5/5; 359/360] START colsample_bytree=0.9, max_depth=6, n_estimators=500.....\n",
      "[CV 5/5; 359/360] END colsample_bytree=0.9, max_depth=6, n_estimators=500;, score=0.948 total time=   0.9s\n",
      "[CV 1/5; 360/360] START colsample_bytree=0.9, max_depth=6, n_estimators=550.....\n",
      "[CV 1/5; 360/360] END colsample_bytree=0.9, max_depth=6, n_estimators=550;, score=0.946 total time=   1.2s\n",
      "[CV 2/5; 360/360] START colsample_bytree=0.9, max_depth=6, n_estimators=550.....\n",
      "[CV 2/5; 360/360] END colsample_bytree=0.9, max_depth=6, n_estimators=550;, score=0.949 total time=   1.3s\n",
      "[CV 3/5; 360/360] START colsample_bytree=0.9, max_depth=6, n_estimators=550.....\n",
      "[CV 3/5; 360/360] END colsample_bytree=0.9, max_depth=6, n_estimators=550;, score=0.948 total time=   1.2s\n",
      "[CV 4/5; 360/360] START colsample_bytree=0.9, max_depth=6, n_estimators=550.....\n",
      "[CV 4/5; 360/360] END colsample_bytree=0.9, max_depth=6, n_estimators=550;, score=0.953 total time=   1.0s\n",
      "[CV 5/5; 360/360] START colsample_bytree=0.9, max_depth=6, n_estimators=550.....\n",
      "[CV 5/5; 360/360] END colsample_bytree=0.9, max_depth=6, n_estimators=550;, score=0.948 total time=   1.0s\n"
     ]
    }
   ],
   "source": [
    "xgbGrid = {'n_estimators': list(range(300, 600, 50)),\n",
    "          'max_depth': list(range(1,7)),\n",
    "          'colsample_bytree' : [x / 10 for x in range(0,10)]}\n",
    "xgbSearch2 = GridSearchCV(xgbModel, xgbGrid, cv=5, verbose=10).fit(Xscaled, Ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0228235d-46f2-495d-87a9-d0801e8afe64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9522364998336117\n",
      "{'colsample_bytree': 0.9, 'max_depth': 3, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "print(xgbSearch.best_score_)\n",
    "print(xgbSearch.best_params_)\n",
    "# We can see that the best number of estimators was 300 with a max depth of 3 and less than half of the features samples on each tree\n",
    "#, this is similar to the result we saw above with a max depth of 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5368652c-5727-4c1d-95d8-4dc875419b23",
   "metadata": {},
   "source": [
    "As we can see from our grid search on XGBTrees, we get an accuracy of about 95%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba425c26-414e-4ab5-8c07-9dd0245c0b8b",
   "metadata": {},
   "source": [
    "In the following cells, we test SVC machines which can produce fairly accurate models at around 94%, however they are slow to train and we can not perform a proper grid search on them unless we let the code run for a whole day. The gridSearch was forceStopped by interrupting the kernel when improvements were not seen, too slow, or taking too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "525db20c-5e73-403b-ae28-e067bc150d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV 1/3; 1/8] START C=0.5, kernel=linear........................................\n",
      "[CV 1/3; 1/8] END .........C=0.5, kernel=linear;, score=0.900 total time= 1.1min\n",
      "[CV 2/3; 1/8] START C=0.5, kernel=linear........................................\n",
      "[CV 2/3; 1/8] END .........C=0.5, kernel=linear;, score=0.900 total time= 1.1min\n",
      "[CV 3/3; 1/8] START C=0.5, kernel=linear........................................\n",
      "[CV 3/3; 1/8] END .........C=0.5, kernel=linear;, score=0.902 total time= 1.1min\n",
      "[CV 1/3; 2/8] START C=0.3333333333333333, kernel=linear.........................\n",
      "[CV 1/3; 2/8] END C=0.3333333333333333, kernel=linear;, score=0.900 total time= 1.0min\n",
      "[CV 2/3; 2/8] START C=0.3333333333333333, kernel=linear.........................\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m svcModel \u001b[38;5;241m=\u001b[39m SVC(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      4\u001b[0m svcGrid\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      5\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mx \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m10\u001b[39m)]}\n\u001b[1;32m----> 6\u001b[0m svcSearch \u001b[38;5;241m=\u001b[39m GridSearchCV(svcModel, svcGrid, cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(Xscaled, Ydata)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    917\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    918\u001b[0m         clone(base_estimator),\n\u001b[0;32m    919\u001b[0m         X,\n\u001b[0;32m    920\u001b[0m         y,\n\u001b[0;32m    921\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    922\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    923\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    924\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    925\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    927\u001b[0m     )\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    929\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    930\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    931\u001b[0m     )\n\u001b[0;32m    932\u001b[0m )\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    893\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 895\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:250\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    249\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m--> 250\u001b[0m fit(X, y, sample_weight, solver_type, kernel, random_seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:329\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    315\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    319\u001b[0m (\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[1;32m--> 329\u001b[0m ) \u001b[38;5;241m=\u001b[39m libsvm\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    330\u001b[0m     X,\n\u001b[0;32m    331\u001b[0m     y,\n\u001b[0;32m    332\u001b[0m     svm_type\u001b[38;5;241m=\u001b[39msolver_type,\n\u001b[0;32m    333\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    334\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_weight_\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m0\u001b[39m)),\n\u001b[0;32m    335\u001b[0m     kernel\u001b[38;5;241m=\u001b[39mkernel,\n\u001b[0;32m    336\u001b[0m     C\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC,\n\u001b[0;32m    337\u001b[0m     nu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnu,\n\u001b[0;32m    338\u001b[0m     probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobability,\n\u001b[0;32m    339\u001b[0m     degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegree,\n\u001b[0;32m    340\u001b[0m     shrinking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshrinking,\n\u001b[0;32m    341\u001b[0m     tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n\u001b[0;32m    342\u001b[0m     cache_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_size,\n\u001b[0;32m    343\u001b[0m     coef0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef0,\n\u001b[0;32m    344\u001b[0m     gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gamma,\n\u001b[0;32m    345\u001b[0m     epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon,\n\u001b[0;32m    346\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[0;32m    347\u001b[0m     random_seed\u001b[38;5;241m=\u001b[39mrandom_seed,\n\u001b[0;32m    348\u001b[0m )\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svcModel = SVC(random_state=42)\n",
    "\n",
    "svcGrid={'kernel': ['linear'],\n",
    "         'C': [1/x for x in range(2,10)]}\n",
    "svcSearch = GridSearchCV(svcModel, svcGrid, cv = 3, verbose=10).fit(Xscaled, Ydata)\n",
    "# stopping code from finishing early because it does not appear that a linear fit can do much better than .9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "61c30cea-819f-4e3f-b7a3-9275606bf0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "[CV 1/3; 1/72] START C=1, degree=2, gamma=scale, kernel=poly....................\n",
      "[CV 1/3; 1/72] END C=1, degree=2, gamma=scale, kernel=poly;, score=0.922 total time=  45.6s\n",
      "[CV 2/3; 1/72] START C=1, degree=2, gamma=scale, kernel=poly....................\n",
      "[CV 2/3; 1/72] END C=1, degree=2, gamma=scale, kernel=poly;, score=0.923 total time=  46.8s\n",
      "[CV 3/3; 1/72] START C=1, degree=2, gamma=scale, kernel=poly....................\n",
      "[CV 3/3; 1/72] END C=1, degree=2, gamma=scale, kernel=poly;, score=0.924 total time=  45.8s\n",
      "[CV 1/3; 2/72] START C=1, degree=2, gamma=auto, kernel=poly.....................\n",
      "[CV 1/3; 2/72] END C=1, degree=2, gamma=auto, kernel=poly;, score=0.928 total time=  47.8s\n",
      "[CV 2/3; 2/72] START C=1, degree=2, gamma=auto, kernel=poly.....................\n",
      "[CV 2/3; 2/72] END C=1, degree=2, gamma=auto, kernel=poly;, score=0.927 total time=  46.9s\n",
      "[CV 3/3; 2/72] START C=1, degree=2, gamma=auto, kernel=poly.....................\n",
      "[CV 3/3; 2/72] END C=1, degree=2, gamma=auto, kernel=poly;, score=0.928 total time=  49.4s\n",
      "[CV 1/3; 3/72] START C=1, degree=3, gamma=scale, kernel=poly....................\n",
      "[CV 1/3; 3/72] END C=1, degree=3, gamma=scale, kernel=poly;, score=0.924 total time=  48.4s\n",
      "[CV 2/3; 3/72] START C=1, degree=3, gamma=scale, kernel=poly....................\n",
      "[CV 2/3; 3/72] END C=1, degree=3, gamma=scale, kernel=poly;, score=0.924 total time=  47.6s\n",
      "[CV 3/3; 3/72] START C=1, degree=3, gamma=scale, kernel=poly....................\n",
      "[CV 3/3; 3/72] END C=1, degree=3, gamma=scale, kernel=poly;, score=0.927 total time=  46.4s\n",
      "[CV 1/3; 4/72] START C=1, degree=3, gamma=auto, kernel=poly.....................\n",
      "[CV 1/3; 4/72] END C=1, degree=3, gamma=auto, kernel=poly;, score=0.935 total time= 1.0min\n",
      "[CV 2/3; 4/72] START C=1, degree=3, gamma=auto, kernel=poly.....................\n",
      "[CV 2/3; 4/72] END C=1, degree=3, gamma=auto, kernel=poly;, score=0.935 total time=  59.8s\n",
      "[CV 3/3; 4/72] START C=1, degree=3, gamma=auto, kernel=poly.....................\n",
      "[CV 3/3; 4/72] END C=1, degree=3, gamma=auto, kernel=poly;, score=0.939 total time=  59.0s\n",
      "[CV 1/3; 5/72] START C=1, degree=4, gamma=scale, kernel=poly....................\n",
      "[CV 1/3; 5/72] END C=1, degree=4, gamma=scale, kernel=poly;, score=0.925 total time=  49.6s\n",
      "[CV 2/3; 5/72] START C=1, degree=4, gamma=scale, kernel=poly....................\n",
      "[CV 2/3; 5/72] END C=1, degree=4, gamma=scale, kernel=poly;, score=0.924 total time=  50.1s\n",
      "[CV 3/3; 5/72] START C=1, degree=4, gamma=scale, kernel=poly....................\n",
      "[CV 3/3; 5/72] END C=1, degree=4, gamma=scale, kernel=poly;, score=0.927 total time=  53.2s\n",
      "[CV 1/3; 6/72] START C=1, degree=4, gamma=auto, kernel=poly.....................\n",
      "[CV 1/3; 6/72] END C=1, degree=4, gamma=auto, kernel=poly;, score=0.939 total time= 1.7min\n",
      "[CV 2/3; 6/72] START C=1, degree=4, gamma=auto, kernel=poly.....................\n",
      "[CV 2/3; 6/72] END C=1, degree=4, gamma=auto, kernel=poly;, score=0.937 total time= 1.8min\n",
      "[CV 3/3; 6/72] START C=1, degree=4, gamma=auto, kernel=poly.....................\n",
      "[CV 3/3; 6/72] END C=1, degree=4, gamma=auto, kernel=poly;, score=0.941 total time= 1.7min\n",
      "[CV 1/3; 7/72] START C=1, degree=5, gamma=scale, kernel=poly....................\n",
      "[CV 1/3; 7/72] END C=1, degree=5, gamma=scale, kernel=poly;, score=0.924 total time=  53.8s\n",
      "[CV 2/3; 7/72] START C=1, degree=5, gamma=scale, kernel=poly....................\n",
      "[CV 2/3; 7/72] END C=1, degree=5, gamma=scale, kernel=poly;, score=0.922 total time=  55.1s\n",
      "[CV 3/3; 7/72] START C=1, degree=5, gamma=scale, kernel=poly....................\n",
      "[CV 3/3; 7/72] END C=1, degree=5, gamma=scale, kernel=poly;, score=0.926 total time=  53.6s\n",
      "[CV 1/3; 8/72] START C=1, degree=5, gamma=auto, kernel=poly.....................\n",
      "[CV 1/3; 8/72] END C=1, degree=5, gamma=auto, kernel=poly;, score=0.939 total time= 3.4min\n",
      "[CV 2/3; 8/72] START C=1, degree=5, gamma=auto, kernel=poly.....................\n",
      "[CV 2/3; 8/72] END C=1, degree=5, gamma=auto, kernel=poly;, score=0.938 total time= 3.9min\n",
      "[CV 3/3; 8/72] START C=1, degree=5, gamma=auto, kernel=poly.....................\n",
      "[CV 3/3; 8/72] END C=1, degree=5, gamma=auto, kernel=poly;, score=0.942 total time= 3.3min\n",
      "[CV 1/3; 9/72] START C=2, degree=2, gamma=scale, kernel=poly....................\n",
      "[CV 1/3; 9/72] END C=2, degree=2, gamma=scale, kernel=poly;, score=0.926 total time=  47.9s\n",
      "[CV 2/3; 9/72] START C=2, degree=2, gamma=scale, kernel=poly....................\n",
      "[CV 2/3; 9/72] END C=2, degree=2, gamma=scale, kernel=poly;, score=0.926 total time=  47.5s\n",
      "[CV 3/3; 9/72] START C=2, degree=2, gamma=scale, kernel=poly....................\n",
      "[CV 3/3; 9/72] END C=2, degree=2, gamma=scale, kernel=poly;, score=0.926 total time=  49.4s\n",
      "[CV 1/3; 10/72] START C=2, degree=2, gamma=auto, kernel=poly....................\n",
      "[CV 1/3; 10/72] END C=2, degree=2, gamma=auto, kernel=poly;, score=0.929 total time=  53.4s\n",
      "[CV 2/3; 10/72] START C=2, degree=2, gamma=auto, kernel=poly....................\n",
      "[CV 2/3; 10/72] END C=2, degree=2, gamma=auto, kernel=poly;, score=0.929 total time=  52.3s\n",
      "[CV 3/3; 10/72] START C=2, degree=2, gamma=auto, kernel=poly....................\n",
      "[CV 3/3; 10/72] END C=2, degree=2, gamma=auto, kernel=poly;, score=0.930 total time=  53.6s\n",
      "[CV 1/3; 11/72] START C=2, degree=3, gamma=scale, kernel=poly...................\n",
      "[CV 1/3; 11/72] END C=2, degree=3, gamma=scale, kernel=poly;, score=0.928 total time=  49.0s\n",
      "[CV 2/3; 11/72] START C=2, degree=3, gamma=scale, kernel=poly...................\n",
      "[CV 2/3; 11/72] END C=2, degree=3, gamma=scale, kernel=poly;, score=0.929 total time=  48.6s\n",
      "[CV 3/3; 11/72] START C=2, degree=3, gamma=scale, kernel=poly...................\n",
      "[CV 3/3; 11/72] END C=2, degree=3, gamma=scale, kernel=poly;, score=0.931 total time=  48.4s\n",
      "[CV 1/3; 12/72] START C=2, degree=3, gamma=auto, kernel=poly....................\n",
      "[CV 1/3; 12/72] END C=2, degree=3, gamma=auto, kernel=poly;, score=0.936 total time= 1.3min\n",
      "[CV 2/3; 12/72] START C=2, degree=3, gamma=auto, kernel=poly....................\n",
      "[CV 2/3; 12/72] END C=2, degree=3, gamma=auto, kernel=poly;, score=0.936 total time= 1.3min\n",
      "[CV 3/3; 12/72] START C=2, degree=3, gamma=auto, kernel=poly....................\n",
      "[CV 3/3; 12/72] END C=2, degree=3, gamma=auto, kernel=poly;, score=0.940 total time= 1.3min\n",
      "[CV 1/3; 13/72] START C=2, degree=4, gamma=scale, kernel=poly...................\n",
      "[CV 1/3; 13/72] END C=2, degree=4, gamma=scale, kernel=poly;, score=0.931 total time=  51.8s\n",
      "[CV 2/3; 13/72] START C=2, degree=4, gamma=scale, kernel=poly...................\n",
      "[CV 2/3; 13/72] END C=2, degree=4, gamma=scale, kernel=poly;, score=0.929 total time=  53.8s\n",
      "[CV 3/3; 13/72] START C=2, degree=4, gamma=scale, kernel=poly...................\n",
      "[CV 3/3; 13/72] END C=2, degree=4, gamma=scale, kernel=poly;, score=0.933 total time=  54.8s\n",
      "[CV 1/3; 14/72] START C=2, degree=4, gamma=auto, kernel=poly....................\n",
      "[CV 1/3; 14/72] END C=2, degree=4, gamma=auto, kernel=poly;, score=0.939 total time= 2.4min\n",
      "[CV 2/3; 14/72] START C=2, degree=4, gamma=auto, kernel=poly....................\n",
      "[CV 2/3; 14/72] END C=2, degree=4, gamma=auto, kernel=poly;, score=0.937 total time= 2.8min\n",
      "[CV 3/3; 14/72] START C=2, degree=4, gamma=auto, kernel=poly....................\n",
      "[CV 3/3; 14/72] END C=2, degree=4, gamma=auto, kernel=poly;, score=0.942 total time= 2.6min\n",
      "[CV 1/3; 15/72] START C=2, degree=5, gamma=scale, kernel=poly...................\n",
      "[CV 1/3; 15/72] END C=2, degree=5, gamma=scale, kernel=poly;, score=0.930 total time= 1.0min\n",
      "[CV 2/3; 15/72] START C=2, degree=5, gamma=scale, kernel=poly...................\n",
      "[CV 2/3; 15/72] END C=2, degree=5, gamma=scale, kernel=poly;, score=0.928 total time= 1.0min\n",
      "[CV 3/3; 15/72] START C=2, degree=5, gamma=scale, kernel=poly...................\n",
      "[CV 3/3; 15/72] END C=2, degree=5, gamma=scale, kernel=poly;, score=0.933 total time=  57.7s\n",
      "[CV 1/3; 16/72] START C=2, degree=5, gamma=auto, kernel=poly....................\n",
      "[CV 1/3; 16/72] END C=2, degree=5, gamma=auto, kernel=poly;, score=0.939 total time= 6.2min\n",
      "[CV 2/3; 16/72] START C=2, degree=5, gamma=auto, kernel=poly....................\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m svcGrid2\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoly\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      2\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      3\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdegree\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m6\u001b[39m)),\n\u001b[0;32m      4\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m10\u001b[39m))}\n\u001b[1;32m----> 5\u001b[0m svcSearch2 \u001b[38;5;241m=\u001b[39m GridSearchCV(svcModel, svcGrid2, cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(Xscaled, Ydata)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    917\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    918\u001b[0m         clone(base_estimator),\n\u001b[0;32m    919\u001b[0m         X,\n\u001b[0;32m    920\u001b[0m         y,\n\u001b[0;32m    921\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    922\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    923\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    924\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    925\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    927\u001b[0m     )\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    929\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    930\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    931\u001b[0m     )\n\u001b[0;32m    932\u001b[0m )\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    893\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 895\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:250\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    249\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m--> 250\u001b[0m fit(X, y, sample_weight, solver_type, kernel, random_seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:329\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    315\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    319\u001b[0m (\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[1;32m--> 329\u001b[0m ) \u001b[38;5;241m=\u001b[39m libsvm\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    330\u001b[0m     X,\n\u001b[0;32m    331\u001b[0m     y,\n\u001b[0;32m    332\u001b[0m     svm_type\u001b[38;5;241m=\u001b[39msolver_type,\n\u001b[0;32m    333\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    334\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_weight_\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m0\u001b[39m)),\n\u001b[0;32m    335\u001b[0m     kernel\u001b[38;5;241m=\u001b[39mkernel,\n\u001b[0;32m    336\u001b[0m     C\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC,\n\u001b[0;32m    337\u001b[0m     nu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnu,\n\u001b[0;32m    338\u001b[0m     probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobability,\n\u001b[0;32m    339\u001b[0m     degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegree,\n\u001b[0;32m    340\u001b[0m     shrinking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshrinking,\n\u001b[0;32m    341\u001b[0m     tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n\u001b[0;32m    342\u001b[0m     cache_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_size,\n\u001b[0;32m    343\u001b[0m     coef0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef0,\n\u001b[0;32m    344\u001b[0m     gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gamma,\n\u001b[0;32m    345\u001b[0m     epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon,\n\u001b[0;32m    346\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[0;32m    347\u001b[0m     random_seed\u001b[38;5;241m=\u001b[39mrandom_seed,\n\u001b[0;32m    348\u001b[0m )\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "svcGrid2={'kernel': ['poly'],\n",
    "         'gamma': ['scale', 'auto'],\n",
    "         'degree': list(range(2,6)),\n",
    "         'C': list(range(1,10))}\n",
    "svcSearch2 = GridSearchCV(svcModel, svcGrid2, cv = 3, verbose=10).fit(Xscaled, Ydata)\n",
    "# stopped early because it appears best score is around .94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7fef40e7-a88e-4c70-b4f8-3d3b7d814b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV 1/3; 1/8] START C=2, gamma=auto, kernel=rbf.................................\n",
      "[CV 1/3; 1/8] END ..C=2, gamma=auto, kernel=rbf;, score=0.941 total time= 1.3min\n",
      "[CV 2/3; 1/8] START C=2, gamma=auto, kernel=rbf.................................\n",
      "[CV 2/3; 1/8] END ..C=2, gamma=auto, kernel=rbf;, score=0.939 total time= 1.3min\n",
      "[CV 3/3; 1/8] START C=2, gamma=auto, kernel=rbf.................................\n",
      "[CV 3/3; 1/8] END ..C=2, gamma=auto, kernel=rbf;, score=0.944 total time= 1.3min\n",
      "[CV 1/3; 2/8] START C=3, gamma=auto, kernel=rbf.................................\n",
      "[CV 1/3; 2/8] END ..C=3, gamma=auto, kernel=rbf;, score=0.941 total time= 1.4min\n",
      "[CV 2/3; 2/8] START C=3, gamma=auto, kernel=rbf.................................\n",
      "[CV 2/3; 2/8] END ..C=3, gamma=auto, kernel=rbf;, score=0.940 total time= 1.4min\n",
      "[CV 3/3; 2/8] START C=3, gamma=auto, kernel=rbf.................................\n",
      "[CV 3/3; 2/8] END ..C=3, gamma=auto, kernel=rbf;, score=0.945 total time= 1.4min\n",
      "[CV 1/3; 3/8] START C=4, gamma=auto, kernel=rbf.................................\n",
      "[CV 1/3; 3/8] END ..C=4, gamma=auto, kernel=rbf;, score=0.942 total time= 1.4min\n",
      "[CV 2/3; 3/8] START C=4, gamma=auto, kernel=rbf.................................\n",
      "[CV 2/3; 3/8] END ..C=4, gamma=auto, kernel=rbf;, score=0.940 total time= 1.4min\n",
      "[CV 3/3; 3/8] START C=4, gamma=auto, kernel=rbf.................................\n",
      "[CV 3/3; 3/8] END ..C=4, gamma=auto, kernel=rbf;, score=0.945 total time= 1.4min\n",
      "[CV 1/3; 4/8] START C=5, gamma=auto, kernel=rbf.................................\n",
      "[CV 1/3; 4/8] END ..C=5, gamma=auto, kernel=rbf;, score=0.942 total time= 1.4min\n",
      "[CV 2/3; 4/8] START C=5, gamma=auto, kernel=rbf.................................\n",
      "[CV 2/3; 4/8] END ..C=5, gamma=auto, kernel=rbf;, score=0.941 total time= 1.4min\n",
      "[CV 3/3; 4/8] START C=5, gamma=auto, kernel=rbf.................................\n",
      "[CV 3/3; 4/8] END ..C=5, gamma=auto, kernel=rbf;, score=0.945 total time= 1.5min\n",
      "[CV 1/3; 5/8] START C=6, gamma=auto, kernel=rbf.................................\n",
      "[CV 1/3; 5/8] END ..C=6, gamma=auto, kernel=rbf;, score=0.942 total time= 1.4min\n",
      "[CV 2/3; 5/8] START C=6, gamma=auto, kernel=rbf.................................\n",
      "[CV 2/3; 5/8] END ..C=6, gamma=auto, kernel=rbf;, score=0.941 total time= 1.4min\n",
      "[CV 3/3; 5/8] START C=6, gamma=auto, kernel=rbf.................................\n",
      "[CV 3/3; 5/8] END ..C=6, gamma=auto, kernel=rbf;, score=0.945 total time= 1.5min\n",
      "[CV 1/3; 6/8] START C=7, gamma=auto, kernel=rbf.................................\n",
      "[CV 1/3; 6/8] END ..C=7, gamma=auto, kernel=rbf;, score=0.942 total time= 1.4min\n",
      "[CV 2/3; 6/8] START C=7, gamma=auto, kernel=rbf.................................\n",
      "[CV 2/3; 6/8] END ..C=7, gamma=auto, kernel=rbf;, score=0.941 total time= 1.5min\n",
      "[CV 3/3; 6/8] START C=7, gamma=auto, kernel=rbf.................................\n",
      "[CV 3/3; 6/8] END ..C=7, gamma=auto, kernel=rbf;, score=0.946 total time= 1.5min\n",
      "[CV 1/3; 7/8] START C=8, gamma=auto, kernel=rbf.................................\n",
      "[CV 1/3; 7/8] END ..C=8, gamma=auto, kernel=rbf;, score=0.942 total time= 1.5min\n",
      "[CV 2/3; 7/8] START C=8, gamma=auto, kernel=rbf.................................\n",
      "[CV 2/3; 7/8] END ..C=8, gamma=auto, kernel=rbf;, score=0.941 total time= 1.5min\n",
      "[CV 3/3; 7/8] START C=8, gamma=auto, kernel=rbf.................................\n",
      "[CV 3/3; 7/8] END ..C=8, gamma=auto, kernel=rbf;, score=0.946 total time= 1.5min\n",
      "[CV 1/3; 8/8] START C=9, gamma=auto, kernel=rbf.................................\n",
      "[CV 1/3; 8/8] END ..C=9, gamma=auto, kernel=rbf;, score=0.942 total time= 1.5min\n",
      "[CV 2/3; 8/8] START C=9, gamma=auto, kernel=rbf.................................\n",
      "[CV 2/3; 8/8] END ..C=9, gamma=auto, kernel=rbf;, score=0.941 total time= 1.5min\n",
      "[CV 3/3; 8/8] START C=9, gamma=auto, kernel=rbf.................................\n",
      "[CV 3/3; 8/8] END ..C=9, gamma=auto, kernel=rbf;, score=0.946 total time= 1.6min\n"
     ]
    }
   ],
   "source": [
    "svcGrid3={'kernel': ['rbf'],\n",
    "        'gamma': ['auto'],\n",
    "        'C': list(range(2,10))}\n",
    "svcSearch3 = GridSearchCV(svcModel, svcGrid3, cv = 3, verbose=10).fit(Xscaled, Ydata)\n",
    "# stopped early because it appeared scale was not working well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ae98aac9-dc4f-46d1-a802-7077ca43583e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9431665338772305\n",
      "{'C': 8, 'gamma': 'auto', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(svcSearch3.best_score_)\n",
    "print(svcSearch3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "47d2fc80-109e-421b-bf9e-0c2b0f79afe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3; 1/1] START C=8, gamma=0.1, kernel=rbf..................................\n",
      "[CV 1/3; 1/1] END ...C=8, gamma=0.1, kernel=rbf;, score=0.943 total time= 2.2min\n",
      "[CV 2/3; 1/1] START C=8, gamma=0.1, kernel=rbf..................................\n",
      "[CV 2/3; 1/1] END ...C=8, gamma=0.1, kernel=rbf;, score=0.942 total time= 1.9min\n",
      "[CV 3/3; 1/1] START C=8, gamma=0.1, kernel=rbf..................................\n",
      "[CV 3/3; 1/1] END ...C=8, gamma=0.1, kernel=rbf;, score=0.946 total time= 2.1min\n"
     ]
    }
   ],
   "source": [
    "svcGrid4 = {'C': [8],\n",
    "           'kernel': ['rbf'],\n",
    "           'gamma': [.1]\n",
    "           }\n",
    "svcSearch4 = GridSearchCV(svcModel, svcGrid4, cv = 3, verbose=10).fit(Xscaled, Ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "aef24e32-e956-4491-9651-0acd6bbb5ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV 1/3; 1/4] START C=8, degree=2, gamma=0.1, kernel=poly.......................\n",
      "[CV 1/3; 1/4] END C=8, degree=2, gamma=0.1, kernel=poly;, score=0.929 total time= 2.5min\n",
      "[CV 2/3; 1/4] START C=8, degree=2, gamma=0.1, kernel=poly.......................\n",
      "[CV 2/3; 1/4] END C=8, degree=2, gamma=0.1, kernel=poly;, score=0.931 total time= 2.4min\n",
      "[CV 3/3; 1/4] START C=8, degree=2, gamma=0.1, kernel=poly.......................\n",
      "[CV 3/3; 1/4] END C=8, degree=2, gamma=0.1, kernel=poly;, score=0.932 total time= 2.5min\n",
      "[CV 1/3; 2/4] START C=8, degree=3, gamma=0.1, kernel=poly.......................\n",
      "[CV 1/3; 2/4] END C=8, degree=3, gamma=0.1, kernel=poly;, score=0.939 total time=10.3min\n",
      "[CV 2/3; 2/4] START C=8, degree=3, gamma=0.1, kernel=poly.......................\n",
      "[CV 2/3; 2/4] END C=8, degree=3, gamma=0.1, kernel=poly;, score=0.938 total time=10.3min\n",
      "[CV 3/3; 2/4] START C=8, degree=3, gamma=0.1, kernel=poly.......................\n",
      "[CV 3/3; 2/4] END C=8, degree=3, gamma=0.1, kernel=poly;, score=0.942 total time=10.2min\n",
      "[CV 1/3; 3/4] START C=8, degree=4, gamma=0.1, kernel=poly.......................\n",
      "[CV 1/3; 3/4] END C=8, degree=4, gamma=0.1, kernel=poly;, score=0.940 total time=49.1min\n",
      "[CV 2/3; 3/4] START C=8, degree=4, gamma=0.1, kernel=poly.......................\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m svcGrid5 \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoly\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      2\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m.1\u001b[39m],\n\u001b[0;32m      3\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdegree\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m6\u001b[39m)),\n\u001b[0;32m      4\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m8\u001b[39m]}\n\u001b[1;32m----> 5\u001b[0m svcSearch5 \u001b[38;5;241m=\u001b[39m GridSearchCV(svcModel, svcGrid5, cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(Xscaled, Ydata)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    917\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    918\u001b[0m         clone(base_estimator),\n\u001b[0;32m    919\u001b[0m         X,\n\u001b[0;32m    920\u001b[0m         y,\n\u001b[0;32m    921\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    922\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    923\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    924\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    925\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    927\u001b[0m     )\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    929\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    930\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    931\u001b[0m     )\n\u001b[0;32m    932\u001b[0m )\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    893\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 895\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:250\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    249\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m--> 250\u001b[0m fit(X, y, sample_weight, solver_type, kernel, random_seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:329\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    315\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    319\u001b[0m (\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[1;32m--> 329\u001b[0m ) \u001b[38;5;241m=\u001b[39m libsvm\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    330\u001b[0m     X,\n\u001b[0;32m    331\u001b[0m     y,\n\u001b[0;32m    332\u001b[0m     svm_type\u001b[38;5;241m=\u001b[39msolver_type,\n\u001b[0;32m    333\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    334\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_weight_\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m0\u001b[39m)),\n\u001b[0;32m    335\u001b[0m     kernel\u001b[38;5;241m=\u001b[39mkernel,\n\u001b[0;32m    336\u001b[0m     C\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC,\n\u001b[0;32m    337\u001b[0m     nu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnu,\n\u001b[0;32m    338\u001b[0m     probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobability,\n\u001b[0;32m    339\u001b[0m     degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegree,\n\u001b[0;32m    340\u001b[0m     shrinking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshrinking,\n\u001b[0;32m    341\u001b[0m     tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n\u001b[0;32m    342\u001b[0m     cache_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_size,\n\u001b[0;32m    343\u001b[0m     coef0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef0,\n\u001b[0;32m    344\u001b[0m     gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gamma,\n\u001b[0;32m    345\u001b[0m     epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon,\n\u001b[0;32m    346\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[0;32m    347\u001b[0m     random_seed\u001b[38;5;241m=\u001b[39mrandom_seed,\n\u001b[0;32m    348\u001b[0m )\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "svcGrid5 = {'kernel': ['poly'],\n",
    "         'gamma': [.1],\n",
    "         'degree': list(range(2,6)),\n",
    "         'C': [8]}\n",
    "svcSearch5 = GridSearchCV(svcModel, svcGrid5, cv = 3, verbose=10).fit(Xscaled, Ydata)\n",
    "# not using a degree 4 or higher with a small gamma because of run time to fit (took 50 minutes per model per validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6940f6a-286d-4c3c-a959-1e3c5fa08a94",
   "metadata": {},
   "source": [
    "next let us view the confusion matrix for the 2 estimators that we regarded as fast enough and accurate enough (XGBClassifier and KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "df3f8b29-39f1-4a61-a6a1-26887b90e60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x197f44bff50>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "# our best model came from the xgboost algorithm so we will use that model for our scores\n",
    "# we could ensemble our best performing algorithms together to average their prediction and this may provide a more accurate prediction.\n",
    "xgbEstimator = xgbSearch.best_estimator_\n",
    "ConfusionMatrixDisplay.from_estimator(xgbEstimator, Xscaled_val, y_val, values_format=\"d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bda775d2-64f9-4774-aa5e-942e53fda1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x197f43f22d0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knnEstimator = neighborSearchScaled.best_estimator_\n",
    "ConfusionMatrixDisplay.from_estimator(knnEstimator, Xscaled_val, y_val, values_format=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b76dec-b9f7-4068-9361-7849819006f5",
   "metadata": {},
   "source": [
    "We can see from the confusion matrices that there are a lot more 0's than there are 1's and it is more common for both of our models to inaccurately predict a 1 as a 0 rather than a 0 as a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8deec8c4-a850-4200-9dde-939e3686ccda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x197f43f2510>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RocCurveDisplay.from_estimator(xgbEstimator, Xscaled_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ac5cc478-e831-4497-80a5-649e46851d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x197f2053cb0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RocCurveDisplay.from_estimator(knnEstimator, Xscaled_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa41f2a-9aab-4951-a6b7-9d4ad63630ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
